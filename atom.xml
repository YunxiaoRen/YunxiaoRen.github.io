<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>生信拾光</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-09-11T23:07:18.712Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>六六</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>两个文件的异同</title>
    <link href="http://yoursite.com/2020/06/compare_files.html"/>
    <id>http://yoursite.com/2020/06/compare_files.html</id>
    <published>2020-06-28T18:15:28.000Z</published>
    <updated>2020-09-11T23:07:18.712Z</updated>
    
    <content type="html"><![CDATA[<h3 id="comm-diff-和-grep"><a href="#comm-diff-和-grep" class="headerlink" title="comm, diff 和 grep"></a>comm, diff 和 grep</h3><p>基于comm, diff和grep的用法总结</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">comm A B</span><br><span class="line">diff A B</span><br><span class="line">grep -f A B</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="comm"><a href="#comm" class="headerlink" title="comm"></a>comm</h3><p><strong>comm</strong>是对两个已经<strong>有序</strong>的文件进行比较，可以比较输出：仅在A中出现的、仅在B中出现的、在两个文件中都存在的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">comm -1 A B 不显示在A文件中独有内容(显示B文件独有内容+两个文件共有)</span><br><span class="line">comm -2 A B 不显示在B文件中独有内容</span><br><span class="line">comm -3 A B 不显示同时在两个文件中都存在的内容</span><br><span class="line">comm -12 A B 显示A与B公共的部分</span><br><span class="line">comm -23 A B 显示A独有的</span><br><span class="line">comm -13 A B 显示B独有的</span><br></pre></td></tr></table></figure><p><img src="/2020/06/compare_files.htm/fig1.png" alt="image.png" style="zoom:50%;"></p><h3 id="diff"><a href="#diff" class="headerlink" title="diff"></a><strong>diff</strong></h3><p>diff是比较两个文件之间的不同，给出使两个一致的建议，diff有前后顺序，前面的为旧文件，后面的为新文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">diff A B  直接显示两个文件不同，并给出修改一致的建议(主要是对旧文件的建议)</span><br><span class="line">diff -c A B  通过显示两个文件上下文，给出两个文件增减或删除信息，同时</span><br><span class="line">diff A B</span><br><span class="line">3,4c3,6</span><br><span class="line">&lt; c</span><br><span class="line">&lt; d</span><br><span class="line">---</span><br><span class="line">&gt; e</span><br><span class="line">&gt; f</span><br><span class="line">&gt; g</span><br><span class="line">&gt; h</span><br></pre></td></tr></table></figure><h3 id="grep"><a href="#grep" class="headerlink" title="grep"></a>grep</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">grep -v -f a b  从b中剔除a中有的,即b中特有的</span><br><span class="line">grep -v -f b a  从a中剔除b中有的,即a中特有的</span><br><span class="line">grep -v -f A B</span><br><span class="line">e</span><br><span class="line">f</span><br><span class="line">g</span><br><span class="line">h</span><br><span class="line">grep -v -f  B A</span><br><span class="line">c</span><br><span class="line">d</span><br></pre></td></tr></table></figure><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://www.jianshu.com/p/5ab86345b6bf" target="_blank" rel="noopener">https://www.jianshu.com/p/5ab86345b6bf</a></p><p><a href="https://blog.csdn.net/hit_hlj_sgy/article/details/20625527" target="_blank" rel="noopener">https://blog.csdn.net/hit_hlj_sgy/article/details/20625527</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;comm-diff-和-grep&quot;&gt;&lt;a href=&quot;#comm-diff-和-grep&quot; class=&quot;headerlink&quot; title=&quot;comm, diff 和 grep&quot;&gt;&lt;/a&gt;comm, diff 和 grep&lt;/h3&gt;&lt;p&gt;基于comm, diff和grep的用法总结&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;comm A B&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;diff A B&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;grep -f A B&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="shell" scheme="http://yoursite.com/tags/shell/"/>
    
      <category term="text processing" scheme="http://yoursite.com/tags/text-processing/"/>
    
  </entry>
  
  <entry>
    <title>Linux shell 字符穿操作</title>
    <link href="http://yoursite.com/2020/06/character_shell.html"/>
    <id>http://yoursite.com/2020/06/character_shell.html</id>
    <published>2020-06-28T18:15:10.000Z</published>
    <updated>2020-09-11T17:31:45.908Z</updated>
    
    <content type="html"><![CDATA[<h3 id="截取"><a href="#截取" class="headerlink" title="截取"></a>截取</h3><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">word=abcd-//master-01://httpab</span><br></pre></td></tr></table></figure><h4 id="从左向右"><a href="#从左向右" class="headerlink" title="从左向右:"></a>从左向右:</h4><p><strong>截取第一个//后的字符串</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word#*//&#125;</span><br><span class="line"># master-01://httpab</span><br></pre></td></tr></table></figure><p><strong>截取最后一个//后的字符串</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word##*//&#125; </span><br><span class="line">httpab</span><br></pre></td></tr></table></figure><a id="more"></a><h4 id="从右向左"><a href="#从右向左" class="headerlink" title="从右向左: %"></a>从右向左: %</h4><p><strong>截取第一个//后的字符串</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word%//*&#125; </span><br><span class="line">abcd-//master-01:</span><br></pre></td></tr></table></figure><p><strong>截取第二个//后的字符串</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word%%//*&#125; </span><br><span class="line">abcd-</span><br></pre></td></tr></table></figure><h4 id="截取特定序列位置的字符"><a href="#截取特定序列位置的字符" class="headerlink" title="截取特定序列位置的字符"></a>截取特定序列位置的字符</h4><p><strong>前3个字符</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word:0:3&#125;</span><br></pre></td></tr></table></figure><p><strong>第2到5的字符</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word:1:4&#125;</span><br><span class="line">bcd-</span><br></pre></td></tr></table></figure><p><strong>从第二个字符到末尾</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word:1&#125;</span><br><span class="line">bcd-//master-01://httpab</span><br></pre></td></tr></table></figure><h3 id="替换-before-after"><a href="#替换-before-after" class="headerlink" title="替换:/before/after"></a>替换:/before/after</h3><h4 id="将第一个ab替换为AB"><a href="#将第一个ab替换为AB" class="headerlink" title="将第一个ab替换为AB"></a>将第一个ab替换为AB</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word/#ab/AB&#125; </span><br><span class="line">或 echo $&#123;word/ab/AB&#125; </span><br><span class="line">ABcd-//master-01://httpab</span><br></pre></td></tr></table></figure><h4 id="从左到右，匹配第一个，替换-为cd"><a href="#从左到右，匹配第一个，替换-为cd" class="headerlink" title="从左到右，匹配第一个，替换//为cd"></a>从左到右，匹配第一个，替换//为cd</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word/\/\//cd&#125;</span><br><span class="line">abcd-cdmaster-01://httpab</span><br></pre></td></tr></table></figure><h4 id="将所有匹配的-替换为cd"><a href="#将所有匹配的-替换为cd" class="headerlink" title="将所有匹配的//替换为cd"></a>将所有匹配的//替换为cd</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word//\/\//cd&#125;</span><br><span class="line">abcd-cdmaster-01:cdhttpab</span><br></pre></td></tr></table></figure><h4 id="后缀匹配"><a href="#后缀匹配" class="headerlink" title="后缀匹配"></a>后缀匹配</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">word=abcd-//master-01://httpab</span><br><span class="line">echo $&#123;word/%http*/xy&#125; </span><br><span class="line"># 输出:abcd-//master-01://xy</span><br><span class="line">echo $&#123;word/%ab/xy&#125;</span><br><span class="line"># 输出:abcd-//master-01://httpxy</span><br><span class="line">echo $&#123;word/%ab*/xy&#125;</span><br><span class="line"># 出现*，会从起始匹配</span><br><span class="line"># 输出:xy</span><br></pre></td></tr></table></figure><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 删除前3个字符</span><br><span class="line">echo $&#123;word#*$&#123;word:0:3&#125;&#125; </span><br><span class="line"># 删除后3个字符</span><br><span class="line">echo $&#123;word%*$&#123;word:(-3)&#125;&#125;</span><br><span class="line"># 删除第一个ab</span><br><span class="line">echo $&#123;word/ab/&#125; </span><br><span class="line">删除所有ab</span><br><span class="line">echo $&#123;word//ab/&#125;</span><br></pre></td></tr></table></figure><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://blog.csdn.net/qq_23091073/article/details/83066518" target="_blank" rel="noopener">https://blog.csdn.net/qq_23091073/article/details/83066518</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;截取&quot;&gt;&lt;a href=&quot;#截取&quot; class=&quot;headerlink&quot; title=&quot;截取&quot;&gt;&lt;/a&gt;截取&lt;/h3&gt;&lt;h4 id=&quot;示例&quot;&gt;&lt;a href=&quot;#示例&quot; class=&quot;headerlink&quot; title=&quot;示例&quot;&gt;&lt;/a&gt;示例&lt;/h4&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;word=abcd-//master-01://httpab&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h4 id=&quot;从左向右&quot;&gt;&lt;a href=&quot;#从左向右&quot; class=&quot;headerlink&quot; title=&quot;从左向右:&quot;&gt;&lt;/a&gt;从左向右:&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;截取第一个//后的字符串&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;echo $&amp;#123;word#*//&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# master-01://httpab&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;截取最后一个//后的字符串&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;echo $&amp;#123;word##*//&amp;#125; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;httpab&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="shell" scheme="http://yoursite.com/tags/shell/"/>
    
      <category term="text processing" scheme="http://yoursite.com/tags/text-processing/"/>
    
  </entry>
  
  <entry>
    <title>不同服务器间以及服务器与本地的文件传输</title>
    <link href="http://yoursite.com/2020/06/file_transmission.html"/>
    <id>http://yoursite.com/2020/06/file_transmission.html</id>
    <published>2020-06-28T18:14:51.000Z</published>
    <updated>2020-09-11T19:15:28.920Z</updated>
    
    <content type="html"><![CDATA[<p>前提是在同一网络下，可以使用 <code>scp</code> 命令。</p><p>如：</p><h3 id="两服务器间的传输"><a href="#两服务器间的传输" class="headerlink" title="两服务器间的传输"></a>两服务器间的传输</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp user1@server_addess_ip:/file_adderess user2@server2_address_ip</span><br><span class="line">## eg:</span><br><span class="line">scp root@192.168.8.138:/home/ligh/index.php root@192.168.8.139:/root</span><br></pre></td></tr></table></figure><h3 id="服务器和本地间的传输"><a href="#服务器和本地间的传输" class="headerlink" title="服务器和本地间的传输"></a>服务器和本地间的传输</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">user1@server_addess_ip:/file_adderess /d</span><br><span class="line"></span><br><span class="line">## eg:</span><br><span class="line">scp root@192.168.8.138:/home/ligh/index.php /d/data</span><br></pre></td></tr></table></figure><h3 id="指定端口非22的传输"><a href="#指定端口非22的传输" class="headerlink" title="指定端口非22的传输"></a>指定端口非22的传输</h3><p>使用  <code>P</code> 参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -P 223  root@192.168.8.13e:/home/strains.tar.gz ./</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前提是在同一网络下，可以使用 &lt;code&gt;scp&lt;/code&gt; 命令。&lt;/p&gt;
&lt;p&gt;如：&lt;/p&gt;
&lt;h3 id=&quot;两服务器间的传输&quot;&gt;&lt;a href=&quot;#两服务器间的传输&quot; class=&quot;headerlink&quot; title=&quot;两服务器间的传输&quot;&gt;&lt;/a&gt;两服务器间的传输&lt;
      
    
    </summary>
    
    
      <category term="shell" scheme="http://yoursite.com/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>Pandas库</title>
    <link href="http://yoursite.com/2020/06/Pandas_libarary.html"/>
    <id>http://yoursite.com/2020/06/Pandas_libarary.html</id>
    <published>2020-06-28T18:14:01.000Z</published>
    <updated>2020-09-12T08:14:20.777Z</updated>
    
    <content type="html"><![CDATA[<p>Pandas库是基于Numpy库来创建的，Numpy主要用于矩阵操作，而Pandas主要用于数据处理。</p><p>Pandas主要有两种重要的数据结构：Series和DataFrame.</p><ul><li><p>Series: 类似一个一维数组，一个Series对应DataFrame的一列</p></li><li><p>DataFrame:类似一个二维数组，一个DataFrame由几个Series列构成。</p><p><img src="/2020/06/Pandas_libarary.htm/fig1.png" style="zoom:50%;"></p></li></ul><p><img src="/2020/06/Pandas_libarary.htm/fig1.png" alt="image.png"></p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://zhuanlan.zhihu.com/p/40373125" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/40373125</a></li><li><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html" target="_blank" rel="noopener">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Pandas库是基于Numpy库来创建的，Numpy主要用于矩阵操作，而Pandas主要用于数据处理。&lt;/p&gt;
&lt;p&gt;Pandas主要有两种重要的数据结构：Series和DataFrame.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Series: 类似一个一维数组，一个Series
      
    
    </summary>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>NumPy介绍</title>
    <link href="http://yoursite.com/2020/06/Numpy_introduction.html"/>
    <id>http://yoursite.com/2020/06/Numpy_introduction.html</id>
    <published>2020-06-28T18:13:50.000Z</published>
    <updated>2020-09-11T20:59:19.372Z</updated>
    
    <content type="html"><![CDATA[<p>Pandas库是基于Numpy库来创建的，Numpy主要用于矩阵操作，而Pandas主要用于数据处理。</p><p>Pandas主要有两种重要的数据结构：Series和DataFrame.</p><ul><li>Series: 类似一个一维数组，一个Series对应DataFrame的一列</li><li>DataFrame:类似一个二维数组，一个DataFrame由几个Series列构成。</li></ul><a id="more"></a><p><img src="/2020/06/Numpy_introduction.htm/1591819950732-0cf02f6a-c25b-4ca1-8876-17dc2e63dd9e-20200628202724030.png" alt="image.png"></p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://zhuanlan.zhihu.com/p/40373125" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/40373125</a></li><li><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html" target="_blank" rel="noopener">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Pandas库是基于Numpy库来创建的，Numpy主要用于矩阵操作，而Pandas主要用于数据处理。&lt;/p&gt;
&lt;p&gt;Pandas主要有两种重要的数据结构：Series和DataFrame.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Series: 类似一个一维数组，一个Series对应DataFrame的一列&lt;/li&gt;
&lt;li&gt;DataFrame:类似一个二维数组，一个DataFrame由几个Series列构成。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>R语言中读取含有空白内容的数据</title>
    <link href="http://yoursite.com/2020/06/R_read_blank_content.html"/>
    <id>http://yoursite.com/2020/06/R_read_blank_content.html</id>
    <published>2020-06-28T18:13:22.000Z</published>
    <updated>2020-09-11T17:53:34.774Z</updated>
    
    <content type="html"><![CDATA[<p><strong>数据内容</strong></p><p><img src="/2020/06/R_read_blank_content.htm/1592293564053-baa557ba-9fdb-46ea-b659-dd2b941c6a24.png" alt="image.png"></p><p><strong>导入数据：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test &lt;-read.table(&quot;filename.txt&quot;,header=TRUE）</span><br></pre></td></tr></table></figure><p>  会出现错误：Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, :3行没有2元素</p><p><strong>修改：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test &lt;-read.table(&quot;filename.txt&quot;,header=TRUE,fill=TRUE）</span><br></pre></td></tr></table></figure><p><strong>空值设为NA</strong></p><p><strong><code>na.strings = &quot;&quot;</code></strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test &lt;-read.table(&quot;filename.txt&quot;,header=TRUE, fill=TRUE, na.strings = &quot;&quot;)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;数据内容&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/06/R_read_blank_content.htm/1592293564053-baa557ba-9fdb-46ea-b659-dd2b941c6a24.png&quot; alt=&quot;ima
      
    
    </summary>
    
    
      <category term="R" scheme="http://yoursite.com/tags/R/"/>
    
  </entry>
  
  <entry>
    <title>apply家族函数的用法</title>
    <link href="http://yoursite.com/2020/06/apply-family-function.html"/>
    <id>http://yoursite.com/2020/06/apply-family-function.html</id>
    <published>2020-06-28T18:12:47.000Z</published>
    <updated>2020-09-12T08:29:06.910Z</updated>
    
    <content type="html"><![CDATA[<h3 id="apply家族函数"><a href="#apply家族函数" class="headerlink" title="apply家族函数"></a>apply家族函数</h3><p>apply函数族是R语言中数据处理的一组核心函数，通过使用apply函数，我们可以实现对数据的循环、分组、过滤、类型控制等操作。</p><p><img src="/2020/06/apply-family-function.htm/fig1.png" alt></p><p><img src="/2020/06/apply-family-function.htm/fig1.png" style="zoom:50%;"></p><a id="more"></a><h3 id="apply-函数的用法"><a href="#apply-函数的用法" class="headerlink" title="apply 函数的用法"></a>apply 函数的用法</h3><p>常用的apply族函数有apply和sapply。apply函数是最常用的代替for循环的函数。apply函数可以对矩阵、数据框、数组(二维、多维)，按行或列进行循环计算，对子元素进行迭代，并把子元素以参数传递的形式给自定义的FUN函数中，并以返回计算结果。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apply(X, MARGIN, FUN, ...)</span><br></pre></td></tr></table></figure><p>参数列表：</p><ul><li>X:数组、矩阵、数据框</li><li>MARGIN: 按行计算或按按列计算，1表示按行，2表示按列</li><li>FUN: 自定义的调用函数</li><li>…: 更多参数，可选</li></ul><p>如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; x&lt;-matrix(1:12,ncol=3)</span><br><span class="line">&gt; apply(x,1,sum)</span><br><span class="line">[1] 15 18 21 24</span><br></pre></td></tr></table></figure><h3 id><a href="#" class="headerlink" title=" "></a> </h3><h3 id="lapply-函数的用法"><a href="#lapply-函数的用法" class="headerlink" title="lapply 函数的用法"></a>lapply 函数的用法</h3><p>lapply函数是一个最基础循环操作函数之一，用来对list、data.frame数据集进行循环，并返回和X长度同样的list结构作为结果集，通过lapply的开头的第一个字母’l’就可以判断返回结果集的类型。</p><p>函数定义：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lapply(X, FUN, ...)</span><br></pre></td></tr></table></figure><p>参数列表：</p><ul><li>X:list、data.frame数据</li><li>FUN: 自定义的调用函数</li><li>…: 更多参数，可选</li></ul><h3 id="sapply函数的用法"><a href="#sapply函数的用法" class="headerlink" title="sapply函数的用法"></a>sapply函数的用法</h3><p>sapply函数是一个简化版的lapply，sapply增加了2个参数simplify和USE.NAMES，主要就是让输出看起来更友好，返回值为向量，而不是list对象。</p><p>函数定义：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sapply(X, FUN, ..., simplify=TRUE, USE.NAMES = TRUE)</span><br></pre></td></tr></table></figure><p>参数列表：</p><ul><li>X:数组、矩阵、数据框</li><li>FUN: 自定义的调用函数</li><li>…: 更多参数，可选</li><li>simplify: 是否数组化，当值array时，输出结果按数组进行分组</li><li>USE.NAMES: 如果X为字符串，TRUE设置字符串为数据名，FALSE不设置</li></ul><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li>掌握R语言中的apply函数族 <a href="http://blog.fens.me/r-apply/" target="_blank" rel="noopener">http://blog.fens.me/r-apply/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;apply家族函数&quot;&gt;&lt;a href=&quot;#apply家族函数&quot; class=&quot;headerlink&quot; title=&quot;apply家族函数&quot;&gt;&lt;/a&gt;apply家族函数&lt;/h3&gt;&lt;p&gt;apply函数族是R语言中数据处理的一组核心函数，通过使用apply函数，我们可以实现对数据的循环、分组、过滤、类型控制等操作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/06/apply-family-function.htm/fig1.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/06/apply-family-function.htm/fig1.png&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="R" scheme="http://yoursite.com/tags/R/"/>
    
  </entry>
  
  <entry>
    <title>在R语言中替换空值</title>
    <link href="http://yoursite.com/2020/06/R_NA.html"/>
    <id>http://yoursite.com/2020/06/R_NA.html</id>
    <published>2020-06-28T18:12:21.000Z</published>
    <updated>2020-09-11T19:39:56.523Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>如下图所示，想替换无任何字符，又不是NA的值，替换为0</p><p><img src="/2020/06/R_NA.htm/1590757573945-fb0f1f16-10ad-4e49-8aee-9449b8f23b80.png" alt="image.png"></p><a id="more"></a><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><ul><li>最初的思路是想匹配两个双引号，但是发现这里的双引号是表示观测值是字符串的数据类型，而不是该字符串本身的字符，尝试了很久也没有匹配成功。</li><li>然后想着将nothing的字符串转为NA，然后将NA转换为0，又因为该数据集是matrix类型，方便整列操作，首先将数据转换为数据框</li></ul><p><img src="/2020/06/R_NA.htm/1590758057421-48ea7d94-d247-4ad0-a826-a26bd633c7f4.png" alt="image.png"></p><p>然后将nothing替换为NA</p><p><img src="/2020/06/R_NA.htm/1590758121879-42bed638-730a-4315-b8cc-a10224feb883.png" alt="image.png"></p><p>最后替换为0，但是发现替换不了，虽然这些值确实是NA</p><p><img src="/2020/06/R_NA.htm/1590760122629-c60cffa8-a98d-4e6d-ad9d-5953ef7265bd.png" alt="image.png"></p><p>检查数据格式，这些<na>是factor，所以这里无法替换</na></p><p><img src="/2020/06/R_NA.htm/1590760226503-08c32bea-6295-4149-bcf1-000d74c2393c.png" alt="image.png"></p><p>最终明白问题出现在将matrix转换为data.frame，应该在此时加上 <code>stringsAsFactors = F</code> 的参数</p><p><img src="/2020/06/R_NA.htm/1590760463196-ca4183f7-b955-4a97-b616-fb9ce2635451.png" alt="image.png"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>在读入数据框或者转换为数据框时，记得加上<code>stringsAsFactors = F</code> 的参数</li><li>匹配特定观测值，然后重新赋值，df[df==”value”] &lt;- newvalue</li><li>R处理数据时要注意数据格式</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;如下图所示，想替换无任何字符，又不是NA的值，替换为0&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/06/R_NA.htm/1590757573945-fb0f1f16-10ad-4e49-8aee-9449b8f23b80.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="R" scheme="http://yoursite.com/tags/R/"/>
    
  </entry>
  
  <entry>
    <title>正则表达式初体验</title>
    <link href="http://yoursite.com/2020/06/Regular%20Expression.html"/>
    <id>http://yoursite.com/2020/06/Regular Expression.html</id>
    <published>2020-06-28T18:11:52.000Z</published>
    <updated>2020-09-11T20:00:17.318Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>正则表达式(Regular Expression)在字符串模式匹配，在字符串搜索和替换中展现强大的功能。</p><p>常用的正则表达式语法我将其总结为7类：</p><p>先看一个概括的整理</p><p><img src="/2020/06/Regular Expression.htm/1590761619931-4e3ce7f4-d158-4883-bb04-ac35bc16f566.png" alt="image.png"></p><a id="more"></a><ul><li><p>字符类**</p></li><li><ul><li><code>\w</code> : 匹配数字和字符</li><li><code>.</code> : 匹配除换行符 \n 之外的任何单字符</li><li><code>[a-z]</code>  和 <code>[A-Z]</code> :匹配从a到z或者A到Z的任意字符</li><li><code>[0-9]</code> : 匹配0到9的任意数字</li></ul></li><li><p><strong>数值类</strong></p></li><li><ul><li><code>\d</code> ：匹配数字</li></ul></li><li><p>分隔符类</p></li><li><ul><li><code>\s</code> : 匹配white space(包括空格、tab等)</li></ul></li><li><p><strong>定位类：在字符类和数值类前面</strong></p></li><li><ul><li><code>^</code> : 字符开头</li><li><code>$</code> ：字符结尾</li><li><code>\b</code> : 单词结界符</li></ul></li><li><p><strong>定量类，包含数值型和特殊符类，放在字符类和数值类后面</strong></p></li><li><ul><li>数值型：{}， 大括号里加数字</li><li><code>*</code> : 0次或多次</li><li><code>+</code> : 1次或多次</li><li><code>?</code> :  0或1次</li></ul></li><li><p><strong>逻辑关系类</strong></p></li><li><ul><li><code>[]</code> ：表示逻辑关系或，比如[abc]表示a或者b或c</li><li><code>(|)</code> :  () 和 | 结合也表示逻辑关系或</li></ul></li><li><p><strong>分组类</strong></p></li><li><ul><li><code>**()**</code> : 用于分组</li></ul></li></ul><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>R语言可以结合gsub使用正则匹配语法</p><p>gsub语法： <code>gsub(&quot;old value 或 pattern&quot;,&quot;new value&quot;,data)</code> </p><p><img src="/2020/06/Regular Expression.htm/1590763067379-cde65a24-d421-46ef-ab59-c6b5cac4b771.png" alt="image.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;p&gt;正则表达式(Regular Expression)在字符串模式匹配，在字符串搜索和替换中展现强大的功能。&lt;/p&gt;
&lt;p&gt;常用的正则表达式语法我将其总结为7类：&lt;/p&gt;
&lt;p&gt;先看一个概括的整理&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/06/Regular Expression.htm/1590761619931-4e3ce7f4-d158-4883-bb04-ac35bc16f566.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="shell" scheme="http://yoursite.com/tags/shell/"/>
    
      <category term="text processing" scheme="http://yoursite.com/tags/text-processing/"/>
    
  </entry>
  
  <entry>
    <title>机器学习中如何处理分类变量的不均衡</title>
    <link href="http://yoursite.com/2020/06/sample_unbalance_ML.html"/>
    <id>http://yoursite.com/2020/06/sample_unbalance_ML.html</id>
    <published>2020-06-28T18:09:41.000Z</published>
    <updated>2020-09-11T19:57:26.415Z</updated>
    
    <content type="html"><![CDATA[<p>Imbalanced classes put “accuracy” out of business. This is a surprisingly common problem in machine learning (specifically in classification), occurring in datasets with a disproportionate ratio of observations in each class</p><ul><li><p>Up-sample the minority class</p></li><li><ul><li>resample module with <code>replace = True</code></li></ul></li><li><p>Down-sample the majority class</p></li><li><ul><li>resample module with <code>replace = False</code></li></ul></li><li><p>Change your performance metric</p></li><li><ul><li><strong>Area Under ROC Curve</strong> (AUROC)</li><li><code>from sklearn.metrics import roc_auc_score</code></li></ul></li><li><p>Penalize algorithms (cost-sensitive training)</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SVC(kernel=&apos;linear&apos;, </span><br><span class="line">            class_weight=&apos;balanced&apos;, # penalize</span><br><span class="line">            probability=True)</span><br></pre></td></tr></table></figure><ul><li><p>Use tree-based algorithms</p></li><li><ul><li><code>from sklearn.ensemble import RandomForestClassifier</code></li></ul></li></ul><p><img src="/2020/06/sample_unbalance_ML.htm/fig1.jpg" alt></p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn import svm</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.metrics import accuracy_score</span><br><span class="line">from sklearn.utils import resample</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">input = pd.read_csv(&apos;trime_skinput.csv&apos;) # row.names equls numbers</span><br><span class="line">input.trimethoprim_sulfamethoxazole.value_counts()</span><br><span class="line">input_major = input[input.trimethoprim_sulfamethoxazole == &quot;R&quot;]</span><br><span class="line">input_minor = input[input.trimethoprim_sulfamethoxazole == &quot;S&quot;]</span><br><span class="line"></span><br><span class="line">input_minor_upsampled = resample(input_minor,</span><br><span class="line">                                 replace = True,</span><br><span class="line">                                 n_samples = 67,</span><br><span class="line">                                random_state=123)</span><br><span class="line"></span><br><span class="line">input_upsampled = pd.concat([input_major,input_minor_upsampled])</span><br><span class="line">input_upsampled.trimethoprim_sulfamethoxazole.value_counts()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X = input_upsampled.iloc[:,0:19277]</span><br><span class="line">y = input_upsampled.iloc[:,19277:19278]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)</span><br><span class="line"></span><br><span class="line">### train model</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">svclassifier = SVC(kernel=&apos;linear&apos;)</span><br><span class="line"></span><br><span class="line">svclassifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">## predict </span><br><span class="line">y_pred = svclassifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"># evaluation </span><br><span class="line">from sklearn.metrics import classification_report, confusion_matrix</span><br><span class="line">print(confusion_matrix(y_test,y_pred))</span><br><span class="line">print(classification_report(y_test,y_pred))</span><br><span class="line"># upsampling</span><br><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           R       1.00      0.88      0.93        16</span><br><span class="line">           S       0.85      1.00      0.92        11</span><br><span class="line"></span><br><span class="line">    accuracy                           0.93        27</span><br><span class="line">   macro avg       0.92      0.94      0.93        27</span><br><span class="line">weighted avg       0.94      0.93      0.93        27</span><br><span class="line"></span><br><span class="line">## don&apos;t do anything</span><br><span class="line">                precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           R       0.88      1.00      0.93        14</span><br><span class="line">           S       0.00      0.00      0.00         2</span><br><span class="line"></span><br><span class="line">    accuracy                           0.88        16</span><br><span class="line">   macro avg       0.44      0.50      0.47        16</span><br><span class="line">weighted avg       0.77      0.88      0.82        16</span><br></pre></td></tr></table></figure><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li>How to Handle Imbalanced Classes in Machine Learning：<a href="https://elitedatascience.com/imbalanced-classes" target="_blank" rel="noopener">https://elitedatascience.com/imbalanced-classes</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Imbalanced classes put “accuracy” out of business. This is a surprisingly common problem in machine learning (specifically in classification), occurring in datasets with a disproportionate ratio of observations in each class&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Up-sample the minority class&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;ul&gt;
&lt;li&gt;resample module with &lt;code&gt;replace = True&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Down-sample the majority class&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;ul&gt;
&lt;li&gt;resample module with &lt;code&gt;replace = False&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Change your performance metric&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Area Under ROC Curve&lt;/strong&gt; (AUROC)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;from sklearn.metrics import roc_auc_score&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Penalize algorithms (cost-sensitive training)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;SVC(kernel=&amp;apos;linear&amp;apos;, &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            class_weight=&amp;apos;balanced&amp;apos;, # penalize&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            probability=True)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Use tree-based algorithms&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;from sklearn.ensemble import RandomForestClassifier&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2020/06/sample_unbalance_ML.htm/fig1.jpg&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>使用Python与Scikit-learn实现随机森林分析</title>
    <link href="http://yoursite.com/2020/06/random_forest_python.html"/>
    <id>http://yoursite.com/2020/06/random_forest_python.html</id>
    <published>2020-06-28T18:09:05.000Z</published>
    <updated>2020-09-11T19:20:54.768Z</updated>
    
    <content type="html"><![CDATA[<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li>Understanding Random Forests Classifiers in Python<a href="https://www.datacamp.com/community/tutorials/random-forests-classifier-python" target="_blank" rel="noopener">: //www.datacamp.com/community/tutorials/random-forests-classifier-python</a></li><li>Random Forest Algorithm with Python and Scikit-Learn<a href="https://stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/" target="_blank" rel="noopener">: //stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/</a></li><li>Random Forest in Python<a href="https://towardsdatascience.com/random-forest-in-python-24d0893d51c0" target="_blank" rel="noopener">: //towardsdatascience.com/random-forest-in-python-24d0893d51c0</a></li></ul><h3 id="随机森林（RandomForest）算法"><a href="#随机森林（RandomForest）算法" class="headerlink" title="随机森林（RandomForest）算法"></a>随机森林（RandomForest）算法</h3><p>随机森林属于集成学习（Ensemble Learning）的一类算法，结合了多种相同类型的算法，即多个决策树，从而形成了一个随机森林树。</p><blockquote><p>随即森林是用随机的方式建立一个森林，森林里面有很多的决策树组成，随机森林的每一棵决策树之间是没有关联的。上世纪八十年代Breiman等人发明分类树的算法（Breiman et al. 1984），通过反复二分数据进行分类或回归，计算量大大降低。2001年Breiman把分类树组合成随机森林（Breiman 2001a），即在变量（列）的使用和数据（行）的使用上进行随机化，生成很多分类树，再汇总分类树的结果。随机森林在运算量没有显著提高的前提下提高了预测精度。随机森林对多元公线性不敏感，结果对缺失数据和非平衡的数据比较稳健，可以很好地预测多达几千个解释变量的作用（Breiman 2001b），被誉为当前最好的算法之一（Iverson et al. 2008）。</p><p>参考：<a href="https://zhuanlan.zhihu.com/p/22097796" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/22097796</a></p></blockquote><a id="more"></a><h3 id="随机森林工作原理"><a href="#随机森林工作原理" class="headerlink" title="随机森林工作原理"></a>随机森林工作原理</h3><p><img src="/2020/06/random_forest_python.htm/1591801985780-f9e9e5e3-2124-4f44-97a6-11217dc66dee.png" alt="image.png"></p><h3 id="随机森林优缺点"><a href="#随机森林优缺点" class="headerlink" title="随机森林优缺点"></a>随机森林优缺点</h3><p><strong>优点</strong></p><ul><li>准确度高</li><li>没有过拟合问题</li><li>可用于分类和回归问题</li><li>可以处理缺失值，一是用中位数代替连续变量，二是计算缺失值的近似加权平均值；也可用于没有归一化的问题</li></ul><p><strong>缺点</strong></p><ul><li>速度慢</li><li>与决策树相比较难解释</li></ul><h3 id="随即森林与决策树"><a href="#随即森林与决策树" class="headerlink" title="随即森林与决策树"></a>随即森林与决策树</h3><ul><li>随机森林是一组多决策树。</li><li>深度决策树可能会出现过拟合，但随机森林通过在随机子集上创建树来防止过拟合。</li><li>决策树的计算速度更快。</li><li>随机森林很难解释，而决策树很容易解释，可以转换为规则。</li></ul><h3 id="利用Scikit-learn实现随即森林的分析"><a href="#利用Scikit-learn实现随即森林的分析" class="headerlink" title="利用Scikit-learn实现随即森林的分析"></a>利用Scikit-learn实现随即森林的分析</h3><p>随机森林通过 <code>RandomForestClassifier</code>实现<strong>分类</strong>问题</p><p>随机森林通过 <code>RandomForestRegressor</code> 实现<strong>回归</strong>问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br></pre></td></tr></table></figure><h3 id="随机森林解决回归问题"><a href="#随机森林解决回归问题" class="headerlink" title="随机森林解决回归问题"></a>随机森林解决回归问题</h3><ul><li>问题</li></ul><p>根据汽油税（美分），人均收入（美元），已铺设的高速公路（以英里为单位）和驾驶执照人口与汽油税的比例，来预测美国48个州的汽油消耗量（百万加仑）。</p><p>数据链接：<a href="https://drive.google.com/file/d/1mVmGNx6cbfvRHC_DvF12ZL3wGLSHD9f_/view" target="_blank" rel="noopener">https://drive.google.com/file/d/1mVmGNx6cbfvRHC_DvF12ZL3wGLSHD9f_/view</a></p><ul><li>读入数据</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset = pd.read_csv(&apos;petrol_consumption.csv&apos;)</span><br><span class="line">dataset.head()</span><br></pre></td></tr></table></figure><p><img src="/2020/06/random_forest_python.htm/1592223752291-004d252c-0cc7-4d36-90bd-8653ab0932d2.png" alt="image.png"></p><ul><li>数据前处理</li></ul><p>提取’attributes’ 和 ‘label’; 拆分测试数据和训练数据集</p><p>注意：<code>random_state</code> 设置随机数种子，以保证多次运行的结果相同</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X = dataset.iloc[:, 0:4].values</span><br><span class="line">y = dataset.iloc[:, 4].values</span><br><span class="line"></span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)</span><br></pre></td></tr></table></figure><ul><li>数据归一化（Feature Scaling）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Feature Scaling</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">sc = StandardScaler()</span><br><span class="line">X_train = sc.fit_transform(X_train)</span><br><span class="line">X_test = sc.transform(X_test)</span><br></pre></td></tr></table></figure><ul><li>训练模型</li></ul><p>注意：重要参数 <strong><code>n_estimators</code></strong> , 表示随机森林树的数目</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line"></span><br><span class="line">regressor = RandomForestRegressor(n_estimators=20, random_state=0)</span><br><span class="line">regressor.fit(X_train, y_train)</span><br><span class="line">y_pred = regressor.predict(X_test)</span><br></pre></td></tr></table></figure><ul><li>模型评估</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import metrics</span><br><span class="line"></span><br><span class="line">print(&apos;Mean Absolute Error:&apos;, metrics.mean_absolute_error(y_test, y_pred))</span><br><span class="line">print(&apos;Mean Squared Error:&apos;, metrics.mean_squared_error(y_test, y_pred))</span><br><span class="line">print(&apos;Root Mean Squared Error:&apos;, np.sqrt(metrics.mean_squared_error(y_test, y_pred)))</span><br></pre></td></tr></table></figure><p><img src="/2020/06/random_forest_python.htm/1592224214897-36546d34-1651-44db-8102-eb29912fd01a.png" alt="image.png"></p><p>当参数改为200时，模型评估结果提升了<strong><code>n_estimators=200</code></strong></p><p><img src="/2020/06/random_forest_python.htm/1592224281077-4a7049c2-c4b7-47b6-8d15-e5cf05aa1fe1.png" alt="image.png"></p><h3 id="随机森林解决分类问题"><a href="#随机森林解决分类问题" class="headerlink" title="随机森林解决分类问题"></a>随机森林解决分类问题</h3><ul><li>问题：根据四个属性（即图像小波变换后的图像的方差，偏度，熵和图像的弯曲度）来预测银行纸币是否真实</li></ul><ul><li>数据：<a href="https://drive.google.com/file/d/13nw-uRXPY8XIZQxKRNZ3yYlho-CYm_Qt/view" target="_blank" rel="noopener">https://drive.google.com/file/d/13nw-uRXPY8XIZQxKRNZ3yYlho-CYm_Qt/view</a></li></ul><ul><li>读入数据</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">dataset = pd.read_csv(&quot;D:/Datasets/bill_authentication.csv&quot;)</span><br><span class="line">dataset.head()</span><br></pre></td></tr></table></figure><p><img src="/2020/06/random_forest_python.htm/1592224457537-501c6246-7a4e-4ef8-8efa-0a931e9a45a4.png" alt="image.png"></p><ul><li>数据预处理</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = dataset.iloc[:, 0:4].values</span><br><span class="line">y = dataset.iloc[:, 4].values</span><br></pre></td></tr></table></figure><p>拆分测试数据和训练数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)</span><br></pre></td></tr></table></figure><ul><li>归一化</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Feature Scaling</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">sc = StandardScaler()</span><br><span class="line">X_train = sc.fit_transform(X_train)</span><br><span class="line">X_test = sc.transform(X_test)</span><br></pre></td></tr></table></figure><ul><li>训练模型</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">regressor = RandomForestClassifier(n_estimators=20, random_state=0)</span><br><span class="line">regressor.fit(X_train, y_train)</span><br><span class="line">y_pred = regressor.predict(X_test)</span><br></pre></td></tr></table></figure><ul><li>模型评估</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import classification_report, confusion_matrix, accuracy_score</span><br><span class="line">print(confusion_matrix(y_test,y_pred))</span><br><span class="line">print(classification_report(y_test,y_pred))</span><br><span class="line">print(accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure><p><img src="/2020/06/random_forest_python.htm/1592224658958-fa055da7-c285-437a-8580-f3dac49ad06b.png" alt="image.png"></p><p>这里将n_estimators=20 改为200时，结果并没有明显改变</p><p><img src="/2020/06/random_forest_python.htm/1592224709652-34fa9d3c-e9df-47e6-8001-e99abd86d588.png" alt="image.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;参考资料&quot;&gt;&lt;a href=&quot;#参考资料&quot; class=&quot;headerlink&quot; title=&quot;参考资料&quot;&gt;&lt;/a&gt;参考资料&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Understanding Random Forests Classifiers in Python&lt;a href=&quot;https://www.datacamp.com/community/tutorials/random-forests-classifier-python&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;: //www.datacamp.com/community/tutorials/random-forests-classifier-python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Random Forest Algorithm with Python and Scikit-Learn&lt;a href=&quot;https://stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;: //stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Random Forest in Python&lt;a href=&quot;https://towardsdatascience.com/random-forest-in-python-24d0893d51c0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;: //towardsdatascience.com/random-forest-in-python-24d0893d51c0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;随机森林（RandomForest）算法&quot;&gt;&lt;a href=&quot;#随机森林（RandomForest）算法&quot; class=&quot;headerlink&quot; title=&quot;随机森林（RandomForest）算法&quot;&gt;&lt;/a&gt;随机森林（RandomForest）算法&lt;/h3&gt;&lt;p&gt;随机森林属于集成学习（Ensemble Learning）的一类算法，结合了多种相同类型的算法，即多个决策树，从而形成了一个随机森林树。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;随即森林是用随机的方式建立一个森林，森林里面有很多的决策树组成，随机森林的每一棵决策树之间是没有关联的。上世纪八十年代Breiman等人发明分类树的算法（Breiman et al. 1984），通过反复二分数据进行分类或回归，计算量大大降低。2001年Breiman把分类树组合成随机森林（Breiman 2001a），即在变量（列）的使用和数据（行）的使用上进行随机化，生成很多分类树，再汇总分类树的结果。随机森林在运算量没有显著提高的前提下提高了预测精度。随机森林对多元公线性不敏感，结果对缺失数据和非平衡的数据比较稳健，可以很好地预测多达几千个解释变量的作用（Breiman 2001b），被誉为当前最好的算法之一（Iverson et al. 2008）。&lt;/p&gt;
&lt;p&gt;参考：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/22097796&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://zhuanlan.zhihu.com/p/22097796&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>使用Python与Scikit-learn实现逻辑回归分析</title>
    <link href="http://yoursite.com/2020/06/logistic_regression_python.html"/>
    <id>http://yoursite.com/2020/06/logistic_regression_python.html</id>
    <published>2020-06-28T18:08:24.000Z</published>
    <updated>2020-09-11T19:20:23.289Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a" target="_blank" rel="noopener">https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a</a></p><p><img src="/2020/06/logistic_regression_python.htm/fig-1.png" alt></p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd  </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">input_Cef = pd.read_csv(<span class="string">"input_Cef.csv"</span>)</span><br><span class="line">input_Cef.head()</span><br><span class="line">   </span><br><span class="line">X = input_Cef.iloc[:,<span class="number">1</span>:<span class="number">6027</span>]</span><br><span class="line">y = input_Cef[<span class="string">"Ceftazidim_S.vs.R"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1. Import the model &amp; Splitting Data into Training and Test Sets</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.20</span>,random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make an instance of the Model</span></span><br><span class="line"><span class="comment"># all parameters not specified are set to their defaults</span></span><br><span class="line"><span class="comment"># Changing the solver had a minor effect on accuracy, but at least it was a lot faster</span></span><br><span class="line">logreg = LogisticRegression(solver = <span class="string">'lbfgs'</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 3. Training the model </span></span><br><span class="line">logreg.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Step 4. Predict labels for new data </span></span><br><span class="line">y_pred = logreg.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step5: Measuring Model Performance</span></span><br><span class="line"><span class="comment"># accuracy , precision, recall, F1 Score, ROC Curve</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## accuracy</span></span><br><span class="line">score = logreg.score(X_test, y_test)</span><br><span class="line">print(score)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## precision, recall, F1 Score</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">print(classification_report(y_test, y_pred))</span><br><span class="line"></span><br><span class="line"><span class="comment">## ROC Curve</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">logit_roc_auc2 = roc_auc_score(y_test, y_pred)</span><br><span class="line">probas = logreg.predict_proba(X_test)[:,<span class="number">1</span>]</span><br><span class="line">fpr2, tpr2, thresholds2 = roc_curve(y_test, probas)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(fpr2, tpr2, label=<span class="string">'Logistic Regression for Ceftazidim (area = %0.2f)'</span> % logit_roc_auc2)</span><br><span class="line"><span class="comment">#plt.plot([0, 1], [0, 1],'r--')</span></span><br><span class="line"><span class="comment">#plt.xlim([0.0, 1.0])</span></span><br><span class="line"><span class="comment">#plt.ylim([0.0, 1.05])</span></span><br><span class="line">plt.xlabel(<span class="string">'False Positive Rate'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'True Positive Rate'</span>)</span><br><span class="line">plt.title(<span class="string">'Receiver operating characteristic'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">"lower right"</span>)</span><br><span class="line">plt.savefig(<span class="string">'./Fig2_Log_ROC_Cef.pdf'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/06/logistic_regression_python.htm/fig-1.png&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>稀疏矩阵与机器学习</title>
    <link href="http://yoursite.com/2020/06/Sparse_Matrices_ML.html"/>
    <id>http://yoursite.com/2020/06/Sparse_Matrices_ML.html</id>
    <published>2020-06-28T18:06:40.000Z</published>
    <updated>2020-09-11T20:05:06.309Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><strong>Introduction to Sparse Matrices for Machine Learning</strong></p></blockquote><h3 id="什么是稀疏矩阵？"><a href="#什么是稀疏矩阵？" class="headerlink" title="什么是稀疏矩阵？"></a>什么是稀疏矩阵？</h3><p>大部分包含零值的矩阵称为稀疏矩阵(sparse Matrices)，相对应的是大多数值非零的密集矩阵(Dense Matrices)。稀疏矩阵在机器学习领域非常常见，如计数类数据，或者one-hot encoding编码的数据等。数据的稀疏性可以通过零值的比例量化（sparsity = count zero elements / total elements）。稀疏矩阵会产生处理时间和存储空间的问题。而<strong>SciPy</strong>提供了很多高效的方法可以直接用于存储和处理稀疏矩阵。</p><p><img src="/2020/06/Sparse_Matrices_ML.htm/figure-ab.jpg" alt></p><a id="more"></a><h3 id="稀疏矩阵数据处理——SciPy"><a href="#稀疏矩阵数据处理——SciPy" class="headerlink" title="稀疏矩阵数据处理——SciPy"></a>稀疏矩阵数据处理——SciPy</h3><p>SciPy中提供了多种数据结构可以有效处理稀疏矩阵，如：</p><p><strong>Dictionary of Keys:</strong> 一个字典使用行和列索引映射出一个值</p><p><strong>List of Lists:</strong> 每行作为一个list存储，每个list里包含column index和值</p><p><strong>Coordinate List:</strong> 存储一个元组列表，每个元组包含行索引，列索引和值</p><p><strong>Compressed Sparse Row (CSR) :</strong> 使用三个一维数组表示非零值，行范围和列索引。在机器学习中经常使用。</p><p><strong>Compressed Sparse Column:</strong> 对列索引进行压缩并在行索引之前先读取</p><p><img src="/2020/06/Sparse_Matrices_ML.htm/1593354304703-ea0a7d87-344f-4042-a4fb-63ab1456ed40.png" alt="image.png"></p><p><img src="/2020/06/Sparse_Matrices_ML.htm/1593354414857-4435ef02-f1c7-41f9-b9af-3959e384200e.png" alt="image.png"></p><h4 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from numpy import array</span><br><span class="line">from scipy import sparse</span><br><span class="line">import numpy as np</span><br><span class="line"># create dense matrix</span><br><span class="line">A = array([[1, 0, 0, 1, 0, 0], [0, 0, 2, 0, 0, 1], [0, 0, 0, 2, 0, 0]])</span><br><span class="line">print(A)</span><br><span class="line"># convert to sparse matrix (CSR method)</span><br><span class="line">S = csr_matrix(A)</span><br><span class="line">print(S)</span><br><span class="line"># reconstruct dense matrix</span><br><span class="line">B = S.todense()</span><br><span class="line">print(B)</span><br><span class="line"># reconstruct numpy array</span><br><span class="line">C = S.toarray()</span><br><span class="line">print(C)</span><br></pre></td></tr></table></figure><h3 id="稀疏矩阵与机器学习"><a href="#稀疏矩阵与机器学习" class="headerlink" title="稀疏矩阵与机器学习"></a>稀疏矩阵与机器学习</h3><p>python的sklearn模块很多模型可以使用sparse数据结构作为输入。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://machinelearningmastery.com/sparse-matrices-for-machine-learning/" target="_blank" rel="noopener">https://machinelearningmastery.com/sparse-matrices-for-machine-learning/</a></p><p><a href="https://docs.scipy.org/doc/scipy/reference/sparse.html" target="_blank" rel="noopener">https://docs.scipy.org/doc/scipy/reference/sparse.html</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Introduction to Sparse Matrices for Machine Learning&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;什么是稀疏矩阵？&quot;&gt;&lt;a href=&quot;#什么是稀疏矩阵？&quot; class=&quot;headerlink&quot; title=&quot;什么是稀疏矩阵？&quot;&gt;&lt;/a&gt;什么是稀疏矩阵？&lt;/h3&gt;&lt;p&gt;大部分包含零值的矩阵称为稀疏矩阵(sparse Matrices)，相对应的是大多数值非零的密集矩阵(Dense Matrices)。稀疏矩阵在机器学习领域非常常见，如计数类数据，或者one-hot encoding编码的数据等。数据的稀疏性可以通过零值的比例量化（sparsity = count zero elements / total elements）。稀疏矩阵会产生处理时间和存储空间的问题。而&lt;strong&gt;SciPy&lt;/strong&gt;提供了很多高效的方法可以直接用于存储和处理稀疏矩阵。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/06/Sparse_Matrices_ML.htm/figure-ab.jpg&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>机器学习中的模型验证</title>
    <link href="http://yoursite.com/2020/06/model_validation_ML.html"/>
    <id>http://yoursite.com/2020/06/model_validation_ML.html</id>
    <published>2020-06-28T17:59:14.000Z</published>
    <updated>2020-09-11T19:57:58.328Z</updated>
    
    <content type="html"><![CDATA[<h2 id="model-validation"><a href="#model-validation" class="headerlink" title="model validation"></a>model validation</h2><p>Model validation is important step in machine learning. Cross validation and bootstrapping methods can be used for model validation. Both of them are resampling methods.Cross validation resamples without replacement,bootstrap resamples with replacement.</p><p><strong>reference</strong> - <a href="https://arxiv.org/pdf/1811.12808.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1811.12808.pdf</a></p><p><img src="/2020/06/model_validation_ML.htm/love-699480_640.jpg" alt></p><a id="more"></a><h3 id="Cross-validation"><a href="#Cross-validation" class="headerlink" title="Cross validation"></a>Cross validation</h3><p>Cross-validation is a series of methods for estimating the true error of a model to ensure that the model being trained is also valid on real data. The methods include:</p><ul><li>Hold-out cross validation</li><li>k-fold cross validation</li><li>leave-one-out cross validation</li></ul><h4 id="hold-out-validation"><a href="#hold-out-validation" class="headerlink" title="hold-out validation"></a>hold-out validation</h4><p>The raw data set is splited into two parts, one is the training set to fit the model and the other one is the validation set to estimate the model error.</p><p>It Usually takes 20% or 30% as the validation set; The sampling is <strong>randomly stratified</strong> with the target variable Y for reducing the bias between the training/test set and the full set (bias).</p><p><strong>Advantages and disadvantages:</strong></p><ul><li>The method is simple, requiring only random partitioning and low computational complexity.</li><li>The effect on the validation set can fluctuate considerably because each partitioning is different.</li></ul><h4 id="k-fold-cross-validation"><a href="#k-fold-cross-validation" class="headerlink" title="k-fold cross validation"></a>k-fold cross validation</h4><p>In k-fold cross-validation, the raw data is randomly splited into k equal sized subdata set. one of subdata set is retained as the testing data, and the remaining k-1 subdata set are used as training data set. The cross-validation process is then repeated k times.</p><p><img src="/2020/06/model_validation_ML.htm/1593367023322-337a099f-600b-4b59-9467-8b9ef49a4fa7.png" alt="image.png"></p><p><strong>Advantages and disadvantages：</strong></p><ul><li>Ultimately all of data are used for fitting the model.</li><li>The estimate of the test error may be high</li><li>If K is too high (e.g., extreme K=n), the error estimate will have high variance; if K is too low (e.g., 2, 3), high bias will occur, Usually K=5 or K=10.</li></ul><h4 id="leave-one-out-cross-validation"><a href="#leave-one-out-cross-validation" class="headerlink" title="leave-one-out cross validation"></a>leave-one-out cross validation</h4><p>A special case of cross-validation in the case of K=n, take n-1 samples at a time for modeling, 1 sample for evaluation, and repeat for n times.</p><h3 id="bootstrapping"><a href="#bootstrapping" class="headerlink" title="bootstrapping"></a>bootstrapping</h3><p>Bootstrap is a resampling method with replacement, and the idea is also used random forests.</p><ul><li>One sample of the original size is repeated with playback to obtain K samples of the same size.</li><li>Calculate the specified statistics (e.g., mean, standard deviation) for each sample, or fit the model to the parameters to obtain a bootstrap distribution of some statistic/parameter similar to the bootstrap distribution obtained by bootstrap sampling from the total.</li><li>Taking the average of the bootstrap distribution is an estimate of the overall parameter.</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;model-validation&quot;&gt;&lt;a href=&quot;#model-validation&quot; class=&quot;headerlink&quot; title=&quot;model validation&quot;&gt;&lt;/a&gt;model validation&lt;/h2&gt;&lt;p&gt;Model validation is important step in machine learning. Cross validation and bootstrapping methods can be used for model validation. Both of them are resampling methods.Cross validation resamples without replacement,bootstrap resamples with replacement.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;reference&lt;/strong&gt; - &lt;a href=&quot;https://arxiv.org/pdf/1811.12808.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://arxiv.org/pdf/1811.12808.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/06/model_validation_ML.htm/love-699480_640.jpg&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>用于COVID-19研究的计算机策略大集锦</title>
    <link href="http://yoursite.com/2020/05/COVID-19_tools.html"/>
    <id>http://yoursite.com/2020/05/COVID-19_tools.html</id>
    <published>2020-05-24T11:01:14.000Z</published>
    <updated>2020-09-11T20:04:28.380Z</updated>
    
    <content type="html"><![CDATA[<p><strong>文章信息</strong></p><p>题目：Computational strategies to combat COVID-19: Useful tools to accelerate SARS-CoV-2 and Coronavirus research                           </p><p>杂志：Preprints</p><p>时间：23 May 2020</p><p>链接: <a href="https://www.preprints.org/manuscript/202005.0376/v1" target="_blank" rel="noopener">https://www.preprints.org/manuscript/202005.0376/v1</a></p><p><strong>figure</strong></p><p><img src="/2020/05/COVID-19_tools.htm/1590306372902-96cb47c3-6aa3-48ed-b191-1ebf93d885ec.png" alt="image.png"></p><p><strong>文章介绍</strong></p><p>这篇综述是由欧洲病毒生物信息中心（EVBC）整理的关于COVID-19研究的分析流程和工具。涉及1）SARS-CoV-2的检测，2）测序数据的分析，3）COVID-19流行病学的追踪，4）病毒的进化，5）潜在药物靶标，治疗策略等方面。</p><p>详细的工具列表链接，可以在EVBC网站查看：<a href="http://evbc.uni-jena.de/tools/coronavirus-tools/" target="_blank" rel="noopener">http://evbc.uni-jena.de/tools/coronavirus-tools/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;文章信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;题目：Computational strategies to combat COVID-19: Useful tools to accelerate SARS-CoV-2 and Coronavirus resear
      
    
    </summary>
    
    
      <category term="文献摘要" scheme="http://yoursite.com/tags/%E6%96%87%E7%8C%AE%E6%91%98%E8%A6%81/"/>
    
      <category term="database" scheme="http://yoursite.com/tags/database/"/>
    
  </entry>
  
  <entry>
    <title>从EBI批量下载数据</title>
    <link href="http://yoursite.com/2020/05/download_data_from_EBI.html"/>
    <id>http://yoursite.com/2020/05/download_data_from_EBI.html</id>
    <published>2020-05-18T08:42:38.000Z</published>
    <updated>2020-09-11T19:18:51.297Z</updated>
    
    <content type="html"><![CDATA[<p>ERR地址的规律：差别在于后三个地址，先是ERR number字符串的前6个字符，然后是ERR完整字符串，最后是ERR字符串加上 <code>_1</code> 或 <code>_2</code></p><p>如：</p><p><img src="/2020/05/download_data_from_EBI.htm/1589790261584-b3c7220e-2691-4b63-92f9-21acf439465a.png" alt="image.png"></p><p>根据此规律批量从EBI下载数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for i in $(cat ERR_numlist);do wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/$&#123;i:0:6&#125;/$i/$i\_*.fastq.gz; done</span><br></pre></td></tr></table></figure><ul><li>首先从excel 表格中提取Lane.accession列，即ERR number列，命名为<strong>ERR_numlist</strong>，然后上传到服务器；</li><li>切记所有从windows上传到服务器的文件最好先进行格式转化，否则由于文件格式，容易报错。 <strong><code>dos2unix ERR_numlist</code></strong> </li><li><code>${i:0:6}</code> ：是指输出字符串i的前6个字符， <code>0</code> :表示从第几位开始， <code>6</code> :表示截取的长度</li></ul><p><img src="/2020/05/download_data_from_EBI.htm/fig1.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ERR地址的规律：差别在于后三个地址，先是ERR number字符串的前6个字符，然后是ERR完整字符串，最后是ERR字符串加上 &lt;code&gt;_1&lt;/code&gt; 或 &lt;code&gt;_2&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;如：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/05/do
      
    
    </summary>
    
    
      <category term="shell" scheme="http://yoursite.com/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>t-test和方差分析</title>
    <link href="http://yoursite.com/2020/05/t-test_annova.html"/>
    <id>http://yoursite.com/2020/05/t-test_annova.html</id>
    <published>2020-05-17T08:22:58.000Z</published>
    <updated>2020-09-11T19:13:49.601Z</updated>
    
    <content type="html"><![CDATA[<h3 id="t-test"><a href="#t-test" class="headerlink" title="t-test"></a>t-test</h3><p><strong>t-test是比较两组变量的平均值是否有显著性差异</strong></p><p><img src="/2020/05/t-test_annova.htm/1589702913894-0ff87132-df98-47cc-aa51-d3d6b4127469-20200517103250465.png" alt="image.png" style="zoom:50%;"></p><a id="more"></a><p><strong>类比于线性回归计算t-test的R squared</strong></p><ul><li><strong>1）首先忽略x轴，计算总平均值</strong></li></ul><p><img src="/2020/05/t-test_annova.htm/1589703098963-a13f78e7-3120-47b1-9902-02ae10aa989a-20200517103250668.png" alt="image.png" style="zoom:33%;"></p><ul><li>2) 计算相对于平均值的偏差平方和</li></ul><p><img src="/2020/05/t-test_annova.htm/1589703245599-1a324c15-00a1-4696-8837-fb72f47a6262-20200517103250743.png" alt="image.png" style="zoom:33%;"><img src="/2020/05/t-test_annova.htm/1589703466338-96b36840-acd0-497e-8d21-7635be860718-20200517103250065.png" alt="image.png" style="zoom:33%;"></p><p><strong>3） 拟合模型</strong></p><p> <img src="/2020/05/t-test_annova.htm/1589703466338-96b36840-acd0-497e-8d21-7635be860718-20200517103250065.png" alt="image.png" style="zoom:33%;"></p><p>4）计算相对于模型line的偏差平方和</p><p><img src="/2020/05/t-test_annova.htm/1589703384412-7c9ecf7e-9081-4b29-b966-1a02eeb0a589-20200517103250886.png" alt="image.png" style="zoom:33%;"><img src="/2020/05/t-test_annova.htm/1589703577012-29901c39-6517-4f8d-a27b-72f39a294726-20200517103250846.png" alt="image.png"></p><p><strong>线性回归和t-test的对比总结：</strong></p><p>   <img src="/2020/05/t-test_annova.htm/1589703577012-29901c39-6517-4f8d-a27b-72f39a294726-20200517103250846.png" alt="image.png" style="zoom:33%;"></p><h3 id="方差分析"><a href="#方差分析" class="headerlink" title="方差分析"></a>方差分析</h3><p>方差分析即Analysis of Variance, 简称ANOVA，是比较多组变量间的平均值是否有显著性差异。是t-test的拓展。</p><p><img src="/2020/05/t-test_annova.htm/1589703782892-4a90d9f5-4bb3-4879-9d51-d059a144891c-20200517103251076.png" alt="image.png" style="zoom:33%;"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;t-test&quot;&gt;&lt;a href=&quot;#t-test&quot; class=&quot;headerlink&quot; title=&quot;t-test&quot;&gt;&lt;/a&gt;t-test&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;t-test是比较两组变量的平均值是否有显著性差异&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/05/t-test_annova.htm/1589702913894-0ff87132-df98-47cc-aa51-d3d6b4127469-20200517103250465.png&quot; alt=&quot;image.png&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="statistics" scheme="http://yoursite.com/tags/statistics/"/>
    
  </entry>
  
  <entry>
    <title>逻辑回归</title>
    <link href="http://yoursite.com/2020/05/Logistic_regression.html"/>
    <id>http://yoursite.com/2020/05/Logistic_regression.html</id>
    <published>2020-05-17T07:56:44.000Z</published>
    <updated>2020-09-11T20:51:08.259Z</updated>
    
    <content type="html"><![CDATA[<p><strong>逻辑回归是什么？主要用于解决什么问题？与线性回归有什么关系？如何计算和评估逻辑回归的最佳模型？逻辑回归与概率回归的异同？在R中如何实现？</strong></p><p>首先还是先看wiki对逻辑回归（logisitic regression）的解释</p><blockquote><p>Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable。</p></blockquote><p>逻辑回归（logistic/logit regression）主要应用于解决<strong>二分类</strong>问题，和线性回归都属于线性模型，但是逻辑回归是解决分类问题，而线性回归是解决回归问题。逻辑回归通过最大似然法（Maximum likelihood）寻找最佳模型。可以通过summary()函数的输出结果AIC值对比模型的拟合程度，或者通过sensitivity, specifity评估，既可以以ROC和AUC的结果评估。概率回归也用于二分类问题，和逻辑回归类似。不同的是逻辑回归使用累积逻辑函数（cumulative logistic function），概率回归使用正态累积密度函数（normal cumulative density function）。实际应用两个模型时时可根据自己的爱好选择。逻辑回归在R中的实现以 <strong><code>glm()</code></strong> 函数实现，并指定参数 <code>**family = binomial**</code> , 而概率回归以glm()函数，并指定 <strong><code>family =binomial(link=&quot;probit&quot;)</code></strong> 。</p><a id="more"></a><p><img src="/2020/05/Logistic_regression.htm/1589442464586-dd9e1642-d738-407f-9656-5ce4e1f54b52.png" alt="image.png" style="zoom:33%;"></p><p><img src="/2020/05/Logistic_regression.htm/1589442582323-ba9a09c2-6ab3-4f39-93fd-5bc66333621a.png" alt="image.png" style="zoom:33%;"></p><p><img src="/2020/05/Logistic_regression.htm/1589443161905-b5a2b69c-41f4-46e2-aac4-c146bb467f45.png" alt="image.png" style="zoom:33%;"></p><p><img src="/2020/05/Logistic_regression.htm/1589701563491-be26730c-2d7b-4668-8035-5ca409555214.png" alt="image.png" style="zoom:33%;"></p><p><img src="/2020/05/Logistic_regression.htm/1589701561833-3cec8e36-edf6-4df1-8a80-af7d3fb2230e.png" alt="image.png" style="zoom:33%;"></p><p><img src="/2020/05/Logistic_regression.htm/1589702022864-d99f6c13-a484-493f-a313-8c6a9ab70514.png" alt="image.png" style="zoom:33%;"></p><p><strong>参考资料：</strong></p><p>statquest逻辑回归视频：<a href="https://www.youtube.com/playlist?list=PLblh5JKOoLUKxzEP5HA2d-Li7IJkHfXSe" target="_blank" rel="noopener">https://www.youtube.com/playlist?list=PLblh5JKOoLUKxzEP5HA2d-Li7IJkHfXSe</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;逻辑回归是什么？主要用于解决什么问题？与线性回归有什么关系？如何计算和评估逻辑回归的最佳模型？逻辑回归与概率回归的异同？在R中如何实现？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先还是先看wiki对逻辑回归（logisitic regression）的解释&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;逻辑回归（logistic/logit regression）主要应用于解决&lt;strong&gt;二分类&lt;/strong&gt;问题，和线性回归都属于线性模型，但是逻辑回归是解决分类问题，而线性回归是解决回归问题。逻辑回归通过最大似然法（Maximum likelihood）寻找最佳模型。可以通过summary()函数的输出结果AIC值对比模型的拟合程度，或者通过sensitivity, specifity评估，既可以以ROC和AUC的结果评估。概率回归也用于二分类问题，和逻辑回归类似。不同的是逻辑回归使用累积逻辑函数（cumulative logistic function），概率回归使用正态累积密度函数（normal cumulative density function）。实际应用两个模型时时可根据自己的爱好选择。逻辑回归在R中的实现以 &lt;strong&gt;&lt;code&gt;glm()&lt;/code&gt;&lt;/strong&gt; 函数实现，并指定参数 &lt;code&gt;**family = binomial**&lt;/code&gt; , 而概率回归以glm()函数，并指定 &lt;strong&gt;&lt;code&gt;family =binomial(link=&amp;quot;probit&amp;quot;)&lt;/code&gt;&lt;/strong&gt; 。&lt;/p&gt;
    
    </summary>
    
    
      <category term="statistics" scheme="http://yoursite.com/tags/statistics/"/>
    
  </entry>
  
  <entry>
    <title>线性回归和线性模型</title>
    <link href="http://yoursite.com/2020/05/linear%20regression_linear_model.html"/>
    <id>http://yoursite.com/2020/05/linear regression_linear_model.html</id>
    <published>2020-05-17T06:40:38.000Z</published>
    <updated>2020-09-11T20:07:09.240Z</updated>
    
    <content type="html"><![CDATA[<p><strong>什么是线性回归和线性模型？他们的关系是什么？如何计算和评估线性回归模型？如何在R中实现？</strong></p><h2 id="线性回归和线性模型"><a href="#线性回归和线性模型" class="headerlink" title="线性回归和线性模型"></a><strong>线性回归和线性模型</strong></h2><p>首先看下wiki给出的解释：</p><blockquote><p>In statistics, linear regression is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression</p></blockquote><p>线性回归即用来寻找变量间的线性关系，属于线性模型的一个分支，通常使用最小二乘法（least squared method)寻找</p><p>最佳模型，并用R suqared( R2 ）评估模型的拟合程度，R2越大表示模型拟合效果越好。在R中以lm()函数实现，代码公式为 <code>lm(dependent varaible ~ independent varaibles, data</code> .</p><a id="more"></a><p><img src="/2020/05/linear regression_linear_model.htm/1589697274717-c22e4977-8d06-4552-8dda-1906453aa44a.png" alt="image.png" style="zoom:50%;"></p><p><img src="/2020/05/linear regression_linear_model.htm/1589697479975-0256eaec-3fd1-4829-9bca-4ab84782d79c.png" alt="image.png" style="zoom:50%;"></p><p><strong>p-value矫正：</strong> <strong>Bonferroni Correction和Benjamini and Hochberg method</strong></p><p>Bonferroni Correction是p-value的一个矫正方法，相对严格；FDR是另一种矫正p-value的方法，而Benjamini and Hochberg method（即BH)是FDR的一个计算方法。</p><blockquote><p>We know P-value threshold is set artificially, the samller p-value represents the lower false positive for the result, but not mean it is absolutly true. For example, if the P-value equals 0.05, 10,000 tests are done, the number of false positive results will be 0.05*10,000 = 500. The false positive results will be enlarged with the incresasing the number of tests . Therefor, we need to introduce multiple tests for correction to reduce the number of false positive results. </p><p>There are two main correction methods used:</p><p><strong>1) Bonferroni Correction</strong></p></blockquote><blockquote><p>The Bonferroni method is a simplest and most brutally effective method of correction, which rejects all the possibilities of false pofitive results, and eliminates them by correcting the threshold of the P value. </p></blockquote><blockquote><p>The formula for Bonferroni method is p<em>(1/n), where p is the original P value threshold, and n is the total number of tests. If the original P value is is 0.05, and the number of test is 10,000, then the threshold after Bonferroni correction is equal to 0.05/10,000 = 0.000005, in this case, the number of false positive results in 10,000 test is 10,000 </em> 0.000005 = 0.5, less than 1. </p></blockquote><blockquote><p>But Bonferroni correction is too stringent, it will cause not only false positives are rejected by corrected threshold, but mant positives are also rejected. </p></blockquote><blockquote><p><strong>2) FDR( False Discovery Rate)</strong></p><p>FDR corrects for p-values in a relatively gentle wat compared to Bonferroni. It attempts to get a balance between false positives and false negatives, keeping the false/true positive ratio within a certain range. For example, if we set a threshold of 0.05 for 10,000 tests,the probabilty of false positives remains within 0.05, which is called FDR&lt;0.05.</p></blockquote><blockquote><p>So how to calculate FDR from p value, there are several estimation models. The most used is <strong>Benjamini and Hochberg method,</strong> also known as <strong>BH method</strong>. </p></blockquote><blockquote><p>BH method requires the results of total <strong>m</strong> tests to be ranked in descending order, <strong>k is the rank of p value in one of the results.</strong> </p></blockquote><blockquote><p>find the maximum k value that meets the original threshold α, satisfy P(k) &lt;= α<em>k/m, consider the ranking to be significanand different for all tests from 1 to k, and calculate the corresponding q value as q=p</em>(m/k). </p></blockquote><p><strong>参考资料：</strong></p><p>statquest线性回归视频 : <a href="https://www.youtube.com/playlist?list=PLblh5JKOoLUIzaEkCLIUxQFjPIlapw8nU" target="_blank" rel="noopener">https://www.youtube.com/playlist?list=PLblh5JKOoLUIzaEkCLIUxQFjPIlapw8nU</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;什么是线性回归和线性模型？他们的关系是什么？如何计算和评估线性回归模型？如何在R中实现？&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;线性回归和线性模型&quot;&gt;&lt;a href=&quot;#线性回归和线性模型&quot; class=&quot;headerlink&quot; title=&quot;线性回归和线性模型&quot;&gt;&lt;/a&gt;&lt;strong&gt;线性回归和线性模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;首先看下wiki给出的解释：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In statistics, linear regression is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;线性回归即用来寻找变量间的线性关系，属于线性模型的一个分支，通常使用最小二乘法（least squared method)寻找&lt;/p&gt;
&lt;p&gt;最佳模型，并用R suqared( R2 ）评估模型的拟合程度，R2越大表示模型拟合效果越好。在R中以lm()函数实现，代码公式为 &lt;code&gt;lm(dependent varaible ~ independent varaibles, data&lt;/code&gt; .&lt;/p&gt;
    
    </summary>
    
    
      <category term="statistics" scheme="http://yoursite.com/tags/statistics/"/>
    
  </entry>
  
  <entry>
    <title>人肠内分泌细胞的高分辨率mRNA和分泌组图谱</title>
    <link href="http://yoursite.com/2020/05/High-Resolution_mRNA_and_Secretome_Atlas_of_Human_Enteroendocrine_Cells.html"/>
    <id>http://yoursite.com/2020/05/High-Resolution_mRNA_and_Secretome_Atlas_of_Human_Enteroendocrine_Cells.html</id>
    <published>2020-05-13T20:01:52.000Z</published>
    <updated>2020-09-11T19:17:53.239Z</updated>
    
    <content type="html"><![CDATA[<p><strong>文章信息</strong></p><p>题目：High-Resolution mRNA and Secretome Atlas of Human Enteroendocrine Cells</p><p>杂志：Cell</p><p>时间：May 13, 2020</p><p>链接: <a href="https://doi.org/10.1016/j.cell.2020.04.036" target="_blank" rel="noopener">https://doi.org/10.1016/j.cell.2020.04.036</a></p><p>肠道内分泌细胞（EEC）感知肠道内容物，释放激素，调节胃肠活动、全身代谢和食物摄入量。关于人类肠道内分泌细胞亚型的分子构成和个体激素的分泌调节，目前还不甚了解。在这里，我们描述了一个基于有机体的平台，用于人类EECs的功能研究。EEC的形成是在体外通过NEUROG3的瞬时表达诱导的。设计了一套肠道器质体，其中主要的激素被荧光标记。生成了不同EEC亚型的单细胞mRNA图谱，并通过质谱法记录了其分泌的产物。我们注意到与小鼠EECs的关键差异，包括激素、感觉受体和转录因子。值得注意的是，确定了几种激素类分子。泌素诱导的GLP-1的分泌是EEC间交流的典范。事实上，个别EEC亚型携带着各种EEC激素的受体。本研究为研究人类EEC的发育和功能提供了丰富的资源。</p><p><img src="/2020/05/High-Resolution_mRNA_and_Secretome_Atlas_of_Human_Enteroendocrine_Cells.htm/1589400011510-19258e40-16de-43b2-9a27-cd1ec0badc25.jpeg" alt="200513-fig-.jpg" style="zoom:50%;"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;文章信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;题目：High-Resolution mRNA and Secretome Atlas of Human Enteroendocrine Cells&lt;/p&gt;
&lt;p&gt;杂志：Cell&lt;/p&gt;
&lt;p&gt;时间：May 13, 
      
    
    </summary>
    
    
      <category term="文献摘要" scheme="http://yoursite.com/tags/%E6%96%87%E7%8C%AE%E6%91%98%E8%A6%81/"/>
    
  </entry>
  
</feed>
