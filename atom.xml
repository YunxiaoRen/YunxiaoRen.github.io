<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>生信拾光</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2021-09-19T20:51:56.223Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>六六</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>整合多组学数据和图像卷积网络鉴定新的癌症基因和相关的分子机制</title>
    <link href="http://yoursite.com/2021/09/19/f8c75c1b.html"/>
    <id>http://yoursite.com/2021/09/19/f8c75c1b.html</id>
    <published>2021-09-19T20:30:07.000Z</published>
    <updated>2021-09-19T20:51:56.223Z</updated>
    
    <content type="html"><![CDATA[<h2 id="文章信息"><a href="#文章信息" class="headerlink" title="文章信息"></a>文章信息</h2><p>题目：Integration of multiomics data with graph convolutional networks to identify new cancer genes and their associated molecular mechanisms</p><p>杂志：Nature Machine Intelligence</p><p>IF:16.65</p><p>时间：12 April 2021</p><p>链接：<a href="https://www.nature.com/articles/s42256-021-00325-y" target="_blank" rel="noopener">https://www.nature.com/articles/s42256-021-00325-y</a></p><h2 id="一句话评价"><a href="#一句话评价" class="headerlink" title="一句话评价"></a>一句话评价</h2><p>使用机器学习方法——图像卷积网络对多组学数据（SNPs, CNV，DAN methylation，protein interaction (PPI) networks）进行挖掘，预测新的癌症基因以及这些基因发挥功能的机制。</p><p><img src="/2021/09/19/f8c75c1b/image-20210919224314468.png" alt="image-20210919224314468" style="zoom:50%;"></p><p><img src="/2021/09/19/f8c75c1b/image-20210919224447370.png" alt="image-20210919224447370"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;文章信息&quot;&gt;&lt;a href=&quot;#文章信息&quot; class=&quot;headerlink&quot; title=&quot;文章信息&quot;&gt;&lt;/a&gt;文章信息&lt;/h2&gt;&lt;p&gt;题目：Integration of multiomics data with graph convolutional net
      
    
    </summary>
    
      <category term="literature" scheme="http://yoursite.com/categories/literature/"/>
    
    
      <category term="CNN" scheme="http://yoursite.com/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>多标签分类提高耐药性预测能力</title>
    <link href="http://yoursite.com/2021/04/04/c387b45f.html"/>
    <id>http://yoursite.com/2021/04/04/c387b45f.html</id>
    <published>2021-04-04T08:19:04.000Z</published>
    <updated>2021-04-11T22:20:51.937Z</updated>
    
    <content type="html"><![CDATA[<h2 id="文章信息"><a href="#文章信息" class="headerlink" title="文章信息"></a>文章信息</h2><p>题目：Exploiting HIV-1 protease and reverse transcriptase cross-resistance information for improved drug resistance prediction by means of multi-label classification</p><p>杂志：BioData Mining</p><p>IF: 2.672</p><p>时间：2016</p><p>链接：DOI 10.1186/s13040-016-0089-1</p><h2 id="一句话评价"><a href="#一句话评价" class="headerlink" title="一句话评价"></a>一句话评价</h2><p>多标签分类应用</p><a id="more"></a><h2 id="文章介绍"><a href="#文章介绍" class="headerlink" title="文章介绍"></a>文章介绍</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>（背景，亮点，方法，结果，意义）</p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>（详细解读）</p><h3 id="结果和结论"><a href="#结果和结论" class="headerlink" title="结果和结论"></a>结果和结论</h3><p>（简要，理顺逻辑）</p><h3 id="创新性和意义"><a href="#创新性和意义" class="headerlink" title="创新性和意义"></a>创新性和意义</h3><p>（思路，方法或者数据资源对自己有什么启示）</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;文章信息&quot;&gt;&lt;a href=&quot;#文章信息&quot; class=&quot;headerlink&quot; title=&quot;文章信息&quot;&gt;&lt;/a&gt;文章信息&lt;/h2&gt;&lt;p&gt;题目：Exploiting HIV-1 protease and reverse transcriptase cross-resistance information for improved drug resistance prediction by means of multi-label classification&lt;/p&gt;
&lt;p&gt;杂志：BioData Mining&lt;/p&gt;
&lt;p&gt;IF: 2.672&lt;/p&gt;
&lt;p&gt;时间：2016&lt;/p&gt;
&lt;p&gt;链接：DOI 10.1186/s13040-016-0089-1&lt;/p&gt;
&lt;h2 id=&quot;一句话评价&quot;&gt;&lt;a href=&quot;#一句话评价&quot; class=&quot;headerlink&quot; title=&quot;一句话评价&quot;&gt;&lt;/a&gt;一句话评价&lt;/h2&gt;&lt;p&gt;多标签分类应用&lt;/p&gt;
    
    </summary>
    
      <category term="literature" scheme="http://yoursite.com/categories/literature/"/>
    
    
      <category term="AMR" scheme="http://yoursite.com/tags/AMR/"/>
    
      <category term="multi-label classification" scheme="http://yoursite.com/tags/multi-label-classification/"/>
    
  </entry>
  
  <entry>
    <title>在HIV-1耐药性预测中利用交叉耐药信息的多标签分类方法</title>
    <link href="http://yoursite.com/2021/04/03/f1069cae.html"/>
    <id>http://yoursite.com/2021/04/03/f1069cae.html</id>
    <published>2021-04-03T08:17:58.000Z</published>
    <updated>2021-04-06T14:49:33.562Z</updated>
    
    <content type="html"><![CDATA[<h2 id="文章信息"><a href="#文章信息" class="headerlink" title="文章信息"></a>文章信息</h2><p>题目：Multilabel classification for exploiting cross-resistance information in HIV-1 drug resistance prediction</p><p>杂志：Bioinformatics (Sequence Analysis)</p><p>IF: 5.610 (2019)</p><p>时间：June 21, 2013</p><p>链接：doi:10.1093/bioinformatics/btt331</p><h2 id="一句话评价"><a href="#一句话评价" class="headerlink" title="一句话评价"></a>一句话评价</h2><p>多标签分类算法</p><a id="more"></a><h2 id="文章介绍"><a href="#文章介绍" class="headerlink" title="文章介绍"></a>文章介绍</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>耐药性是疾病治疗中面临的一个重要难题。很多细菌或病毒还经常出现交叉耐药现象。不仅导致了当前治疗大的某一药物产生耐药性，而且对未使用的药物也产生耐药性。因此，耐药性的自动分类和预测在临床研究上具有重要的意义。而机器学习虽然已广泛用于抗药性研究，但是多重交叉耐药的信息还有待研究。</p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><h4 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h4><p><img src="/2021/04/03/f1069cae/image-20210406163704225.png" alt="image-20210406163704225" style="zoom:50%;"></p><p>IC50 ratio: 这里与药物的抗性相关，IC50 ratio cutoff是每个药物定义为抗性的临界值。</p><h4 id="多标签分类"><a href="#多标签分类" class="headerlink" title="多标签分类"></a>多标签分类</h4><h4 id="分类器链（Classification-Chains-CC）"><a href="#分类器链（Classification-Chains-CC）" class="headerlink" title="分类器链（Classification Chains, CC）"></a>分类器链（Classification Chains, CC）</h4><h4 id="CC的组合"><a href="#CC的组合" class="headerlink" title="CC的组合"></a>CC的组合</h4><h3 id="结果和结论"><a href="#结果和结论" class="headerlink" title="结果和结论"></a>结果和结论</h3><p>（简要，理顺逻辑）</p><h3 id="创新性和意义"><a href="#创新性和意义" class="headerlink" title="创新性和意义"></a>创新性和意义</h3><p>（思路，方法或者数据资源对自己有什么启示）</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;文章信息&quot;&gt;&lt;a href=&quot;#文章信息&quot; class=&quot;headerlink&quot; title=&quot;文章信息&quot;&gt;&lt;/a&gt;文章信息&lt;/h2&gt;&lt;p&gt;题目：Multilabel classification for exploiting cross-resistance information in HIV-1 drug resistance prediction&lt;/p&gt;
&lt;p&gt;杂志：Bioinformatics (Sequence Analysis)&lt;/p&gt;
&lt;p&gt;IF: 5.610 (2019)&lt;/p&gt;
&lt;p&gt;时间：June 21, 2013&lt;/p&gt;
&lt;p&gt;链接：doi:10.1093/bioinformatics/btt331&lt;/p&gt;
&lt;h2 id=&quot;一句话评价&quot;&gt;&lt;a href=&quot;#一句话评价&quot; class=&quot;headerlink&quot; title=&quot;一句话评价&quot;&gt;&lt;/a&gt;一句话评价&lt;/h2&gt;&lt;p&gt;多标签分类算法&lt;/p&gt;
    
    </summary>
    
      <category term="literature" scheme="http://yoursite.com/categories/literature/"/>
    
    
      <category term="AMR" scheme="http://yoursite.com/tags/AMR/"/>
    
      <category term="multi-label classification" scheme="http://yoursite.com/tags/multi-label-classification/"/>
    
  </entry>
  
  <entry>
    <title>机器学习在药物抗性分析中的应用</title>
    <link href="http://yoursite.com/2021/04/02/9fe5283f.html"/>
    <id>http://yoursite.com/2021/04/02/9fe5283f.html</id>
    <published>2021-04-02T21:44:14.000Z</published>
    <updated>2021-04-06T11:31:21.791Z</updated>
    
    <content type="html"><![CDATA[<h2 id="文章信息"><a href="#文章信息" class="headerlink" title="文章信息"></a>文章信息</h2><p>题目：Application of machine learning techniques to tuberculosis drug resistance analysis</p><p>杂志：Bioinformatics, Data and text mining</p><p>IF: 5.610 (2019)</p><p>时间：21 November, 2018</p><p>链接：doi: 10.1093/bioinformatics/bty949</p><h2 id="一句话评价"><a href="#一句话评价" class="headerlink" title="一句话评价"></a>一句话评价</h2><p>对比了不同的机器学习算法（LR，gradient tree boosting）在预测肺结核药物抗性中的性能</p><a id="more"></a><h2 id="文章介绍"><a href="#文章介绍" class="headerlink" title="文章介绍"></a>文章介绍</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><ul><li>及时识别结核分枝杆菌（MTB）对现有药物的耐药性对降低死亡率和防止现有抗生素耐药性的扩大至关重要。机器学习方法已被广泛应用于及时预测特定药物下MTB的耐药性和识别耐药标志物。然而，它们在耐药性预测和耐药性标志物识别方面还没有在全球多中心的MTB样本大队列上得到验证。</li><li>本文收集的样本来自6个大洲中的16个国家，共有13402个isolates，涉及到11种药物。</li><li>对比的机器学习方法有：SVM, LR, product-of-marginals (PM), gradient tree boosting, Adaboost, RF。其中LR和gradient tree boosting的性能比其他的算法好。</li><li>此外，根据突变位点的排序提供了一些潜在的研究靶标。并给出了文中所用的源码： <a href="http://www.robots.ox.ac.uk/davidc/code.php" target="_blank" rel="noopener">http://www.robots.ox.ac.uk/davidc/code.php</a></li></ul><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p><img src="/2021/04/02/9fe5283f/image-20210405120750554.png" alt="image-20210405120750554" style="zoom:50%;"></p><h4 id="WGS数据分析"><a href="#WGS数据分析" class="headerlink" title="WGS数据分析"></a>WGS数据分析</h4><p>序列比对，call变异位点，过滤低质量的变异位点，最终保留5919个位点。</p><h4 id="Baseline-Methods"><a href="#Baseline-Methods" class="headerlink" title="Baseline Methods"></a>Baseline Methods</h4><p>现有的基线方法是根据一些预先确定的变异库将药物分类为存在耐药性或不存在耐药性。直接关联(DA)的方法使用 “OR “规则来分类一个分离株对特定药物的抗药性：如果分离株的任何突变都是抗药性变异，则被标记为抗药性。否则，如果分离物中只有易感变异存在，则被归为易感。</p><p>变异库参考：Whole-genome sequencing for prediction of Mycobacterium tuberculosis drug susceptibility and resistance: a retrospective cohort study. Lancet Infect. Dis</p><ul><li><a href="https://pubmed.ncbi.nlm.nih.gov/26116186/" target="_blank" rel="noopener">https://pubmed.ncbi.nlm.nih.gov/26116186/</a></li></ul><h4 id="线性降维"><a href="#线性降维" class="headerlink" title="线性降维"></a>线性降维</h4><p>使用PCA对特征（变异位点）进行降维</p><h4 id="分类器方法"><a href="#分类器方法" class="headerlink" title="分类器方法"></a>分类器方法</h4><p>SVM, LR, product-of-marginals (PM), gradient tree boosting, Adaboost, RF</p><h3 id><a href="#" class="headerlink" title=" "></a> </h3><h3 id="结果和结论"><a href="#结果和结论" class="headerlink" title="结果和结论"></a>结果和结论</h3><h4 id="数据描述"><a href="#数据描述" class="headerlink" title="数据描述"></a>数据描述</h4><ul><li>总分离株（isolates）的数量：13402</li><li>变异位点：是与之前鉴定到的23个抗性基因相关的位点，共有5919个位点</li><li>11个药物的标签信息（Resistant/Susceptible）, 标签信息不平衡，所有11种药物的易感性分离株均大大高于耐药性分离株。</li></ul><p><img src="/2021/04/02/9fe5283f/image-20210405110521290.png" alt="image-20210405110521290" style="zoom:50%;"></p><h4 id="特征空间（Feature-Spaces）"><a href="#特征空间（Feature-Spaces）" class="headerlink" title="特征空间（Feature Spaces）"></a>特征空间（Feature Spaces）</h4><p>为了评估不同分类器的性能，文中考虑了三个特征集。1） F1是基线特征空间，即在23个候选基因内发现的所有变异。2） F2是根据另一篇文章（<a href="https://pubmed.ncbi.nlm.nih.gov/26116186/）中列出的预定抗药性相关变异。3）" target="_blank" rel="noopener">https://pubmed.ncbi.nlm.nih.gov/26116186/）中列出的预定抗药性相关变异。3）</a> F3是F1的子集，仅包括特定药物的抗药性相关基因（每种药物特有的抗药性决定因素基因，也是根据之前的一篇文章（<a href="https://pubmed.ncbi.nlm.nih.gov/26116186/）。" target="_blank" rel="noopener">https://pubmed.ncbi.nlm.nih.gov/26116186/）。</a></p><h4 id="训练和测试"><a href="#训练和测试" class="headerlink" title="训练和测试"></a>训练和测试</h4><p>分类模型是通过训练一个平衡的训练数据集，然后在不平衡的数据集上进行测试来执行的。并运行超过100次的5-kfold的交叉验证。在每个fold, 选取20%数据作为测试集，剩余的80%的训练集，将易感样本随机分选，使耐药和易感样本的数量相等，然后拆分训练集和验证集（80%:20%）。</p><p>模型评估参数： accuracy, sensitivity, spe- cificity, F1-score 和ROC curve的 area under curve (AUC) </p><h4 id="分类结果"><a href="#分类结果" class="headerlink" title="分类结果"></a>分类结果</h4><p><img src="/2021/04/02/9fe5283f/image-20210405112431592.png" alt="image-20210405112431592" style="zoom:50%;"></p><p><img src="/2021/04/02/9fe5283f/image-20210405112659308.png" alt="image-20210405112659308" style="zoom:50%;"></p><h4 id="突变排序"><a href="#突变排序" class="headerlink" title="突变排序"></a>突变排序</h4><p>选取性能最好的模型，然后提取前10个对每个药物有特有抗性的features。</p><p><img src="/2021/04/02/9fe5283f/image-20210405113331833.png" alt="image-20210405113331833" style="zoom:50%;"></p><h3 id="创新性和意义"><a href="#创新性和意义" class="headerlink" title="创新性和意义"></a>创新性和意义</h3><ul><li>样本量大，最后提供了药物相关的一些潜在靶标</li><li>文章思路：首先是WGS变异分析，然后选取之前研究的25个抗性基因相关的变异位点，再通过降维方法进一步减小特征的维度，最后比较不同的模型对不同组合提取的特征数据集的性能，并通过特征选择给出了每种药物特有的潜在变异位点。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;文章信息&quot;&gt;&lt;a href=&quot;#文章信息&quot; class=&quot;headerlink&quot; title=&quot;文章信息&quot;&gt;&lt;/a&gt;文章信息&lt;/h2&gt;&lt;p&gt;题目：Application of machine learning techniques to tuberculosis drug resistance analysis&lt;/p&gt;
&lt;p&gt;杂志：Bioinformatics, Data and text mining&lt;/p&gt;
&lt;p&gt;IF: 5.610 (2019)&lt;/p&gt;
&lt;p&gt;时间：21 November, 2018&lt;/p&gt;
&lt;p&gt;链接：doi: 10.1093/bioinformatics/bty949&lt;/p&gt;
&lt;h2 id=&quot;一句话评价&quot;&gt;&lt;a href=&quot;#一句话评价&quot; class=&quot;headerlink&quot; title=&quot;一句话评价&quot;&gt;&lt;/a&gt;一句话评价&lt;/h2&gt;&lt;p&gt;对比了不同的机器学习算法（LR，gradient tree boosting）在预测肺结核药物抗性中的性能&lt;/p&gt;
    
    </summary>
    
      <category term="literature" scheme="http://yoursite.com/categories/literature/"/>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="AMR" scheme="http://yoursite.com/tags/AMR/"/>
    
  </entry>
  
  <entry>
    <title>深度学习提高抗生肽的识别</title>
    <link href="http://yoursite.com/2021/04/01/fff0078d.html"/>
    <id>http://yoursite.com/2021/04/01/fff0078d.html</id>
    <published>2021-04-01T15:25:04.000Z</published>
    <updated>2021-04-04T21:53:39.286Z</updated>
    
    <content type="html"><![CDATA[<h2 id="文章信息"><a href="#文章信息" class="headerlink" title="文章信息"></a>文章信息</h2><p>题目：Deep learning improves antimicrobial peptide recognition</p><p>杂志：Bioinformatics</p><p>IF: 5.610 (2019)</p><p>时间：24 march, 2018</p><p>链接：doi: 10.1093/bioinformatics/bty179</p><h2 id="一句话评价"><a href="#一句话评价" class="headerlink" title="一句话评价"></a>一句话评价</h2><p>通过卷积网络层和循环神经网络层组合构建的深度学习模型识别抗生肽。</p><a id="more"></a><h2 id="文章介绍"><a href="#文章介绍" class="headerlink" title="文章介绍"></a>文章介绍</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><ul><li>细菌对抗生素药物的抗性越来越引起人们的关注，对经济，生命健康和社会造成重要的挑战。抗生肽（Antimicrobial peptides ，AMPs）是天然免疫的组成部分，也是研发药物广泛使用的靶点。机器学习的方法可以为湿实验的研究者提供一些潜在的研究位点。</li><li>这篇文章使用卷积网络层和循环神经网络层组成的神经网络模型识别抗菌活动。最终训练的模型也比一般的方法表现更好。此外，通过潜入权重(Embedding Weights)，他们提出了reduced-alphabet representation的方法，最终实现可以只用9个氨基酸分子准确识别AMP。</li><li>最后，他们也提供了模型和数据相关的网站：Antimicrobial Peptide Scanner vr.2 web server， <a href="http://www.ampscanner.com" target="_blank" rel="noopener">www.ampscanner.com</a></li></ul><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><h4 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h4><ul><li>APD vr.3 database： <a href="http://aps.unmc.edu/AP，" target="_blank" rel="noopener">http://aps.unmc.edu/AP，</a> 主要是革兰氏阴性和阳性细菌的AMP</li><li>过滤掉长度小于10的氨基酸以及和CD-Hit &gt; 90%的共有的序列，最终使用的AMP有1778个，训练集：712，验证集：354，测试集：712。</li><li>人工构建了non-AMP的序列：Torrent et al., 2011; Xiao et al., 2013<ul><li>Torrent,M. et al. (2011) Connecting peptide physicochemical and antimicro- bial properties by a rational prediction model. PLoS One, 6, e16968.</li><li>Xiao,X. et al. (2013) iAMP-2L: a two-level <strong>multi-label classifier</strong> for identifying antimicrobial peptides and their functional types. Anal. Biochem., 436, 168–177.</li><li>从UniProt下载了肽段序列，并过滤掉包含抗性的序列</li></ul></li></ul><h4 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h4><p><img src="/2021/04/01/fff0078d/fig1.png" style="zoom:50%;"></p><p><strong>基于Keras框架搭建的模型</strong>：</p><ul><li>肽段序列被编码为长度为200的序列，20个氨基酸依次编码为1-20，其余以0填充。</li><li>embedding_vector_length: 128</li><li>卷积层：1D convolution, <code>nb_filter: 64, filter_length: 16, init: normal, strides: 1, border_mode: same, activation: relu</code></li><li>池化层：Maxpooling layer，size=5</li><li>LSTM层：100 units, <code>(unroll: True, stateful: False, dropout: 0.1 and rest default settings)</code></li><li>Dense 层：激活函数：sigmoid</li><li>其他参数：10 epochs， ‘adam’ 优化器， loss: binary_cros- sentropy, metrics: accuracy).</li></ul><p><strong>调参：</strong></p><p>Hyperas wrapper package for Keras：<a href="https://github.com/maxpumperla/hyperas" target="_blank" rel="noopener">https://github.com/maxpumperla/hyperas</a> </p><p><strong>模型评估：</strong></p><p>用到评估metrics有：</p><ul><li><p>sensitivity (SENS)</p></li><li><p>specificity (SPEC)</p></li><li><p>ACC </p></li><li><p>Matthews Correlation Coefficient (MCC)</p></li><li><p>ROC curve: pROC package in R</p></li></ul><h3 id="结果和结论"><a href="#结果和结论" class="headerlink" title="结果和结论"></a>结果和结论</h3><p><strong>构建的模型性能：</strong></p><p><img src="/2021/04/01/fff0078d/image-20210404222508046.png" alt="image-20210404222508046" style="zoom:50%;"></p><p><strong>与其他方法的比较</strong></p><p><img src="/2021/04/01/fff0078d/image-20210404222646572.png" alt="image-20210404222646572" style="zoom:50%;"></p><h3 id="创新性和意义"><a href="#创新性和意义" class="headerlink" title="创新性和意义"></a>创新性和意义</h3><ul><li>基于抗生肽识别抗菌性活动</li><li>模型的结构：结合了卷积层和循环神经网络层</li><li>输入数据的处理：embeding layer的处理</li><li>Reduced alphabet model analysis</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;文章信息&quot;&gt;&lt;a href=&quot;#文章信息&quot; class=&quot;headerlink&quot; title=&quot;文章信息&quot;&gt;&lt;/a&gt;文章信息&lt;/h2&gt;&lt;p&gt;题目：Deep learning improves antimicrobial peptide recognition&lt;/p&gt;
&lt;p&gt;杂志：Bioinformatics&lt;/p&gt;
&lt;p&gt;IF: 5.610 (2019)&lt;/p&gt;
&lt;p&gt;时间：24 march, 2018&lt;/p&gt;
&lt;p&gt;链接：doi: 10.1093/bioinformatics/bty179&lt;/p&gt;
&lt;h2 id=&quot;一句话评价&quot;&gt;&lt;a href=&quot;#一句话评价&quot; class=&quot;headerlink&quot; title=&quot;一句话评价&quot;&gt;&lt;/a&gt;一句话评价&lt;/h2&gt;&lt;p&gt;通过卷积网络层和循环神经网络层组合构建的深度学习模型识别抗生肽。&lt;/p&gt;
    
    </summary>
    
      <category term="literature" scheme="http://yoursite.com/categories/literature/"/>
    
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
      <category term="CNN" scheme="http://yoursite.com/tags/CNN/"/>
    
      <category term="AMP" scheme="http://yoursite.com/tags/AMP/"/>
    
      <category term="LSTM" scheme="http://yoursite.com/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>基因组变异的理解和分析</title>
    <link href="http://yoursite.com/2020/10/21/e3914e23.html"/>
    <id>http://yoursite.com/2020/10/21/e3914e23.html</id>
    <published>2020-10-21T19:56:05.000Z</published>
    <updated>2020-10-21T21:21:10.497Z</updated>
    
    <content type="html"><![CDATA[<h3 id="什么是遗传变异"><a href="#什么是遗传变异" class="headerlink" title="什么是遗传变异"></a>什么是遗传变异</h3><p>遗传变异（genetic variation）是指一个群体中个体之间DNA序列的差异。变异可发生在生殖细胞（即精子和卵子）中，也发生在体细胞(所有其他)中。只有在生殖细胞中产生的变异才能从一个个体遗传给另一个个体，从而影响种群的动态，并最终影响进化。</p><p><strong>突变（Mutation）和重组（Recombination）</strong>是变异的主要来源。</p><h3 id="遗传变异的类型"><a href="#遗传变异的类型" class="headerlink" title="遗传变异的类型"></a>遗传变异的类型</h3><ul><li><p><strong>点突变Single base-pair mutation</strong></p><p>只有一个碱基发生了替换，具体包括Transition和Transversion。Transition指嘌呤(A/G)之间或嘧啶(T/C)之间的替换。Transversion指嘌呤和嘧啶间的替换。</p></li><li><p><strong>插入/缺失（Indel）</strong></p><p>主要指在基因组某个位置上发生较短长度的<strong>线性片段</strong>插入或者删除的现象。强调<strong>线性</strong>的原因是，这里的插入和删除是<strong>有前后顺序的</strong>与下述的结构性变异不同。Indel长度通常在50bp以下，更多时候甚至是不超过10bp，这个长度范围内的序列变化可以通过Smith-Waterman 的局部比对算法来<strong>准确</strong>获得，并且也能够在目前短读长的测序数据中较好地检测出来。</p></li><li><p><strong>结构变异</strong></p><p>通常就是指基因组上大长度的序列变化和位置关系变化。类型很多，包括长度在50bp以上的长片段序列插入或者删除（Big Indel）、串联重复（Tandem repeate）、染色体倒位（Inversion）、染色体内部或染色体之间的序列易位（Translocation）、拷贝数变异（CNV）以及形式更为复杂的嵌合性变异。1Kb与3Mb之间的序列，包括插入、缺失、拷贝数变异、倒位和易位。</p></li></ul><a id="more"></a><h3 id="变异的鉴定和分析"><a href="#变异的鉴定和分析" class="headerlink" title="变异的鉴定和分析"></a>变异的鉴定和分析</h3><p>变异的鉴定主要分为两个步骤：<strong>比对和variants calling</strong></p><ul><li><p><strong>比对</strong></p><p>​    常用的软件有：BWA，Bowtie2。将质控后的数据(fastq)比对到参考基因组上，得到比对后的reads（bam或CRAM格式）。</p></li><li><p><strong>variants calling</strong></p><p>常用的软件有GATK, bcftools, FreeBays等，这里的variants通常只包含SNPs和Indels，最终得到vcf格式的文件。</p></li></ul><p><img src="/2020/10/21/e3914e23/image-20201021223957905.png" alt="image-20201021223957905"></p><ul><li><p><strong>vcf文件格式介绍</strong></p><p>vcf是<strong>Variant Call Format</strong>的简称，即是变异文件储存的标准格式。下图是E.coli 变异分析的vcf文件示例。</p><ul><li>CHROM： 染色体，由于E.coli是一个环形的基因组，这里没有区分染色体</li><li>POS: 变异位点</li><li>REF: 参考基因组位点的碱基</li><li>ALT：个体变异位点的碱基</li><li>QUAL：质量</li><li>FILTER：如果使用GATK过滤后，会对通过过滤的变异位点有PASS的标签</li><li>INFO: 这一栏包含的信息较多，其中<ul><li>DP：表示覆盖在这个位点的总reads数，也就是这个位点的测序深度</li><li>GT: 表示genotype，通常用”/” or “|”分隔两个数字，“|”phase过也就是杂合的两个等位基因知道哪个等位基因来自哪条染色体；0代表参考基因组的碱基类型；1代表ALT碱基类型的第一个碱基（多个碱基用”,”分隔），2代表ALT第二个碱基，以此类推；比如 REF列为：A， ALT列为G,T；那么0/1基因型为AG 杂合，1/1基因型为GG纯合SNP；1/2代表GT基因型；./.表示缺失。</li></ul></li></ul></li></ul><p><img src="/2020/10/21/e3914e23/image-20201021225018928.png" alt="image-20201021225018928" style="zoom:50%;"></p><h3 id="变异分析常用的工具：bcftools-amp-vcftools"><a href="#变异分析常用的工具：bcftools-amp-vcftools" class="headerlink" title="变异分析常用的工具：bcftools &amp; vcftools"></a>变异分析常用的工具：bcftools &amp; vcftools</h3><h4 id="bcftools的部分功能介绍"><a href="#bcftools的部分功能介绍" class="headerlink" title="bcftools的部分功能介绍"></a>bcftools的部分功能介绍</h4><ul><li><p>Calling Variants</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bcftools mpileup -f REF.fa sample.sorted.bam | bcftools call -vm -Oz &gt; sample.vcf.gz</span><br></pre></td></tr></table></figure></li><li><p>提取等位基因和基因型信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bcftools query -f '%CHROM %POS %REF %ALT [%TGT]\n' query.vcf.gz -o query.extract.txt</span><br></pre></td></tr></table></figure></li></ul><ul><li>变异位点的基本统计分析</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bcftools stats sample.vcf &gt; sample.vcf.stats</span><br><span class="line">plot-vcfstats sample.vcf.stats -p sample.vcf.stats.plot_output</span><br></pre></td></tr></table></figure><p><img src="/2020/10/21/e3914e23/image-20201021231029324.png" alt="image-20201021231029324" style="zoom:50%;"></p><p><img src="/2020/10/21/e3914e23/image-20201021231018278.png" alt="image-20201021231018278" style="zoom:50%;"></p><h4 id="vcftools的部分功能介绍"><a href="#vcftools的部分功能介绍" class="headerlink" title="vcftools的部分功能介绍"></a>vcftools的部分功能介绍</h4><ul><li><p>vcf文件的过滤</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vcftools --vcf sample.vcf --minDP 4 --max-missing 0.2 --minQ 30 --recode --recode-INFO-all --out filter</span><br></pre></td></tr></table></figure><p><code>max-missing 0.5</code>: 过滤低于50％的基因型</p><p><code>--minDP 4</code>:过滤depth低于4的reads<br><code>--recode</code>: 标志告诉程序使用过滤器写入一个新的vcf文件，<code>--recode-INFO-all</code>保留旧vcf文件中的所有INFO标志。</p><p><code>--out</code> 输出的文件名称的前缀</p></li><li><p>拆分SNPs和Indels</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## 保留SNPs</span></span></span><br><span class="line">vcftools --vcf filter.recode.vcf --remove-indels --recode --recode-INFO-all --out filter.snps </span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## 保留Indels</span></span></span><br><span class="line">vcftools --vcf filter.recode.vcf --keep-only-indels --recode --recode-INFO-all --out filter.indels</span><br></pre></td></tr></table></figure></li></ul><p>###参考</p><ul><li><a href="https://www.ebi.ac.uk/training-beta/online/courses/human-genetic-variation-introduction/what-is-genetic-variation/" target="_blank" rel="noopener">Human Genetic Variation</a></li><li><a href="https://www.omicsclass.com/article/6" target="_blank" rel="noopener">看懂变异记录结果文件（VCF）</a></li><li><a href="https://www.jianshu.com/p/957efb50108f" target="_blank" rel="noopener">VCF格式</a></li><li><a href="https://luansheng.netlify.app/2019/08/29/how-to-use-bcftools/" target="_blank" rel="noopener">bcftools使用笔记</a></li><li>vcftools: <a href="http://vcftools.sourceforge.net/man_latest.html" target="_blank" rel="noopener">http://vcftools.sourceforge.net/man_latest.html</a></li><li>bcftools: <a href="http://samtools.github.io/bcftools/bcftools.html" target="_blank" rel="noopener">http://samtools.github.io/bcftools/bcftools.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;什么是遗传变异&quot;&gt;&lt;a href=&quot;#什么是遗传变异&quot; class=&quot;headerlink&quot; title=&quot;什么是遗传变异&quot;&gt;&lt;/a&gt;什么是遗传变异&lt;/h3&gt;&lt;p&gt;遗传变异（genetic variation）是指一个群体中个体之间DNA序列的差异。变异可发生在生殖细胞（即精子和卵子）中，也发生在体细胞(所有其他)中。只有在生殖细胞中产生的变异才能从一个个体遗传给另一个个体，从而影响种群的动态，并最终影响进化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;突变（Mutation）和重组（Recombination）&lt;/strong&gt;是变异的主要来源。&lt;/p&gt;
&lt;h3 id=&quot;遗传变异的类型&quot;&gt;&lt;a href=&quot;#遗传变异的类型&quot; class=&quot;headerlink&quot; title=&quot;遗传变异的类型&quot;&gt;&lt;/a&gt;遗传变异的类型&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;点突变Single base-pair mutation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;只有一个碱基发生了替换，具体包括Transition和Transversion。Transition指嘌呤(A/G)之间或嘧啶(T/C)之间的替换。Transversion指嘌呤和嘧啶间的替换。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;插入/缺失（Indel）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;主要指在基因组某个位置上发生较短长度的&lt;strong&gt;线性片段&lt;/strong&gt;插入或者删除的现象。强调&lt;strong&gt;线性&lt;/strong&gt;的原因是，这里的插入和删除是&lt;strong&gt;有前后顺序的&lt;/strong&gt;与下述的结构性变异不同。Indel长度通常在50bp以下，更多时候甚至是不超过10bp，这个长度范围内的序列变化可以通过Smith-Waterman 的局部比对算法来&lt;strong&gt;准确&lt;/strong&gt;获得，并且也能够在目前短读长的测序数据中较好地检测出来。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;结构变异&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通常就是指基因组上大长度的序列变化和位置关系变化。类型很多，包括长度在50bp以上的长片段序列插入或者删除（Big Indel）、串联重复（Tandem repeate）、染色体倒位（Inversion）、染色体内部或染色体之间的序列易位（Translocation）、拷贝数变异（CNV）以及形式更为复杂的嵌合性变异。1Kb与3Mb之间的序列，包括插入、缺失、拷贝数变异、倒位和易位。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Data Sciences" scheme="http://yoursite.com/categories/Data-Sciences/"/>
    
    
      <category term="software" scheme="http://yoursite.com/tags/software/"/>
    
      <category term="Genome Variants" scheme="http://yoursite.com/tags/Genome-Variants/"/>
    
  </entry>
  
  <entry>
    <title>python实现的一些数据预处理</title>
    <link href="http://yoursite.com/2020/09/12/2d57b01f.html"/>
    <id>http://yoursite.com/2020/09/12/2d57b01f.html</id>
    <published>2020-09-12T19:35:02.000Z</published>
    <updated>2020-09-12T21:09:41.639Z</updated>
    
    <content type="html"><![CDATA[<p>利用python进行数据分析和计算时，经常用到两种数据类型：数据框(DataFrame)和数组（array)。两种数据类型的转换、多个数据的合并以及计算数据中的最值等问题是频率较高的操作。下面介绍解决这些问题的方法。</p><p>首先导入python中最常用的数据处理两个模块：numpy模块、pandas模块。然后创建一个DataFrame类型数据df，两个数组arr1和arr2。</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"> </span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">'A'</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],<span class="string">'B'</span>:[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],<span class="string">'C'</span>:[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]&#125;)</span><br><span class="line">arr1= np.array([[<span class="number">21</span>,<span class="number">22</span>,<span class="number">23</span>], [<span class="number">24</span>,<span class="number">25</span>,<span class="number">26</span>]])</span><br><span class="line">arr2 = np.array([[<span class="number">27</span>,<span class="number">28</span>,<span class="number">29</span>], [<span class="number">31</span>,<span class="number">32</span>,<span class="number">33</span>]])</span><br></pre></td></tr></table></figure><h3 id="数据类型转换"><a href="#数据类型转换" class="headerlink" title="数据类型转换"></a>数据类型转换</h3><h4 id="1-DataFrame转换为array"><a href="#1-DataFrame转换为array" class="headerlink" title="(1) DataFrame转换为array"></a>(1) DataFrame转换为array</h4><ul><li>使用DataFrame中的values方法</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>df</span><br><span class="line">   A  B  C</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">4</span>  <span class="number">7</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  <span class="number">5</span>  <span class="number">8</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">6</span>  <span class="number">9</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(df)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>'&gt;</span></span><br><span class="line"><span class="class"></span></span><br><span class="line">&gt;&gt;&gt; df_arr = df.values</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df_arr</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">4</span>, <span class="number">7</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">5</span>, <span class="number">8</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">6</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(df_arr)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">numpy</span>.<span class="title">ndarray</span>'&gt;</span></span><br></pre></td></tr></table></figure><ul><li>使用Numpy中的array方法</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>df_arr2 = np.array(df)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df_arr2</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">4</span>, <span class="number">7</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">5</span>, <span class="number">8</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">6</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(df_arr2)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">numpy</span>.<span class="title">ndarray</span>'&gt;</span></span><br></pre></td></tr></table></figure><h4 id="2-array转换为Data-Frame"><a href="#2-array转换为Data-Frame" class="headerlink" title="(2) array转换为Data Frame"></a>(2) array转换为Data Frame</h4><p>使用Pandas 的DataFrame方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>df2 = pd.DataFrame(df_arr)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df2</span><br><span class="line">   <span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span></span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">4</span>  <span class="number">7</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  <span class="number">5</span>  <span class="number">8</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">6</span>  <span class="number">9</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(df2)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>'&gt;</span></span><br></pre></td></tr></table></figure><h3 id="数据合并、拼接"><a href="#数据合并、拼接" class="headerlink" title="数据合并、拼接"></a>数据合并、拼接</h3><p>数据合并常见的情况有两个数据框或数组进行水平或垂直方向的合并。</p><h4 id="（1）-DataFrame的合并"><a href="#（1）-DataFrame的合并" class="headerlink" title="（1） DataFrame的合并"></a>（1） DataFrame的合并</h4><p>方法有：</p><ul><li>pandas的<strong>merge函数</strong></li></ul><p><code>df = pd.merge(df1, df2, how=&#39;left&#39;, on=&#39;id&#39;)</code></p><p><code>how=&#39;left&#39;</code>  表示以df1为基准数据，<code>on=&#39;id&#39;</code>表示合并时的索引ID</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>df1</span><br><span class="line">   A  B  C</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">4</span>  <span class="number">7</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  <span class="number">5</span>  <span class="number">8</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">6</span>  <span class="number">9</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df2</span><br><span class="line">   A   D   E</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">40</span>  <span class="number">70</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  <span class="number">50</span>  <span class="number">80</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">60</span>  <span class="number">90</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df3 = pd.merge(df1, df2, how=<span class="string">'left'</span>, on=<span class="string">'A'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df3</span><br><span class="line">   A  B  C   D   E</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">4</span>  <span class="number">7</span>  <span class="number">40</span>  <span class="number">70</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  <span class="number">5</span>  <span class="number">8</span>  <span class="number">50</span>  <span class="number">80</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">6</span>  <span class="number">9</span>  <span class="number">60</span>  <span class="number">90</span></span><br></pre></td></tr></table></figure><ul><li>pandas的<strong>concat函数</strong></li></ul><p><code>df = pd.concat(df1,df2, axis )</code>, axis=1表示列拼接，axis=0表示行拼接</p><p>只是简单的只进行数据拼接，并不进行去除差异或相似的操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>df4 = pd.concat([df1,df2],axis=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df4</span><br><span class="line">   A    B    C     D     E</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">4.0</span>  <span class="number">7.0</span>   NaN   NaN</span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  <span class="number">5.0</span>  <span class="number">8.0</span>   NaN   NaN</span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">6.0</span>  <span class="number">9.0</span>   NaN   NaN</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  NaN  NaN  <span class="number">40.0</span>  <span class="number">70.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  NaN  NaN  <span class="number">50.0</span>  <span class="number">80.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  NaN  NaN  <span class="number">60.0</span>  <span class="number">90.0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df5 = pd.concat([df1,df2],axis=<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df5</span><br><span class="line">   A  B  C  A   D   E</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">4</span>  <span class="number">7</span>  <span class="number">1</span>  <span class="number">40</span>  <span class="number">70</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  <span class="number">5</span>  <span class="number">8</span>  <span class="number">2</span>  <span class="number">50</span>  <span class="number">80</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">6</span>  <span class="number">9</span>  <span class="number">3</span>  <span class="number">60</span>  <span class="number">90</span></span><br></pre></td></tr></table></figure><h4 id="2-Array的合并"><a href="#2-Array的合并" class="headerlink" title="(2) Array的合并"></a>(2) Array的合并</h4><p>方法包括以下几种，常见的有concatenate, stack,hstack和vastack</p><p><img src="/2020/09/12/2d57b01f/image-20200912224933250.png" alt="image-20200912224933250"></p><p><strong>原始数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr1= np.array([[<span class="number">21</span>,<span class="number">22</span>,<span class="number">23</span>], [<span class="number">24</span>,<span class="number">25</span>,<span class="number">26</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr2 = np.array([[<span class="number">27</span>,<span class="number">28</span>,<span class="number">29</span>], [<span class="number">31</span>,<span class="number">32</span>,<span class="number">33</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr1</span><br><span class="line">array([[<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>],</span><br><span class="line">       [<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr2</span><br><span class="line">array([[<span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>],</span><br><span class="line">       [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(arr1)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">numpy</span>.<span class="title">ndarray</span>'&gt;</span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">type</span><span class="params">(arr2)</span></span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> '<span class="title">numpy</span>.<span class="title">ndarray</span>'&gt;</span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">arr1</span>.<span class="title">shape</span></span></span><br><span class="line"><span class="class"><span class="params">(<span class="number">2</span>, <span class="number">3</span>)</span></span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">arr2</span>.<span class="title">shape</span></span></span><br><span class="line"><span class="class"><span class="params">(<span class="number">2</span>, <span class="number">3</span>)</span></span></span><br></pre></td></tr></table></figure><ul><li><p><strong>concatenate</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; arr3=np.concatenate((arr1, arr2)) # 默认axis=0，行方向合并</span><br><span class="line">&gt;&gt;&gt; arr3</span><br><span class="line">array([[21, 22, 23],</span><br><span class="line">       [24, 25, 26],</span><br><span class="line">       [27, 28, 29],</span><br><span class="line">       [31, 32, 33]])</span><br><span class="line">&gt;&gt;&gt; arr3.shape</span><br><span class="line">(4, 3)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; arr4=np.concatenate((arr1, arr2),axis=1)</span><br><span class="line">&gt;&gt;&gt; arr4</span><br><span class="line">array([[21, 22, 23, 27, 28, 29],</span><br><span class="line">       [24, 25, 26, 31, 32, 33]])</span><br></pre></td></tr></table></figure></li></ul><ul><li><strong>stack</strong></li></ul><p><code>np.stack(())</code>合并后的数据是多个数组，纬度增加。参数axis默认值为0.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr5 = np.stack((arr1, arr2))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr5</span><br><span class="line">array([[[<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>]],</span><br><span class="line"></span><br><span class="line">       [[<span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>],</span><br><span class="line">        [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr5.shape</span><br><span class="line">(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr6 = np.stack((arr1, arr2),axis=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr6</span><br><span class="line">array([[[<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>]],</span><br><span class="line"></span><br><span class="line">       [[<span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>],</span><br><span class="line">        [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr6.shape</span><br><span class="line">(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr7 = np.stack((arr1, arr2),axis=<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr7</span><br><span class="line">array([[[<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>]],</span><br><span class="line"></span><br><span class="line">       [[<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>],</span><br><span class="line">        [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>]]])</span><br></pre></td></tr></table></figure><ul><li><strong>hstack</strong>：水平合并, 数组纬度没变</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.hstack((arr1,arr2))</span><br><span class="line">array([[<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>],</span><br><span class="line">       [<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>, <span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>]])</span><br></pre></td></tr></table></figure><ul><li><strong>vstack</strong>：垂直合并，数组纬度没变</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.vstack((arr1,arr2))</span><br><span class="line">array([[<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>],</span><br><span class="line">       [<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>],</span><br><span class="line">       [<span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>],</span><br><span class="line">       [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>]])</span><br></pre></td></tr></table></figure><h3 id="最值"><a href="#最值" class="headerlink" title="最值"></a>最值</h3><p>使用numpy的max/min函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr1</span><br><span class="line">array([[<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>],</span><br><span class="line">       [<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.max(arr1)</span><br><span class="line"><span class="number">26</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.max(arr1,axis=<span class="number">0</span>)</span><br><span class="line">array([<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.max(arr1,axis=<span class="number">1</span>)</span><br><span class="line">array([<span class="number">23</span>, <span class="number">26</span>])</span><br></pre></td></tr></table></figure><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://blog.csdn.net/guofei_fly/article/details/85485173?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param" target="_blank" rel="noopener">Numpy中的数组拼接、合并操作</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;利用python进行数据分析和计算时，经常用到两种数据类型：数据框(DataFrame)和数组（array)。两种数据类型的转换、多个数据的合并以及计算数据中的最值等问题是频率较高的操作。下面介绍解决这些问题的方法。&lt;/p&gt;
&lt;p&gt;首先导入python中最常用的数据处理两个模块：numpy模块、pandas模块。然后创建一个DataFrame类型数据df，两个数组arr1和arr2。&lt;/p&gt;
    
    </summary>
    
      <category term="Data Sciences" scheme="http://yoursite.com/categories/Data-Sciences/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="data preprocessing" scheme="http://yoursite.com/tags/data-preprocessing/"/>
    
  </entry>
  
  <entry>
    <title>两个文件的异同</title>
    <link href="http://yoursite.com/2020/06/28/13171.html"/>
    <id>http://yoursite.com/2020/06/28/13171.html</id>
    <published>2020-06-28T18:15:28.000Z</published>
    <updated>2020-09-12T09:49:57.647Z</updated>
    
    <content type="html"><![CDATA[<h3 id="comm-diff-和-grep"><a href="#comm-diff-和-grep" class="headerlink" title="comm, diff 和 grep"></a>comm, diff 和 grep</h3><p>基于comm, diff和grep的用法总结</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">comm A B</span><br><span class="line">diff A B</span><br><span class="line">grep -f A B</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="comm"><a href="#comm" class="headerlink" title="comm"></a>comm</h3><p><strong>comm</strong>是对两个已经<strong>有序</strong>的文件进行比较，可以比较输出：仅在A中出现的、仅在B中出现的、在两个文件中都存在的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">comm -1 A B 不显示在A文件中独有内容(显示B文件独有内容+两个文件共有)</span><br><span class="line">comm -2 A B 不显示在B文件中独有内容</span><br><span class="line">comm -3 A B 不显示同时在两个文件中都存在的内容</span><br><span class="line">comm -12 A B 显示A与B公共的部分</span><br><span class="line">comm -23 A B 显示A独有的</span><br><span class="line">comm -13 A B 显示B独有的</span><br></pre></td></tr></table></figure><p><img src="/2020/06/28/13171/fig1.png" alt="image.png" style="zoom:50%;"></p><h3 id="diff"><a href="#diff" class="headerlink" title="diff"></a><strong>diff</strong></h3><p>diff是比较两个文件之间的不同，给出使两个一致的建议，diff有前后顺序，前面的为旧文件，后面的为新文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">diff A B  直接显示两个文件不同，并给出修改一致的建议(主要是对旧文件的建议)</span><br><span class="line">diff -c A B  通过显示两个文件上下文，给出两个文件增减或删除信息，同时</span><br><span class="line">diff A B</span><br><span class="line">3,4c3,6</span><br><span class="line">&lt; c</span><br><span class="line">&lt; d</span><br><span class="line">---</span><br><span class="line">&gt; e</span><br><span class="line">&gt; f</span><br><span class="line">&gt; g</span><br><span class="line">&gt; h</span><br></pre></td></tr></table></figure><h3 id="grep"><a href="#grep" class="headerlink" title="grep"></a>grep</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">grep -v -f a b  从b中剔除a中有的,即b中特有的</span><br><span class="line">grep -v -f b a  从a中剔除b中有的,即a中特有的</span><br><span class="line">grep -v -f A B</span><br><span class="line">e</span><br><span class="line">f</span><br><span class="line">g</span><br><span class="line">h</span><br><span class="line">grep -v -f  B A</span><br><span class="line">c</span><br><span class="line">d</span><br></pre></td></tr></table></figure><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://www.jianshu.com/p/5ab86345b6bf" target="_blank" rel="noopener">https://www.jianshu.com/p/5ab86345b6bf</a></p><p><a href="https://blog.csdn.net/hit_hlj_sgy/article/details/20625527" target="_blank" rel="noopener">https://blog.csdn.net/hit_hlj_sgy/article/details/20625527</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;comm-diff-和-grep&quot;&gt;&lt;a href=&quot;#comm-diff-和-grep&quot; class=&quot;headerlink&quot; title=&quot;comm, diff 和 grep&quot;&gt;&lt;/a&gt;comm, diff 和 grep&lt;/h3&gt;&lt;p&gt;基于comm, diff和grep的用法总结&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;comm A B&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;diff A B&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;grep -f A B&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="shell" scheme="http://yoursite.com/tags/shell/"/>
    
      <category term="text processing" scheme="http://yoursite.com/tags/text-processing/"/>
    
  </entry>
  
  <entry>
    <title>Linux shell 字符穿操作</title>
    <link href="http://yoursite.com/2020/06/28/17442.html"/>
    <id>http://yoursite.com/2020/06/28/17442.html</id>
    <published>2020-06-28T18:15:10.000Z</published>
    <updated>2020-09-12T09:49:57.626Z</updated>
    
    <content type="html"><![CDATA[<h3 id="截取"><a href="#截取" class="headerlink" title="截取"></a>截取</h3><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">word=abcd-//master-01://httpab</span><br></pre></td></tr></table></figure><h4 id="从左向右"><a href="#从左向右" class="headerlink" title="从左向右:"></a>从左向右:</h4><p><strong>截取第一个//后的字符串</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word#*//&#125;</span><br><span class="line"># master-01://httpab</span><br></pre></td></tr></table></figure><p><strong>截取最后一个//后的字符串</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word##*//&#125; </span><br><span class="line">httpab</span><br></pre></td></tr></table></figure><a id="more"></a><h4 id="从右向左"><a href="#从右向左" class="headerlink" title="从右向左: %"></a>从右向左: %</h4><p><strong>截取第一个//后的字符串</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word%//*&#125; </span><br><span class="line">abcd-//master-01:</span><br></pre></td></tr></table></figure><p><strong>截取第二个//后的字符串</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word%%//*&#125; </span><br><span class="line">abcd-</span><br></pre></td></tr></table></figure><h4 id="截取特定序列位置的字符"><a href="#截取特定序列位置的字符" class="headerlink" title="截取特定序列位置的字符"></a>截取特定序列位置的字符</h4><p><strong>前3个字符</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word:0:3&#125;</span><br></pre></td></tr></table></figure><p><strong>第2到5的字符</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word:1:4&#125;</span><br><span class="line">bcd-</span><br></pre></td></tr></table></figure><p><strong>从第二个字符到末尾</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word:1&#125;</span><br><span class="line">bcd-//master-01://httpab</span><br></pre></td></tr></table></figure><h3 id="替换-before-after"><a href="#替换-before-after" class="headerlink" title="替换:/before/after"></a>替换:/before/after</h3><h4 id="将第一个ab替换为AB"><a href="#将第一个ab替换为AB" class="headerlink" title="将第一个ab替换为AB"></a>将第一个ab替换为AB</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word/#ab/AB&#125; </span><br><span class="line">或 echo $&#123;word/ab/AB&#125; </span><br><span class="line">ABcd-//master-01://httpab</span><br></pre></td></tr></table></figure><h4 id="从左到右，匹配第一个，替换-为cd"><a href="#从左到右，匹配第一个，替换-为cd" class="headerlink" title="从左到右，匹配第一个，替换//为cd"></a>从左到右，匹配第一个，替换//为cd</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word/\/\//cd&#125;</span><br><span class="line">abcd-cdmaster-01://httpab</span><br></pre></td></tr></table></figure><h4 id="将所有匹配的-替换为cd"><a href="#将所有匹配的-替换为cd" class="headerlink" title="将所有匹配的//替换为cd"></a>将所有匹配的//替换为cd</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word//\/\//cd&#125;</span><br><span class="line">abcd-cdmaster-01:cdhttpab</span><br></pre></td></tr></table></figure><h4 id="后缀匹配"><a href="#后缀匹配" class="headerlink" title="后缀匹配"></a>后缀匹配</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">word=abcd-//master-01://httpab</span><br><span class="line">echo $&#123;word/%http*/xy&#125; </span><br><span class="line"># 输出:abcd-//master-01://xy</span><br><span class="line">echo $&#123;word/%ab/xy&#125;</span><br><span class="line"># 输出:abcd-//master-01://httpxy</span><br><span class="line">echo $&#123;word/%ab*/xy&#125;</span><br><span class="line"># 出现*，会从起始匹配</span><br><span class="line"># 输出:xy</span><br></pre></td></tr></table></figure><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 删除前3个字符</span><br><span class="line">echo $&#123;word#*$&#123;word:0:3&#125;&#125; </span><br><span class="line"># 删除后3个字符</span><br><span class="line">echo $&#123;word%*$&#123;word:(-3)&#125;&#125;</span><br><span class="line"># 删除第一个ab</span><br><span class="line">echo $&#123;word/ab/&#125; </span><br><span class="line">删除所有ab</span><br><span class="line">echo $&#123;word//ab/&#125;</span><br></pre></td></tr></table></figure><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://blog.csdn.net/qq_23091073/article/details/83066518" target="_blank" rel="noopener">https://blog.csdn.net/qq_23091073/article/details/83066518</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;截取&quot;&gt;&lt;a href=&quot;#截取&quot; class=&quot;headerlink&quot; title=&quot;截取&quot;&gt;&lt;/a&gt;截取&lt;/h3&gt;&lt;h4 id=&quot;示例&quot;&gt;&lt;a href=&quot;#示例&quot; class=&quot;headerlink&quot; title=&quot;示例&quot;&gt;&lt;/a&gt;示例&lt;/h4&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;word=abcd-//master-01://httpab&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h4 id=&quot;从左向右&quot;&gt;&lt;a href=&quot;#从左向右&quot; class=&quot;headerlink&quot; title=&quot;从左向右:&quot;&gt;&lt;/a&gt;从左向右:&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;截取第一个//后的字符串&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;echo $&amp;#123;word#*//&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# master-01://httpab&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;截取最后一个//后的字符串&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;echo $&amp;#123;word##*//&amp;#125; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;httpab&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="shell" scheme="http://yoursite.com/tags/shell/"/>
    
      <category term="text processing" scheme="http://yoursite.com/tags/text-processing/"/>
    
  </entry>
  
  <entry>
    <title>不同服务器间以及服务器与本地的文件传输</title>
    <link href="http://yoursite.com/2020/06/28/28636.html"/>
    <id>http://yoursite.com/2020/06/28/28636.html</id>
    <published>2020-06-28T18:14:51.000Z</published>
    <updated>2020-09-12T09:49:57.647Z</updated>
    
    <content type="html"><![CDATA[<p>前提是在同一网络下，可以使用 <code>scp</code> 命令。</p><p>如：</p><h3 id="两服务器间的传输"><a href="#两服务器间的传输" class="headerlink" title="两服务器间的传输"></a>两服务器间的传输</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp user1@server_addess_ip:/file_adderess user2@server2_address_ip</span><br><span class="line">## eg:</span><br><span class="line">scp root@192.168.8.138:/home/ligh/index.php root@192.168.8.139:/root</span><br></pre></td></tr></table></figure><h3 id="服务器和本地间的传输"><a href="#服务器和本地间的传输" class="headerlink" title="服务器和本地间的传输"></a>服务器和本地间的传输</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">user1@server_addess_ip:/file_adderess /d</span><br><span class="line"></span><br><span class="line">## eg:</span><br><span class="line">scp root@192.168.8.138:/home/ligh/index.php /d/data</span><br></pre></td></tr></table></figure><h3 id="指定端口非22的传输"><a href="#指定端口非22的传输" class="headerlink" title="指定端口非22的传输"></a>指定端口非22的传输</h3><p>使用  <code>P</code> 参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -P 223  root@192.168.8.13e:/home/strains.tar.gz ./</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前提是在同一网络下，可以使用 &lt;code&gt;scp&lt;/code&gt; 命令。&lt;/p&gt;
&lt;p&gt;如：&lt;/p&gt;
&lt;h3 id=&quot;两服务器间的传输&quot;&gt;&lt;a href=&quot;#两服务器间的传输&quot; class=&quot;headerlink&quot; title=&quot;两服务器间的传输&quot;&gt;&lt;/a&gt;两服务器间的传输&lt;
      
    
    </summary>
    
    
      <category term="shell" scheme="http://yoursite.com/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>Pandas库</title>
    <link href="http://yoursite.com/2020/06/28/45881.html"/>
    <id>http://yoursite.com/2020/06/28/45881.html</id>
    <published>2020-06-28T18:14:01.000Z</published>
    <updated>2020-09-12T09:49:57.627Z</updated>
    
    <content type="html"><![CDATA[<p>Pandas库是基于Numpy库来创建的，Numpy主要用于矩阵操作，而Pandas主要用于数据处理。</p><p>Pandas主要有两种重要的数据结构：Series和DataFrame.</p><ul><li><p>Series: 类似一个一维数组，一个Series对应DataFrame的一列</p></li><li><p>DataFrame:类似一个二维数组，一个DataFrame由几个Series列构成。</p><p><img src="/2020/06/28/45881/fig1.png" style="zoom:50%;"></p></li></ul><p><img src="/2020/06/28/45881/fig1.png" alt="image.png"></p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://zhuanlan.zhihu.com/p/40373125" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/40373125</a></li><li><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html" target="_blank" rel="noopener">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Pandas库是基于Numpy库来创建的，Numpy主要用于矩阵操作，而Pandas主要用于数据处理。&lt;/p&gt;
&lt;p&gt;Pandas主要有两种重要的数据结构：Series和DataFrame.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Series: 类似一个一维数组，一个Series
      
    
    </summary>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>NumPy介绍</title>
    <link href="http://yoursite.com/2020/06/28/49844.html"/>
    <id>http://yoursite.com/2020/06/28/49844.html</id>
    <published>2020-06-28T18:13:50.000Z</published>
    <updated>2020-09-12T09:49:57.627Z</updated>
    
    <content type="html"><![CDATA[<p>Pandas库是基于Numpy库来创建的，Numpy主要用于矩阵操作，而Pandas主要用于数据处理。</p><p>Pandas主要有两种重要的数据结构：Series和DataFrame.</p><ul><li>Series: 类似一个一维数组，一个Series对应DataFrame的一列</li><li>DataFrame:类似一个二维数组，一个DataFrame由几个Series列构成。</li></ul><a id="more"></a><p><img src="/2020/06/28/49844/1591819950732-0cf02f6a-c25b-4ca1-8876-17dc2e63dd9e-20200628202724030.png" alt="image.png"></p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://zhuanlan.zhihu.com/p/40373125" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/40373125</a></li><li><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html" target="_blank" rel="noopener">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Pandas库是基于Numpy库来创建的，Numpy主要用于矩阵操作，而Pandas主要用于数据处理。&lt;/p&gt;
&lt;p&gt;Pandas主要有两种重要的数据结构：Series和DataFrame.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Series: 类似一个一维数组，一个Series对应DataFrame的一列&lt;/li&gt;
&lt;li&gt;DataFrame:类似一个二维数组，一个DataFrame由几个Series列构成。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>R语言中读取含有空白内容的数据</title>
    <link href="http://yoursite.com/2020/06/28/64095.html"/>
    <id>http://yoursite.com/2020/06/28/64095.html</id>
    <published>2020-06-28T18:13:22.000Z</published>
    <updated>2020-09-12T09:49:57.629Z</updated>
    
    <content type="html"><![CDATA[<p><strong>数据内容</strong></p><p><img src="/2020/06/28/64095/1592293564053-baa557ba-9fdb-46ea-b659-dd2b941c6a24.png" alt="image.png"></p><p><strong>导入数据：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test &lt;-read.table(&quot;filename.txt&quot;,header=TRUE）</span><br></pre></td></tr></table></figure><p>  会出现错误：Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, :3行没有2元素</p><p><strong>修改：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test &lt;-read.table(&quot;filename.txt&quot;,header=TRUE,fill=TRUE）</span><br></pre></td></tr></table></figure><p><strong>空值设为NA</strong></p><p><strong><code>na.strings = &quot;&quot;</code></strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test &lt;-read.table(&quot;filename.txt&quot;,header=TRUE, fill=TRUE, na.strings = &quot;&quot;)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;数据内容&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/06/28/64095/1592293564053-baa557ba-9fdb-46ea-b659-dd2b941c6a24.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;
      
    
    </summary>
    
    
      <category term="R" scheme="http://yoursite.com/tags/R/"/>
    
  </entry>
  
  <entry>
    <title>apply家族函数的用法</title>
    <link href="http://yoursite.com/2020/06/28/12691.html"/>
    <id>http://yoursite.com/2020/06/28/12691.html</id>
    <published>2020-06-28T18:12:47.000Z</published>
    <updated>2020-09-12T11:40:14.676Z</updated>
    
    <content type="html"><![CDATA[<h3 id="apply家族函数"><a href="#apply家族函数" class="headerlink" title="apply家族函数"></a>apply家族函数</h3><p>apply函数族是R语言中数据处理的一组核心函数，通过使用apply函数，我们可以实现对数据的循环、分组、过滤、类型控制等操作。</p><p><img src="/2020/06/28/12691/fig1.png" style="zoom:50%;"></p><a id="more"></a><h3 id="apply-函数的用法"><a href="#apply-函数的用法" class="headerlink" title="apply 函数的用法"></a>apply 函数的用法</h3><p>常用的apply族函数有apply和sapply。apply函数是最常用的代替for循环的函数。apply函数可以对矩阵、数据框、数组(二维、多维)，按行或列进行循环计算，对子元素进行迭代，并把子元素以参数传递的形式给自定义的FUN函数中，并以返回计算结果。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apply(X, MARGIN, FUN, ...)</span><br></pre></td></tr></table></figure><p>参数列表：</p><ul><li>X:数组、矩阵、数据框</li><li>MARGIN: 按行计算或按按列计算，1表示按行，2表示按列</li><li>FUN: 自定义的调用函数</li><li>…: 更多参数，可选</li></ul><p>如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; x&lt;-matrix(1:12,ncol=3)</span><br><span class="line">&gt; apply(x,1,sum)</span><br><span class="line">[1] 15 18 21 24</span><br></pre></td></tr></table></figure><h3 id><a href="#" class="headerlink" title=" "></a> </h3><h3 id="lapply-函数的用法"><a href="#lapply-函数的用法" class="headerlink" title="lapply 函数的用法"></a>lapply 函数的用法</h3><p>lapply函数是一个最基础循环操作函数之一，用来对list、data.frame数据集进行循环，并返回和X长度同样的list结构作为结果集，通过lapply的开头的第一个字母’l’就可以判断返回结果集的类型。</p><p>函数定义：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lapply(X, FUN, ...)</span><br></pre></td></tr></table></figure><p>参数列表：</p><ul><li>X:list、data.frame数据</li><li>FUN: 自定义的调用函数</li><li>…: 更多参数，可选</li></ul><h3 id="sapply函数的用法"><a href="#sapply函数的用法" class="headerlink" title="sapply函数的用法"></a>sapply函数的用法</h3><p>sapply函数是一个简化版的lapply，sapply增加了2个参数simplify和USE.NAMES，主要就是让输出看起来更友好，返回值为向量，而不是list对象。</p><p>函数定义：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sapply(X, FUN, ..., simplify=TRUE, USE.NAMES = TRUE)</span><br></pre></td></tr></table></figure><p>参数列表：</p><ul><li>X:数组、矩阵、数据框</li><li>FUN: 自定义的调用函数</li><li>…: 更多参数，可选</li><li>simplify: 是否数组化，当值array时，输出结果按数组进行分组</li><li>USE.NAMES: 如果X为字符串，TRUE设置字符串为数据名，FALSE不设置</li></ul><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li>掌握R语言中的apply函数族 <a href="http://blog.fens.me/r-apply/" target="_blank" rel="noopener">http://blog.fens.me/r-apply/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;apply家族函数&quot;&gt;&lt;a href=&quot;#apply家族函数&quot; class=&quot;headerlink&quot; title=&quot;apply家族函数&quot;&gt;&lt;/a&gt;apply家族函数&lt;/h3&gt;&lt;p&gt;apply函数族是R语言中数据处理的一组核心函数，通过使用apply函数，我们可以实现对数据的循环、分组、过滤、类型控制等操作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/06/28/12691/fig1.png&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="R" scheme="http://yoursite.com/tags/R/"/>
    
  </entry>
  
  <entry>
    <title>在R语言中替换空值</title>
    <link href="http://yoursite.com/2020/06/28/6918.html"/>
    <id>http://yoursite.com/2020/06/28/6918.html</id>
    <published>2020-06-28T18:12:21.000Z</published>
    <updated>2020-09-12T09:49:57.667Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>如下图所示，想替换无任何字符，又不是NA的值，替换为0</p><p><img src="/2020/06/28/6918/1590757573945-fb0f1f16-10ad-4e49-8aee-9449b8f23b80.png" alt="image.png"></p><a id="more"></a><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><ul><li>最初的思路是想匹配两个双引号，但是发现这里的双引号是表示观测值是字符串的数据类型，而不是该字符串本身的字符，尝试了很久也没有匹配成功。</li><li>然后想着将nothing的字符串转为NA，然后将NA转换为0，又因为该数据集是matrix类型，方便整列操作，首先将数据转换为数据框</li></ul><p><img src="/2020/06/28/6918/1590758057421-48ea7d94-d247-4ad0-a826-a26bd633c7f4.png" alt="image.png"></p><p>然后将nothing替换为NA</p><p><img src="/2020/06/28/6918/1590758121879-42bed638-730a-4315-b8cc-a10224feb883.png" alt="image.png"></p><p>最后替换为0，但是发现替换不了，虽然这些值确实是NA</p><p><img src="/2020/06/28/6918/1590760122629-c60cffa8-a98d-4e6d-ad9d-5953ef7265bd.png" alt="image.png"></p><p>检查数据格式，这些<na>是factor，所以这里无法替换</na></p><p><img src="/2020/06/28/6918/1590760226503-08c32bea-6295-4149-bcf1-000d74c2393c.png" alt="image.png"></p><p>最终明白问题出现在将matrix转换为data.frame，应该在此时加上 <code>stringsAsFactors = F</code> 的参数</p><p><img src="/2020/06/28/6918/1590760463196-ca4183f7-b955-4a97-b616-fb9ce2635451.png" alt="image.png"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>在读入数据框或者转换为数据框时，记得加上<code>stringsAsFactors = F</code> 的参数</li><li>匹配特定观测值，然后重新赋值，df[df==”value”] &lt;- newvalue</li><li>R处理数据时要注意数据格式</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;如下图所示，想替换无任何字符，又不是NA的值，替换为0&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/06/28/6918/1590757573945-fb0f1f16-10ad-4e49-8aee-9449b8f23b80.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="R" scheme="http://yoursite.com/tags/R/"/>
    
  </entry>
  
  <entry>
    <title>正则表达式初体验</title>
    <link href="http://yoursite.com/2020/06/28/44637.html"/>
    <id>http://yoursite.com/2020/06/28/44637.html</id>
    <published>2020-06-28T18:11:52.000Z</published>
    <updated>2020-09-12T09:49:57.684Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>正则表达式(Regular Expression)在字符串模式匹配，在字符串搜索和替换中展现强大的功能。</p><p>常用的正则表达式语法我将其总结为7类：</p><p>先看一个概括的整理</p><p><img src="/2020/06/28/44637/1590761619931-4e3ce7f4-d158-4883-bb04-ac35bc16f566.png" alt="image.png"></p><a id="more"></a><ul><li><p>字符类**</p></li><li><ul><li><code>\w</code> : 匹配数字和字符</li><li><code>.</code> : 匹配除换行符 \n 之外的任何单字符</li><li><code>[a-z]</code>  和 <code>[A-Z]</code> :匹配从a到z或者A到Z的任意字符</li><li><code>[0-9]</code> : 匹配0到9的任意数字</li></ul></li><li><p><strong>数值类</strong></p></li><li><ul><li><code>\d</code> ：匹配数字</li></ul></li><li><p>分隔符类</p></li><li><ul><li><code>\s</code> : 匹配white space(包括空格、tab等)</li></ul></li><li><p><strong>定位类：在字符类和数值类前面</strong></p></li><li><ul><li><code>^</code> : 字符开头</li><li><code>$</code> ：字符结尾</li><li><code>\b</code> : 单词结界符</li></ul></li><li><p><strong>定量类，包含数值型和特殊符类，放在字符类和数值类后面</strong></p></li><li><ul><li>数值型：{}， 大括号里加数字</li><li><code>*</code> : 0次或多次</li><li><code>+</code> : 1次或多次</li><li><code>?</code> :  0或1次</li></ul></li><li><p><strong>逻辑关系类</strong></p></li><li><ul><li><code>[]</code> ：表示逻辑关系或，比如[abc]表示a或者b或c</li><li><code>(|)</code> :  () 和 | 结合也表示逻辑关系或</li></ul></li><li><p><strong>分组类</strong></p></li><li><ul><li><code>**()**</code> : 用于分组</li></ul></li></ul><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>R语言可以结合gsub使用正则匹配语法</p><p>gsub语法： <code>gsub(&quot;old value 或 pattern&quot;,&quot;new value&quot;,data)</code> </p><p><img src="/2020/06/28/44637/1590763067379-cde65a24-d421-46ef-ab59-c6b5cac4b771.png" alt="image.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;p&gt;正则表达式(Regular Expression)在字符串模式匹配，在字符串搜索和替换中展现强大的功能。&lt;/p&gt;
&lt;p&gt;常用的正则表达式语法我将其总结为7类：&lt;/p&gt;
&lt;p&gt;先看一个概括的整理&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/06/28/44637/1590761619931-4e3ce7f4-d158-4883-bb04-ac35bc16f566.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="shell" scheme="http://yoursite.com/tags/shell/"/>
    
      <category term="text processing" scheme="http://yoursite.com/tags/text-processing/"/>
    
  </entry>
  
  <entry>
    <title>机器学习中如何处理分类变量的不均衡</title>
    <link href="http://yoursite.com/2020/06/28/35362.html"/>
    <id>http://yoursite.com/2020/06/28/35362.html</id>
    <published>2020-06-28T18:09:41.000Z</published>
    <updated>2020-09-12T11:45:42.747Z</updated>
    
    <content type="html"><![CDATA[<p>Imbalanced classes put “accuracy” out of business. This is a surprisingly common problem in machine learning (specifically in classification), occurring in datasets with a disproportionate ratio of observations in each class</p><ul><li><p>Up-sample the minority class</p></li><li><ul><li>resample module with <code>replace = True</code></li></ul></li><li><p>Down-sample the majority class</p></li><li><ul><li>resample module with <code>replace = False</code></li></ul></li><li><p>Change your performance metric</p></li><li><ul><li><strong>Area Under ROC Curve</strong> (AUROC)</li><li><code>from sklearn.metrics import roc_auc_score</code></li></ul></li><li><p>Penalize algorithms (cost-sensitive training)</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SVC(kernel=&apos;linear&apos;, </span><br><span class="line">            class_weight=&apos;balanced&apos;, # penalize</span><br><span class="line">            probability=True)</span><br></pre></td></tr></table></figure><ul><li><p>Use tree-based algorithms</p></li><li><ul><li><code>from sklearn.ensemble import RandomForestClassifier</code></li></ul></li></ul><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn import svm</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.metrics import accuracy_score</span><br><span class="line">from sklearn.utils import resample</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">input = pd.read_csv(&apos;trime_skinput.csv&apos;) # row.names equls numbers</span><br><span class="line">input.trimethoprim_sulfamethoxazole.value_counts()</span><br><span class="line">input_major = input[input.trimethoprim_sulfamethoxazole == &quot;R&quot;]</span><br><span class="line">input_minor = input[input.trimethoprim_sulfamethoxazole == &quot;S&quot;]</span><br><span class="line"></span><br><span class="line">input_minor_upsampled = resample(input_minor,</span><br><span class="line">                                 replace = True,</span><br><span class="line">                                 n_samples = 67,</span><br><span class="line">                                random_state=123)</span><br><span class="line"></span><br><span class="line">input_upsampled = pd.concat([input_major,input_minor_upsampled])</span><br><span class="line">input_upsampled.trimethoprim_sulfamethoxazole.value_counts()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X = input_upsampled.iloc[:,0:19277]</span><br><span class="line">y = input_upsampled.iloc[:,19277:19278]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)</span><br><span class="line"></span><br><span class="line">### train model</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">svclassifier = SVC(kernel=&apos;linear&apos;)</span><br><span class="line"></span><br><span class="line">svclassifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">## predict </span><br><span class="line">y_pred = svclassifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"># evaluation </span><br><span class="line">from sklearn.metrics import classification_report, confusion_matrix</span><br><span class="line">print(confusion_matrix(y_test,y_pred))</span><br><span class="line">print(classification_report(y_test,y_pred))</span><br><span class="line"># upsampling</span><br><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           R       1.00      0.88      0.93        16</span><br><span class="line">           S       0.85      1.00      0.92        11</span><br><span class="line"></span><br><span class="line">    accuracy                           0.93        27</span><br><span class="line">   macro avg       0.92      0.94      0.93        27</span><br><span class="line">weighted avg       0.94      0.93      0.93        27</span><br><span class="line"></span><br><span class="line">## don&apos;t do anything</span><br><span class="line">                precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           R       0.88      1.00      0.93        14</span><br><span class="line">           S       0.00      0.00      0.00         2</span><br><span class="line"></span><br><span class="line">    accuracy                           0.88        16</span><br><span class="line">   macro avg       0.44      0.50      0.47        16</span><br><span class="line">weighted avg       0.77      0.88      0.82        16</span><br></pre></td></tr></table></figure><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li>How to Handle Imbalanced Classes in Machine Learning：<a href="https://elitedatascience.com/imbalanced-classes" target="_blank" rel="noopener">https://elitedatascience.com/imbalanced-classes</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Imbalanced classes put “accuracy” out of business. This is a surprisingly common problem in machine learning (specifically in classification), occurring in datasets with a disproportionate ratio of observations in each class&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Up-sample the minority class&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;ul&gt;
&lt;li&gt;resample module with &lt;code&gt;replace = True&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Down-sample the majority class&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;ul&gt;
&lt;li&gt;resample module with &lt;code&gt;replace = False&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Change your performance metric&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Area Under ROC Curve&lt;/strong&gt; (AUROC)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;from sklearn.metrics import roc_auc_score&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Penalize algorithms (cost-sensitive training)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;SVC(kernel=&amp;apos;linear&amp;apos;, &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            class_weight=&amp;apos;balanced&amp;apos;, # penalize&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            probability=True)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Use tree-based algorithms&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;from sklearn.ensemble import RandomForestClassifier&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>使用Python与Scikit-learn实现随机森林分析</title>
    <link href="http://yoursite.com/2020/06/28/25483.html"/>
    <id>http://yoursite.com/2020/06/28/25483.html</id>
    <published>2020-06-28T18:09:05.000Z</published>
    <updated>2020-09-12T09:49:57.652Z</updated>
    
    <content type="html"><![CDATA[<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li>Understanding Random Forests Classifiers in Python<a href="https://www.datacamp.com/community/tutorials/random-forests-classifier-python" target="_blank" rel="noopener">: //www.datacamp.com/community/tutorials/random-forests-classifier-python</a></li><li>Random Forest Algorithm with Python and Scikit-Learn<a href="https://stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/" target="_blank" rel="noopener">: //stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/</a></li><li>Random Forest in Python<a href="https://towardsdatascience.com/random-forest-in-python-24d0893d51c0" target="_blank" rel="noopener">: //towardsdatascience.com/random-forest-in-python-24d0893d51c0</a></li></ul><h3 id="随机森林（RandomForest）算法"><a href="#随机森林（RandomForest）算法" class="headerlink" title="随机森林（RandomForest）算法"></a>随机森林（RandomForest）算法</h3><p>随机森林属于集成学习（Ensemble Learning）的一类算法，结合了多种相同类型的算法，即多个决策树，从而形成了一个随机森林树。</p><blockquote><p>随即森林是用随机的方式建立一个森林，森林里面有很多的决策树组成，随机森林的每一棵决策树之间是没有关联的。上世纪八十年代Breiman等人发明分类树的算法（Breiman et al. 1984），通过反复二分数据进行分类或回归，计算量大大降低。2001年Breiman把分类树组合成随机森林（Breiman 2001a），即在变量（列）的使用和数据（行）的使用上进行随机化，生成很多分类树，再汇总分类树的结果。随机森林在运算量没有显著提高的前提下提高了预测精度。随机森林对多元公线性不敏感，结果对缺失数据和非平衡的数据比较稳健，可以很好地预测多达几千个解释变量的作用（Breiman 2001b），被誉为当前最好的算法之一（Iverson et al. 2008）。</p><p>参考：<a href="https://zhuanlan.zhihu.com/p/22097796" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/22097796</a></p></blockquote><a id="more"></a><h3 id="随机森林工作原理"><a href="#随机森林工作原理" class="headerlink" title="随机森林工作原理"></a>随机森林工作原理</h3><p><img src="/2020/06/28/25483/1591801985780-f9e9e5e3-2124-4f44-97a6-11217dc66dee.png" alt="image.png"></p><h3 id="随机森林优缺点"><a href="#随机森林优缺点" class="headerlink" title="随机森林优缺点"></a>随机森林优缺点</h3><p><strong>优点</strong></p><ul><li>准确度高</li><li>没有过拟合问题</li><li>可用于分类和回归问题</li><li>可以处理缺失值，一是用中位数代替连续变量，二是计算缺失值的近似加权平均值；也可用于没有归一化的问题</li></ul><p><strong>缺点</strong></p><ul><li>速度慢</li><li>与决策树相比较难解释</li></ul><h3 id="随即森林与决策树"><a href="#随即森林与决策树" class="headerlink" title="随即森林与决策树"></a>随即森林与决策树</h3><ul><li>随机森林是一组多决策树。</li><li>深度决策树可能会出现过拟合，但随机森林通过在随机子集上创建树来防止过拟合。</li><li>决策树的计算速度更快。</li><li>随机森林很难解释，而决策树很容易解释，可以转换为规则。</li></ul><h3 id="利用Scikit-learn实现随即森林的分析"><a href="#利用Scikit-learn实现随即森林的分析" class="headerlink" title="利用Scikit-learn实现随即森林的分析"></a>利用Scikit-learn实现随即森林的分析</h3><p>随机森林通过 <code>RandomForestClassifier</code>实现<strong>分类</strong>问题</p><p>随机森林通过 <code>RandomForestRegressor</code> 实现<strong>回归</strong>问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br></pre></td></tr></table></figure><h3 id="随机森林解决回归问题"><a href="#随机森林解决回归问题" class="headerlink" title="随机森林解决回归问题"></a>随机森林解决回归问题</h3><ul><li>问题</li></ul><p>根据汽油税（美分），人均收入（美元），已铺设的高速公路（以英里为单位）和驾驶执照人口与汽油税的比例，来预测美国48个州的汽油消耗量（百万加仑）。</p><p>数据链接：<a href="https://drive.google.com/file/d/1mVmGNx6cbfvRHC_DvF12ZL3wGLSHD9f_/view" target="_blank" rel="noopener">https://drive.google.com/file/d/1mVmGNx6cbfvRHC_DvF12ZL3wGLSHD9f_/view</a></p><ul><li>读入数据</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset = pd.read_csv(&apos;petrol_consumption.csv&apos;)</span><br><span class="line">dataset.head()</span><br></pre></td></tr></table></figure><p><img src="/2020/06/28/25483/1592223752291-004d252c-0cc7-4d36-90bd-8653ab0932d2.png" alt="image.png"></p><ul><li>数据前处理</li></ul><p>提取’attributes’ 和 ‘label’; 拆分测试数据和训练数据集</p><p>注意：<code>random_state</code> 设置随机数种子，以保证多次运行的结果相同</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X = dataset.iloc[:, 0:4].values</span><br><span class="line">y = dataset.iloc[:, 4].values</span><br><span class="line"></span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)</span><br></pre></td></tr></table></figure><ul><li>数据归一化（Feature Scaling）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Feature Scaling</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">sc = StandardScaler()</span><br><span class="line">X_train = sc.fit_transform(X_train)</span><br><span class="line">X_test = sc.transform(X_test)</span><br></pre></td></tr></table></figure><ul><li>训练模型</li></ul><p>注意：重要参数 <strong><code>n_estimators</code></strong> , 表示随机森林树的数目</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line"></span><br><span class="line">regressor = RandomForestRegressor(n_estimators=20, random_state=0)</span><br><span class="line">regressor.fit(X_train, y_train)</span><br><span class="line">y_pred = regressor.predict(X_test)</span><br></pre></td></tr></table></figure><ul><li>模型评估</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import metrics</span><br><span class="line"></span><br><span class="line">print(&apos;Mean Absolute Error:&apos;, metrics.mean_absolute_error(y_test, y_pred))</span><br><span class="line">print(&apos;Mean Squared Error:&apos;, metrics.mean_squared_error(y_test, y_pred))</span><br><span class="line">print(&apos;Root Mean Squared Error:&apos;, np.sqrt(metrics.mean_squared_error(y_test, y_pred)))</span><br></pre></td></tr></table></figure><p><img src="/2020/06/28/25483/1592224214897-36546d34-1651-44db-8102-eb29912fd01a.png" alt="image.png"></p><p>当参数改为200时，模型评估结果提升了<strong><code>n_estimators=200</code></strong></p><p><img src="/2020/06/28/25483/1592224281077-4a7049c2-c4b7-47b6-8d15-e5cf05aa1fe1.png" alt="image.png"></p><h3 id="随机森林解决分类问题"><a href="#随机森林解决分类问题" class="headerlink" title="随机森林解决分类问题"></a>随机森林解决分类问题</h3><ul><li>问题：根据四个属性（即图像小波变换后的图像的方差，偏度，熵和图像的弯曲度）来预测银行纸币是否真实</li></ul><ul><li>数据：<a href="https://drive.google.com/file/d/13nw-uRXPY8XIZQxKRNZ3yYlho-CYm_Qt/view" target="_blank" rel="noopener">https://drive.google.com/file/d/13nw-uRXPY8XIZQxKRNZ3yYlho-CYm_Qt/view</a></li></ul><ul><li>读入数据</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">dataset = pd.read_csv(&quot;D:/Datasets/bill_authentication.csv&quot;)</span><br><span class="line">dataset.head()</span><br></pre></td></tr></table></figure><p><img src="/2020/06/28/25483/1592224457537-501c6246-7a4e-4ef8-8efa-0a931e9a45a4.png" alt="image.png"></p><ul><li>数据预处理</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = dataset.iloc[:, 0:4].values</span><br><span class="line">y = dataset.iloc[:, 4].values</span><br></pre></td></tr></table></figure><p>拆分测试数据和训练数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)</span><br></pre></td></tr></table></figure><ul><li>归一化</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Feature Scaling</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">sc = StandardScaler()</span><br><span class="line">X_train = sc.fit_transform(X_train)</span><br><span class="line">X_test = sc.transform(X_test)</span><br></pre></td></tr></table></figure><ul><li>训练模型</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">regressor = RandomForestClassifier(n_estimators=20, random_state=0)</span><br><span class="line">regressor.fit(X_train, y_train)</span><br><span class="line">y_pred = regressor.predict(X_test)</span><br></pre></td></tr></table></figure><ul><li>模型评估</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import classification_report, confusion_matrix, accuracy_score</span><br><span class="line">print(confusion_matrix(y_test,y_pred))</span><br><span class="line">print(classification_report(y_test,y_pred))</span><br><span class="line">print(accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure><p><img src="/2020/06/28/25483/1592224658958-fa055da7-c285-437a-8580-f3dac49ad06b.png" alt="image.png"></p><p>这里将n_estimators=20 改为200时，结果并没有明显改变</p><p><img src="/2020/06/28/25483/1592224709652-34fa9d3c-e9df-47e6-8001-e99abd86d588.png" alt="image.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;参考资料&quot;&gt;&lt;a href=&quot;#参考资料&quot; class=&quot;headerlink&quot; title=&quot;参考资料&quot;&gt;&lt;/a&gt;参考资料&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Understanding Random Forests Classifiers in Python&lt;a href=&quot;https://www.datacamp.com/community/tutorials/random-forests-classifier-python&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;: //www.datacamp.com/community/tutorials/random-forests-classifier-python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Random Forest Algorithm with Python and Scikit-Learn&lt;a href=&quot;https://stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;: //stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Random Forest in Python&lt;a href=&quot;https://towardsdatascience.com/random-forest-in-python-24d0893d51c0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;: //towardsdatascience.com/random-forest-in-python-24d0893d51c0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;随机森林（RandomForest）算法&quot;&gt;&lt;a href=&quot;#随机森林（RandomForest）算法&quot; class=&quot;headerlink&quot; title=&quot;随机森林（RandomForest）算法&quot;&gt;&lt;/a&gt;随机森林（RandomForest）算法&lt;/h3&gt;&lt;p&gt;随机森林属于集成学习（Ensemble Learning）的一类算法，结合了多种相同类型的算法，即多个决策树，从而形成了一个随机森林树。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;随即森林是用随机的方式建立一个森林，森林里面有很多的决策树组成，随机森林的每一棵决策树之间是没有关联的。上世纪八十年代Breiman等人发明分类树的算法（Breiman et al. 1984），通过反复二分数据进行分类或回归，计算量大大降低。2001年Breiman把分类树组合成随机森林（Breiman 2001a），即在变量（列）的使用和数据（行）的使用上进行随机化，生成很多分类树，再汇总分类树的结果。随机森林在运算量没有显著提高的前提下提高了预测精度。随机森林对多元公线性不敏感，结果对缺失数据和非平衡的数据比较稳健，可以很好地预测多达几千个解释变量的作用（Breiman 2001b），被誉为当前最好的算法之一（Iverson et al. 2008）。&lt;/p&gt;
&lt;p&gt;参考：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/22097796&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://zhuanlan.zhihu.com/p/22097796&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>使用Python与Scikit-learn实现逻辑回归分析</title>
    <link href="http://yoursite.com/2020/06/28/30893.html"/>
    <id>http://yoursite.com/2020/06/28/30893.html</id>
    <published>2020-06-28T18:08:24.000Z</published>
    <updated>2020-09-12T09:49:57.651Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a" target="_blank" rel="noopener">https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a</a></p><p><img src="/2020/06/28/30893/fig-1.png" alt></p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd  </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">input_Cef = pd.read_csv(<span class="string">"input_Cef.csv"</span>)</span><br><span class="line">input_Cef.head()</span><br><span class="line">   </span><br><span class="line">X = input_Cef.iloc[:,<span class="number">1</span>:<span class="number">6027</span>]</span><br><span class="line">y = input_Cef[<span class="string">"Ceftazidim_S.vs.R"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1. Import the model &amp; Splitting Data into Training and Test Sets</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.20</span>,random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make an instance of the Model</span></span><br><span class="line"><span class="comment"># all parameters not specified are set to their defaults</span></span><br><span class="line"><span class="comment"># Changing the solver had a minor effect on accuracy, but at least it was a lot faster</span></span><br><span class="line">logreg = LogisticRegression(solver = <span class="string">'lbfgs'</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 3. Training the model </span></span><br><span class="line">logreg.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Step 4. Predict labels for new data </span></span><br><span class="line">y_pred = logreg.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step5: Measuring Model Performance</span></span><br><span class="line"><span class="comment"># accuracy , precision, recall, F1 Score, ROC Curve</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## accuracy</span></span><br><span class="line">score = logreg.score(X_test, y_test)</span><br><span class="line">print(score)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## precision, recall, F1 Score</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">print(classification_report(y_test, y_pred))</span><br><span class="line"></span><br><span class="line"><span class="comment">## ROC Curve</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">logit_roc_auc2 = roc_auc_score(y_test, y_pred)</span><br><span class="line">probas = logreg.predict_proba(X_test)[:,<span class="number">1</span>]</span><br><span class="line">fpr2, tpr2, thresholds2 = roc_curve(y_test, probas)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(fpr2, tpr2, label=<span class="string">'Logistic Regression for Ceftazidim (area = %0.2f)'</span> % logit_roc_auc2)</span><br><span class="line"><span class="comment">#plt.plot([0, 1], [0, 1],'r--')</span></span><br><span class="line"><span class="comment">#plt.xlim([0.0, 1.0])</span></span><br><span class="line"><span class="comment">#plt.ylim([0.0, 1.05])</span></span><br><span class="line">plt.xlabel(<span class="string">'False Positive Rate'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'True Positive Rate'</span>)</span><br><span class="line">plt.title(<span class="string">'Receiver operating characteristic'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">"lower right"</span>)</span><br><span class="line">plt.savefig(<span class="string">'./Fig2_Log_ROC_Cef.pdf'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/06/28/30893/fig-1.png&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>稀疏矩阵与机器学习</title>
    <link href="http://yoursite.com/2020/06/28/46638.html"/>
    <id>http://yoursite.com/2020/06/28/46638.html</id>
    <published>2020-06-28T18:06:40.000Z</published>
    <updated>2020-09-12T09:49:57.689Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><strong>Introduction to Sparse Matrices for Machine Learning</strong></p></blockquote><h3 id="什么是稀疏矩阵？"><a href="#什么是稀疏矩阵？" class="headerlink" title="什么是稀疏矩阵？"></a>什么是稀疏矩阵？</h3><p>大部分包含零值的矩阵称为稀疏矩阵(sparse Matrices)，相对应的是大多数值非零的密集矩阵(Dense Matrices)。稀疏矩阵在机器学习领域非常常见，如计数类数据，或者one-hot encoding编码的数据等。数据的稀疏性可以通过零值的比例量化（sparsity = count zero elements / total elements）。稀疏矩阵会产生处理时间和存储空间的问题。而<strong>SciPy</strong>提供了很多高效的方法可以直接用于存储和处理稀疏矩阵。</p><p><img src="/2020/06/28/46638/figure-ab.jpg" alt></p><a id="more"></a><h3 id="稀疏矩阵数据处理——SciPy"><a href="#稀疏矩阵数据处理——SciPy" class="headerlink" title="稀疏矩阵数据处理——SciPy"></a>稀疏矩阵数据处理——SciPy</h3><p>SciPy中提供了多种数据结构可以有效处理稀疏矩阵，如：</p><p><strong>Dictionary of Keys:</strong> 一个字典使用行和列索引映射出一个值</p><p><strong>List of Lists:</strong> 每行作为一个list存储，每个list里包含column index和值</p><p><strong>Coordinate List:</strong> 存储一个元组列表，每个元组包含行索引，列索引和值</p><p><strong>Compressed Sparse Row (CSR) :</strong> 使用三个一维数组表示非零值，行范围和列索引。在机器学习中经常使用。</p><p><strong>Compressed Sparse Column:</strong> 对列索引进行压缩并在行索引之前先读取</p><p><img src="/2020/06/28/46638/1593354304703-ea0a7d87-344f-4042-a4fb-63ab1456ed40.png" alt="image.png"></p><p><img src="/2020/06/28/46638/1593354414857-4435ef02-f1c7-41f9-b9af-3959e384200e.png" alt="image.png"></p><h4 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from numpy import array</span><br><span class="line">from scipy import sparse</span><br><span class="line">import numpy as np</span><br><span class="line"># create dense matrix</span><br><span class="line">A = array([[1, 0, 0, 1, 0, 0], [0, 0, 2, 0, 0, 1], [0, 0, 0, 2, 0, 0]])</span><br><span class="line">print(A)</span><br><span class="line"># convert to sparse matrix (CSR method)</span><br><span class="line">S = csr_matrix(A)</span><br><span class="line">print(S)</span><br><span class="line"># reconstruct dense matrix</span><br><span class="line">B = S.todense()</span><br><span class="line">print(B)</span><br><span class="line"># reconstruct numpy array</span><br><span class="line">C = S.toarray()</span><br><span class="line">print(C)</span><br></pre></td></tr></table></figure><h3 id="稀疏矩阵与机器学习"><a href="#稀疏矩阵与机器学习" class="headerlink" title="稀疏矩阵与机器学习"></a>稀疏矩阵与机器学习</h3><p>python的sklearn模块很多模型可以使用sparse数据结构作为输入。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://machinelearningmastery.com/sparse-matrices-for-machine-learning/" target="_blank" rel="noopener">https://machinelearningmastery.com/sparse-matrices-for-machine-learning/</a></p><p><a href="https://docs.scipy.org/doc/scipy/reference/sparse.html" target="_blank" rel="noopener">https://docs.scipy.org/doc/scipy/reference/sparse.html</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Introduction to Sparse Matrices for Machine Learning&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;什么是稀疏矩阵？&quot;&gt;&lt;a href=&quot;#什么是稀疏矩阵？&quot; class=&quot;headerlink&quot; title=&quot;什么是稀疏矩阵？&quot;&gt;&lt;/a&gt;什么是稀疏矩阵？&lt;/h3&gt;&lt;p&gt;大部分包含零值的矩阵称为稀疏矩阵(sparse Matrices)，相对应的是大多数值非零的密集矩阵(Dense Matrices)。稀疏矩阵在机器学习领域非常常见，如计数类数据，或者one-hot encoding编码的数据等。数据的稀疏性可以通过零值的比例量化（sparsity = count zero elements / total elements）。稀疏矩阵会产生处理时间和存储空间的问题。而&lt;strong&gt;SciPy&lt;/strong&gt;提供了很多高效的方法可以直接用于存储和处理稀疏矩阵。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/06/28/46638/figure-ab.jpg&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
</feed>
