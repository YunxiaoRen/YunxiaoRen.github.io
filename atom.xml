<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>生信拾光</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-05-13T19:41:48.441Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>六六</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>lncRNA的保守和不保守</title>
    <link href="http://yoursite.com/2020/05/13/Wed%20May%2013%202020%2021:38:56%20GMT+0200/"/>
    <id>http://yoursite.com/2020/05/13/Wed May 13 2020 21:38:56 GMT+0200/</id>
    <published>2020-05-13T19:38:56.000Z</published>
    <updated>2020-05-13T19:41:48.441Z</updated>
    
    <content type="html"><![CDATA[<p><strong>文章信息</strong></p><p>题目：Distinct Processing of lncRNAs Contributes to Non-conserved Functions in Stem Cells</p><p>杂志：Cell</p><p>时间：6 April 2020</p><p>链接: h<a href="https://doi.org/10.1016/j.cell.2020.03.006" target="_blank" rel="noopener">ttps://doi.org/10.1016/j.cell.2020.03.006</a></p><p><strong>该文章的评论文章：</strong></p><p>题目：The Secret Life of lncRNAs: Conserved, yet Not Conserved</p><p>链接：<a href="https://doi.org/10.1016/j.cell.2020.04.012" target="_blank" rel="noopener">https://doi.org/10.1016/j.cell.2020.04.012</a></p><p><strong>文章介绍</strong></p><p>长非编码RNA（lncRNAs）的进化速度比mRNAs更快。保守的lncRNAs是否经过保守的加工、定位和功能仍未被探索。中科院陈玲玲教授团队报告了人类（h) 和小鼠 (m) 胚胎干细胞（ESCs）中不同的lncRNAs的亚细胞定位。与mESCs相比，在hESCs的细胞质中定位的lncRNAs的比例明显高于mESCs。事实证明，这对hESC的多能性很重要。FAST是一种位置保守的lncRNA，但在加工和定位方面并不保守。在hESCs中，细胞质定位的h FAST与E3泛素连接酶β-TrCP的WD40域结合，并阻止其与磷酸化的β-catenin相互作用，以防止降解，导致激活WNT信号转导，这是多能性所需的。与此相反，m Fast在mESCs中被核保留，其处理被拼接因子PPIE抑制，而PPIE在mESCs中高表达，但在hESCs中没有。这些发现揭示了lncRNA的加工和定位是之前未被重视的作用于快速进化的贡献者。</p><a id="more"></a><p><img src="/2020/05/13/Wed May 13 2020 21:38:56 GMT+0200/1589397881556-d461906a-a11a-423f-9412-b01efafa4b1a.png" alt="image.png" style="zoom: 33%;"></p><p>Harshita Sharma 对这篇文章的评论：Guo及其同事发现了lncRNA演化的新的复杂性，在人类ESCs中，位置保守的lncRNAs被广泛地拼接并输出到细胞质中，而小鼠的lncRNAs主要是未拼接和核保留。不同的处理导致了物种特异性的lncRNA在多能性维持中的功能。</p><p><img src="/2020/05/13/Wed May 13 2020 21:38:56 GMT+0200/1589397879457-7fa9fb7d-706c-425e-a71e-235f7c043761.png" alt="image.png" style="zoom:33%;"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;文章信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;题目：Distinct Processing of lncRNAs Contributes to Non-conserved Functions in Stem Cells&lt;/p&gt;
&lt;p&gt;杂志：Cell&lt;/p&gt;
&lt;p&gt;时间：6 April 2020&lt;/p&gt;
&lt;p&gt;链接: h&lt;a href=&quot;https://doi.org/10.1016/j.cell.2020.03.006&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ttps://doi.org/10.1016/j.cell.2020.03.006&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;该文章的评论文章：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;题目：The Secret Life of lncRNAs: Conserved, yet Not Conserved&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://doi.org/10.1016/j.cell.2020.04.012&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://doi.org/10.1016/j.cell.2020.04.012&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;文章介绍&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;长非编码RNA（lncRNAs）的进化速度比mRNAs更快。保守的lncRNAs是否经过保守的加工、定位和功能仍未被探索。中科院陈玲玲教授团队报告了人类（h) 和小鼠 (m) 胚胎干细胞（ESCs）中不同的lncRNAs的亚细胞定位。与mESCs相比，在hESCs的细胞质中定位的lncRNAs的比例明显高于mESCs。事实证明，这对hESC的多能性很重要。FAST是一种位置保守的lncRNA，但在加工和定位方面并不保守。在hESCs中，细胞质定位的h FAST与E3泛素连接酶β-TrCP的WD40域结合，并阻止其与磷酸化的β-catenin相互作用，以防止降解，导致激活WNT信号转导，这是多能性所需的。与此相反，m Fast在mESCs中被核保留，其处理被拼接因子PPIE抑制，而PPIE在mESCs中高表达，但在hESCs中没有。这些发现揭示了lncRNA的加工和定位是之前未被重视的作用于快速进化的贡献者。&lt;/p&gt;
    
    </summary>
    
    
      <category term="文献摘要" scheme="http://yoursite.com/tags/%E6%96%87%E7%8C%AE%E6%91%98%E8%A6%81/"/>
    
      <category term="lncRNA" scheme="http://yoursite.com/tags/lncRNA/"/>
    
  </entry>
  
  <entry>
    <title>利用机器学习模型从全基因组序列中预测胸膜肺炎放线菌抗药性</title>
    <link href="http://yoursite.com/2020/05/13/Wed%20May%2013%202020%2020:46:43%20GMT+0200/"/>
    <id>http://yoursite.com/2020/05/13/Wed May 13 2020 20:46:43 GMT+0200/</id>
    <published>2020-05-13T18:46:43.000Z</published>
    <updated>2020-05-13T18:50:13.423Z</updated>
    
    <content type="html"><![CDATA[<p><strong>文章信息</strong></p><p>题目：Evaluation of Machine Learning Models for Predicting Antimicrobial Resistance of Actinobacillus pleuropneumoniae From Whole Genome Sequences</p><p>杂志：Frontiers in Microbiology</p><p>时间：06 February 2020</p><p>链接: <a href="https://doi.org/10.3389/fmicb.2020.00048" target="_blank" rel="noopener">https://doi.org/10.3389/fmicb.2020.00048</a></p><p><img src="/2020/05/13/Wed May 13 2020 20:46:43 GMT+0200/1588845190895-1ed386ed-9893-4e0e-85a7-551c120d3d77-20200513204949002.png" alt="2020-05-07_fig2.png"></p><p><strong>文章概述</strong></p><p>抗生素耐药性(AMR)正在成为世界各国面临的一个巨大公共安全问题，识别对某些抗生素耐药或易感菌株的新方法对于对抗抗生素耐药病原体至关重要。由于基因组数据集和AST表型越来越多，基于基因型的机器学习方法作为一种诊断工具显示出了巨大的希望。</p><p>本文采用<strong>支持向量机（</strong> <strong>Support Vector Machine</strong>，<strong>SVM）和集覆盖机（**</strong>Set Covering Machine<strong>，</strong>SCM）<strong>模型来学习和预测</strong>五种药物（<strong>四环素类、氨苄西林、磺胺恶唑、曲美沙星和恩诺沙星）的耐药性。</strong>SVM模型利用分离菌的基因组与参比基因之间共存的k-mers的数量来学习和预测细菌对特定抗生素的表型<strong>，</strong>而单片机模型则采用贪婪的方法构造布尔函数的联结或解联，找到最简洁的k-mers集，从而准确预测表型。<strong>对SVM和SCM模型的训练集进行</strong>五倍交叉验证<strong>，选择最佳的超参数值，以避免模型过度拟合。结果表明，无论哪种药物的耐药机制是获得性耐药还是染色体点突变，</strong>5种药物的SVM和SCM模型的训练准确率（平均交叉验证得分）和测试准确率均在90%以上。5种药物的表型与模型预测的相关性结果表明，SVM和SCM模型均能显著地将耐药分离菌从敏感分离菌中分离出来（P&lt;0.01），可作为抗生素耐药性监测和兽药临床诊断的潜在工具。</p><a id="more"></a><p><strong>方法详解</strong></p><p><strong>数据来源：</strong></p><ul><li><p>从<strong>Bosse等人(2017)文章</strong>获得<strong>96株</strong>胸膜肺炎分离菌株的<strong>5种</strong>抗菌药物(四环素、氨苄西林、磺胺恶唑、甲氧苄氨嘧啶和恩罗沙星)的<strong>WGS序列和双耐药表型</strong></p></li><li><ul><li>Study: PRJEB2343</li></ul></li></ul><p>Reference: Whole genome sequencing for surveillance of antimicrobial resistance in <em>Actinobacillus pleuropneumoniae</em>. <em>Front. Microbiol.</em> 8:311. doi: 10.3389/fmicb.2017.00311</p><p><strong>分析方法：</strong></p><ul><li>WGS assemle: Velvet 1.2.08</li><li>AMR genes contig: 从ResFinder 数据库</li><li>matrix of the co-occurring k-mers：Ray Surveyor tool</li><li><strong>Reference-Based SVM Model</strong>：radial basis function kernel，Python sklearn 包实现分析</li><li><strong>Reference-Free SCM Model</strong>：implemented by <strong>Kover</strong>, an open-source software implemented in the Python and C programming languages</li><li>Model Selection and Performance Evaluation: five-fold cross-validation, 评价指标：sensitivity, specificity, accuracy, and precision</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;文章信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;题目：Evaluation of Machine Learning Models for Predicting Antimicrobial Resistance of Actinobacillus pleuropneumoniae From Whole Genome Sequences&lt;/p&gt;
&lt;p&gt;杂志：Frontiers in Microbiology&lt;/p&gt;
&lt;p&gt;时间：06 February 2020&lt;/p&gt;
&lt;p&gt;链接: &lt;a href=&quot;https://doi.org/10.3389/fmicb.2020.00048&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://doi.org/10.3389/fmicb.2020.00048&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/05/13/Wed May 13 2020 20:46:43 GMT+0200/1588845190895-1ed386ed-9893-4e0e-85a7-551c120d3d77-20200513204949002.png&quot; alt=&quot;2020-05-07_fig2.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;文章概述&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;抗生素耐药性(AMR)正在成为世界各国面临的一个巨大公共安全问题，识别对某些抗生素耐药或易感菌株的新方法对于对抗抗生素耐药病原体至关重要。由于基因组数据集和AST表型越来越多，基于基因型的机器学习方法作为一种诊断工具显示出了巨大的希望。&lt;/p&gt;
&lt;p&gt;本文采用&lt;strong&gt;支持向量机（&lt;/strong&gt; &lt;strong&gt;Support Vector Machine&lt;/strong&gt;，&lt;strong&gt;SVM）和集覆盖机（**&lt;/strong&gt;Set Covering Machine&lt;strong&gt;，&lt;/strong&gt;SCM）&lt;strong&gt;模型来学习和预测&lt;/strong&gt;五种药物（&lt;strong&gt;四环素类、氨苄西林、磺胺恶唑、曲美沙星和恩诺沙星）的耐药性。&lt;/strong&gt;SVM模型利用分离菌的基因组与参比基因之间共存的k-mers的数量来学习和预测细菌对特定抗生素的表型&lt;strong&gt;，&lt;/strong&gt;而单片机模型则采用贪婪的方法构造布尔函数的联结或解联，找到最简洁的k-mers集，从而准确预测表型。&lt;strong&gt;对SVM和SCM模型的训练集进行&lt;/strong&gt;五倍交叉验证&lt;strong&gt;，选择最佳的超参数值，以避免模型过度拟合。结果表明，无论哪种药物的耐药机制是获得性耐药还是染色体点突变，&lt;/strong&gt;5种药物的SVM和SCM模型的训练准确率（平均交叉验证得分）和测试准确率均在90%以上。5种药物的表型与模型预测的相关性结果表明，SVM和SCM模型均能显著地将耐药分离菌从敏感分离菌中分离出来（P&amp;lt;0.01），可作为抗生素耐药性监测和兽药临床诊断的潜在工具。&lt;/p&gt;
    
    </summary>
    
    
      <category term="文献摘要" scheme="http://yoursite.com/tags/%E6%96%87%E7%8C%AE%E6%91%98%E8%A6%81/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="AMR" scheme="http://yoursite.com/tags/AMR/"/>
    
  </entry>
  
  <entry>
    <title>使用随机子空间集合的机器学习从三种病原体的泛基因组中识别出抗生素耐药性决定因素</title>
    <link href="http://yoursite.com/2020/05/13/Wed%20May%2013%202020%2020:41:58%20GMT+0200/"/>
    <id>http://yoursite.com/2020/05/13/Wed May 13 2020 20:41:58 GMT+0200/</id>
    <published>2020-05-13T18:41:58.000Z</published>
    <updated>2020-05-13T18:51:51.390Z</updated>
    
    <content type="html"><![CDATA[<p><strong>文章信息</strong></p><p>题目：Machine learning with random subspace ensembles identifies antimicrobial resistance determinants from pan-genomes of three pathogens</p><p>杂志：PLOS COMPUTATIONAL BIOLOGY</p><p>时间：March 2, 2020</p><p>链接: <a href="https://doi.org/10.1371/journal.pcbi.1007608" target="_blank" rel="noopener">https://doi.org/10.1371/journal.pcbi.1007608</a></p><p><img src="/2020/05/13/Wed May 13 2020 20:41:58 GMT+0200/1588841404348-eb669a8a-0061-49bb-83d7-bbfcf683eb24.png" alt="2020-05-07_fig1.png"></p><p><strong>文章概述</strong></p><p>抗菌剂耐药性的演变对全球公共卫生构成了持续的威胁。 测序工作已经获得了数千种耐药微生物分离物的基因组序列，需要强大的计算工具来系统地阐明AMR的遗传基础。</p><p>在这里，文章提出了一种可通用的机器学习工作流程，基于构建的参考菌株诊断泛基因组和训练<strong>随机子空间集合（RSEs）</strong>，用于鉴定驱动AMR的遗传特征。这一工作流程对<strong>三种病原体</strong>的<strong>14种抗菌素</strong>的耐药性谱进行了研究，其中包括<strong>288种金黄色葡萄球菌</strong>、<strong>456种绿脓杆菌和1588种大肠杆菌基因组</strong>。文章发现，与常见的统计学检验和以前的集合方法相比，他们发现通过<strong>特征选择法</strong>检测已知的AMR更可靠，利用该方法共识别出45个已知的AMR基因和等位基因，以及25个由域级注释支持的候选关联。此外，发现来自于RSE方法的结果与现有的氟喹诺酮（FQ) 的理解是一致的。(FQ)抗药性是由于这三种生物体中主要药物靶点gyrA和parC的突变引起的，并表明这些基因在FQ抗药性方面的突变情况是简单的。随着更大的数据集的出现，我们希望这种方法能够更可靠地预测更多微生物病原体的AMR决定因素。</p><a id="more"></a><p><strong>方法详解</strong></p><p><strong>数据来源</strong>：数据集是从PATRIC数据库下载的，共包括288,456和1588个金黄色葡萄球菌、铜绿假单胞菌和大肠杆菌的基因组数据。</p><p><strong>数据预处理</strong>：鉴定开放阅读框，对编码基因进行聚类；由于AMR的致病变异通常存在于个体突变水平，他们对每个泛基因组的每个基因的所有观察到的独特氨基酸序列变异或“等位基因”进行了识别和列举。</p><p><strong>模型选择和训练</strong>：首先基于支持向量机（support vector machine ，SVM)方法训练模型（SVM是通过scikit-learn实现的），训练集来自六种针对金黄色葡萄球菌的抗生素治疗方法。验证是根据从文献和CARD数据库中收集的已知的的AMR基因。</p><p>然后使用相同的特征矩阵和AMR表型，对每个抗生素病例训练了两种类型的SVM合集，以将基因组分类为易感或耐药，由500个SVM组成，每个SVM训练的结果是：1）随机抽取80%的基因组和所有特征的随机样本，得到类似于中的引导合集；或2）随机抽取80%的基因组和50%的特征，得到<strong>随机子空间合集（RSE</strong>），这种调整以前被证明可以提高在高维生物数据上训练的SVM的准确性。类似地，特征按特征权重进行排序。</p><p>最后使用SVM-RSE的方法在P. aeruginosa和E.coli数据集中鉴定已知的AMR基因。</p><p><strong><img src="/2020/05/13/Wed May 13 2020 20:41:58 GMT+0200/1588838311456-3629ce5d-d5cb-43ed-83cd-77e5a060fe24.png" alt="image.png"></strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;文章信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;题目：Machine learning with random subspace ensembles identifies antimicrobial resistance determinants from pan-genomes of three pathogens&lt;/p&gt;
&lt;p&gt;杂志：PLOS COMPUTATIONAL BIOLOGY&lt;/p&gt;
&lt;p&gt;时间：March 2, 2020&lt;/p&gt;
&lt;p&gt;链接: &lt;a href=&quot;https://doi.org/10.1371/journal.pcbi.1007608&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://doi.org/10.1371/journal.pcbi.1007608&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/05/13/Wed May 13 2020 20:41:58 GMT+0200/1588841404348-eb669a8a-0061-49bb-83d7-bbfcf683eb24.png&quot; alt=&quot;2020-05-07_fig1.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;文章概述&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;抗菌剂耐药性的演变对全球公共卫生构成了持续的威胁。 测序工作已经获得了数千种耐药微生物分离物的基因组序列，需要强大的计算工具来系统地阐明AMR的遗传基础。&lt;/p&gt;
&lt;p&gt;在这里，文章提出了一种可通用的机器学习工作流程，基于构建的参考菌株诊断泛基因组和训练&lt;strong&gt;随机子空间集合（RSEs）&lt;/strong&gt;，用于鉴定驱动AMR的遗传特征。这一工作流程对&lt;strong&gt;三种病原体&lt;/strong&gt;的&lt;strong&gt;14种抗菌素&lt;/strong&gt;的耐药性谱进行了研究，其中包括&lt;strong&gt;288种金黄色葡萄球菌&lt;/strong&gt;、&lt;strong&gt;456种绿脓杆菌和1588种大肠杆菌基因组&lt;/strong&gt;。文章发现，与常见的统计学检验和以前的集合方法相比，他们发现通过&lt;strong&gt;特征选择法&lt;/strong&gt;检测已知的AMR更可靠，利用该方法共识别出45个已知的AMR基因和等位基因，以及25个由域级注释支持的候选关联。此外，发现来自于RSE方法的结果与现有的氟喹诺酮（FQ) 的理解是一致的。(FQ)抗药性是由于这三种生物体中主要药物靶点gyrA和parC的突变引起的，并表明这些基因在FQ抗药性方面的突变情况是简单的。随着更大的数据集的出现，我们希望这种方法能够更可靠地预测更多微生物病原体的AMR决定因素。&lt;/p&gt;
    
    </summary>
    
      <category term="literature" scheme="http://yoursite.com/categories/literature/"/>
    
    
      <category term="文献摘要" scheme="http://yoursite.com/tags/%E6%96%87%E7%8C%AE%E6%91%98%E8%A6%81/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>利用深度学习从宏基因组数据中预测抗生素抗性基因—DeepARG（方法详解）</title>
    <link href="http://yoursite.com/2020/05/06/Wed%20May%2006%202020%2012:44:55%20GMT+0200/"/>
    <id>http://yoursite.com/2020/05/06/Wed May 06 2020 12:44:55 GMT+0200/</id>
    <published>2020-05-06T10:44:55.000Z</published>
    <updated>2020-05-06T10:56:31.310Z</updated>
    
    <content type="html"><![CDATA[<p>​               <img src="/2020/05/06/Wed May 06 2020 12:44:55 GMT+0200/1588755936726-a2a86d1c-ae3a-40bc-aaa2-974114d7e81f-20200506124808009.png" alt="image.png" style="zoom:50%;"></p><h3 id="方法概述："><a href="#方法概述：" class="headerlink" title="方法概述："></a>方法概述：</h3><p>从CARD,ARDB和UNIPROT 3个数据库分别提取抗性基因（antibiotic resistance genes,ARGs）, 3个数据库分别提取到2161，2290和28108个抗性基因。然后对3个数据库的抗性基因进行注释和分类，CARD和ARDB共鉴定到102个抗生素，包括30个抗生素分类。UNIPROT通过文本挖掘注释，然年再结合CARD和ARDB两个数据库验证。</p><p>得到经过前处理后的数据，利用深度神经网络训练模型，凭借Python中的Theano库的Lasagne模块实现模型训练。分别对短读长序列和长基因序列分开训练，得到deepARG-SS 和 deepARG-LS。</p><p>评估模型通过两个方法：一是UNIPROT的70%数据作为训练数据，30%作为测试验证数据；二是借助MEGARes数据库的数据作为独立的验证数据集，评估模型的表现。</p><a id="more"></a><h3 id="数据来源："><a href="#数据来源：" class="headerlink" title="数据来源："></a>数据来源：</h3><p>数据来自3个数据库：<strong>CARD,ARDB和UNIPROT</strong></p><h3 id="数据前处理"><a href="#数据前处理" class="headerlink" title="数据前处理"></a>数据前处理</h3><p><img src="/2020/05/06/Wed May 06 2020 12:44:55 GMT+0200/1588754695659-2c3b9a82-cbe0-453a-8663-e0c55346c1f6-20200506124806659.png" alt="image.png"></p><p><img src="/2020/05/06/Wed May 06 2020 12:44:55 GMT+0200/1588754740918-4ee1605e-db2c-4cfd-906d-7dd74b38da83-20200506124807027.png" alt="image.png"></p><h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><p><img src="/2020/05/06/Wed May 06 2020 12:44:55 GMT+0200/1588754750458-42a8a187-40da-4df8-b7bb-6c409d3f6853-20200506124807310.png" alt="image.png"></p><h3 id="模型验证"><a href="#模型验证" class="headerlink" title="模型验证"></a>模型验证</h3><p>从模型验证的结果看，似乎模型的效果太好了，不知道是否有过拟合的现象。</p><p><img src="/2020/05/06/Wed May 06 2020 12:44:55 GMT+0200/1588754581852-30322794-6acc-493f-b457-2985bb53ea91-20200506124807265.png" alt="image.png"></p><h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><p><strong>github代码打不开：</strong></p><p><a href="https://gaarangoa@bitbucket.org/gaarangoa/deeparg-ss.git" target="_blank" rel="noopener">https://gaarangoa@bitbucket.org/gaarangoa/deeparg-ss.git</a></p><p><strong>网站在线分析：</strong></p><p><a href="https://bench.cs.vt.edu/deeparg" target="_blank" rel="noopener">https://bench.cs.vt.edu/deeparg</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;​               &lt;img src=&quot;/2020/05/06/Wed May 06 2020 12:44:55 GMT+0200/1588755936726-a2a86d1c-ae3a-40bc-aaa2-974114d7e81f-20200506124808009.png&quot; alt=&quot;image.png&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;方法概述：&quot;&gt;&lt;a href=&quot;#方法概述：&quot; class=&quot;headerlink&quot; title=&quot;方法概述：&quot;&gt;&lt;/a&gt;方法概述：&lt;/h3&gt;&lt;p&gt;从CARD,ARDB和UNIPROT 3个数据库分别提取抗性基因（antibiotic resistance genes,ARGs）, 3个数据库分别提取到2161，2290和28108个抗性基因。然后对3个数据库的抗性基因进行注释和分类，CARD和ARDB共鉴定到102个抗生素，包括30个抗生素分类。UNIPROT通过文本挖掘注释，然年再结合CARD和ARDB两个数据库验证。&lt;/p&gt;
&lt;p&gt;得到经过前处理后的数据，利用深度神经网络训练模型，凭借Python中的Theano库的Lasagne模块实现模型训练。分别对短读长序列和长基因序列分开训练，得到deepARG-SS 和 deepARG-LS。&lt;/p&gt;
&lt;p&gt;评估模型通过两个方法：一是UNIPROT的70%数据作为训练数据，30%作为测试验证数据；二是借助MEGARes数据库的数据作为独立的验证数据集，评估模型的表现。&lt;/p&gt;
    
    </summary>
    
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
      <category term="AMR" scheme="http://yoursite.com/tags/AMR/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络入门</title>
    <link href="http://yoursite.com/2020/05/04/Mon%20May%2004%202020%2011:43:33%20GMT+0200/"/>
    <id>http://yoursite.com/2020/05/04/Mon May 04 2020 11:43:33 GMT+0200/</id>
    <published>2020-05-04T09:43:33.000Z</published>
    <updated>2020-05-04T21:21:58.314Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2020/05/04/Mon May 04 2020 11:43:33 GMT+0200/fig1.png" style="zoom:50%;"></p><h3 id="卷积神经网络-CNN-简介"><a href="#卷积神经网络-CNN-简介" class="headerlink" title="卷积神经网络(CNN)简介"></a>卷积神经网络(CNN)简介</h3><p><strong>卷积神经网络即Convolutional Neural Networks (CNN or COnvNet)</strong> 是一种自动化提取特征的深度学习模型。这是一种深度的前馈人工神经网络（ feed-forward artificial neural network），前馈神经网络也称作多层感知机（multi-layer perceptrons，MLPs）。</p><p>CNNs是受生物视觉皮层的启发。视觉皮层有一些小区域的细胞，它们对视野的特定区域很敏感。这个想法是由Hubel和Wiesel在1962年做的一个的实验扩展了这个想法。在这个实验中，研究人员表明，大脑中的一些个别神经元只有在出现垂直或水平边缘等特定方向的边缘时才会激活或发射。但是在2012年，Alex Krizhevsky利用卷积神经网络赢得了当年的ImageNet大赛，将分类误差从26%降到15%，之后CNNs再一次火爆。</p><p>CNNs如今在多个领域都展现出巨大的应用潜能。如：</p><ul><li>图像识别，目标检测，分割，人脸识别</li><li>自动驾驶汽车等</li></ul><a id="more"></a><h3 id="卷积神经网络-CNN-的结构单元"><a href="#卷积神经网络-CNN-的结构单元" class="headerlink" title="卷积神经网络(CNN)的结构单元"></a>卷积神经网络(CNN)的结构单元</h3><p><img src="/2020/05/04/Mon May 04 2020 11:43:33 GMT+0200/1588619184008-278128ad-0eb0-4470-9a00-e6c030273227.png" alt="fig2.png"></p><h4 id="输入层-input-layer"><a href="#输入层-input-layer" class="headerlink" title="输入层(input layer)"></a>输入层(input layer)</h4><h4 id="卷积层（convolution-layer"><a href="#卷积层（convolution-layer" class="headerlink" title="卷积层（convolution layer)"></a>卷积层（convolution layer)</h4><blockquote><p>权值共享。我们通过卷积核与输入进行卷积运算。通过下图可以理解如何进行卷积运算。卷积核从左到右对输入进行扫描，每次滑动1格（步长为1），下图为滑动一次后，卷积核每个元素和输入中绿色框相应位置的元素相乘后累加，得到输出中绿色框中的0。一般会使用多个卷积核对输入数据进行卷积，得到多个特征图</p></blockquote><p><img src="/2020/05/04/Mon May 04 2020 11:43:33 GMT+0200/fig3.png" style="zoom:33%;"></p><h4 id="激活层"><a href="#激活层" class="headerlink" title="激活层"></a>激活层</h4><blockquote><p>对卷积层的输出进行一个非线性映射，因为卷积计算是一种线性计算。常见的激活函数有relu、tanh、sigmoid等，一般使用relu。使用relu的原因是在反向传播计算梯度中，使用relu求导明显会比tanh和sigmoid简单，可以<strong>减少计算量</strong></p></blockquote><h4 id="池化层-subsampling-pooling-layer"><a href="#池化层-subsampling-pooling-layer" class="headerlink" title="池化层(subsampling/pooling layer)"></a>池化层(subsampling/pooling layer)</h4><blockquote><p>池化的目的就是减少特征图的维度，减少数据的运算量。池化层是在卷积层之后，对卷积的输出，进行池化运算。池化运算，一般有两种MaxPooling和MeanPooling。</p></blockquote><p><img src="/2020/05/04/Mon May 04 2020 11:43:33 GMT+0200/fig4.png" style="zoom:33%;"></p><h4 id="全连接层-Fully-connected-layer"><a href="#全连接层-Fully-connected-layer" class="headerlink" title="全连接层(Fully connected layer)"></a>全连接层(Fully connected layer)</h4><blockquote><p>主要是对特征进行重新的拟合，减少特征信息的丢失。通过卷积池化操作后得到的是多个特征矩阵，而全连接层的输入为向量，所以在进行全连接层之前，要将多个特征矩阵“压平”为一个向量。</p></blockquote><h4 id="输出层-output-layer"><a href="#输出层-output-layer" class="headerlink" title="输出层(output layer)"></a>输出层(output layer)</h4><h3 id="卷积神经网络-CNN-代码示例"><a href="#卷积神经网络-CNN-代码示例" class="headerlink" title="卷积神经网络(CNN)代码示例"></a>卷积神经网络(CNN)代码示例</h3><p>这里介绍以Keras实现CNN的代码示例</p><h4 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h4><p>Fashion-MNIST数据集是Zalando的文章图像数据集，包含来自10个类别的70000个时尚产品的28x28灰度图像，每个类别有7000个图像。训练集有60000张图片，测试集有10000张图片。</p><h4 id="数据载入"><a href="#数据载入" class="headerlink" title="数据载入"></a>数据载入</h4><p>首先载入Keras模块，其是基于tensorflow框架的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># install tensorflow</span><br><span class="line">pip install tensorflow</span><br><span class="line">pip install keras</span><br><span class="line">from keras.datasets import fashion_mnist</span><br><span class="line">(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()</span><br></pre></td></tr></table></figure><p><strong>调整像素和图像大小</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from keras.utils import to_categorical</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">print(&apos;Training data shape : &apos;, train_X.shape, train_Y.shape)</span><br><span class="line"></span><br><span class="line">print(&apos;Testing data shape : &apos;, test_X.shape, test_Y.shape)</span><br><span class="line"></span><br><span class="line"># Find the unique numbers from the train labels</span><br><span class="line">classes = np.unique(train_Y)</span><br><span class="line">nClasses = len(classes)</span><br><span class="line">print(&apos;Total number of outputs : &apos;, nClasses)</span><br><span class="line">print(&apos;Output classes : &apos;, classes)</span><br></pre></td></tr></table></figure><p>可以看出输出的类别共包括10（0-9）类</p><p><strong>查看数据集中图像</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=[5,5])</span><br><span class="line"></span><br><span class="line"># Display the first image in training data</span><br><span class="line">plt.subplot(121)</span><br><span class="line">plt.imshow(train_X[0,:,:], cmap=&apos;gray&apos;)</span><br><span class="line">plt.title(&quot;Ground Truth : &#123;&#125;&quot;.format(train_Y[0]))</span><br><span class="line"></span><br><span class="line"># Display the first image in testing data</span><br><span class="line">plt.subplot(122)</span><br><span class="line">plt.imshow(test_X[0,:,:], cmap=&apos;gray&apos;)</span><br><span class="line">plt.title(&quot;Ground Truth : &#123;&#125;&quot;.format(test_Y[0]))</span><br></pre></td></tr></table></figure><p><img src="/2020/05/04/Mon May 04 2020 11:43:33 GMT+0200/fig5.png" style="zoom:33%;"></p><p>上面两个图的输出看起来像一个短靴，这个类被分配了一个类标签9。同样的，其他的时尚产品会有不同的标签，但是相似的产品会有相同的标签。这意味着所有7000张短靴图片的类别标签都是9。</p><h4 id="数据前处理"><a href="#数据前处理" class="headerlink" title="数据前处理"></a>数据前处理</h4><p>上面的图像可以看出是灰度图像，像素值的范围再0-255,且图像的维度为28*28. </p><ul><li>Step1: 首先将训练数据和测试数据的28<em>28图像转化为28</em>28*1的矩阵</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_X = train_X.reshape(-1, 28,28, 1)</span><br><span class="line">test_X = test_X.reshape(-1, 28,28, 1)</span><br><span class="line">train_X.shape, test_X.shape</span><br></pre></td></tr></table></figure><ul><li>Step2: 现在的数据是int8格式的，因此在将其输入网络之前，需要将其类型转换为float32，还必须重新调整范围为0 - 1(包括1)的像素值。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_X = train_X.astype(&apos;float32&apos;)</span><br><span class="line">test_X = test_X.astype(&apos;float32&apos;)</span><br><span class="line">train_X = train_X / 255.</span><br><span class="line">test_X = test_X / 255.</span><br></pre></td></tr></table></figure><ul><li>Step3: 将类标签转换为一个热编码向量</li></ul><p>机器学习算法不能直接处理分类数据, 故需将分类数据转换为数字向量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Change the labels from categorical to one-hot encoding</span><br><span class="line">train_Y_one_hot = to_categorical(train_Y)</span><br><span class="line">test_Y_one_hot = to_categorical(test_Y)</span><br><span class="line"></span><br><span class="line"># Display the change for category label using one-hot encoding</span><br><span class="line">print(&apos;Original label:&apos;, train_Y[0])</span><br><span class="line">print(&apos;After conversion to one-hot:&apos;, train_Y_one_hot[0])</span><br></pre></td></tr></table></figure><ul><li>拆分训练数据和测试数据集</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)</span><br><span class="line"># check the shape of training and validation set</span><br><span class="line">train_X.shape,valid_X.shape,train_label.shape,valid_label.shape</span><br></pre></td></tr></table></figure><h4 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h4><p>图像的大小是28 x 28。前面将图像矩阵转换为数组，在0和1之间重新调整大小，重塑它的大小为28 x 28 x 28 x 1，然后将其作为网络的输入。</p><p>下面将使用三个卷积层。</p><p>第一层将有32-3×3个滤波器。</p><p>第二层将有64-3×3滤波器和</p><p>第三层将有128-3×3个滤镜。</p><p>此外，还有3个最大pooling层，每个层的大小为2×2。</p><p><img src="/2020/05/04/Mon May 04 2020 11:43:33 GMT+0200/fig7.png" style="zoom:50%;"></p><h4 id="创建模型"><a href="#创建模型" class="headerlink" title="创建模型"></a>创建模型</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import keras</span><br><span class="line">from keras.models import Sequential,Input,Model</span><br><span class="line">from keras.layers import Dense, Dropout, Flatten</span><br><span class="line">from keras.layers import Conv2D, MaxPooling2D</span><br><span class="line">from keras.layers.normalization import BatchNormalization</span><br><span class="line">from keras.layers.advanced_activations import LeakyReLU</span><br></pre></td></tr></table></figure><p>这里使用64的批处理量，也可以使用128或256的批处理量，这一切都取决于内存。它对确定学习参数的贡献很大，并影响到预测的准确性。你将训练网络的20个时程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">batch_size = 64</span><br><span class="line">epochs = 20</span><br><span class="line">num_classes = 10</span><br></pre></td></tr></table></figure><h4 id="神经网络架构"><a href="#神经网络架构" class="headerlink" title="神经网络架构"></a>神经网络架构</h4><p>在Keras中，可以通过逐一添加所需的图层来堆叠图层。首先用Conv2D()添加第一个卷积层。注意，之所以使用这个函数，是因为在处理图像。 接下来，添加Leaky ReLU激活函数，它可以帮助网络学习非线性决策边界。因为这里的例子有十个不同的类，需要一个非线性决策边界，可以将这十个不能线性分离的类分开。</p><p>更具体地说，添加了Leaky ReLU，因为它们试图修复垂死的整流线性单元（ReLU）问题。ReLU 激活函数在神经网络架构中被大量使用，在卷积网络中，ReLU 激活函数被证明比广泛使用的对数 sigmoid 函数更有效。截止到2017年，这种激活函数是深度神经网络中最流行的一种激活函数。ReLU函数允许将激活函数的阈值设定为零。然而，在训练过程中，ReLU单元可能会 “死亡”。当一个大的梯度流过ReLU神经元时，就会发生这种情况：它可能会导致权重以这样的方式更新，以至于神经元再也不会在任何数据点上激活。如果这种情况发生，那么流经该单元的梯度将永远为零。泄漏的ReLU试图解决这个问题：函数不会为零，而是有一个小的负斜率。</p><p>接下来，用MaxPooling2D()等添加最大池化层。最后一层是Dense层，它有一个软MAX的激活函数，有10个单位，这对于这个多类分类问题是需要的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">fashion_model = Sequential()</span><br><span class="line">fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation=&apos;linear&apos;,input_shape=(28,28,1),padding=&apos;same&apos;))</span><br><span class="line">fashion_model.add(LeakyReLU(alpha=0.1))</span><br><span class="line">fashion_model.add(MaxPooling2D((2, 2),padding=&apos;same&apos;))</span><br><span class="line">fashion_model.add(Conv2D(64, (3, 3), activation=&apos;linear&apos;,padding=&apos;same&apos;))</span><br><span class="line">fashion_model.add(LeakyReLU(alpha=0.1))</span><br><span class="line">fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding=&apos;same&apos;))</span><br><span class="line">fashion_model.add(Conv2D(128, (3, 3), activation=&apos;linear&apos;,padding=&apos;same&apos;))</span><br><span class="line">fashion_model.add(LeakyReLU(alpha=0.1))                  </span><br><span class="line">fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding=&apos;same&apos;))</span><br><span class="line">fashion_model.add(Flatten())</span><br><span class="line">fashion_model.add(Dense(128, activation=&apos;linear&apos;))</span><br><span class="line">fashion_model.add(LeakyReLU(alpha=0.1))                  </span><br><span class="line">fashion_model.add(Dense(num_classes, activation=&apos;softmax&apos;))</span><br></pre></td></tr></table></figure><h4 id="编译模型"><a href="#编译模型" class="headerlink" title="编译模型"></a>编译模型</h4><p>使用Adam optimizer</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=[&apos;accuracy&apos;])</span><br></pre></td></tr></table></figure><p>使用summary函数来可视化在上述步骤中创建的层。这将显示每个层中的一些参数(权重和偏差)以及模型中的总参数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fashion_model.summary()</span><br></pre></td></tr></table></figure><h4 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h4><p>使用Keras的fit()函数训练模型，该模型训练了20个 epochs。fit()函数将返回一个历史对象；通过在fashion_train中讲述这个函数的结果，你可以在以后用它来绘制训练和验证之间的精度和损失函数图，这将帮助你直观地分析你的模型的性能。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fashion_train = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))</span><br></pre></td></tr></table></figure><h4 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_eval = fashion_model.evaluate(test_X, test_Y_one_hot, verbose=0)</span><br><span class="line">print(&apos;Test loss:&apos;, test_eval[0])</span><br><span class="line">print(&apos;Test accuracy:&apos;, test_eval[1])</span><br></pre></td></tr></table></figure><h4 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">accuracy = fashion_train.history[&apos;acc&apos;]</span><br><span class="line">val_accuracy = fashion_train.history[&apos;val_acc&apos;]</span><br><span class="line">loss = fashion_train.history[&apos;loss&apos;]</span><br><span class="line">val_loss = fashion_train.history[&apos;val_loss&apos;]</span><br><span class="line">epochs = range(len(accuracy))</span><br><span class="line">plt.plot(epochs, accuracy, &apos;bo&apos;, label=&apos;Training accuracy&apos;)</span><br><span class="line">plt.plot(epochs, val_accuracy, &apos;b&apos;, label=&apos;Validation accuracy&apos;)</span><br><span class="line">plt.title(&apos;Training and validation accuracy&apos;)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(epochs, loss, &apos;bo&apos;, label=&apos;Training loss&apos;)</span><br><span class="line">plt.plot(epochs, val_loss, &apos;b&apos;, label=&apos;Validation loss&apos;)</span><br><span class="line">plt.title(&apos;Training and validation loss&apos;)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/05/04/Mon May 04 2020 11:43:33 GMT+0200/fig8.png" style="zoom:50%;"></p><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><blockquote><ul><li><a href="http://keraschina.com/keras_cnn/" target="_blank" rel="noopener">CNN讲解及实践</a></li><li><a href="https://www.zhihu.com/question/52668301" target="_blank" rel="noopener">CNN（卷积神经网络）</a></li><li><a href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python" target="_blank" rel="noopener">Convolutional Neural Networks in Python with Keras</a></li><li><a href="https://towardsdatascience.com/convolutional-neural-networks-for-beginners-using-keras-and-tensorflow-2-c578f7b3bf25" target="_blank" rel="noopener">Convolutional Neural Networks for Beginners using Keras and TensorFlow</a></li><li><a href="https://geek-docs.com/deep-learning" target="_blank" rel="noopener">深度学习</a></li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/2020/05/04/Mon May 04 2020 11:43:33 GMT+0200/fig1.png&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;卷积神经网络-CNN-简介&quot;&gt;&lt;a href=&quot;#卷积神经网络-CNN-简介&quot; class=&quot;headerlink&quot; title=&quot;卷积神经网络(CNN)简介&quot;&gt;&lt;/a&gt;卷积神经网络(CNN)简介&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;卷积神经网络即Convolutional Neural Networks (CNN or COnvNet)&lt;/strong&gt; 是一种自动化提取特征的深度学习模型。这是一种深度的前馈人工神经网络（ feed-forward artificial neural network），前馈神经网络也称作多层感知机（multi-layer perceptrons，MLPs）。&lt;/p&gt;
&lt;p&gt;CNNs是受生物视觉皮层的启发。视觉皮层有一些小区域的细胞，它们对视野的特定区域很敏感。这个想法是由Hubel和Wiesel在1962年做的一个的实验扩展了这个想法。在这个实验中，研究人员表明，大脑中的一些个别神经元只有在出现垂直或水平边缘等特定方向的边缘时才会激活或发射。但是在2012年，Alex Krizhevsky利用卷积神经网络赢得了当年的ImageNet大赛，将分类误差从26%降到15%，之后CNNs再一次火爆。&lt;/p&gt;
&lt;p&gt;CNNs如今在多个领域都展现出巨大的应用潜能。如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图像识别，目标检测，分割，人脸识别&lt;/li&gt;
&lt;li&gt;自动驾驶汽车等&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
      <category term="CNN" scheme="http://yoursite.com/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>机器学习练习数据</title>
    <link href="http://yoursite.com/2020/05/02/Sat%20May%2002%202020%2018:44:09%20GMT+0200/"/>
    <id>http://yoursite.com/2020/05/02/Sat May 02 2020 18:44:09 GMT+0200/</id>
    <published>2020-05-02T16:44:09.000Z</published>
    <updated>2020-05-02T16:50:26.971Z</updated>
    
    <content type="html"><![CDATA[<p>机器学习可以使用的公共练习数据资源：</p><ul><li><p><a href="https://www.openml.org/" target="_blank" rel="noopener">OpenML</a></p><p><img src="/2020/05/02/Sat May 02 2020 18:44:09 GMT+0200/fig1.png" style="zoom:50%;"></p></li><li><p><a href="http://archive.ics.uci.edu/ml/datasets.php" target="_blank" rel="noopener">UCL机器学习库</a></p></li><li><p><a href="https://www.kaggle.com/" target="_blank" rel="noopener">kaggle</a></p></li><li><p><a href="https://www.kdnuggets.com/datasets/index.html" target="_blank" rel="noopener">KDnuggets</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;机器学习可以使用的公共练习数据资源：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://www.openml.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;OpenML&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/05/
      
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>单细胞层面解析鼠大脑甲基化图谱</title>
    <link href="http://yoursite.com/2020/05/02/Sat%20May%2002%202020%2010:52:20%20GMT+0200/"/>
    <id>http://yoursite.com/2020/05/02/Sat May 02 2020 10:52:20 GMT+0200/</id>
    <published>2020-05-02T08:52:20.000Z</published>
    <updated>2020-05-02T14:08:17.564Z</updated>
    
    <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>单细胞层面解析鼠大脑甲基化图谱</p><p><strong>文章信息</strong></p><p>题目：DNA Methylation Atlas of Mouse Brain at Single-Cell Resolution</p><p>杂志：bioRxiv</p><p>时间：April 30, 2020</p><p>链接: <a href="https://www.biorxiv.org/content/10.1101/2020.04.30.069377v1" target="_blank" rel="noopener">https://www.biorxiv.org/content/10.1101/2020.04.30.069377v1</a></p><p><strong>figure</strong></p><p><img src="/2020/05/02/Sat May 02 2020 10:52:20 GMT+0200/fig1.png" style="zoom:50%;"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>哺乳动物大脑细胞在基因表达、解剖学和功能上是有显著差别的，但是目前为止对DNA对其调控作用知之甚少。这篇文章从鼠的45个脑区域，提取出110，294个细胞核，并对其进行单核DNA甲基化测序，从而探讨鼠大脑的甲基化图谱。文章发现了161个细胞群具有不同的空间位置和靶标。从特征基因、调控元件和转录因子的注释结果中观察到潜在的调控图谱支持了假定细胞类型的分配，并揭示了在兴奋性和抑制性细胞中重复使用调控因子来确定亚型。此外，文章中使用人工神经网络模型预测单个神经元细胞类型和脑区域空间位置。文章还通过整合DNA甲基化,单核染色质可及性和染色质高级结构的contracts数据，注释小鼠大脑中数百种细胞类型的调控基因组。为整个小鼠大脑神经元多样性和空间组织奠定了表观遗传学基础。</p><ul><li><p>数据：<a href="https://portal.nemoarchive.org/" target="_blank" rel="noopener">https://portal.nemoarchive.org/</a> </p></li><li><p>可视化：<a href="http://neomorph.salk.edu/mouse_brain.php" target="_blank" rel="noopener">http://neomorph.salk.edu/mouse_brain.php</a></p></li><li><p>代码： <a href="https://cemba-data.readthedocs.io/en/latest/" target="_blank" rel="noopener">https://cemba-data.readthedocs.io/en/latest/</a> </p><ul><li><a href="https://github.com/lhqing/mouse_brain_2020" target="_blank" rel="noopener">https://github.com/lhqing/mouse_brain_2020</a></li></ul></li></ul><p><strong>个人评价：</strong></p><p>单细胞脑组织图谱，在最近两年有多篇研究被报道过，不仅包括鼠，人的脑细胞图谱也有相关文章发表。这篇文章的独特之处在于研究甲基化图谱，同时结合多组学技术，构建大脑更全面表观图谱。随着单细胞技术飞入寻常百姓家，可以看出单细胞多组学的结合是近期的一个发展方向。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;一句话评价&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;单细胞层面解析鼠大脑甲基化图谱&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;文章信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;题目：DNA Methylation Atlas of Mouse Brain at Single-Cell Resolution&lt;/p&gt;
&lt;p&gt;杂志：bioRxiv&lt;/p&gt;
&lt;p&gt;时间：April 30, 2020&lt;/p&gt;
&lt;p&gt;链接: &lt;a href=&quot;https://www.biorxiv.org/content/10.1101/2020.04.30.069377v1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.biorxiv.org/content/10.1101/2020.04.30.069377v1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;figure&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/05/02/Sat May 02 2020 10:52:20 GMT+0200/fig1.png&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="single cell" scheme="http://yoursite.com/tags/single-cell/"/>
    
      <category term="文献摘要" scheme="http://yoursite.com/tags/%E6%96%87%E7%8C%AE%E6%91%98%E8%A6%81/"/>
    
  </entry>
  
  <entry>
    <title>Scikit-Learn实现SVM</title>
    <link href="http://yoursite.com/2020/05/01/Fri%20May%2001%202020%2009:36:11%20GMT+0200/"/>
    <id>http://yoursite.com/2020/05/01/Fri May 01 2020 09:36:11 GMT+0200/</id>
    <published>2020-05-01T07:36:11.000Z</published>
    <updated>2020-05-02T17:06:24.136Z</updated>
    
    <content type="html"><![CDATA[<p><strong>支持向量机SVM（Support Vector Machines)是监督学习中一类算法，可用于分类、回归和异常值检测。</strong></p><p>具体原理可参考 <a href="[http://renyx.top/2020/04/21/Tue%20Apr%2021%202020%2014:41:09%20GMT+0200/](http://renyx.top/2020/04/21/Tue Apr 21 2020 14:41:09 GMT+0200/">SVM从原理到实现</a>)。R和python都有相关包和模块可以实现SVM，这里讨论如何在python中实现SVM。</p><p>python中是借助于<strong>scikit-learn</strong>库实现，<strong>scikit-learn</strong>是python中基于NumPy, SciPy 和matplotlib的一个机器学习库，包含多种功能，可以实现分类、回归、聚类，降维，模型选择和预处理等分析。</p><ul><li><a href="https://scikit-learn.org/stable/index.html" target="_blank" rel="noopener">https://scikit-learn.org/stable/index.html</a></li></ul><p><img src="/2020/05/01/Fri May 01 2020 09:36:11 GMT+0200/fig1.png" style="zoom:50%;"></p><a id="more"></a><h4 id="安装scikit-learn"><a href="#安装scikit-learn" class="headerlink" title="安装scikit-learn"></a>安装scikit-learn</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U scikit-learn</span><br></pre></td></tr></table></figure><p>检验是否安装成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python -m pip show scikit-learn # to see which version and where scikit-learn is installed</span><br><span class="line">python -m pip freeze # to see all packages installed in the active virtualenv</span><br><span class="line">python -c "import sklearn; sklearn.show_versions()"</span><br></pre></td></tr></table></figure><h4 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h4><p>scikit learn的输入数据支持密集型向量（包括numpy.ndarray和numpy.asarray）和疏散型向量（任何scipy.sparse）。然而，要使用支持向量机对稀疏数据进行预测，它必须适合此类数据。要获得最佳性能，请使用C-ordered numpy.ndarray（密集）或scipy.sparse.csr_matrix（稀疏），dtype=float64。</p><p>输入数据需包括两个数组(array)，<strong>数组X [n_samples,n_features], 数组Y[n_samples]</strong>。</p><p>示例数据：bankdata:</p><p><img src="/2020/05/01/Fri May 01 2020 09:36:11 GMT+0200/fig2.png" alt></p><p>Class为类别，以0，1表示，其他特征值都是数值。</p><p>首先把特征属性和类别标签分开,得到初始数据X和y.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = bankdata.drop(<span class="string">'Class'</span>, axis=<span class="number">1</span>) </span><br><span class="line">y = bankdata[<span class="string">'Class'</span>]</span><br></pre></td></tr></table></figure><h4 id="训练集和测试集的区分"><a href="#训练集和测试集的区分" class="headerlink" title="训练集和测试集的区分"></a>训练集和测试集的区分</h4><p>Scikit-Learn中的<code>model_selection</code>模块包含的<code>train_test_split</code>函数可以设置训练集和测试集的分割。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.20</span>)</span><br></pre></td></tr></table></figure><h4 id="算法训练"><a href="#算法训练" class="headerlink" title="算法训练"></a>算法训练</h4><p>Scikit-Learn中的SVM模块包含<code>SVC, NuSVC以及LinearSVC</code>函数</p><p>SVC和NuSVC是相似的方法，但接受的参数集略有不同，并且有不同的数学公式。另一方面，LinearSVC是支持向量分类在线性核情况下的另一种实现。注意，LinearSVC不接受关键字kernel，因为这被假定为线性的。它也缺少SVC和NuSVC的一些成员，比如<code>support_.</code>。</p><p>与其他分类器一样，SVC、NuSVC和LinearSVC将两个数组作为输入：一个数组X的大小[n_samples，n_features]包含训练样本，一个数组y的类标签（字符串或整数），大小[n_samples]：</p><p>这里以线性为例，把训练数据传给 SVC 类 <code>fit</code> 方法来训练算法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">svclassifier = SVC(kernel=<span class="string">'linear'</span>)</span><br><span class="line">svclassifier.fit(X_train, y_train)</span><br></pre></td></tr></table></figure><h4 id="预测模型"><a href="#预测模型" class="headerlink" title="预测模型"></a>预测模型</h4><p><code>SVC</code> 类的 <code>predict</code> 方法可以用来预测新的数据的类别</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred = svclassifier.predict(X_test)</span><br></pre></td></tr></table></figure><h4 id="算法评价"><a href="#算法评价" class="headerlink" title="算法评价"></a>算法评价</h4><p>精度、召回率和 F1 是分类任务最常用的一些评价指标.Scikit-Learn 的 <code>metrics</code> 模块中提供了 <code>classification_report</code> 和<code>confusion_matrix</code> 等方法，这些方法可以快速的计算这些评价指标.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report, confusion_matrix</span><br><span class="line">print(confusion_matrix(y_test,y_pred))</span><br><span class="line">print(classification_report(y_test,y_pred))</span><br></pre></td></tr></table></figure><h4 id="评价结果"><a href="#评价结果" class="headerlink" title="评价结果"></a>评价结果</h4><p><img src="/2020/05/01/Fri May 01 2020 09:36:11 GMT+0200/fig3.png" style="zoom:50%;"></p><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><ul><li><a href="https://juejin.im/post/5b7fd39af265da43831fa136" target="_blank" rel="noopener">用 Scikit-Learn 实现 SVM 和 Kernel SVM</a></li><li><p><a href="https://scikit-learn.org/stable/modules/svm.html" target="_blank" rel="noopener">Support Vector Machines</a></p></li><li><p><a href="https://www.qikegu.com/docs/4065" target="_blank" rel="noopener">Sklearn 教程</a></p></li><li><a href="https://www.cnblogs.com/luyaoblog/p/6775342.html" target="_blank" rel="noopener"><a href="https://www.cnblogs.com/luyaoblog/p/6775342.html" target="_blank" rel="noopener">Python中的支持向量机SVM的使用（有实例）</a></a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;支持向量机SVM（Support Vector Machines)是监督学习中一类算法，可用于分类、回归和异常值检测。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;具体原理可参考 &lt;a href=&quot;[http://renyx.top/2020/04/21/Tue%20Apr%2021%202020%2014:41:09%20GMT+0200/](http://renyx.top/2020/04/21/Tue Apr 21 2020 14:41:09 GMT+0200/&quot;&gt;SVM从原理到实现&lt;/a&gt;)。R和python都有相关包和模块可以实现SVM，这里讨论如何在python中实现SVM。&lt;/p&gt;
&lt;p&gt;python中是借助于&lt;strong&gt;scikit-learn&lt;/strong&gt;库实现，&lt;strong&gt;scikit-learn&lt;/strong&gt;是python中基于NumPy, SciPy 和matplotlib的一个机器学习库，包含多种功能，可以实现分类、回归、聚类，降维，模型选择和预处理等分析。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://scikit-learn.org/stable/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://scikit-learn.org/stable/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2020/05/01/Fri May 01 2020 09:36:11 GMT+0200/fig1.png&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="Scikit-Learn" scheme="http://yoursite.com/tags/Scikit-Learn/"/>
    
      <category term="SVM" scheme="http://yoursite.com/tags/SVM/"/>
    
  </entry>
  
  <entry>
    <title>python基础知识</title>
    <link href="http://yoursite.com/2020/04/21/Tue%20Apr%2021%202020%2021:52:23%20GMT+0200/"/>
    <id>http://yoursite.com/2020/04/21/Tue Apr 21 2020 21:52:23 GMT+0200/</id>
    <published>2020-04-21T19:52:23.000Z</published>
    <updated>2020-04-21T20:43:44.982Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Python基础语法"><a href="#Python基础语法" class="headerlink" title="Python基础语法"></a>Python基础语法</h3><p><img src="/2020/04/21/Tue Apr 21 2020 21:52:23 GMT+0200/fig0.png" style="zoom:50%;"></p><a id="more"></a><p><strong>书写规则</strong>：</p><p><code>#</code>： 表注释；<code>import</code>: 倒入模块；有缩进之分，通常为4字符</p><p><strong>基础数据类型：</strong></p><ul><li>整数int: 如1, 3, 5</li><li>浮点数float: 如 1.2；3.5</li><li>字符串（str): “8” “python”</li><li>布尔值（bool): True False</li></ul><p>检测数据类型：<code>type()</code>,如type(“8”)  是<code>string</code></p><p>转换数据类型：int(); float(); str(); bool() </p><p><strong>变量的定义和常用操作：</strong></p><p>变量名称通常以字母和下划线开头，中间包括字母、数字和下划线</p><h3 id="序列"><a href="#序列" class="headerlink" title="序列"></a>序列</h3><p><strong>序列的概念</strong></p><ul><li><p>有序的排列；可以通过下标偏移量访问</p></li><li><p>包括字符串，列表和元组</p><p><img src="/2020/04/21/Tue Apr 21 2020 21:52:23 GMT+0200/fig1.png" alt="fig1" style="zoom:50%;"></p></li><li><p>字符串可以是单引号或双引号；列表是[]创建；元组是() 创建</p></li></ul><p><strong>序列的基本操作</strong></p><p><img src="/2020/04/21/Tue Apr 21 2020 21:52:23 GMT+0200/fig2.png" style="zoom:50%;"></p><p><strong>字符串的定义和常用操作</strong></p><ul><li>切片操作符[]</li><li>成员关系： in ; not in</li><li>连接和重复操作</li></ul><p><strong>元组的定义和常用操作</strong></p><ul><li>包含序列的基本操作</li><li>元组内容不可变更</li></ul><p><strong>列表的定义和常用操作</strong></p><ul><li>包含序列的基本操作</li><li>列表内容可变更，可以增加或移除元素</li><li><code>append</code>末尾添加元素；<code>remove</code>移除元素</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Python基础语法&quot;&gt;&lt;a href=&quot;#Python基础语法&quot; class=&quot;headerlink&quot; title=&quot;Python基础语法&quot;&gt;&lt;/a&gt;Python基础语法&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/2020/04/21/Tue Apr 21 2020 21:52:23 GMT+0200/fig0.png&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>SVM从原理到实现</title>
    <link href="http://yoursite.com/2020/04/21/Tue%20Apr%2021%202020%2014:41:09%20GMT+0200/"/>
    <id>http://yoursite.com/2020/04/21/Tue Apr 21 2020 14:41:09 GMT+0200/</id>
    <published>2020-04-21T12:41:09.000Z</published>
    <updated>2020-04-21T15:01:18.408Z</updated>
    
    <content type="html"><![CDATA[<h3 id="SVM-简介"><a href="#SVM-简介" class="headerlink" title="SVM 简介"></a>SVM 简介</h3><p><strong>SVM(Support Vector Machines)</strong>支持向量机是机器学习中的一种分类算法，属于监督式学习，也可以同时用于分类和回归问题。SVM的核心思想是找到最大的边际超平面，以最大程度地将数据集划分为类。</p><a id="more"></a><h3 id="SVM原理"><a href="#SVM原理" class="headerlink" title="SVM原理"></a>SVM原理</h3><p><strong>术语</strong></p><ul><li><p><strong>Margin</strong></p><p>边距是最接近的分类点上的两条线之间的间隙。 这是从线到支持向量或最接近点的垂直距离来计算的。 如果两个类之间的边距较大，则认为是良好的边距，较小的边距是较差的边距</p><p><img src="/2020/04/21/Tue Apr 21 2020 14:41:09 GMT+0200/fig2.png" style="zoom:50%;"></p></li><li><p><strong>Soft Margin</strong></p><p>允许错误分类，这时观测值和阈值间的距离也称作Soft Margin。使用Cross Validation确定在 Soft Margin错误分类的个数，从而得到最好的分类模型。</p><p><img src="/2020/04/21/Tue Apr 21 2020 14:41:09 GMT+0200/fig3.png" style="zoom:50%;"></p></li><li><p><strong>支持向量</strong>（Support Vectors)</p><p>支持向量是最靠近超平面的数据点。 这些点将通过计算边距更好地定义分隔线。 这些点与分类器的构建更相关</p><p><img src="/2020/04/21/Tue Apr 21 2020 14:41:09 GMT+0200/fig4.png" style="zoom:50%;"></p><p>当处理的数据是一维时，Support Vector Classifier 是一个单独点；当处理的数据是二维时，Support Vector Classifier是一条线(如下图2-D)；当处理的数据是三维时，<strong>Support Vector Classifier 是一个超平面（hyperplane）</strong>(如下图3-D)</p><p>图2-D：</p><p><img src="/2020/04/21/Tue Apr 21 2020 14:41:09 GMT+0200/fig5.png" style="zoom: 25%;"></p><p>图3-D：</p><p><img src="/2020/04/21/Tue Apr 21 2020 14:41:09 GMT+0200/fig6.png" style="zoom:25%;"></p></li></ul><p><strong>SVM 背后的原理</strong></p><p>首先以低维数据开始</p><p><img src="/2020/04/21/Tue Apr 21 2020 14:41:09 GMT+0200/fig7.png" style="zoom:25%;"></p><p>然后将数据转为更高的维度</p><p><img src="/2020/04/21/Tue Apr 21 2020 14:41:09 GMT+0200/fig8.png" alt="fig8" style="zoom:25%;"></p><p>找到一个Support Vector Classifier可以将高维数据分为两类</p><p><img src="/2020/04/21/Tue Apr 21 2020 14:41:09 GMT+0200/fig9.png" style="zoom:25%;"></p><p><strong>SVM数学原理</strong></p><p>利用<strong>核函数（Kernel Functions)</strong>找到Support Vector Classifier</p><ul><li><strong>Polynomial Kernel</strong>（多项核）:包含参数d,表示多项式的维度,如d=1,表示1维，d=3,表示3维。</li><li><strong>Radial Kernel</strong>:用于无限维度</li></ul><h3 id="SVM优缺点"><a href="#SVM优缺点" class="headerlink" title="SVM优缺点"></a>SVM优缺点</h3><p><strong>优点：</strong></p><ul><li><strong>High Dimensionality</strong></li><li><strong>Memory Efficiency</strong></li><li><strong>Versatility</strong></li></ul><p><strong>缺点：</strong></p><ul><li><strong>Kernel Parameters Selection</strong></li><li><strong>Non-Probabilistic</strong></li></ul><h3 id="R和Python中实现SVM"><a href="#R和Python中实现SVM" class="headerlink" title="R和Python中实现SVM"></a>R和Python中实现SVM</h3><p><strong>R中实现SVM</strong></p><p>R中可以借助<strong>package <code>e1071</code></strong>，</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Import Library</span></span><br><span class="line"><span class="keyword">require</span>(e1071) <span class="comment">#Contains the SVM </span></span><br><span class="line">Train &lt;- read.csv(file.choose())</span><br><span class="line">Test &lt;- read.csv(file.choose())</span><br><span class="line"><span class="comment"># there are various options associated with SVM training; like changing kernel, gamma and C value.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># create model</span></span><br><span class="line">model &lt;- svm(Target~Predictor1+Predictor2+Predictor3,data=Train,kernel=<span class="string">'linear'</span>,gamma=<span class="number">0.2</span>,cost=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">preds &lt;- predict(model,Test)</span><br><span class="line">table(preds)</span><br><span class="line"></span><br><span class="line">链接：https://www.zhihu.com/question/<span class="number">21094489</span>/answer/<span class="number">392090279</span></span><br></pre></td></tr></table></figure><p>具体参考：<a href="https://www.datacamp.com/community/tutorials/support-vector-machines-r" target="_blank" rel="noopener">https://www.datacamp.com/community/tutorials/support-vector-machines-r</a></p><p><strong>Python中实现SVM</strong></p><p>Python中可以借助scikit-learn库，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Import Library</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="comment">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span></span><br><span class="line"><span class="comment"># Create SVM classification object </span></span><br><span class="line">model = svm.svc(kernel=<span class="string">'linear'</span>, c=<span class="number">1</span>, gamma=<span class="number">1</span>) </span><br><span class="line"><span class="comment"># there is various option associated with it, like changing kernel, gamma and C value. Will discuss more # about it in next section.Train the model using the training sets and check score</span></span><br><span class="line">model.fit(X, y)</span><br><span class="line">model.score(X, y)</span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= model.predict(x_test)</span><br><span class="line"></span><br><span class="line">链接：https://www.zhihu.com/question/<span class="number">21094489</span>/answer/<span class="number">392090279</span></span><br></pre></td></tr></table></figure><p><strong>参考资料</strong></p><ul><li><p><a href="https://www.youtube.com/watch?v=Qc5IyLW_hns&amp;list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&amp;index=51" target="_blank" rel="noopener">Statquest有关SVM视频</a></p></li><li><p><a href="https://www.datacamp.com/community/tutorials/support-vector-machines-r" target="_blank" rel="noopener">Support Vector Machines in R</a></p></li><li><p><a href="https://www.zhihu.com/question/21094489" target="_blank" rel="noopener">支持向量机(SVM)是什么意思</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/31886934" target="_blank" rel="noopener">支持向量机（SVM）——原理篇</a></p></li><li><p><a href="https://www.r-bloggers.com/machine-learning-using-support-vector-machines/" target="_blank" rel="noopener">Machine Learning Using Support Vector Machines</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;SVM-简介&quot;&gt;&lt;a href=&quot;#SVM-简介&quot; class=&quot;headerlink&quot; title=&quot;SVM 简介&quot;&gt;&lt;/a&gt;SVM 简介&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;SVM(Support Vector Machines)&lt;/strong&gt;支持向量机是机器学习中的一种分类算法，属于监督式学习，也可以同时用于分类和回归问题。SVM的核心思想是找到最大的边际超平面，以最大程度地将数据集划分为类。&lt;/p&gt;
    
    </summary>
    
      <category term="Data Sciences" scheme="http://yoursite.com/categories/Data-Sciences/"/>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>机器学习在生物医学中的应用</title>
    <link href="http://yoursite.com/2020/04/18/Sat%20Apr%2018%202020%2010:04:07%20GMT+0200/"/>
    <id>http://yoursite.com/2020/04/18/Sat Apr 18 2020 10:04:07 GMT+0200/</id>
    <published>2020-04-18T08:04:07.000Z</published>
    <updated>2020-04-19T20:31:15.378Z</updated>
    
    <content type="html"><![CDATA[<p><strong>文章信息</strong></p><p>题目：How Machine Learning Will Transform Biomedicine</p><p>杂志：Cell</p><p>时间：April 2,2020</p><p>链接: <a href="https://doi.org/10.1016/j.cell.2020.03.022" target="_blank" rel="noopener">https://doi.org/10.1016/j.cell.2020.03.022</a></p><p><img src="/2020/04/18/Sat Apr 18 2020 10:04:07 GMT+0200/fig1.png" style="zoom:50%;"></p><a id="more"></a><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>机器学习在语音识别，自动化驾驶汽车，生物医学等领域展现了巨大的潜在应用。机器学习将如何影响生物医学？这篇综述从机器学习对临床诊断、精准治疗和健康监管3个方面进行讨论。介绍了机器学习在这3个领域成功应用的例子，以及面临的机遇和挑战。此外也对机器学习的基本概念有简单的概述。</p><p><strong>机器学习中的基本概念</strong></p><ul><li><p><strong>监督学习、非监督学习和半监督学习</strong></p><p>监督学习在预测数据时是基于含有标签的过去数据；非监督学习是对没有标签数据进行分析学习，如聚类等；半监督学习首先执行无监督学习，然后从无监督学习中基于认为标记发现结构</p></li><li><p><strong>分类和回归</strong></p><p>都是监督学习的方法，分类是预测离散的类别，如正常与患病；而回归预测实际值的输出，如对治疗的反应</p></li><li><p><strong>集成学习</strong></p><p>集成方法建立了许多模型，并使用所有模型的平均值生成预测。常见的集成方法包括随机森林、梯度增强和叠加/元集成</p></li><li><p><strong>深度学习</strong></p><p>能够学习复杂非线性函数的多层人工神经网络。对于非结构化数据（如图像、语音或文本）非常有用，但通常不提供驱动函数的数据方面的细节</p></li><li><p><strong>贝叶斯学习</strong></p><p>结合先验知识和数据来执行机器学习的方法</p></li><li><p><strong>降维</strong></p><p>通过选择重要特征或组合特征来捕获数据集中的差异，减少数据集的属性或特征数。通常用于提高机器学习模型的性能和帮助可视化</p></li><li><p><strong>联合学习</strong></p><p>从分布在多个位置且不能组合成单个数据集的数据中增量学习的方法。当数据位于多个临床系统中或从敏感的个人数据中学习时，联合学习非常有用</p></li></ul><p><img src="/2020/04/18/Sat Apr 18 2020 10:04:07 GMT+0200/fig2.png" style="zoom:50%;"></p><p><strong>机器学习在诊断和治疗中应用例子</strong></p><ul><li><p>The genomic and transcriptomic architecture of 2,000 breast tumours reveals novel subgroups</p><blockquote><p><a href="https://www.nature.com/articles/nature10983" target="_blank" rel="noopener">https://www.nature.com/articles/nature10983</a></p></blockquote></li><li><p>DeepCC: a novel deep learning-based framework for cancer molecular subtype classification</p><blockquote><p><a href="https://www.nature.com/articles/s41389-019-0157-8" target="_blank" rel="noopener">https://www.nature.com/articles/s41389-019-0157-8</a> </p></blockquote></li><li><p>Predicting drug response of tumors from integrated genomic profiles by deep neural networks</p><blockquote><p><a href="https://www.ncbi.nlm.nih.gov/pubmed/30704458" target="_blank" rel="noopener">https://www.ncbi.nlm.nih.gov/pubmed/30704458</a></p></blockquote></li><li><p>A community effort to assess and improve drug sensitivity prediction algorithms</p><blockquote><p><a href="https://www.nature.com/articles/nbt.2877" target="_blank" rel="noopener">https://www.nature.com/articles/nbt.2877</a></p></blockquote></li><li><p>A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: a systematic review and meta-analysis</p><blockquote><p><a href="https://www.thelancet.com/journals/landig/article/PIIS2589-7500(19)30123-2/fulltext" target="_blank" rel="noopener">https://www.thelancet.com/journals/landig/article/PIIS2589-7500(19)30123-2/fulltext</a></p></blockquote></li><li><p>Prediction of gestational diabetes based on nationwide electronic health records</p><blockquote><p><a href="https://www.ncbi.nlm.nih.gov/pubmed/31932807" target="_blank" rel="noopener">https://www.ncbi.nlm.nih.gov/pubmed/31932807</a></p></blockquote></li><li><p>Privacy-Preserving Patient Similarity Learning in a Federated Environment: Development and Analysis</p><blockquote><p><a href="https://www.ncbi.nlm.nih.gov/pubmed/29653917" target="_blank" rel="noopener">https://www.ncbi.nlm.nih.gov/pubmed/29653917</a></p></blockquote></li><li><p>Smartwatch Algorithm for Automated Detection of Atrial Fibrillation</p><blockquote><p><a href="https://www.sciencedirect.com/science/article/pii/S0735109718334867?via%3Dihub" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/pii/S0735109718334867?via%3Dihub</a></p></blockquote></li><li><p>Contactless cardiac arrest detection using smart devices</p><blockquote><p><a href="https://www.nature.com/articles/s41746-019-0128-7" target="_blank" rel="noopener">https://www.nature.com/articles/s41746-019-0128-7</a></p></blockquote></li></ul><p><img src="/2020/04/18/Sat Apr 18 2020 10:04:07 GMT+0200/fig3.png" style="zoom:50%;"></p><p>### </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;文章信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;题目：How Machine Learning Will Transform Biomedicine&lt;/p&gt;
&lt;p&gt;杂志：Cell&lt;/p&gt;
&lt;p&gt;时间：April 2,2020&lt;/p&gt;
&lt;p&gt;链接: &lt;a href=&quot;https://doi.org/10.1016/j.cell.2020.03.022&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://doi.org/10.1016/j.cell.2020.03.022&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/04/18/Sat Apr 18 2020 10:04:07 GMT+0200/fig1.png&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="文献摘要" scheme="http://yoursite.com/tags/%E6%96%87%E7%8C%AE%E6%91%98%E8%A6%81/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>接纳自己的不完美</title>
    <link href="http://yoursite.com/2020/04/12/Sun%20Apr%2012%202020%2023:15:52%20GMT+0200/"/>
    <id>http://yoursite.com/2020/04/12/Sun Apr 12 2020 23:15:52 GMT+0200/</id>
    <published>2020-04-12T21:15:52.000Z</published>
    <updated>2020-04-12T21:18:51.605Z</updated>
    
    <content type="html"><![CDATA[<p><strong>《心灵捕手 Good Will Hunting 》（1997）</strong></p><p><img src="/2020/04/12/Sun Apr 12 2020 23:15:52 GMT+0200/心灵捕手.png" style="zoom:50%;"></p><p><strong>豆瓣剧情简介</strong></p><blockquote><p>麻省理工学院的数学教授蓝波在席上公布了一道困难的数学题，却被年轻的清洁工威尔（马特·戴蒙 饰）解了出来。可是威尔却是个问题少年，成天和好朋友查克（本·阿弗莱特 饰）等人四处闲逛，打架滋事。当蓝波找到这个天才的时候，他正因为打架袭警被法庭宣判送进看守所。蓝波向法官求情保释，才使他免于牢狱之灾。蓝波为了让威尔找到自己的人生目标，不浪费他的数学天赋，请了很多心理学专家为威尔做辅导，但是威尔十分抗拒，专家们都束手无策。无计可施之下，蓝波求助于他大学的好友，心理学教授尚恩（罗宾·威廉姆斯 饰），希望能够帮助威尔打开心房。经过蓝波和尚恩的不懈努力，威尔渐渐敞开心胸，而好友查克的一席话，更是让他豁然开朗。</p></blockquote><p>这部电影从表面上可以归类为心里咨询与教育的影片，我更喜欢这部电影映射出的人与人之间相处与交流的原则：彼此坦诚，才可以赢得信任，进而走进对方的内心。以及每个人应该学会与内心的自己相处，正面认识自己，接纳自己的不完美。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;《心灵捕手 Good Will Hunting 》（1997）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/04/12/Sun Apr 12 2020 23:15:52 GMT+0200/心灵捕手.png&quot; style=&quot;zoom:50%
      
    
    </summary>
    
    
      <category term="影评" scheme="http://yoursite.com/tags/%E5%BD%B1%E8%AF%84/"/>
    
  </entry>
  
  <entry>
    <title>基于微生物组学数据的深度表征学习预测疾病</title>
    <link href="http://yoursite.com/2020/04/12/Sun%20Apr%2012%202020%2021:36:46%20GMT+0200/"/>
    <id>http://yoursite.com/2020/04/12/Sun Apr 12 2020 21:36:46 GMT+0200/</id>
    <published>2020-04-12T19:36:46.000Z</published>
    <updated>2020-04-12T20:02:10.428Z</updated>
    
    <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>深度表征学习在疾病预测中的应用</p><p><strong>文章信息</strong></p><p>题目：DeepMicro: deep representation learning for disease prediction based on microbiome data</p><p>杂志：Scientific Reports</p><p>时间：7 April, 2020</p><p>链接: <a href="https://www.nature.com/articles/s41598-020-63159-5" target="_blank" rel="noopener">https://www.nature.com/articles/s41598-020-63159-5</a></p><p><strong>figure</strong></p><p><img src="/2020/04/12/Sun Apr 12 2020 21:36:46 GMT+0200/fig1.png" style="zoom:50%;"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>微生物组学数据在人类健康和疾病领域中扮演着重要的作用，然而，微生物组学数据的高纬性，以及样本量低等特点使基于机器学习的预测算法面临极大的挑战。这篇文章基于深度表征学习框架，提出了DeepMicro的方法，可使用各种自动编码器成功的将高维数据转换为低维表示，加快了模型训练和超参数优化过程，在基本方法的基础上提高了8-30倍。在5个不同的数据集上的测试显示DeepMicro在疾病预测方面潜在应用。</p><p>DeepMicro的实现环境和使用的工具包有：</p><ul><li>Python 3.5.2</li><li>Numpy 1.16.2, </li><li>Pandas 0.24.2, </li><li>Scipy 1.2.1, </li><li>Scikt-learn 0.20.3, </li><li>Keras 2.2.4</li><li>Tensorflow 1.13.1</li></ul><p>代码：<a href="https://github.com/minoh0201/DeepMicro" target="_blank" rel="noopener">https://github.com/minoh0201/DeepMicro</a></p><blockquote><p><strong>表征学习（representation learning）</strong></p><p>机器学习算法的成功与否不仅仅取决于算法本身，也取决于数据的表示。数据的不同表示可能会导致有效信息的隐藏或是曝露，这也决定了算法是不是能直截了当地解决问题。表征学习的目的是对复杂的原始数据化繁为简，把原始数据的无效信息剔除，把有效信息更有效地进行提炼，形成特征，这也应和了机器学习的一大任务——可解释性。 也正是因为特征的有效提取，使得今后的机器学习任务简单并且精确许多。在我们接触机器学习、深度学习之初，我们就知道有一类任务也是提炼数据的，那就是特征工程。与表征学习不同的是，特征工程是人为地处理数据，也是我们常听的“洗数据”。 而表示学习是借助算法让机器自动地学习有用的数据和其特征。 不过这两个思路都在尝试解决机器学习的一个主要问题——如何更合理高效地将特征表示出来。</p><p>链接：<a href="https://www.zhihu.com/question/37162929" target="_blank" rel="noopener">https://www.zhihu.com/question/37162929</a><br>来源：知乎</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;一句话评价&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;深度表征学习在疾病预测中的应用&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;文章信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;题目：DeepMicro: deep representation learning for disease prediction based on microbiome data&lt;/p&gt;
&lt;p&gt;杂志：Scientific Reports&lt;/p&gt;
&lt;p&gt;时间：7 April, 2020&lt;/p&gt;
&lt;p&gt;链接: &lt;a href=&quot;https://www.nature.com/articles/s41598-020-63159-5&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.nature.com/articles/s41598-020-63159-5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;figure&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/04/12/Sun Apr 12 2020 21:36:46 GMT+0200/fig1.png&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="literature" scheme="http://yoursite.com/categories/literature/"/>
    
    
      <category term="文献摘要" scheme="http://yoursite.com/tags/%E6%96%87%E7%8C%AE%E6%91%98%E8%A6%81/"/>
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>提取fastq文件中的序列信息</title>
    <link href="http://yoursite.com/2020/03/30/Mon%20Mar%2030%202020%2020:36:45%20GMT+0200/"/>
    <id>http://yoursite.com/2020/03/30/Mon Mar 30 2020 20:36:45 GMT+0200/</id>
    <published>2020-03-30T18:36:45.000Z</published>
    <updated>2020-03-30T18:51:58.243Z</updated>
    
    <content type="html"><![CDATA[<h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><p>提取fastq文件中的序列信息，并输出为一行</p><p><img src="/2020/03/30/Mon Mar 30 2020 20:36:45 GMT+0200/fg1.png" style="zoom:50%;"></p><h3 id="方法一：paste-cut实现"><a href="#方法一：paste-cut实现" class="headerlink" title="方法一：paste + cut实现"></a>方法一：paste + cut实现</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">head CH2500.fq | paste - - - - | cut -f 2 | paste -d '' -s</span><br></pre></td></tr></table></figure><p><img src="/2020/03/30/Mon Mar 30 2020 20:36:45 GMT+0200/fg2.png" alt></p><ul><li><code>paste - - - -</code> 将fastq的每4行转化为列，并以空格分割；<code></code>cut -f 2<code>提取第二列信息，即之前的第二行信息，序列信息，然后再利用paste ，</code>-d<code>指定分隔符为无，</code>-s` 合并为一行信息</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;目标&quot;&gt;&lt;a href=&quot;#目标&quot; class=&quot;headerlink&quot; title=&quot;目标&quot;&gt;&lt;/a&gt;目标&lt;/h3&gt;&lt;p&gt;提取fastq文件中的序列信息，并输出为一行&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/03/30/Mon Mar 30 2020 20
      
    
    </summary>
    
    
      <category term="shell" scheme="http://yoursite.com/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>肿瘤免疫治疗研究的平台——TIDE</title>
    <link href="http://yoursite.com/2020/02/29/Sat%20Feb%2029%202020%2022:44:18%20GMT+0100/"/>
    <id>http://yoursite.com/2020/02/29/Sat Feb 29 2020 22:44:18 GMT+0100/</id>
    <published>2020-02-29T21:44:18.000Z</published>
    <updated>2020-02-29T21:46:36.840Z</updated>
    
    <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>利用公共数据模拟免疫疗法的效应和耐药性</p><p><strong>文章信息</strong></p><p>题目：Large-scale public data reuse to model immunotherapy response and resistance                           </p><p>杂志：Genome Medicine</p><p>时间：26 February,2020</p><p>链接: <a href="https://doi.org/10.1186/s13073-020-0721-z" target="_blank" rel="noopener">https://doi.org/10.1186/s13073-020-0721-z</a>                       </p><p><strong>figure</strong></p><p><img src="/2020/02/29/Sat Feb 29 2020 22:44:18 GMT+0100/resize,w_1500-20200229224559989.png" alt="image.png"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>这是刘小乐老师实验室开发的一个网络平台——TIDE(<a href="http://tide.dfci.harvard.edu/login/" target="_blank" rel="noopener">http://tide.dfci.harvard.edu/login/</a>) （很好奇为什么命名为TIDE，而且网站图标也是来自<a href="https://mall.jd.com/index-1000001829.html" target="_blank" rel="noopener">汰渍</a>），用于推断调节肿瘤免疫的基因的功能，并评估预测免疫检查点抑制剂(immune checkpoint blockade,ICB)临床反应的标记物。</p><p>他们共处理了12项公开发表的ICB临床研究中的998例肿瘤的组学数据，以及8个已发表的用于鉴定参与调节淋巴细胞介导的肿瘤杀伤和免疫治疗的基因CRISPR筛选研究。其中ICB队列的临床数据共有188个肿瘤队列中的33000个样本，这些样本主要来自TCGA,METABRIC和PRECOG数据库，以及实验室内部数据。该网络平台的功能包括3个交互分析模块：将与肿瘤免疫逃逸相关的标记物进行排序，生成假设；然后通过AUC score 和生存曲线对标记物评估；最后根据标记物对患者分类。</p><p>对肿瘤免疫感兴趣的同学可以仔细研究下文章是如何整合公共数据的，以及利用该平台为课题提供一些新思路。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;一句话评价&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;利用公共数据模拟免疫疗法的效应和耐药性&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;文章信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;题目：Large-scale public data reuse to model immunotherapy response and resistance                           &lt;/p&gt;
&lt;p&gt;杂志：Genome Medicine&lt;/p&gt;
&lt;p&gt;时间：26 February,2020&lt;/p&gt;
&lt;p&gt;链接: &lt;a href=&quot;https://doi.org/10.1186/s13073-020-0721-z&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://doi.org/10.1186/s13073-020-0721-z&lt;/a&gt;                       &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;figure&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/02/29/Sat Feb 29 2020 22:44:18 GMT+0100/resize,w_1500-20200229224559989.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>综述|深度学习框架、应用和发展趋向</title>
    <link href="http://yoursite.com/2020/02/15/Sat%20Feb%2015%202020%2010:13:51%20GMT+0100/"/>
    <id>http://yoursite.com/2020/02/15/Sat Feb 15 2020 10:13:51 GMT+0100/</id>
    <published>2020-02-15T09:13:51.000Z</published>
    <updated>2020-02-20T08:47:44.597Z</updated>
    
    <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>深度学习框架、应用和发展趋向</p><p><strong>文章信息</strong></p><p>题目：A Review of Deep Learning with Special Emphasis on Architectures, Applications and Recent Trends</p><p>杂志：Knowledge-Based Systems</p><p>时间：6 February 2020</p><p>链接: <a href="https://doi.org/10.1016/j.knosys.2020.105596" target="_blank" rel="noopener">https://doi.org/10.1016/j.knosys.2020.105596</a></p><p><strong>figure</strong></p><p><img src="/2020/02/15/Sat Feb 15 2020 10:13:51 GMT+0100/fig1.png" alt></p><p><strong>文章介绍：</strong></p><p>随着公众对深度学习有效性的认识不断提高，利用深度学习解决不同实际问题的愿望也在增加。但是，即使是对专业人员来说，接触该领域所产生的迅速增长的知识体系也是令人望而生畏的。从哪里开始？如何确定特定的深度学习模型是否适用于他们的问题？如何训练和部署这样一个网络？</p><p>这篇综述对组成深度学习的一些关键的多层人工神经网络进行了概述；同时讨论了一些使用多代理方法的自动架构优化方案；此外，由于保证系统的正常运行时间对许多计算机应用来说是至关重要的，我们将介绍如何使用神经网络进行故障检测和随后的缓解；并且对深度学习在不不同领域的应用进行了讨论。</p><p>这篇综述可以作为想涉及深度学习领域的初学者的一篇参考读物。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;一句话评价&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;深度学习框架、应用和发展趋向&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;文章信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;题目：A Review of Deep Learning with Special Emphasis on Ar
      
    
    </summary>
    
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>细菌生物信息资源数据库——PATRIC</title>
    <link href="http://yoursite.com/2020/02/08/Sat%20Feb%2008%202020%2019:22:12%20GMT+0100/"/>
    <id>http://yoursite.com/2020/02/08/Sat Feb 08 2020 19:22:12 GMT+0100/</id>
    <published>2020-02-08T18:22:12.000Z</published>
    <updated>2020-02-12T08:48:20.302Z</updated>
    
    <content type="html"><![CDATA[<p>PATRIC <a href="https://www.patricbrc.org/" target="_blank" rel="noopener">https://www.patricbrc.org/</a> ：即病理系统资源整合中心，提供了集成的数据资源和分析工具，以支持有关细菌感染性疾病的生物医学研究。</p><blockquote><p><strong>PATRIC</strong>, the Pathosystems Resource Integration Center, provides integrated data and analysis tools to support biomedical research on bacterial infectious diseases.</p></blockquote><p>下面是该网站主页，主要包含3个模块：</p><ul><li>第一个是搜索模块，可以对细菌、古细菌、噬菌体以及真核宿主进行搜索，数据包括基因组、基因、转录组实验、分类学等信息；</li><li>第二个是数据分析模块，可以进行基因组组装、注释、RNA-seq、代谢组的分析等</li><li>第三个是多组学数据资源，如AMR数据，基因组数据，蛋白质家族，特殊基因等数据资源</li></ul><a id="more"></a><p><img src="/2020/02/08/Sat Feb 08 2020 19:22:12 GMT+0100/fig1.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;PATRIC &lt;a href=&quot;https://www.patricbrc.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.patricbrc.org/&lt;/a&gt; ：即病理系统资源整合中心，提供了集成的数据资源和分析工具，以支持有关细菌感染性疾病的生物医学研究。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;PATRIC&lt;/strong&gt;, the Pathosystems Resource Integration Center, provides integrated data and analysis tools to support biomedical research on bacterial infectious diseases.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;下面是该网站主页，主要包含3个模块：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一个是搜索模块，可以对细菌、古细菌、噬菌体以及真核宿主进行搜索，数据包括基因组、基因、转录组实验、分类学等信息；&lt;/li&gt;
&lt;li&gt;第二个是数据分析模块，可以进行基因组组装、注释、RNA-seq、代谢组的分析等&lt;/li&gt;
&lt;li&gt;第三个是多组学数据资源，如AMR数据，基因组数据，蛋白质家族，特殊基因等数据资源&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="database" scheme="http://yoursite.com/tags/database/"/>
    
      <category term="AMR" scheme="http://yoursite.com/tags/AMR/"/>
    
  </entry>
  
  <entry>
    <title>类器官和ATAC-seq技术结合研究人前脑发育图谱</title>
    <link href="http://yoursite.com/2020/02/08/Sat%20Feb%2008%202020%2019:12:18%20GMT+0100/"/>
    <id>http://yoursite.com/2020/02/08/Sat Feb 08 2020 19:12:18 GMT+0100/</id>
    <published>2020-02-08T18:12:18.000Z</published>
    <updated>2020-02-08T18:18:31.860Z</updated>
    
    <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>人类前脑发育的染色质可及性动态图谱</p><p><strong>文章信息</strong></p><p>题目：Chromatin accessibility dynamics in a model of human forebrain development                                </p><p>杂志：Science</p><p>时间：24 January 2020</p><p>链接: <a href="http://dx.doi" target="_blank" rel="noopener">http://dx.doi</a>. org/10.1126/ science.aay1645</p><p><strong>figure</strong></p><p><img src="/2020/02/08/Sat Feb 08 2020 19:12:18 GMT+0100/fig1.png" style="zoom:50%;"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>人类前脑发育在很大程度上是细胞水平研究、直接功能研究或操纵所无法达到的。缺乏初级脑组织样本，特别是在后期，以及传统的体外细胞模型的局限性，阻碍了对健康和疾病状态下皮质激素生成的详细机制性理解。而文中利用干细胞3D定向分化技术形成背侧和腹侧的前脑干细胞作为原始研究组织，更加接近体内真实的发育情况，然后利用ATAC-seq和RNA测序技术绘制了体外20多个月的神经元和胶质细胞系的发育图谱。并对增强子和基因的相互作用，以及每个发育时期特异的转录调控因子进行了探究。然后他们利用这个资源绘制了与精神分裂症和自闭症谱系失调相关的基因和遗传变异图，以区分染色质可及性模式，从而揭示细胞类型和易感期。最后，他们鉴定到在皮质神经发生过程中染色质重构的现象，在此期间四分之一的调节区域是活跃的，并推测这些转录因子可能驱动这些发育变化。</p><p><img src="/2020/02/08/Sat Feb 08 2020 19:12:18 GMT+0100/fig2.png" style="zoom:50%;"></p><p>关于脑神经发育过程中染色质可及性图谱的文章已有人发表过，这篇文章仍然能发到Science上，借助了一项重要的实验技术——对干细胞进行重编程然后进行3D培养形成人脑的类器官。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;一句话评价&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;人类前脑发育的染色质可及性动态图谱&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;文章信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;题目：Chromatin accessibility dynamics in a model of human forebrain development                                &lt;/p&gt;
&lt;p&gt;杂志：Science&lt;/p&gt;
&lt;p&gt;时间：24 January 2020&lt;/p&gt;
&lt;p&gt;链接: &lt;a href=&quot;http://dx.doi&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://dx.doi&lt;/a&gt;. org/10.1126/ science.aay1645&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;figure&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/02/08/Sat Feb 08 2020 19:12:18 GMT+0100/fig1.png&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="ATACseq" scheme="http://yoursite.com/tags/ATACseq/"/>
    
      <category term="文献摘要" scheme="http://yoursite.com/tags/%E6%96%87%E7%8C%AE%E6%91%98%E8%A6%81/"/>
    
  </entry>
  
  <entry>
    <title>构建基因调控网络的新算法</title>
    <link href="http://yoursite.com/2020/01/04/Sat%20Jan%2004%202020%2016:25:08%20GMT+0100/"/>
    <id>http://yoursite.com/2020/01/04/Sat Jan 04 2020 16:25:08 GMT+0100/</id>
    <published>2020-01-04T15:25:08.000Z</published>
    <updated>2020-01-04T08:34:51.028Z</updated>
    
    <content type="html"><![CDATA[<p>基因表达数据被广泛用于推测基因调控网络（Gene regulatory networks, GRNs）。单细胞RNAseq数据包含单个细胞的表达信息，非常有利于调控机制的研究。但是，目前从大量的表达数据中明确转录调控机制仍然面临挑战，而且，重构后的调控网络可能无法捕获主要的调控规则。</p><p>这篇文章提出了一个新的方法——TENET：从scRNAseq数据中通过<strong>传递熵（transfer entropy, TE)</strong> 计算基因间的因果关系，从而构建GRNs<strong>。</strong>他们的结果发现已知的靶基因具有显著高的TE值，且TE值越高的基因受各种干扰的影响越大。与其他方法相比，他们的结果表明TENET优于其他GRN预测算法。还有一个重要的性能是该方法可以鉴定关键的调控因子。将TENET应用于胚胎干细胞向神经细胞分化过程中的scRNAseq数据，他们发现Nme2是2i条件下特异性干细胞自我更新的关键因子。</p><p><img src="/2020/01/04/Sat Jan 04 2020 16:25:08 GMT+0100/fig-.png"></p><a id="more"></a><p><strong>一句话评价</strong></p><p>构建基因调控网络的新算法</p><p><strong>文章信息</strong></p><p>题目：Gene network reconstruction using single cell transcriptomic</p><p>data reveals key factors for embryonic stem cell differentiation</p><p>杂志：bioRxiv</p><p>时间：Dec. 21, 2019</p><p>链接: <a href="https://www.biorxiv.org/content/10.1101/2019.12.20.884163v1" target="_blank" rel="noopener">https://www.biorxiv.org/content/10.1101/2019.12.20.884163v1</a></p><blockquote><p>有点遗憾，如果半年前自己上点心的话，可能就能深入这个方向的研究了</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;基因表达数据被广泛用于推测基因调控网络（Gene regulatory networks, GRNs）。单细胞RNAseq数据包含单个细胞的表达信息，非常有利于调控机制的研究。但是，目前从大量的表达数据中明确转录调控机制仍然面临挑战，而且，重构后的调控网络可能无法捕获主要的调控规则。&lt;/p&gt;
&lt;p&gt;这篇文章提出了一个新的方法——TENET：从scRNAseq数据中通过&lt;strong&gt;传递熵（transfer entropy, TE)&lt;/strong&gt; 计算基因间的因果关系，从而构建GRNs&lt;strong&gt;。&lt;/strong&gt;他们的结果发现已知的靶基因具有显著高的TE值，且TE值越高的基因受各种干扰的影响越大。与其他方法相比，他们的结果表明TENET优于其他GRN预测算法。还有一个重要的性能是该方法可以鉴定关键的调控因子。将TENET应用于胚胎干细胞向神经细胞分化过程中的scRNAseq数据，他们发现Nme2是2i条件下特异性干细胞自我更新的关键因子。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/01/04/Sat Jan 04 2020 16:25:08 GMT+0100/fig-.png&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="literature" scheme="http://yoursite.com/categories/literature/"/>
    
    
      <category term="文献摘要" scheme="http://yoursite.com/tags/%E6%96%87%E7%8C%AE%E6%91%98%E8%A6%81/"/>
    
      <category term="scRNA-seq" scheme="http://yoursite.com/tags/scRNA-seq/"/>
    
      <category term="regulation network" scheme="http://yoursite.com/tags/regulation-network/"/>
    
  </entry>
  
  <entry>
    <title>利用多组学数据预测药物组合的驱动网络标记物</title>
    <link href="http://yoursite.com/2019/12/29/Sun%20Dec%2029%202019%2010:47:14%20GMT+0100/"/>
    <id>http://yoursite.com/2019/12/29/Sun Dec 29 2019 10:47:14 GMT+0100/</id>
    <published>2019-12-29T09:47:14.000Z</published>
    <updated>2019-12-29T04:35:29.280Z</updated>
    
    <content type="html"><![CDATA[<p><strong>文章介绍：</strong></p><p>药物组合不仅可能同时抑制多种肿瘤的驱动信号通路，而且有可能减少药物抵抗性。这篇文章介绍了一个利用多组学数据开发的工具——<strong>DrugComboExplorer</strong>，鉴定药物组合的驱动信号通路，并预测药物组合的协同作用。</p><p>该工具通过处理来自单个癌症患者的DNA测序、基因拷贝数、DNA甲基化和RNA序列数据，使用整合的算法（包括bootstrap aggregating-based Markov random field，WGCNA,监督调控网络学习）流程产生驱动信号网络。</p><p>DrugComboExplorer is available at <a href="https://github.com/Roosevelt-" target="_blank" rel="noopener">https://github.com/Roosevelt-</a> PKU/drugcombinationprediction.</p><p><strong>figure</strong></p><p><img src="/2019/12/29/Sun Dec 29 2019 10:47:14 GMT+0100/fig.png" style="zoom:50%;"></p><a id="more"></a><p><strong>文章信息</strong></p><p>题目：Driver network as a biomarker: systematic integration and network modeling of multi-omics data to derive driver signaling pathways for drug combination prediction</p><p>杂志：Bioinformatics,</p><p>时间：15 February 2019</p><p>链接: doi: 10.1093/bioinformatics/btz109</p><blockquote><p>每日文献摘要：第27篇  2019年12月29日 周日</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;文章介绍：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;药物组合不仅可能同时抑制多种肿瘤的驱动信号通路，而且有可能减少药物抵抗性。这篇文章介绍了一个利用多组学数据开发的工具——&lt;strong&gt;DrugComboExplorer&lt;/strong&gt;，鉴定药物组合的驱动信号通路，并预测药物组合的协同作用。&lt;/p&gt;
&lt;p&gt;该工具通过处理来自单个癌症患者的DNA测序、基因拷贝数、DNA甲基化和RNA序列数据，使用整合的算法（包括bootstrap aggregating-based Markov random field，WGCNA,监督调控网络学习）流程产生驱动信号网络。&lt;/p&gt;
&lt;p&gt;DrugComboExplorer is available at &lt;a href=&quot;https://github.com/Roosevelt-&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/Roosevelt-&lt;/a&gt; PKU/drugcombinationprediction.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;figure&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/12/29/Sun Dec 29 2019 10:47:14 GMT+0100/fig.png&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="文献摘要" scheme="http://yoursite.com/tags/%E6%96%87%E7%8C%AE%E6%91%98%E8%A6%81/"/>
    
  </entry>
  
</feed>
