<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>多标签分类法</title>
      <link href="/2022/05/30/5d573439.html"/>
      <url>/2022/05/30/5d573439.html</url>
      
        <content type="html"><![CDATA[<h3 id="多标签分类-（Multi-label-Classification）"><a href="#多标签分类-（Multi-label-Classification）" class="headerlink" title="多标签分类 （Multi-label Classification）"></a>多标签分类 （Multi-label Classification）</h3><p>二分类问题是机器学习中最常遇到的问题，有时候我们也会遇到<strong>多标签分类（Multi-label Classification）</strong>的处理。首先什么是多标签分类，举个例子，比如一部电影的分类可以同时属于“动作类”，也可以是“喜剧类”，<strong>类别标签不是相互排斥的</strong>。另一种有时会和多标签分类混淆的分类问题——<strong>多类别分类（Multi-class Classification）</strong>，<strong>类别标签是相互排斥的</strong>，如水果的分类，水果的类别有葡萄，苹果,香蕉等，但一种水果不可能即是葡萄又是苹果。</p><h3 id="多标签分类方法"><a href="#多标签分类方法" class="headerlink" title="多标签分类方法"></a>多标签分类方法</h3><p>多标签分类的处理方法常见的有以下几种：</p><p>首先我们构建一个多标签示例数据（Fig. A）, χi ∈ x 是一个训练实例，<br>$$<br>L = (\lambda1,\lambda2,…,\lambda m)<br>$$<br>这里 <strong><em>L</em></strong> 是一个类标签的有限集，m&gt;1。</p><h3 id="1-Binary-relevance-BR"><a href="#1-Binary-relevance-BR" class="headerlink" title="1. Binary relevance (BR)"></a>1. Binary relevance (BR)</h3><p>第一种方法是Binary relevance (BR) （Fig. B），即将具有 L 个标签的数据集划分为 L 个二元分类问题。然后以二分类的方法处理。但是这种方法的一个不足是，没有考虑到多标签间的相关性。</p><h4 id="2-Classifier-Chain-CC"><a href="#2-Classifier-Chain-CC" class="headerlink" title="2. Classifier Chain (CC)"></a>2. Classifier Chain (CC)</h4><p>第二种方法是Classifier Chain (CC) （Fig. C），即将L个二元分类器链接成一个“链”，使得一个分类器的输出预测作为所有后续分类器的附加输入，克服了不考虑标签之间依赖关系的缺点，并捕获了标签之间可能的依赖关系。</p><h4 id="3-Ensemble-Classifier-Chains-ECC"><a href="#3-Ensemble-Classifier-Chains-ECC" class="headerlink" title="3. Ensemble Classifier Chains (ECC)"></a>3. Ensemble Classifier Chains (ECC)</h4><p>第三种方法Ensemble Classifier Chains (ECC)（Fig. D）是在CC基础上提出来的，考虑到了“链”的顺序，通过多数投票聚合了多个具有不同顺序的链，从而可以进一步提升分类器的性能。</p><h4 id="4-Label-Powerset-LP"><a href="#4-Label-Powerset-LP" class="headerlink" title="4. Label Powerset (LP)"></a>4. Label Powerset (LP)</h4><p>第四种方法是Label Powerset (LP)（Fig. E），将多标签问题转换为单标签多类问题，即在训练数据中找到的所有唯一标签组合上进行训练。</p><h4 id="5-Random-Label-Space-Partitioning-with-Label-Powerset（RD）"><a href="#5-Random-Label-Space-Partitioning-with-Label-Powerset（RD）" class="headerlink" title="5. Random Label Space Partitioning with Label Powerset（RD）"></a>5. Random Label Space Partitioning with Label Powerset（RD）</h4><p>第五种方法Random Label Space Partitioning with Label Powerset（RD）（Fig. F）是在LP基础上延伸得到的。其将标签空间划分为大小为 k 的分区，每个分区训练一个 LP 分类器，并通过聚合所有 LP 分类器的结果来预测数据。</p><p><img src="/2022/05/30/5d573439/fig-methods.png" alt></p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul><li><a href="https://www.sciencedirect.com/science/article/pii/S2001037022000824" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/pii/S2001037022000824</a></li><li><a href="https://www.jair.org/index.php/jair/article/view/12376" target="_blank" rel="noopener">https://www.jair.org/index.php/jair/article/view/12376</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>MCC | 机器学习中优于F1-score和accuracy的一个性能评价指标</title>
      <link href="/2022/03/28/4248376.html"/>
      <url>/2022/03/28/4248376.html</url>
      
        <content type="html"><![CDATA[<p>在机器学习中，模型性能的评估是一个关键问题。常见的评价指标有F1-score, Accuracy, Precision, Recall, ROC 和 AUC (对这些评价指标不了解的，可以参考生信菜鸟团之前的一篇文章: <a href="https://mp.weixin.qq.com/s/jQpYuuHJXsFi6Au9DaEklg" target="_blank" rel="noopener">机器学习实战 | 机器学习性能指标</a> )。但是我们对这些统计指标的可靠性要保持谨慎的态度，特别是在不平衡的数据集上。</p><h3 id="F1-score-Accuracy-Precision-Recall"><a href="#F1-score-Accuracy-Precision-Recall" class="headerlink" title="F1-score, Accuracy, Precision, Recall"></a>F1-score, Accuracy, Precision, Recall</h3><p>例如，在一个二元分类模型中，我们的数据是宠物图像，每张图片可以是狗🐶或猫🐱，分类器在每张照片中检测到一只宠物，然后我们测量其性能。假如我们总共有24张图片，然后分类器检测的混淆矩阵如下：</p><p><img src="/2022/03/28/4248376/image-20220401104509019.png" alt="image-20220401104509019"></p><p>我们依次计算下Precision, Recall, F1 score。</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Precision</span> = TP/(TP+FP) = <span class="number">18</span>/(<span class="number">18</span>+<span class="number">3</span>) = <span class="number">0.86</span></span><br><span class="line"></span><br><span class="line">Recall = TP/(TP+FN) = <span class="number">18</span>/(<span class="number">18</span>+<span class="number">2</span>) = <span class="number">0.90</span></span><br><span class="line"></span><br><span class="line">F1 = <span class="number">2</span> * (<span class="keyword">Precision</span>*Recall/<span class="keyword">Precision</span>+Recall) = <span class="number">0.88</span></span><br></pre></td></tr></table></figure><p>从以上这些指标的计算结果来看，我们的模型似乎还不错。但是关于猫 (negative class)的分类，只有1个是正确识别了。那为什么F1-score的值还这么高呢？</p><p>从计算公式中，我们可以看出来，无论是Precision, Recall还是F1 score，他们都只关注了一个类别，即positive class。TN完全没有考虑。</p><p>如果我们设定数据中猫是Positive class，那么我们的混淆矩阵可以转换为：</p><p><img src="/2022/03/28/4248376/image-20220401111415412.png" alt="image-20220401111415412"></p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Precision</span> = TP/(TP+FP) = <span class="number">1</span>/(<span class="number">1</span>+<span class="number">2</span>) = <span class="number">0.33</span></span><br><span class="line"></span><br><span class="line">Recall = TP/(TP+FN) = <span class="number">1</span>/(<span class="number">1</span>+<span class="number">3</span>) = <span class="number">0.25</span></span><br><span class="line"></span><br><span class="line">F1 = <span class="number">2</span> * (<span class="keyword">Precision</span>*Recall/<span class="keyword">Precision</span>+Recall) = <span class="number">0.29</span></span><br></pre></td></tr></table></figure><p>从这里的计算结果可以发现，这个分类器对猫的识别很差。</p><p>然后我们再看下Accuracy，</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Accuracy</span> = TP+TN/(TP+TN+FP+FN) = <span class="number">19</span>/<span class="number">24</span>=<span class="number">0.79</span></span><br></pre></td></tr></table></figure><p>这个结果是相当有误导性的，因为虽然 90% (18/20)的狗被准确分类，但猫只有 25% (1/4)。如果取平均值，结果也只有57.5%，也是低于79%的。这里的原因是因为<strong>数据中两个分类的类别是不平衡的</strong>。</p><p><strong>从以上计算中可以知道Accuracy对类别不平衡很敏感；Precision, Recall和 F1 score是不对称的，只关注了一个类别。</strong></p><h3 id="Matthews-correlation-coefficient，MCC"><a href="#Matthews-correlation-coefficient，MCC" class="headerlink" title="Matthews correlation coefficient，MCC"></a>Matthews correlation coefficient，MCC</h3><p>马修斯相关系数 （MCC）是phi系数（φ）的一个特例。即将True Class和Predicted Class视为两个（二进制）变量，并计算它们的相关系数（与计算任何两个变量之间的相关系数类似）。真实值和预测值之间的相关性越高，预测效果越好。只有当预测在所有四个混淆矩阵类别（TP、TN、FN和FP）中都获得了良好的结果时，它才会产生高分。</p><p>计算公式如下：</p><p><img src="/2022/03/28/4248376/image-20220401114108284.png" alt="image-20220401114108284"></p><p>根据计算公式，可知当分类器是完美的（FP = FN = 0），MCC的值是1，表示完全正相关。相反，当分类器总是分类错误时（TP = TN = 0），得到的数值是-1，代表完美的负相关。所以，MCC的值总是在-1和1之间，0意味着分类器不比随机二分类选择好。此外，MCC是完全对称的，所以没有哪个类别比其他类别更重要，如果把正反两个类别换一下，仍然会得到相同的值。</p><p>然后我们再计算一下，上面例举的数据中MCC的值：</p><p><img src="/2022/03/28/4248376/image-20220401115041223.png" alt="image-20220401115041223"></p><p>MCC的值是0.17 ，表明预测类和真实类是弱相关的。从以上的计算和分析，我们知道这种弱相关是因为分类器不擅长对猫进行分类。</p><p>在python中，scikit-learn模块包含MCC计算的函数 </p><p><code>sklearn.metrics.matthews_corrcoef(y_true, y_pred, *, sample_weight=None)</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> matthews_corrcoef</span><br><span class="line">y_true = [+<span class="number">1</span>, +<span class="number">1</span>, +<span class="number">1</span>, <span class="number">-1</span>]</span><br><span class="line">y_pred = [+<span class="number">1</span>, <span class="number">-1</span>, +<span class="number">1</span>, +<span class="number">1</span>]</span><br><span class="line">matthews_corrcoef(y_true, y_pred)</span><br><span class="line"><span class="number">-0.33</span>...</span><br></pre></td></tr></table></figure><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-6413-7" target="_blank" rel="noopener">The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation.</a></li><li><a href="https://towardsdatascience.com/the-best-classification-metric-youve-never-heard-of-the-matthews-correlation-coefficient-3bf50a2f3e9a" target="_blank" rel="noopener">Matthews Correlation Coefficient is The Best Classification Metric You’ve Never Heard Of</a>.</li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html" target="_blank" rel="noopener"><a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" target="_blank" rel="noopener"><code>sklearn.metrics</code></a>.matthews_corrcoef</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>如何处理机器学习中数据不平衡的分类问题</title>
      <link href="/2022/03/01/b21f85bf.html"/>
      <url>/2022/03/01/b21f85bf.html</url>
      
        <content type="html"><![CDATA[<h2 id="数据不平衡的分类问题"><a href="#数据不平衡的分类问题" class="headerlink" title="数据不平衡的分类问题"></a>数据不平衡的分类问题</h2><p>机器学习中数据不平衡的分类问题很常见，如医学中的疾病诊断，患病的数据比例通常小于正常的；还有欺诈识别，垃圾邮件检测，异常值的检测等。而极端的数据不平衡通常会影响模型预测的准确性和泛化性能。</p><p>这里介绍几种处理不平衡数据的计算方法：</p><ul><li>Oversample and downsample</li><li>Generating synthetic data, eg. SMOTE, ADASYN</li><li>GAN</li></ul><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="1-oversample-and-downsample"><a href="#1-oversample-and-downsample" class="headerlink" title="1. oversample and downsample"></a>1. oversample and downsample</h3><p>一种简单直接的方法是随机重采样 (randomly resample)，包括oversample和downsample。Oversample 即对少数组别重复取样，downsample 即从多数类中删除示例。但是，同时要注意Oversample可能导致某些模型过度拟合。downsample可能导致丢失对模型非常宝贵的信息。</p><p><img src="/2022/03/01/b21f85bf/image-20220301223756926.png" alt="image-20220301223756926"></p><p>可以利用python中<code>imbalanced-learn package</code>实现，如</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## install and import package</span></span><br><span class="line">conda install imbalanced-learn</span><br><span class="line"><span class="keyword">import</span> imblearn</span><br><span class="line">print(imblearn.__version__)</span><br><span class="line"><span class="comment"># 0.9.0</span></span><br><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> RandomOverSampler</span><br><span class="line"><span class="keyword">from</span> imblearn.under_sampling <span class="keyword">import</span> RandomUnderSampler</span><br><span class="line"></span><br><span class="line"><span class="comment">## define oversampling strategy</span></span><br><span class="line">oversample = RandomOverSampler(sampling_strategy=<span class="string">'minority'</span>)  <span class="comment">#this strategy would oversampling the minority class to the same number with majority class</span></span><br><span class="line">oversample2 = RandomOverSampler(sampling_strategy=<span class="number">0.5</span>) <span class="comment">#this strategy would oversampling the minority class to half the number of majority class</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># define undersample strategy</span></span><br><span class="line">undersample = RandomUnderSampler(sampling_strategy=<span class="string">'majority'</span>)</span><br><span class="line"><span class="comment"># define undersample strategy</span></span><br><span class="line">undersample2 = RandomUnderSampler(sampling_strategy=<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure><p>这里定义产生一个极度不平衡的数据（1:100的二分类问题），以oversample为例看一下具体实现的过程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define dataset</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</span><br><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> RandomOverSampler</span><br><span class="line"><span class="comment"># define dataset</span></span><br><span class="line">X, y = make_classification(n_samples=<span class="number">10000</span>, weights=[<span class="number">0.99</span>], flip_y=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># summarize class distribution</span></span><br><span class="line">print(Counter(y))</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; Counter(&#123;0: 9900, 1: 100&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># define oversampling strategy</span></span><br><span class="line">oversample = RandomOverSampler(sampling_strategy=<span class="string">'minority'</span>)</span><br><span class="line">oversample2 = RandomOverSampler(sampling_strategy=<span class="number">0.5</span>)</span><br><span class="line"><span class="comment"># fit and apply the transform</span></span><br><span class="line">X_over, y_over = oversample.fit_resample(X, y)</span><br><span class="line"><span class="comment"># summarize class distribution</span></span><br><span class="line">print(Counter(y_over))</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; Counter(&#123;0: 9900, 1: 9900&#125;)</span></span><br><span class="line"></span><br><span class="line">X_over2, y_over2 = oversample2.fit_resample(X, y)</span><br><span class="line">print(Counter(y_over2))</span><br><span class="line"><span class="comment"># &gt;&gt;&gt;Counter(&#123;0: 9900, 1: 4950&#125;)</span></span><br></pre></td></tr></table></figure><h3 id="2-SMOTE"><a href="#2-SMOTE" class="headerlink" title="2. SMOTE"></a>2. SMOTE</h3><p>另一种处理数据不平衡的方法是可以从现有示例中合成新示例。如 SMOTE (Synthetic Minority Oversampling Technique) 即合成少数组别的过采样技术。相对于oversample直接对少数类群中复制示例，SMOTE是根据少数类别的数据产生了新的数据，属于数据增强（data augmentation ）的一种方法。它的工作原理是选择特征空间中接近的示例，在特征空间中的示例之间绘制一条线，并在该线的某个点处绘制一个新样本。具体来说，首先从少数类中随机选择一个例子，然后找到这个例子的k个最近的邻值（通常是k=5）。随机选择一个邻值 ，并在特征空间中两个例子之间随机选择一个点，创建一个合成例子。</p><p>也可以通过python中<code>imbalanced-learn package</code>实现:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## import SMOTE package</span></span><br><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE</span><br><span class="line"></span><br><span class="line"><span class="comment">## transform the dataset</span></span><br><span class="line">oversample = SMOTE()</span><br><span class="line">X, y = oversample.fit_resample(X, y)</span><br><span class="line"><span class="comment">## summarize the new class distribution</span></span><br><span class="line">counter = Counter(y)</span><br><span class="line">print(counter)</span><br></pre></td></tr></table></figure><h3 id="3-ADASYN"><a href="#3-ADASYN" class="headerlink" title="3. ADASYN"></a>3. ADASYN</h3><p>另一种oversample也是通过合成新样本的方法是ADASYN（Adaptive Synthetic Sampling）。它是通过生成与示例密度成反比的合成数据。即该方法在特征空间中少数示例密度低的区域生成更多合成示例，而在密度高的区域生成更少或不生成合成示例。</p><p>实现方法还可以通过python中<code>imbalanced-learn package</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## import ADASYN package</span></span><br><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> ADASYN</span><br><span class="line"><span class="comment"># transform the dataset</span></span><br><span class="line">oversample = ADASYN()</span><br><span class="line">X, y = oversample.fit_resample(X, y)</span><br><span class="line"><span class="comment"># summarize the new class distribution</span></span><br><span class="line">counter = Counter(y)</span><br><span class="line">print(counter)</span><br></pre></td></tr></table></figure><h3 id="4-GAN"><a href="#4-GAN" class="headerlink" title="4. GAN"></a>4. GAN</h3><p>最后介绍一种较新的方法—GAN (Generative Adversarial Networks) ，即生成对抗网络。其最初是为了从对抗训练过程中生成图像而发明的，是基于深度学习的一种数据增强方法。 GAN 由两个组件组成，一个生成器和一个判别器。生成器试图生成与真实数据相似的数据，而鉴别器试图区分真实数据和生成的数据，GAN 的训练基于这两个组件之间的对抗性游戏。GAN同样也可以用于解决数据不平衡的问题上，如DCGAN（<strong>DOI:</strong> <a href="https://doi.org/10.23919/ChiCC.2018.8483334" target="_blank" rel="noopener">10.23919/ChiCC.2018.8483334</a>）用深度卷积网络实现GAN; SDGAN （<strong>DOI:</strong> <a href="https://doi.org/10.1109/TASE.2020.2967415" target="_blank" rel="noopener">10.1109/TASE.2020.2967415</a>）, ACGAN（<a href="https://arxiv.org/abs/1610.09585v4" target="_blank" rel="noopener">arXiv:1610.09585v4</a>）等模型 。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://github.com/scikit-learn-contrib/imbalanced-learn" target="_blank" rel="noopener">https://github.com/scikit-learn-contrib/imbalanced-learn</a></li><li><p><a href="https://imbalanced-learn.org/stable/user_guide.html#user-guide" target="_blank" rel="noopener">https://imbalanced-learn.org/stable/user_guide.html#user-guide</a></p></li><li><p><a href="https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/" target="_blank" rel="noopener">https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/</a></p></li><li><a href="https://arxiv.org/abs/1106.1813" target="_blank" rel="noopener">https://arxiv.org/abs/1106.1813</a></li><li><a href="https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/" target="_blank" rel="noopener">https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/</a></li><li><a href="https://ieeexplore.ieee.org/abstract/document/9411996" target="_blank" rel="noopener">https://ieeexplore.ieee.org/abstract/document/9411996</a></li><li><a href="https://onlinelibrary.wiley.com/doi/10.1002/sam.11570?af=R" target="_blank" rel="noopener">https://onlinelibrary.wiley.com/doi/10.1002/sam.11570?af=R</a></li><li><a href="https://www.sciencedirect.com/science/article/pii/S1877050918314364" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/pii/S1877050918314364</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>220204 | 文献摘要</title>
      <link href="/2022/02/04/a30d0463.html"/>
      <url>/2022/02/04/a30d0463.html</url>
      
        <content type="html"><![CDATA[<h2 id="Nat-M-L-基于条件变换器、知识提炼和强化学习的多约束分子生成"><a href="#Nat-M-L-基于条件变换器、知识提炼和强化学习的多约束分子生成" class="headerlink" title="Nat. M.L. | 基于条件变换器、知识提炼和强化学习的多约束分子生成"></a>Nat. M.L. | 基于条件变换器、知识提炼和强化学习的多约束分子生成</h2><p>题目：Multi-constraint molecular generation based on conditional transformer, knowledge distillation and reinforcement learning</p><p>杂志：Nature Machine Intelligence</p><p>IF: 15</p><p>时间：18 October 2021</p><p>链接：<a href="https://www.nature.com/articles/s42256-021-00403-1" target="_blank" rel="noopener">https://www.nature.com/articles/s42256-021-00403-1</a></p><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>基于机器学习的生成模型可以从头开始生成具有理想的生理化学和药理学特性的新分子。许多优秀的生成模型已经被提出，但分子生成任务中的多目标优化对于大多数现有的模型来说仍然相当具有挑战性。在此，我们提出了<strong>多约束分子生成（multi-constraint molecular generation, MCMG）方法</strong>，通过知识提炼将条件转化器和强化学习算法结合起来，可以满足多种约束。通过有效地学习并将结构-属性关系纳入一个有偏见的生成过程，条件转化器被用来训练一个分子生成模型。然后采用知识蒸提炼型来降低模型的复杂性，以便通过强化学习有效地进行微调，提高生成分子的结构多样性。正如一组综合基准所证明的那样，MCMG是一种非常有效的方法，可以穿越庞大而复杂的化学空间，寻找满足多种属性约束的新型化合物。</p><a id="more"></a>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> transformer </tag>
            
            <tag> reinforcement learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>220203|文献摘要</title>
      <link href="/2022/02/03/d7478ebb.html"/>
      <url>/2022/02/03/d7478ebb.html</url>
      
        <content type="html"><![CDATA[<h2 id="Nat-M-L-将多组学数据与图卷积网络整合以识别新的癌症基因及其相关的分子机制"><a href="#Nat-M-L-将多组学数据与图卷积网络整合以识别新的癌症基因及其相关的分子机制" class="headerlink" title="Nat. M.L. | 将多组学数据与图卷积网络整合以识别新的癌症基因及其相关的分子机制"></a>Nat. M.L. | 将多组学数据与图卷积网络整合以识别新的癌症基因及其相关的分子机制</h2><p>题目：Integration of multiomics data with graph convolutional networks to identify new cancer genes and their associated molecular mechanisms</p><p>杂志：Nature Machine Intelligence</p><p>IF: 15</p><p>时间：12 April 2021</p><p>链接：<a href="https://www.nature.com/articles/s42256-021-00325-y" target="_blank" rel="noopener">https://www.nature.com/articles/s42256-021-00325-y</a></p><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>随着可用的高通量分子数据的增加，也为识别癌症基因带来了计算上的挑战。遗传和非遗传原因都有可能造成肿瘤的发生，这就需要开发预测模型来有效地整合不同的数据模式，同时具有可解释性。我们介绍了<strong>EMOGI</strong>，这是一种基于图卷积网络的可解释的机器学习方法，其通过结合多组学的泛癌症数据来预测癌症基因，如突变、拷贝数变化、DNA甲基化和基因表达，蛋白质-蛋白质相互作用(PPI) 网络等。在不同的PPI网络和数据集中，EMOGI总体来说比其他方法更准确。我们使用分层相关性传播，根据基因的分类是由相互作用组还是由任何一个全向性水平驱动，对基因进行分层，并确定PPI网络的重要模块。我们提出了165个新的癌症基因，这些基因不一定有反复的改变，但与已知的癌症基因有相互作用。而且我们发现，这些基因与功能缺失筛查中的基本基因相对应。我们相信，我们的方法可以为精准肿瘤学开辟新的途径，并可应用于预测癌症的生物标志物。</p><p><img src="/2022/02/03/d7478ebb/image-20220203092107638.png" alt="image-20220203092107638" style="zoom:50%;"></p><blockquote><p>EMOGI框架的示意图。<strong>a, 数据收集和串联</strong>。计算16个TCGA肿瘤类型的所有基因的平均突变率、CNAs、DNA甲基化和基因表达变化，并在一个早期整合方案中进行连接。然后将得到的特征矩阵与PPI网络和一小部分高置信度的癌症/非癌症基因相结合，形成一个网络，其中节点对应于基因，边对应于它们之间已知的相互作用。每个节点/基因都有一个多维的特征向量（b，输入层）。</p><p><strong>b</strong>，在EMOGI模型训练期间，特征通过连续的图卷积层进行转化（见方法），考虑到越来越大的邻域。输出层根据基因的输出概率将其分类为预测的癌症基因和非癌症基因。</p><p><strong>c</strong>, 使用LRP（见方法）提取每个基因分类的最重要的特征（包括不同癌症类型的全能性水平和相互作用伙伴）。随后根据基因的特征贡献进行聚类，每个基因的相互作用贡献被用来检测癌症中具有重要基因-基因联系的模块。</p></blockquote><p><em><a id="more"></a></em></p><h2 id="Nat-M-L-用于估计抗SARS-CoV-2活动的机器学习平台"><a href="#Nat-M-L-用于估计抗SARS-CoV-2活动的机器学习平台" class="headerlink" title="Nat. M.L. | 用于估计抗SARS-CoV-2活动的机器学习平台"></a>Nat. M.L. | 用于估计抗SARS-CoV-2活动的机器学习平台</h2><p>题目：A machine learning platform to estimate anti-SARS-CoV-2 activities</p><p>杂志：Nature Machine Intelligence</p><p>IF: 15</p><p>时间：13 May 2021</p><p>链接：<a href="https://www.nature.com/articles/s42256-021-00335-w" target="_blank" rel="noopener">https://www.nature.com/articles/s42256-021-00335-w</a></p><h3 id="摘要-1"><a href="#摘要-1" class="headerlink" title="摘要"></a>摘要</h3><p>迫切需要针对COVID-19的药物发现和重新定位的策略。在此，我们提出了REDIAL-2020，一套用于估计小分子在一系列SARS-CoV-2相关检测中的活性的计算模型。模型是利用公开的高通量筛选数据，通过采用不同的描述符类型和各种机器学习策略来训练的。这里我们描述了11个模型的开发和使用，这些模型跨越了病毒进入、病毒复制、活病毒感染性、体外感染性和人类细胞毒性等领域。REDIAL-2020可通过DrugCentral网络门户（<a href="http://drugcentral.org/Redial）作为一个网络应用。该网络应用还提供相似性搜索结果，显示与查询最相似的分子，以及相关的实验数据。REDIAL-2020可以作为一个快速的在线工具，用于识别COVID-19治疗的活性分子。" target="_blank" rel="noopener">http://drugcentral.org/Redial）作为一个网络应用。该网络应用还提供相似性搜索结果，显示与查询最相似的分子，以及相关的实验数据。REDIAL-2020可以作为一个快速的在线工具，用于识别COVID-19治疗的活性分子。</a></p>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> graph convolutional networks </tag>
            
            <tag> multiomics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>220202 | 文献摘要</title>
      <link href="/2022/02/02/f09c6d87.html"/>
      <url>/2022/02/02/f09c6d87.html</url>
      
        <content type="html"><![CDATA[<h2 id="Nat-M-L-通过学习随机掩码来解释生物序列的神经网络"><a href="#Nat-M-L-通过学习随机掩码来解释生物序列的神经网络" class="headerlink" title="Nat. M.L. | 通过学习随机掩码来解释生物序列的神经网络"></a>Nat. M.L. | 通过学习随机掩码来解释生物序列的神经网络</h2><p>题目：Interpreting neural networks for biological sequences by learning stochastic masks</p><p>杂志：Nature Machine Intelligence</p><p>IF: 15</p><p>时间：25 January 2022</p><p>链接：<a href="https://www.nature.com/articles/s42256-021-00428-6" target="_blank" rel="noopener">https://www.nature.com/articles/s42256-021-00428-6</a></p><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>基于序列的神经网络可以从大型生物数据集中学习从而做出准确的预测，但模型的解释仍然具有挑战性。许多现有的特征归属方法是针对连续的而不是离散的输入模式而优化的，并孤立地评估单个特征的重要性，使它们不适合解释分子序列中的非线性相互作用。在这里，在计算机视觉和自然语言处理的工作基础上，我们开发了一种基于<strong>深度学习-扰频器网络（Scrambler networks）</strong>的方法，其中最重要的序列位置是通过学习<strong>输入掩码(input masks)</strong>确定的。扰频器学习预测特定位置的评分矩阵，其中不重要的核苷酸或残基通过提高其熵值而被扰乱。我们应用加扰频器来解释遗传变异的影响，发现顺式调控元素之间的非线性相互作用，解释蛋白质-蛋白质相互作用的结合特异性，并确定从头设计的蛋白质的结构决定因素。我们表明，扰频器能够在大型数据集上进行有效的归因，并产生高质量的解释，往往优于最先进的方法。</p><p><img src="/2022/02/02/f09c6d87/image-20220202083212293.png" alt="image-20220202083212293" style="zoom:50%;"></p><p><em><a id="more"></a></em></p><h2 id="Nat-M-L-通过人工智能中的隐私保护协作推进-COVID-19-诊断"><a href="#Nat-M-L-通过人工智能中的隐私保护协作推进-COVID-19-诊断" class="headerlink" title="Nat. M.L. | 通过人工智能中的隐私保护协作推进 COVID-19 诊断"></a>Nat. M.L. | 通过人工智能中的隐私保护协作推进 COVID-19 诊断</h2><p>题目：Advancing COVID-19 diagnosis with privacy-preserving collaboration in artificial intelligence</p><p>杂志：Nature Machine Intelligence</p><p>IF: 15</p><p>时间：15 December 2021</p><p>链接：<a href="https://www.nature.com/articles/s42256-021-00421-z" target="_blank" rel="noopener">https://www.nature.com/articles/s42256-021-00421-z</a></p><h3 id="摘要-1"><a href="#摘要-1" class="headerlink" title="摘要"></a>摘要</h3><p>人工智能为COVID-19的诊断提供了一个有希望的解决方案，然而，围绕安全和可信度的担扰阻碍了大规模代表性医疗数据的收集，为在临床实践中训练一个通用的模型带来了相当大的挑战。为了解决这个问题，我们发起了统一CT-COVID人工智能诊断计划<strong>（Unified CT-COVID AI Diagnostic Initiative，UCADI）</strong>，人工智能模型可以在一个联邦学习框架（<strong>federated learning</strong>）下分布式地训练并在每个主办机构独立执行，而不需要分享数据。这里显示我们的联邦学习框架大大超过了所有的本地模型（在中国的测试灵敏度/特异性为0.973/0.951，在英国为0.730/0.942），达到了与专业放射医师小组相当的性能。我们进一步评估了该模型在保留（从另外两家医院收集的没有联合学习框架的数据）和异质（用造影剂获得）数据上的表现，为模型做出的决定提供了可视化的解释，并分析了模型性能和联邦训练过程中沟通成本之间的权衡。我们的研究是基于从中国和英国的23家医院收集的3336名患者的9573张胸部计算机断层扫描。总的来说，我们的工作推进了利用联合学习在数字健康领域保护隐私的人工智能的前景。</p><p><img src="/2022/02/02/f09c6d87/image-20220202085203685.png" alt="image-20220202085203685" style="zoom:50%;"></p>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> federal learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>综述｜利用深度学习进行多组学数据整合的路线图</title>
      <link href="/2022/01/11/7b8ddaea.html"/>
      <url>/2022/01/11/7b8ddaea.html</url>
      
        <content type="html"><![CDATA[<h2 id="文章信息"><a href="#文章信息" class="headerlink" title="文章信息"></a>文章信息</h2><p>题目：A roadmap for multi-omics data integration using deep learning</p><p>杂志：Briefings in Bioinformatics</p><p>IF: 11.62</p><p>时间：12 November 2021</p><p>链接：<a href="https://doi.org/10.1093/bib/bbab454" target="_blank" rel="noopener">https://doi.org/10.1093/bib/bbab454</a></p><h2 id="一句话评价"><a href="#一句话评价" class="headerlink" title="一句话评价"></a>一句话评价</h2><p>介绍了利用深度学习对多组学数据的整合和应用以及优缺点</p><p><img src="/2022/01/11/7b8ddaea/image-20220202090004483.png" alt="image-20220202090004483"></p><a id="more"></a><h2 id="文章信息-1"><a href="#文章信息-1" class="headerlink" title="文章信息"></a>文章信息</h2><p>题目：Integrating multi-omics data through deep learning for accurate cancer prognosis prediction</p><p>杂志：Computers in Biology and Medicine</p><p>IF: 4.589</p><p>时间：July 2021</p><p>链接：<a href="https://doi.org/10.1016/j.compbiomed.2021.104481" target="_blank" rel="noopener">https://doi.org/10.1016/j.compbiomed.2021.104481</a></p><p>代码： <a href="https://github.com/Hua0113/DCAP" target="_blank" rel="noopener">https://github.com/Hua0113/DCAP</a></p><h2 id="一句话评价-1"><a href="#一句话评价-1" class="headerlink" title="一句话评价"></a>一句话评价</h2><p>通过深度学习整合多组学数据以进行准确的癌症预后预测</p><p><img src="/2022/01/11/7b8ddaea/image-20220111213116633.png" alt="image-20220111213116633"></p><ul><li><p>开发了一种新的多组学方法，在<strong>去噪自动编码器</strong>的基础上准确预测癌症的预后。</p></li><li><p>一个仅使用mRNA数据的轻量级模型在三个外部GEO数据集上得到了独立验证。</p></li><li><p>一个仅使用mRNA数据的轻量级模型在三个外部GEO数据集上得到了独立验证。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>乳腺癌治疗反应的多组学机器学习预测器</title>
      <link href="/2022/01/10/dfeeb526.html"/>
      <url>/2022/01/10/dfeeb526.html</url>
      
        <content type="html"><![CDATA[<p>题目：Multi-omic machine learning predictor of breast cancer therapy response</p><p>杂志：Nature</p><p>IF: 49.96</p><p>时间：7 Dec. 2021</p><p>链接：<a href="https://www.nature.com/articles/s41586-021-04278-5" target="_blank" rel="noopener">https://www.nature.com/articles/s41586-021-04278-5</a></p><p>代码：</p><ul><li><a href="https://github.com/micrisor/NAT-ML" target="_blank" rel="noopener">https://github.com/micrisor/NAT-ML</a></li><li><a href="https://github.com/cclab-brca/neoadjuvant-therapy-response-predictor" target="_blank" rel="noopener">https://github.com/cclab-brca/neoadjuvant-therapy-response-predictor</a></li></ul><h3 id="一句话概括"><a href="#一句话概括" class="headerlink" title="一句话概括"></a>一句话概括</h3><p>使用逻辑回归，SVM和随机森林的组合机器学习方法，结合临床数据、数字病理学数据、基因组和转录组学数据，对乳腺癌治疗的反应进行预测</p><p>###摘要</p><p>乳腺癌是由恶性细胞和肿瘤微环境组成的复杂生态系统。这些肿瘤生态系统的组成和其中的相互作用有助于细胞毒性治疗反应。构建细胞毒性治疗反应的预测器还有待研究。这篇文章收集了<strong>168名</strong>患者在手术前接受化疗+/-HER2靶向治疗的乳腺肿瘤治疗前活检的<strong>临床、数字病理学、基因组和转录组资料</strong>。然后将手术时的病理终点（完全反应或残余疾病）与这些诊断性活检的多组学特征相关联。他们发现，对治疗的反应是由预处理的肿瘤生态系统调节的，其多组学景观可以用机器学习整合到预测模型中。治疗后残余疾病的程度与治疗前的特征单调相关，包括<strong>肿瘤突变和拷贝数变异、肿瘤增殖、免疫浸润和T细胞功能紊乱和排斥</strong>。将这些特征结合到一个多组学机器学习模型中，可预测外部验证队列（75名患者）的病理完全反应，AUC为0.87。总之，对治疗的反应是由通过数据整合和机器学习捕获的整个肿瘤生态系统的基线特征决定的。这种方法可用于开发其他癌症的预测器。</p><p><img src="/2022/01/10/dfeeb526/image-20220111000724850.png" alt="image-20220111000724850"></p><p><img src="/2022/01/10/dfeeb526/image-20220111000748893.png" alt="image-20220111000748893"></p>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>211012｜文献摘要</title>
      <link href="/2021/10/12/b83dc028.html"/>
      <url>/2021/10/12/b83dc028.html</url>
      
        <content type="html"><![CDATA[<h2 id="Nat-Biotechnol-通过迁移学习将单细胞数据映射到参考图谱"><a href="#Nat-Biotechnol-通过迁移学习将单细胞数据映射到参考图谱" class="headerlink" title="Nat. Biotechnol. | 通过迁移学习将单细胞数据映射到参考图谱"></a>Nat. Biotechnol. | 通过迁移学习将单细胞数据映射到参考图谱</h2><p>题目：Mapping single-cell data to reference atlases by transfer learning</p><p>杂志：Nature Biotechnology</p><p>IF: 54.91</p><p>时间：30 August 2021</p><p>链接：<a href="https://www.nature.com/articles/s41587-021-01001-7" target="_blank" rel="noopener">https://www.nature.com/articles/s41587-021-01001-7</a></p><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>现在，大型单细胞图谱被不断地生成，作为分析较小规模研究的参考。然而，由于数据集之间的批次效应、计算资源的有限可用性和原始数据的共享限制，从参考数据中学习是复杂的。在这里，我们介绍了一种深度学习策略，用于在称为单细胞结构手术（single-cell architectural surgery，scArches）的参考之上映射查询数据集。scArches使用转移学习和参数优化来实现高效、分散、迭代的参考构建和新数据集与现有参考的上下文关系，而无需分享原始数据。利用小鼠大脑、胰腺、免疫和全生物体图谱的例子，我们表明scArches保留了生物状态信息，同时消除了批量效应，而且使用的参数比从头整合少四个数量级。最后，scArches在映射到健康参照物时保留了COVID-19的疾病变异，从而能够发现疾病特定的细胞状态。scArches将通过实现参照物图谱的迭代构建、更新、共享和有效使用来促进合作项目。</p><p><img src="/2021/10/12/b83dc028/image-20211012210720260.png" alt="image-20211012210720260"></p><p><em><a id="more"></a></em></p><h2 id="Nat-Commu-深度迁移学习用于减少由于生物医学数据不平等引起的医疗保健差异"><a href="#Nat-Commu-深度迁移学习用于减少由于生物医学数据不平等引起的医疗保健差异" class="headerlink" title="Nat. Commu. | 深度迁移学习用于减少由于生物医学数据不平等引起的医疗保健差异"></a>Nat. Commu. | 深度迁移学习用于减少由于生物医学数据不平等引起的医疗保健差异</h2><p>题目：Deep transfer learning for reducing health care disparities arising from biomedical data inequality</p><p>杂志：Nature Communication</p><p>IF: 14.92</p><p>时间：30 December 2020</p><p>链接：<a href="https://www.nature.com/articles/s41467-020-18918-3" target="_blank" rel="noopener">https://www.nature.com/articles/s41467-020-18918-3</a></p><h3 id="摘要-1"><a href="#摘要-1" class="headerlink" title="摘要"></a>摘要</h3><p>随着人工智能（AI）越来越多地应用于生物医学研究和临床决策，开发对所有种族群体同样有效的无偏见的AI模型对预防和减少健康差异至关重要。然而，通过数据驱动的、基于算法的生物医学研究和临床决策，不同族裔群体之间的生物医学数据不平等将产生新的医疗保健差异。通过对癌症全向数据进行大量的机器学习实验，我们发现目前流行的多民族机器学习方案容易在不同民族之间产生明显的模型性能差异。我们表明，这些性能差异是由族群之间的数据不平等和数据分布差异造成的。我们还发现，<strong>转移学习可以改善处于数据劣势的民族群体的机器学习模型性能，从而为减少民族群体之间的数据不平等造成的医疗差异提供了有效的方法</strong>。</p><p><img src="/2021/10/12/b83dc028/image-20211012211618511.png" alt="image-20211012211618511"></p><h2 id="Nat-Commu-使用二维深度神经网络和迁移学习的组合预测RNA二级结构"><a href="#Nat-Commu-使用二维深度神经网络和迁移学习的组合预测RNA二级结构" class="headerlink" title="Nat. Commu. | 使用二维深度神经网络和迁移学习的组合预测RNA二级结构"></a>Nat. Commu. | 使用二维深度神经网络和迁移学习的组合预测RNA二级结构</h2><p>题目：RNA secondary structure prediction using an ensemble of two-dimensional deep neural networks and transfer learning</p><p>杂志：Nature Communication</p><p>IF: 14.92</p><p>时间：27 November 2019</p><p>链接：<a href="https://www.nature.com/articles/s41467-019-13395-9" target="_blank" rel="noopener">https://www.nature.com/articles/s41467-019-13395-9</a></p><h3 id="摘要-2"><a href="#摘要-2" class="headerlink" title="摘要"></a>摘要</h3><p>我们人类基因组的大部分转录为结构和功能未知的非编码RNA。获得非编码RNA的功能线索需要准确的碱基配对或二级结构预测。然而，目前基于折叠的算法对这种预测的表现已经停滞了十多年。在这里，我们提出使用深度上下文学习来预测碱基对，包括那些由三级相互作用稳定的非经典和非嵌套（假结）碱基对。由于只有&lt;250个非冗余的、高分辨率的RNA结构可用于模型训练，我们利用转移学习，从一个最初用&gt;10,000个非冗余RNA的最近高质量bpRNA数据集训练出来的模型。由此产生的方法在预测所有碱基对，特别是非经典碱基对和非嵌套碱基对方面取得了很大的、有统计学意义的改进。所提出的方法（SPOT-RNA），有免费的服务器和独立的软件，应该对改善RNA结构建模、序列比对和功能注释有帮助。</p><p><img src="/2021/10/12/b83dc028/image-20211012212552824.png" alt="image-20211012212552824" style="zoom:50%;"></p>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> transfer learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>211011-｜文献摘要</title>
      <link href="/2021/10/11/754b48bf.html"/>
      <url>/2021/10/11/754b48bf.html</url>
      
        <content type="html"><![CDATA[<h2 id="Brief-Bioinformatics-DeepHost：用卷积神经网络进行噬菌体宿主预测"><a href="#Brief-Bioinformatics-DeepHost：用卷积神经网络进行噬菌体宿主预测" class="headerlink" title="Brief. Bioinformatics | DeepHost：用卷积神经网络进行噬菌体宿主预测"></a>Brief. Bioinformatics | DeepHost：用卷积神经网络进行噬菌体宿主预测</h2><p>题目：DeepHost: phage host prediction with convolutional neural network</p><p>杂志：Briefings in Bioinformatics</p><p>IF: 11.62</p><p>时间：22 September 2021</p><p>链接：<a href="https://doi.org/10.1093/bib/bbab385" target="_blank" rel="noopener">https://doi.org/10.1093/bib/bbab385</a></p><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>新一代测序技术迅速扩大了已知的噬菌体基因组。与基于培养的方法不同，从下一代测序数据中发现的噬菌体的宿主仍未被描述。噬菌体基因组的高度多样性使得宿主分配任务具有挑战性。为了解决这个问题，我们提出了一个噬菌体宿主预测工具-DeepHost。为了将噬菌体基因组编码成矩阵，我们设计了一种基因组编码方法，应用各种间隔的<strong>K-mer对</strong>来容忍序列变化，包括插入、删除和突变。DeepHost应用卷积神经网络来预测宿主分类法。DeepHost在属级（72个分类群）的预测准确率为96.05%，在种级（118个分类群）的预测准确率为90.78%，比现有的噬菌体宿主预测工具高出10.16-30.48%，取得了与BLAST相当的结果。对于在BLAST中没有命中的基因组，DeepHost在属级获得了38.00%的准确率，在种级获得了26.47%的准确率，使其适用于与现有数据集同源序列较少的基因组。DeepHost是alignment-free的，它比BLAST快，特别是对大的数据集。DeepHost可在<a href="https://github.com/deepomicslab/DeepHost。" target="_blank" rel="noopener">https://github.com/deepomicslab/DeepHost。</a></p><p><strong>文章思路</strong></p><p><img src="/2021/10/11/754b48bf/image-20211011221810475.png" alt="image-20211011221810475"></p><p><strong>基因组序列编码方法：</strong></p><p><img src="/2021/10/11/754b48bf/image-20211011221515028.png" alt="image-20211011221515028"></p><blockquote><p><em>Illustration of the matrix construction process. Given a DNA sequence, all possible 2-mer pairs are collected with spaced distance of 0 (upper) and 1 (lower). For each distance, we construct two matrices.</em></p></blockquote><p><strong>CNN 架构</strong></p><p><img src="/2021/10/11/754b48bf/image-20211011221657856.png" alt="image-20211011221657856"></p>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> machine learning </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>210930 ｜文献摘要</title>
      <link href="/2021/09/30/45570cbd.html"/>
      <url>/2021/09/30/45570cbd.html</url>
      
        <content type="html"><![CDATA[<h2 id="Brief-Bioinformatics-｜评估基于基因组测序数据寻找顺式调控基序的深度学习方法"><a href="#Brief-Bioinformatics-｜评估基于基因组测序数据寻找顺式调控基序的深度学习方法" class="headerlink" title="Brief. Bioinformatics ｜评估基于基因组测序数据寻找顺式调控基序的深度学习方法"></a>Brief. Bioinformatics ｜评估基于基因组测序数据寻找顺式调控基序的深度学习方法</h2><p>题目：Assessing deep learning methods in cis-regulatory motif finding based on genomic sequencing data</p><p>杂志：Briefings in Bioinformatics</p><p>IF: 11.62</p><p>时间：05 October 2021</p><p>链接：<a href="https://doi.org/10.1093/bib/bbab374" target="_blank" rel="noopener">https://doi.org/10.1093/bib/bbab374</a></p><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>从基因组测序数据（如ChIP-seq和CLIP-seq）中识别顺式调控基序，对于识别转录因子（TF）结合位点和推断任何生物体的基因调控机制至关重要。自2015年以来，深度学习（DL）方法已被广泛用于识别TF结合位点和预测基序，其优点是提供一个可扩展的、灵活的和统一的计算方法，以实现高度准确的预测。目前已经开发了20种DL方法。然而，如果没有一个明确和系统的评估，用户将很难为他们的具体研究选择最合适的工具。在这份研究中，他们使用<strong>690个ENCODE ChIP-seq、126个癌症ChIP-seq和55个RNA CLIP-seq数据评估了20种顺式调控图案预测的DL方法</strong>。他们评估了四个指标，包括发现动机的准确性、DNA/RNA序列分类的性能、算法的可扩展性和工具的可用性。评估结果证明了现有DL方法的高度互补性。确定最适合的模型应主要取决于数据的大小和类型以及方法的输出。</p><p><img src="/2021/09/30/45570cbd/image-20211011215253621.png" alt="image-20211011215253621" style="zoom:50%;"></p><p><img src="/2021/09/30/45570cbd/image-20211011215337568.png" alt="image-20211011215337568"></p>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>210929 ｜文献摘要</title>
      <link href="/2021/09/29/cbb33e81.html"/>
      <url>/2021/09/29/cbb33e81.html</url>
      
        <content type="html"><![CDATA[<h2 id="Commun-Biol-Review-人工智能加速抗生素发现"><a href="#Commun-Biol-Review-人工智能加速抗生素发现" class="headerlink" title="Commun. Biol. | Review | 人工智能加速抗生素发现"></a>Commun. Biol. | Review | 人工智能加速抗生素发现</h2><p>题目：Accelerating antibiotic discovery through artificial intelligence</p><p>杂志：Communication Biology</p><p>IF: 6.268</p><p>时间：09 September 2021</p><p>链接：<a href="https://doi.org/10.1038/s42003-021-02586-0" target="_blank" rel="noopener">https://doi.org/10.1038/s42003-021-02586-0</a></p><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>通过靶向结合入侵的生物体，抗生素将自己插入宿主-病原体进化军备竞赛的古老斗争中。随着病原体进化出躲避抗生素的策略，治疗的疗效也逐渐下降，而且必须被取代，这使抗生素与大多数其他形式的药物开发不同。再加上缓慢而昂贵的抗生素开发管道，耐药性病原体的扩散促使人们对有望加快候选药物发现的计算方法产生迫切的兴趣。人工智能（AI）的不断发展鼓励其应用于计算机辅助药物设计的多个层面，并越来越多地应用于抗生素发现。</p><p>这篇综述描述了<br>1）人工智能在发现小分子抗生素和抗菌肽方面的进展。<br>2）除了对抗菌活性的基本预测外，还强调了抗菌化合物的代表性、药物相似性特征的确定、抗菌剂的抗性和新分子设计。<br>3）分析了人工智能驱动的抗生素发现中对开放科学最佳实践的吸收情况，并主张将开放性和可重复性作为加速临床前研究的手段。<br>4）最后，讨论了文献中的趋势和未来探索的领域。</p><p><strong>抗生素发现的相关数据库</strong></p><p><img src="/2021/09/29/cbb33e81/image-20210929133826090.png" alt="image-20210929133826090" style="zoom:50%;"></p><p><strong>计算方法发现抗生素的流程</strong></p><p><img src="/2021/09/29/cbb33e81/image-20210929125714699.png" alt="image-20210929125714699" style="zoom:50%;"></p><p><em><a id="more"></a></em></p><h2 id="Brief-Bioinformatics-｜深度神经网络的基因连接矩阵对三阴性乳腺癌亚型分类和基因选择"><a href="#Brief-Bioinformatics-｜深度神经网络的基因连接矩阵对三阴性乳腺癌亚型分类和基因选择" class="headerlink" title="Brief. Bioinformatics ｜深度神经网络的基因连接矩阵对三阴性乳腺癌亚型分类和基因选择"></a>Brief. Bioinformatics ｜深度神经网络的基因连接矩阵对三阴性乳腺癌亚型分类和基因选择</h2><p>题目：Classification and gene selection of triple-negative breast cancer subtype embedding gene connectivity matrix in deep neural network</p><p>杂志：Briefings in Bioinformatics</p><p>IF: 11.62</p><p>时间：05 September 2021</p><p>链接：<a href="https://doi.org/10.1093/bib/bbaa395" target="_blank" rel="noopener">https://doi.org/10.1093/bib/bbaa395</a></p><h3 id="摘要-1"><a href="#摘要-1" class="headerlink" title="摘要"></a>摘要</h3><p>三阴性乳腺癌（TNBC）一直是肿瘤学治疗中具有挑战性的乳腺癌亚型。通常情况下，它可以被划分为不同的分子亚型。对这六种亚型进行准确和稳定的分类对于TNBC的个性化治疗至关重要。在这项研究中，作者提出了一个新的框架来区分TNBC的六个亚型，这也是少数几个基于<strong>mRNA和长非编码RNA表达数据</strong> 完成分类的研究之一。特别是，他们开发了一种名为<strong>DGGA的基因选择方法</strong>，该方法在衡量基因重要性的过程中考虑了基因之间的相关信息（WGCNA），然后有效地去除多余的基因。他们提出了一种基因评分方法，将GeneRank分数与深度神经网络（DNN）产生的基因重要性结合起来，考虑到亚型间的鉴别和基因内部的相关性，以提高基因选择性能。更重要的是，他们在DNN中嵌入了基因连接矩阵进行稀疏学习，在获得每个基因的相对重要性的测量时，会额外考虑训练过程中的权重变化。最后，遗传算法被用来模拟自然进化过程，以寻找TNBC亚型分类的最佳子集。他们通过交叉验证来验证所提出的方法，结果表明它可以使用较少的基因来获得更准确的分类结果。</p><p>代码在：<a href="https://github.com/RanSuLab/TNBC。" target="_blank" rel="noopener">https://github.com/RanSuLab/TNBC。</a></p><p><img src="/2021/09/29/cbb33e81/image-20210929131232918.png" alt="image-20210929131232918" style="zoom:50%;"></p><h2 id="Brief-Bioinformatics-｜DeepCNV：一种用于验证拷贝数变异-CNV-的深度学习方法"><a href="#Brief-Bioinformatics-｜DeepCNV：一种用于验证拷贝数变异-CNV-的深度学习方法" class="headerlink" title="Brief. Bioinformatics ｜DeepCNV：一种用于验证拷贝数变异 (CNV) 的深度学习方法"></a>Brief. Bioinformatics ｜DeepCNV：一种用于验证拷贝数变异 (CNV) 的深度学习方法</h2><p>题目：DeepCNV: a deep learning approach for authenticating copy number variations</p><p>杂志：Briefings in Bioinformatics</p><p>IF: 11.62</p><p>时间：05 September 2021</p><p>链接：<a href="https://doi.org/10.1093/bib/bbaa381" target="_blank" rel="noopener">https://doi.org/10.1093/bib/bbaa381</a></p><h3 id="摘要-2"><a href="#摘要-2" class="headerlink" title="摘要"></a>摘要</h3><p>拷贝数变异（CNVs）是一类重要的变异，有助于许多疾病表型的发病机制。从基因组数据中检测CNVs仍然很困难，目前应用的大多数方法都存在不可接受的高假阳性率。一个常见的做法是在进一步的下游分析或实验验证之前，由人类专家手动审查原始的CNV调用以过滤假阳性。在这里，他们提出了DeepCNV，一个基于深度学习的工具，目的是在验证CNV调用时取代人类专家，重点是由最准确的CNV调用者之一PennCNV进行调用。深度神经网络算法的复杂性被超过10 000个专家评分的样本所丰富，这些样本被分成训练和测试集。变种的置信度，特别是对于CNVs，是阻碍CNVs与疾病联系起来的主要障碍。结果表明，DeepCNV增加了CNV调用的置信度，其最佳接收者操作特征曲线下面积为0.909，超过了其他机器学习方法。DeepCNV的优越性也通过实验性的湿实验室验证数据集进行了基准测试和确认。我们得出结论，DeepCNV获得的改进使假阳性结果和复制CNV关联结果的失败明显减少。</p><h3 id="CNV图像产生的方法：-PennCNV"><a href="#CNV图像产生的方法：-PennCNV" class="headerlink" title="CNV图像产生的方法： PennCNV"></a>CNV图像产生的方法： PennCNV</h3><p>为了直观地检查CNV调用并判断它们是否为真阳性，我们利用PennCNV提供的辅助可视化程序（visualize_cnv.pl）为CNV调用自动生成图像文件。对于每个CNV调用，它产生一个LRR散点图图像和一个BAF散点图图像。这些图涵盖了一个候选的CNV片段和它的周围区域。LRR图为该区域（候选CNV+其扩展区域）中的每个SNP基因分型画一个点，染色体位置为X坐标，LRR为Y坐标。BAF图以类似的图覆盖同一区域，但使用BAF作为Y坐标。对于这两张图，我们将候选CNV中的SNPs（点）涂成红色，将周围区域的SNPs涂成蓝色。然后，具有CNV调用专业知识的科学家根据视觉效果将它们标记为假阳性或真阳性。图1描述了样本图像。这些图像被用作DeepCNV的输入。图像中的像素范围从0到255。按照标准的图像缩放操作，我们通过将每个像素除以255来规范像素值，因此新的值在0和1之间，供DeepCNV使用。</p><p><img src="/2021/09/29/cbb33e81/image-20210929131744683.png" alt="image-20210929131744683" style="zoom:50%;"></p>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> AMR </tag>
            
            <tag> machine learning </tag>
            
            <tag> 药物研发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>整合多组学数据和图像卷积网络鉴定新的癌症基因和相关的分子机制</title>
      <link href="/2021/09/19/f8c75c1b.html"/>
      <url>/2021/09/19/f8c75c1b.html</url>
      
        <content type="html"><![CDATA[<h2 id="文章信息"><a href="#文章信息" class="headerlink" title="文章信息"></a>文章信息</h2><p>题目：Integration of multiomics data with graph convolutional networks to identify new cancer genes and their associated molecular mechanisms</p><p>杂志：Nature Machine Intelligence</p><p>IF:16.65</p><p>时间：12 April 2021</p><p>链接：<a href="https://www.nature.com/articles/s42256-021-00325-y" target="_blank" rel="noopener">https://www.nature.com/articles/s42256-021-00325-y</a></p><h2 id="一句话评价"><a href="#一句话评价" class="headerlink" title="一句话评价"></a>一句话评价</h2><p>使用机器学习方法——图像卷积网络对多组学数据（SNPs, CNV，DAN methylation，protein interaction (PPI) networks）进行挖掘，预测新的癌症基因以及这些基因发挥功能的机制。</p><p><img src="/2021/09/19/f8c75c1b/image-20210919224314468.png" alt="image-20210919224314468" style="zoom:50%;"></p><p><img src="/2021/09/19/f8c75c1b/image-20210919224447370.png" alt="image-20210919224447370"></p>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多标签分类提高耐药性预测能力</title>
      <link href="/2021/04/04/c387b45f.html"/>
      <url>/2021/04/04/c387b45f.html</url>
      
        <content type="html"><![CDATA[<h2 id="文章信息"><a href="#文章信息" class="headerlink" title="文章信息"></a>文章信息</h2><p>题目：Exploiting HIV-1 protease and reverse transcriptase cross-resistance information for improved drug resistance prediction by means of multi-label classification</p><p>杂志：BioData Mining</p><p>IF: 2.672</p><p>时间：2016</p><p>链接：DOI 10.1186/s13040-016-0089-1</p><h2 id="一句话评价"><a href="#一句话评价" class="headerlink" title="一句话评价"></a>一句话评价</h2><p>多标签分类应用</p><a id="more"></a><h2 id="文章介绍"><a href="#文章介绍" class="headerlink" title="文章介绍"></a>文章介绍</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>（背景，亮点，方法，结果，意义）</p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>（详细解读）</p><h3 id="结果和结论"><a href="#结果和结论" class="headerlink" title="结果和结论"></a>结果和结论</h3><p>（简要，理顺逻辑）</p><h3 id="创新性和意义"><a href="#创新性和意义" class="headerlink" title="创新性和意义"></a>创新性和意义</h3><p>（思路，方法或者数据资源对自己有什么启示）</p>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AMR </tag>
            
            <tag> multi-label classification </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在HIV-1耐药性预测中利用交叉耐药信息的多标签分类方法</title>
      <link href="/2021/04/03/f1069cae.html"/>
      <url>/2021/04/03/f1069cae.html</url>
      
        <content type="html"><![CDATA[<h2 id="文章信息"><a href="#文章信息" class="headerlink" title="文章信息"></a>文章信息</h2><p>题目：Multilabel classification for exploiting cross-resistance information in HIV-1 drug resistance prediction</p><p>杂志：Bioinformatics (Sequence Analysis)</p><p>IF: 5.610 (2019)</p><p>时间：June 21, 2013</p><p>链接：doi:10.1093/bioinformatics/btt331</p><h2 id="一句话评价"><a href="#一句话评价" class="headerlink" title="一句话评价"></a>一句话评价</h2><p>多标签分类算法</p><a id="more"></a><h2 id="文章介绍"><a href="#文章介绍" class="headerlink" title="文章介绍"></a>文章介绍</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>耐药性是疾病治疗中面临的一个重要难题。很多细菌或病毒还经常出现交叉耐药现象。不仅导致了当前治疗大的某一药物产生耐药性，而且对未使用的药物也产生耐药性。因此，耐药性的自动分类和预测在临床研究上具有重要的意义。而机器学习虽然已广泛用于抗药性研究，但是多重交叉耐药的信息还有待研究。</p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><h4 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h4><p><img src="/2021/04/03/f1069cae/image-20210406163704225.png" alt="image-20210406163704225" style="zoom:50%;"></p><p>IC50 ratio: 这里与药物的抗性相关，IC50 ratio cutoff是每个药物定义为抗性的临界值。</p><h4 id="多标签分类"><a href="#多标签分类" class="headerlink" title="多标签分类"></a>多标签分类</h4><h4 id="分类器链（Classification-Chains-CC）"><a href="#分类器链（Classification-Chains-CC）" class="headerlink" title="分类器链（Classification Chains, CC）"></a>分类器链（Classification Chains, CC）</h4><h4 id="CC的组合"><a href="#CC的组合" class="headerlink" title="CC的组合"></a>CC的组合</h4><h3 id="结果和结论"><a href="#结果和结论" class="headerlink" title="结果和结论"></a>结果和结论</h3><p>（简要，理顺逻辑）</p><h3 id="创新性和意义"><a href="#创新性和意义" class="headerlink" title="创新性和意义"></a>创新性和意义</h3><p>（思路，方法或者数据资源对自己有什么启示）</p>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AMR </tag>
            
            <tag> multi-label classification </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习在药物抗性分析中的应用</title>
      <link href="/2021/04/02/9fe5283f.html"/>
      <url>/2021/04/02/9fe5283f.html</url>
      
        <content type="html"><![CDATA[<h2 id="文章信息"><a href="#文章信息" class="headerlink" title="文章信息"></a>文章信息</h2><p>题目：Application of machine learning techniques to tuberculosis drug resistance analysis</p><p>杂志：Bioinformatics, Data and text mining</p><p>IF: 5.610 (2019)</p><p>时间：21 November, 2018</p><p>链接：doi: 10.1093/bioinformatics/bty949</p><h2 id="一句话评价"><a href="#一句话评价" class="headerlink" title="一句话评价"></a>一句话评价</h2><p>对比了不同的机器学习算法（LR，gradient tree boosting）在预测肺结核药物抗性中的性能</p><a id="more"></a><h2 id="文章介绍"><a href="#文章介绍" class="headerlink" title="文章介绍"></a>文章介绍</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><ul><li>及时识别结核分枝杆菌（MTB）对现有药物的耐药性对降低死亡率和防止现有抗生素耐药性的扩大至关重要。机器学习方法已被广泛应用于及时预测特定药物下MTB的耐药性和识别耐药标志物。然而，它们在耐药性预测和耐药性标志物识别方面还没有在全球多中心的MTB样本大队列上得到验证。</li><li>本文收集的样本来自6个大洲中的16个国家，共有13402个isolates，涉及到11种药物。</li><li>对比的机器学习方法有：SVM, LR, product-of-marginals (PM), gradient tree boosting, Adaboost, RF。其中LR和gradient tree boosting的性能比其他的算法好。</li><li>此外，根据突变位点的排序提供了一些潜在的研究靶标。并给出了文中所用的源码： <a href="http://www.robots.ox.ac.uk/davidc/code.php" target="_blank" rel="noopener">http://www.robots.ox.ac.uk/davidc/code.php</a></li></ul><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p><img src="/2021/04/02/9fe5283f/image-20210405120750554.png" alt="image-20210405120750554" style="zoom:50%;"></p><h4 id="WGS数据分析"><a href="#WGS数据分析" class="headerlink" title="WGS数据分析"></a>WGS数据分析</h4><p>序列比对，call变异位点，过滤低质量的变异位点，最终保留5919个位点。</p><h4 id="Baseline-Methods"><a href="#Baseline-Methods" class="headerlink" title="Baseline Methods"></a>Baseline Methods</h4><p>现有的基线方法是根据一些预先确定的变异库将药物分类为存在耐药性或不存在耐药性。直接关联(DA)的方法使用 “OR “规则来分类一个分离株对特定药物的抗药性：如果分离株的任何突变都是抗药性变异，则被标记为抗药性。否则，如果分离物中只有易感变异存在，则被归为易感。</p><p>变异库参考：Whole-genome sequencing for prediction of Mycobacterium tuberculosis drug susceptibility and resistance: a retrospective cohort study. Lancet Infect. Dis</p><ul><li><a href="https://pubmed.ncbi.nlm.nih.gov/26116186/" target="_blank" rel="noopener">https://pubmed.ncbi.nlm.nih.gov/26116186/</a></li></ul><h4 id="线性降维"><a href="#线性降维" class="headerlink" title="线性降维"></a>线性降维</h4><p>使用PCA对特征（变异位点）进行降维</p><h4 id="分类器方法"><a href="#分类器方法" class="headerlink" title="分类器方法"></a>分类器方法</h4><p>SVM, LR, product-of-marginals (PM), gradient tree boosting, Adaboost, RF</p><h3 id><a href="#" class="headerlink" title=" "></a> </h3><h3 id="结果和结论"><a href="#结果和结论" class="headerlink" title="结果和结论"></a>结果和结论</h3><h4 id="数据描述"><a href="#数据描述" class="headerlink" title="数据描述"></a>数据描述</h4><ul><li>总分离株（isolates）的数量：13402</li><li>变异位点：是与之前鉴定到的23个抗性基因相关的位点，共有5919个位点</li><li>11个药物的标签信息（Resistant/Susceptible）, 标签信息不平衡，所有11种药物的易感性分离株均大大高于耐药性分离株。</li></ul><p><img src="/2021/04/02/9fe5283f/image-20210405110521290.png" alt="image-20210405110521290" style="zoom:50%;"></p><h4 id="特征空间（Feature-Spaces）"><a href="#特征空间（Feature-Spaces）" class="headerlink" title="特征空间（Feature Spaces）"></a>特征空间（Feature Spaces）</h4><p>为了评估不同分类器的性能，文中考虑了三个特征集。1） F1是基线特征空间，即在23个候选基因内发现的所有变异。2） F2是根据另一篇文章（<a href="https://pubmed.ncbi.nlm.nih.gov/26116186/）中列出的预定抗药性相关变异。3）" target="_blank" rel="noopener">https://pubmed.ncbi.nlm.nih.gov/26116186/）中列出的预定抗药性相关变异。3）</a> F3是F1的子集，仅包括特定药物的抗药性相关基因（每种药物特有的抗药性决定因素基因，也是根据之前的一篇文章（<a href="https://pubmed.ncbi.nlm.nih.gov/26116186/）。" target="_blank" rel="noopener">https://pubmed.ncbi.nlm.nih.gov/26116186/）。</a></p><h4 id="训练和测试"><a href="#训练和测试" class="headerlink" title="训练和测试"></a>训练和测试</h4><p>分类模型是通过训练一个平衡的训练数据集，然后在不平衡的数据集上进行测试来执行的。并运行超过100次的5-kfold的交叉验证。在每个fold, 选取20%数据作为测试集，剩余的80%的训练集，将易感样本随机分选，使耐药和易感样本的数量相等，然后拆分训练集和验证集（80%:20%）。</p><p>模型评估参数： accuracy, sensitivity, spe- cificity, F1-score 和ROC curve的 area under curve (AUC) </p><h4 id="分类结果"><a href="#分类结果" class="headerlink" title="分类结果"></a>分类结果</h4><p><img src="/2021/04/02/9fe5283f/image-20210405112431592.png" alt="image-20210405112431592" style="zoom:50%;"></p><p><img src="/2021/04/02/9fe5283f/image-20210405112659308.png" alt="image-20210405112659308" style="zoom:50%;"></p><h4 id="突变排序"><a href="#突变排序" class="headerlink" title="突变排序"></a>突变排序</h4><p>选取性能最好的模型，然后提取前10个对每个药物有特有抗性的features。</p><p><img src="/2021/04/02/9fe5283f/image-20210405113331833.png" alt="image-20210405113331833" style="zoom:50%;"></p><h3 id="创新性和意义"><a href="#创新性和意义" class="headerlink" title="创新性和意义"></a>创新性和意义</h3><ul><li>样本量大，最后提供了药物相关的一些潜在靶标</li><li>文章思路：首先是WGS变异分析，然后选取之前研究的25个抗性基因相关的变异位点，再通过降维方法进一步减小特征的维度，最后比较不同的模型对不同组合提取的特征数据集的性能，并通过特征选择给出了每种药物特有的潜在变异位点。</li></ul>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AMR </tag>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习提高抗生肽的识别</title>
      <link href="/2021/04/01/fff0078d.html"/>
      <url>/2021/04/01/fff0078d.html</url>
      
        <content type="html"><![CDATA[<h2 id="文章信息"><a href="#文章信息" class="headerlink" title="文章信息"></a>文章信息</h2><p>题目：Deep learning improves antimicrobial peptide recognition</p><p>杂志：Bioinformatics</p><p>IF: 5.610 (2019)</p><p>时间：24 march, 2018</p><p>链接：doi: 10.1093/bioinformatics/bty179</p><h2 id="一句话评价"><a href="#一句话评价" class="headerlink" title="一句话评价"></a>一句话评价</h2><p>通过卷积网络层和循环神经网络层组合构建的深度学习模型识别抗生肽。</p><a id="more"></a><h2 id="文章介绍"><a href="#文章介绍" class="headerlink" title="文章介绍"></a>文章介绍</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><ul><li>细菌对抗生素药物的抗性越来越引起人们的关注，对经济，生命健康和社会造成重要的挑战。抗生肽（Antimicrobial peptides ，AMPs）是天然免疫的组成部分，也是研发药物广泛使用的靶点。机器学习的方法可以为湿实验的研究者提供一些潜在的研究位点。</li><li>这篇文章使用卷积网络层和循环神经网络层组成的神经网络模型识别抗菌活动。最终训练的模型也比一般的方法表现更好。此外，通过潜入权重(Embedding Weights)，他们提出了reduced-alphabet representation的方法，最终实现可以只用9个氨基酸分子准确识别AMP。</li><li>最后，他们也提供了模型和数据相关的网站：Antimicrobial Peptide Scanner vr.2 web server， <a href="http://www.ampscanner.com" target="_blank" rel="noopener">www.ampscanner.com</a></li></ul><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><h4 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h4><ul><li>APD vr.3 database： <a href="http://aps.unmc.edu/AP，" target="_blank" rel="noopener">http://aps.unmc.edu/AP，</a> 主要是革兰氏阴性和阳性细菌的AMP</li><li>过滤掉长度小于10的氨基酸以及和CD-Hit &gt; 90%的共有的序列，最终使用的AMP有1778个，训练集：712，验证集：354，测试集：712。</li><li>人工构建了non-AMP的序列：Torrent et al., 2011; Xiao et al., 2013<ul><li>Torrent,M. et al. (2011) Connecting peptide physicochemical and antimicro- bial properties by a rational prediction model. PLoS One, 6, e16968.</li><li>Xiao,X. et al. (2013) iAMP-2L: a two-level <strong>multi-label classifier</strong> for identifying antimicrobial peptides and their functional types. Anal. Biochem., 436, 168–177.</li><li>从UniProt下载了肽段序列，并过滤掉包含抗性的序列</li></ul></li></ul><h4 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h4><p><img src="/2021/04/01/fff0078d/fig1.png" style="zoom:50%;"></p><p><strong>基于Keras框架搭建的模型</strong>：</p><ul><li>肽段序列被编码为长度为200的序列，20个氨基酸依次编码为1-20，其余以0填充。</li><li>embedding_vector_length: 128</li><li>卷积层：1D convolution, <code>nb_filter: 64, filter_length: 16, init: normal, strides: 1, border_mode: same, activation: relu</code></li><li>池化层：Maxpooling layer，size=5</li><li>LSTM层：100 units, <code>(unroll: True, stateful: False, dropout: 0.1 and rest default settings)</code></li><li>Dense 层：激活函数：sigmoid</li><li>其他参数：10 epochs， ‘adam’ 优化器， loss: binary_cros- sentropy, metrics: accuracy).</li></ul><p><strong>调参：</strong></p><p>Hyperas wrapper package for Keras：<a href="https://github.com/maxpumperla/hyperas" target="_blank" rel="noopener">https://github.com/maxpumperla/hyperas</a> </p><p><strong>模型评估：</strong></p><p>用到评估metrics有：</p><ul><li><p>sensitivity (SENS)</p></li><li><p>specificity (SPEC)</p></li><li><p>ACC </p></li><li><p>Matthews Correlation Coefficient (MCC)</p></li><li><p>ROC curve: pROC package in R</p></li></ul><h3 id="结果和结论"><a href="#结果和结论" class="headerlink" title="结果和结论"></a>结果和结论</h3><p><strong>构建的模型性能：</strong></p><p><img src="/2021/04/01/fff0078d/image-20210404222508046.png" alt="image-20210404222508046" style="zoom:50%;"></p><p><strong>与其他方法的比较</strong></p><p><img src="/2021/04/01/fff0078d/image-20210404222646572.png" alt="image-20210404222646572" style="zoom:50%;"></p><h3 id="创新性和意义"><a href="#创新性和意义" class="headerlink" title="创新性和意义"></a>创新性和意义</h3><ul><li>基于抗生肽识别抗菌性活动</li><li>模型的结构：结合了卷积层和循环神经网络层</li><li>输入数据的处理：embeding layer的处理</li><li>Reduced alphabet model analysis</li></ul>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> deep learning </tag>
            
            <tag> AMP </tag>
            
            <tag> LSTM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基因组变异的理解和分析</title>
      <link href="/2020/10/21/e3914e23.html"/>
      <url>/2020/10/21/e3914e23.html</url>
      
        <content type="html"><![CDATA[<h3 id="什么是遗传变异"><a href="#什么是遗传变异" class="headerlink" title="什么是遗传变异"></a>什么是遗传变异</h3><p>遗传变异（genetic variation）是指一个群体中个体之间DNA序列的差异。变异可发生在生殖细胞（即精子和卵子）中，也发生在体细胞(所有其他)中。只有在生殖细胞中产生的变异才能从一个个体遗传给另一个个体，从而影响种群的动态，并最终影响进化。</p><p><strong>突变（Mutation）和重组（Recombination）</strong>是变异的主要来源。</p><h3 id="遗传变异的类型"><a href="#遗传变异的类型" class="headerlink" title="遗传变异的类型"></a>遗传变异的类型</h3><ul><li><p><strong>点突变Single base-pair mutation</strong></p><p>只有一个碱基发生了替换，具体包括Transition和Transversion。Transition指嘌呤(A/G)之间或嘧啶(T/C)之间的替换。Transversion指嘌呤和嘧啶间的替换。</p></li><li><p><strong>插入/缺失（Indel）</strong></p><p>主要指在基因组某个位置上发生较短长度的<strong>线性片段</strong>插入或者删除的现象。强调<strong>线性</strong>的原因是，这里的插入和删除是<strong>有前后顺序的</strong>与下述的结构性变异不同。Indel长度通常在50bp以下，更多时候甚至是不超过10bp，这个长度范围内的序列变化可以通过Smith-Waterman 的局部比对算法来<strong>准确</strong>获得，并且也能够在目前短读长的测序数据中较好地检测出来。</p></li><li><p><strong>结构变异</strong></p><p>通常就是指基因组上大长度的序列变化和位置关系变化。类型很多，包括长度在50bp以上的长片段序列插入或者删除（Big Indel）、串联重复（Tandem repeate）、染色体倒位（Inversion）、染色体内部或染色体之间的序列易位（Translocation）、拷贝数变异（CNV）以及形式更为复杂的嵌合性变异。1Kb与3Mb之间的序列，包括插入、缺失、拷贝数变异、倒位和易位。</p></li></ul><a id="more"></a><h3 id="变异的鉴定和分析"><a href="#变异的鉴定和分析" class="headerlink" title="变异的鉴定和分析"></a>变异的鉴定和分析</h3><p>变异的鉴定主要分为两个步骤：<strong>比对和variants calling</strong></p><ul><li><p><strong>比对</strong></p><p>​    常用的软件有：BWA，Bowtie2。将质控后的数据(fastq)比对到参考基因组上，得到比对后的reads（bam或CRAM格式）。</p></li><li><p><strong>variants calling</strong></p><p>常用的软件有GATK, bcftools, FreeBays等，这里的variants通常只包含SNPs和Indels，最终得到vcf格式的文件。</p></li></ul><p><img src="/2020/10/21/e3914e23/image-20201021223957905.png" alt="image-20201021223957905"></p><ul><li><p><strong>vcf文件格式介绍</strong></p><p>vcf是<strong>Variant Call Format</strong>的简称，即是变异文件储存的标准格式。下图是E.coli 变异分析的vcf文件示例。</p><ul><li>CHROM： 染色体，由于E.coli是一个环形的基因组，这里没有区分染色体</li><li>POS: 变异位点</li><li>REF: 参考基因组位点的碱基</li><li>ALT：个体变异位点的碱基</li><li>QUAL：质量</li><li>FILTER：如果使用GATK过滤后，会对通过过滤的变异位点有PASS的标签</li><li>INFO: 这一栏包含的信息较多，其中<ul><li>DP：表示覆盖在这个位点的总reads数，也就是这个位点的测序深度</li><li>GT: 表示genotype，通常用”/” or “|”分隔两个数字，“|”phase过也就是杂合的两个等位基因知道哪个等位基因来自哪条染色体；0代表参考基因组的碱基类型；1代表ALT碱基类型的第一个碱基（多个碱基用”,”分隔），2代表ALT第二个碱基，以此类推；比如 REF列为：A， ALT列为G,T；那么0/1基因型为AG 杂合，1/1基因型为GG纯合SNP；1/2代表GT基因型；./.表示缺失。</li></ul></li></ul></li></ul><p><img src="/2020/10/21/e3914e23/image-20201021225018928.png" alt="image-20201021225018928" style="zoom:50%;"></p><h3 id="变异分析常用的工具：bcftools-amp-vcftools"><a href="#变异分析常用的工具：bcftools-amp-vcftools" class="headerlink" title="变异分析常用的工具：bcftools &amp; vcftools"></a>变异分析常用的工具：bcftools &amp; vcftools</h3><h4 id="bcftools的部分功能介绍"><a href="#bcftools的部分功能介绍" class="headerlink" title="bcftools的部分功能介绍"></a>bcftools的部分功能介绍</h4><ul><li><p>Calling Variants</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bcftools mpileup -f REF.fa sample.sorted.bam | bcftools call -vm -Oz &gt; sample.vcf.gz</span><br></pre></td></tr></table></figure></li><li><p>提取等位基因和基因型信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bcftools query -f '%CHROM %POS %REF %ALT [%TGT]\n' query.vcf.gz -o query.extract.txt</span><br></pre></td></tr></table></figure></li></ul><ul><li>变异位点的基本统计分析</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bcftools stats sample.vcf &gt; sample.vcf.stats</span><br><span class="line">plot-vcfstats sample.vcf.stats -p sample.vcf.stats.plot_output</span><br></pre></td></tr></table></figure><p><img src="/2020/10/21/e3914e23/image-20201021231029324.png" alt="image-20201021231029324" style="zoom:50%;"></p><p><img src="/2020/10/21/e3914e23/image-20201021231018278.png" alt="image-20201021231018278" style="zoom:50%;"></p><h4 id="vcftools的部分功能介绍"><a href="#vcftools的部分功能介绍" class="headerlink" title="vcftools的部分功能介绍"></a>vcftools的部分功能介绍</h4><ul><li><p>vcf文件的过滤</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vcftools --vcf sample.vcf --minDP 4 --max-missing 0.2 --minQ 30 --recode --recode-INFO-all --out filter</span><br></pre></td></tr></table></figure><p><code>max-missing 0.5</code>: 过滤低于50％的基因型</p><p><code>--minDP 4</code>:过滤depth低于4的reads<br><code>--recode</code>: 标志告诉程序使用过滤器写入一个新的vcf文件，<code>--recode-INFO-all</code>保留旧vcf文件中的所有INFO标志。</p><p><code>--out</code> 输出的文件名称的前缀</p></li><li><p>拆分SNPs和Indels</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## 保留SNPs</span></span></span><br><span class="line">vcftools --vcf filter.recode.vcf --remove-indels --recode --recode-INFO-all --out filter.snps </span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## 保留Indels</span></span></span><br><span class="line">vcftools --vcf filter.recode.vcf --keep-only-indels --recode --recode-INFO-all --out filter.indels</span><br></pre></td></tr></table></figure></li></ul><p>###参考</p><ul><li><a href="https://www.ebi.ac.uk/training-beta/online/courses/human-genetic-variation-introduction/what-is-genetic-variation/" target="_blank" rel="noopener">Human Genetic Variation</a></li><li><a href="https://www.omicsclass.com/article/6" target="_blank" rel="noopener">看懂变异记录结果文件（VCF）</a></li><li><a href="https://www.jianshu.com/p/957efb50108f" target="_blank" rel="noopener">VCF格式</a></li><li><a href="https://luansheng.netlify.app/2019/08/29/how-to-use-bcftools/" target="_blank" rel="noopener">bcftools使用笔记</a></li><li>vcftools: <a href="http://vcftools.sourceforge.net/man_latest.html" target="_blank" rel="noopener">http://vcftools.sourceforge.net/man_latest.html</a></li><li>bcftools: <a href="http://samtools.github.io/bcftools/bcftools.html" target="_blank" rel="noopener">http://samtools.github.io/bcftools/bcftools.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> software </tag>
            
            <tag> Genome Variants </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python实现的一些数据预处理</title>
      <link href="/2020/09/12/2d57b01f.html"/>
      <url>/2020/09/12/2d57b01f.html</url>
      
        <content type="html"><![CDATA[<p>利用python进行数据分析和计算时，经常用到两种数据类型：数据框(DataFrame)和数组（array)。两种数据类型的转换、多个数据的合并以及计算数据中的最值等问题是频率较高的操作。下面介绍解决这些问题的方法。</p><p>首先导入python中最常用的数据处理两个模块：numpy模块、pandas模块。然后创建一个DataFrame类型数据df，两个数组arr1和arr2。</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"> </span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">'A'</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],<span class="string">'B'</span>:[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],<span class="string">'C'</span>:[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]&#125;)</span><br><span class="line">arr1= np.array([[<span class="number">21</span>,<span class="number">22</span>,<span class="number">23</span>], [<span class="number">24</span>,<span class="number">25</span>,<span class="number">26</span>]])</span><br><span class="line">arr2 = np.array([[<span class="number">27</span>,<span class="number">28</span>,<span class="number">29</span>], [<span class="number">31</span>,<span class="number">32</span>,<span class="number">33</span>]])</span><br></pre></td></tr></table></figure><h3 id="数据类型转换"><a href="#数据类型转换" class="headerlink" title="数据类型转换"></a>数据类型转换</h3><h4 id="1-DataFrame转换为array"><a href="#1-DataFrame转换为array" class="headerlink" title="(1) DataFrame转换为array"></a>(1) DataFrame转换为array</h4><ul><li>使用DataFrame中的values方法</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>df</span><br><span class="line">   A  B  C</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">4</span>  <span class="number">7</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  <span class="number">5</span>  <span class="number">8</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">6</span>  <span class="number">9</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(df)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>'&gt;</span></span><br><span class="line"><span class="class"></span></span><br><span class="line">&gt;&gt;&gt; df_arr = df.values</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df_arr</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">4</span>, <span class="number">7</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">5</span>, <span class="number">8</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">6</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(df_arr)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">numpy</span>.<span class="title">ndarray</span>'&gt;</span></span><br></pre></td></tr></table></figure><ul><li>使用Numpy中的array方法</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>df_arr2 = np.array(df)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df_arr2</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">4</span>, <span class="number">7</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">5</span>, <span class="number">8</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">6</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(df_arr2)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">numpy</span>.<span class="title">ndarray</span>'&gt;</span></span><br></pre></td></tr></table></figure><h4 id="2-array转换为Data-Frame"><a href="#2-array转换为Data-Frame" class="headerlink" title="(2) array转换为Data Frame"></a>(2) array转换为Data Frame</h4><p>使用Pandas 的DataFrame方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>df2 = pd.DataFrame(df_arr)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df2</span><br><span class="line">   <span class="number">0</span>  <span class="number">1</span>  <span class="number">2</span></span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">4</span>  <span class="number">7</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  <span class="number">5</span>  <span class="number">8</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">6</span>  <span class="number">9</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(df2)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>'&gt;</span></span><br></pre></td></tr></table></figure><h3 id="数据合并、拼接"><a href="#数据合并、拼接" class="headerlink" title="数据合并、拼接"></a>数据合并、拼接</h3><p>数据合并常见的情况有两个数据框或数组进行水平或垂直方向的合并。</p><h4 id="（1）-DataFrame的合并"><a href="#（1）-DataFrame的合并" class="headerlink" title="（1） DataFrame的合并"></a>（1） DataFrame的合并</h4><p>方法有：</p><ul><li>pandas的<strong>merge函数</strong></li></ul><p><code>df = pd.merge(df1, df2, how=&#39;left&#39;, on=&#39;id&#39;)</code></p><p><code>how=&#39;left&#39;</code>  表示以df1为基准数据，<code>on=&#39;id&#39;</code>表示合并时的索引ID</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>df1</span><br><span class="line">   A  B  C</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">4</span>  <span class="number">7</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  <span class="number">5</span>  <span class="number">8</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">6</span>  <span class="number">9</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df2</span><br><span class="line">   A   D   E</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">40</span>  <span class="number">70</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  <span class="number">50</span>  <span class="number">80</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">60</span>  <span class="number">90</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df3 = pd.merge(df1, df2, how=<span class="string">'left'</span>, on=<span class="string">'A'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df3</span><br><span class="line">   A  B  C   D   E</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">4</span>  <span class="number">7</span>  <span class="number">40</span>  <span class="number">70</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  <span class="number">5</span>  <span class="number">8</span>  <span class="number">50</span>  <span class="number">80</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">6</span>  <span class="number">9</span>  <span class="number">60</span>  <span class="number">90</span></span><br></pre></td></tr></table></figure><ul><li>pandas的<strong>concat函数</strong></li></ul><p><code>df = pd.concat(df1,df2, axis )</code>, axis=1表示列拼接，axis=0表示行拼接</p><p>只是简单的只进行数据拼接，并不进行去除差异或相似的操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>df4 = pd.concat([df1,df2],axis=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df4</span><br><span class="line">   A    B    C     D     E</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">4.0</span>  <span class="number">7.0</span>   NaN   NaN</span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  <span class="number">5.0</span>  <span class="number">8.0</span>   NaN   NaN</span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">6.0</span>  <span class="number">9.0</span>   NaN   NaN</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  NaN  NaN  <span class="number">40.0</span>  <span class="number">70.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  NaN  NaN  <span class="number">50.0</span>  <span class="number">80.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  NaN  NaN  <span class="number">60.0</span>  <span class="number">90.0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df5 = pd.concat([df1,df2],axis=<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df5</span><br><span class="line">   A  B  C  A   D   E</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">4</span>  <span class="number">7</span>  <span class="number">1</span>  <span class="number">40</span>  <span class="number">70</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  <span class="number">5</span>  <span class="number">8</span>  <span class="number">2</span>  <span class="number">50</span>  <span class="number">80</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">6</span>  <span class="number">9</span>  <span class="number">3</span>  <span class="number">60</span>  <span class="number">90</span></span><br></pre></td></tr></table></figure><h4 id="2-Array的合并"><a href="#2-Array的合并" class="headerlink" title="(2) Array的合并"></a>(2) Array的合并</h4><p>方法包括以下几种，常见的有concatenate, stack,hstack和vastack</p><p><img src="/2020/09/12/2d57b01f/image-20200912224933250.png" alt="image-20200912224933250"></p><p><strong>原始数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr1= np.array([[<span class="number">21</span>,<span class="number">22</span>,<span class="number">23</span>], [<span class="number">24</span>,<span class="number">25</span>,<span class="number">26</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr2 = np.array([[<span class="number">27</span>,<span class="number">28</span>,<span class="number">29</span>], [<span class="number">31</span>,<span class="number">32</span>,<span class="number">33</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr1</span><br><span class="line">array([[<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>],</span><br><span class="line">       [<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr2</span><br><span class="line">array([[<span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>],</span><br><span class="line">       [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(arr1)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">numpy</span>.<span class="title">ndarray</span>'&gt;</span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">type</span><span class="params">(arr2)</span></span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> '<span class="title">numpy</span>.<span class="title">ndarray</span>'&gt;</span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">arr1</span>.<span class="title">shape</span></span></span><br><span class="line"><span class="class"><span class="params">(<span class="number">2</span>, <span class="number">3</span>)</span></span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">arr2</span>.<span class="title">shape</span></span></span><br><span class="line"><span class="class"><span class="params">(<span class="number">2</span>, <span class="number">3</span>)</span></span></span><br></pre></td></tr></table></figure><ul><li><p><strong>concatenate</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; arr3=np.concatenate((arr1, arr2)) # 默认axis=0，行方向合并</span><br><span class="line">&gt;&gt;&gt; arr3</span><br><span class="line">array([[21, 22, 23],</span><br><span class="line">       [24, 25, 26],</span><br><span class="line">       [27, 28, 29],</span><br><span class="line">       [31, 32, 33]])</span><br><span class="line">&gt;&gt;&gt; arr3.shape</span><br><span class="line">(4, 3)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; arr4=np.concatenate((arr1, arr2),axis=1)</span><br><span class="line">&gt;&gt;&gt; arr4</span><br><span class="line">array([[21, 22, 23, 27, 28, 29],</span><br><span class="line">       [24, 25, 26, 31, 32, 33]])</span><br></pre></td></tr></table></figure></li></ul><ul><li><strong>stack</strong></li></ul><p><code>np.stack(())</code>合并后的数据是多个数组，纬度增加。参数axis默认值为0.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr5 = np.stack((arr1, arr2))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr5</span><br><span class="line">array([[[<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>]],</span><br><span class="line"></span><br><span class="line">       [[<span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>],</span><br><span class="line">        [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr5.shape</span><br><span class="line">(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr6 = np.stack((arr1, arr2),axis=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr6</span><br><span class="line">array([[[<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>]],</span><br><span class="line"></span><br><span class="line">       [[<span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>],</span><br><span class="line">        [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr6.shape</span><br><span class="line">(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr7 = np.stack((arr1, arr2),axis=<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr7</span><br><span class="line">array([[[<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>],</span><br><span class="line">        [<span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>]],</span><br><span class="line"></span><br><span class="line">       [[<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>],</span><br><span class="line">        [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>]]])</span><br></pre></td></tr></table></figure><ul><li><strong>hstack</strong>：水平合并, 数组纬度没变</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.hstack((arr1,arr2))</span><br><span class="line">array([[<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>],</span><br><span class="line">       [<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>, <span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>]])</span><br></pre></td></tr></table></figure><ul><li><strong>vstack</strong>：垂直合并，数组纬度没变</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.vstack((arr1,arr2))</span><br><span class="line">array([[<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>],</span><br><span class="line">       [<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>],</span><br><span class="line">       [<span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>],</span><br><span class="line">       [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>]])</span><br></pre></td></tr></table></figure><h3 id="最值"><a href="#最值" class="headerlink" title="最值"></a>最值</h3><p>使用numpy的max/min函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>arr1</span><br><span class="line">array([[<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>],</span><br><span class="line">       [<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.max(arr1)</span><br><span class="line"><span class="number">26</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.max(arr1,axis=<span class="number">0</span>)</span><br><span class="line">array([<span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.max(arr1,axis=<span class="number">1</span>)</span><br><span class="line">array([<span class="number">23</span>, <span class="number">26</span>])</span><br></pre></td></tr></table></figure><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://blog.csdn.net/guofei_fly/article/details/85485173?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param" target="_blank" rel="noopener">Numpy中的数组拼接、合并操作</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> data preprocessing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>两个文件的异同</title>
      <link href="/2020/06/28/13171.html"/>
      <url>/2020/06/28/13171.html</url>
      
        <content type="html"><![CDATA[<h3 id="comm-diff-和-grep"><a href="#comm-diff-和-grep" class="headerlink" title="comm, diff 和 grep"></a>comm, diff 和 grep</h3><p>基于comm, diff和grep的用法总结</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">comm A B</span><br><span class="line">diff A B</span><br><span class="line">grep -f A B</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="comm"><a href="#comm" class="headerlink" title="comm"></a>comm</h3><p><strong>comm</strong>是对两个已经<strong>有序</strong>的文件进行比较，可以比较输出：仅在A中出现的、仅在B中出现的、在两个文件中都存在的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">comm -1 A B 不显示在A文件中独有内容(显示B文件独有内容+两个文件共有)</span><br><span class="line">comm -2 A B 不显示在B文件中独有内容</span><br><span class="line">comm -3 A B 不显示同时在两个文件中都存在的内容</span><br><span class="line">comm -12 A B 显示A与B公共的部分</span><br><span class="line">comm -23 A B 显示A独有的</span><br><span class="line">comm -13 A B 显示B独有的</span><br></pre></td></tr></table></figure><p><img src="/2020/06/28/13171/fig1.png" alt="image.png" style="zoom:50%;"></p><h3 id="diff"><a href="#diff" class="headerlink" title="diff"></a><strong>diff</strong></h3><p>diff是比较两个文件之间的不同，给出使两个一致的建议，diff有前后顺序，前面的为旧文件，后面的为新文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">diff A B  直接显示两个文件不同，并给出修改一致的建议(主要是对旧文件的建议)</span><br><span class="line">diff -c A B  通过显示两个文件上下文，给出两个文件增减或删除信息，同时</span><br><span class="line">diff A B</span><br><span class="line">3,4c3,6</span><br><span class="line">&lt; c</span><br><span class="line">&lt; d</span><br><span class="line">---</span><br><span class="line">&gt; e</span><br><span class="line">&gt; f</span><br><span class="line">&gt; g</span><br><span class="line">&gt; h</span><br></pre></td></tr></table></figure><h3 id="grep"><a href="#grep" class="headerlink" title="grep"></a>grep</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">grep -v -f a b  从b中剔除a中有的,即b中特有的</span><br><span class="line">grep -v -f b a  从a中剔除b中有的,即a中特有的</span><br><span class="line">grep -v -f A B</span><br><span class="line">e</span><br><span class="line">f</span><br><span class="line">g</span><br><span class="line">h</span><br><span class="line">grep -v -f  B A</span><br><span class="line">c</span><br><span class="line">d</span><br></pre></td></tr></table></figure><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://www.jianshu.com/p/5ab86345b6bf" target="_blank" rel="noopener">https://www.jianshu.com/p/5ab86345b6bf</a></p><p><a href="https://blog.csdn.net/hit_hlj_sgy/article/details/20625527" target="_blank" rel="noopener">https://blog.csdn.net/hit_hlj_sgy/article/details/20625527</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> text processing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux shell 字符穿操作</title>
      <link href="/2020/06/28/17442.html"/>
      <url>/2020/06/28/17442.html</url>
      
        <content type="html"><![CDATA[<h3 id="截取"><a href="#截取" class="headerlink" title="截取"></a>截取</h3><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">word=abcd-//master-01://httpab</span><br></pre></td></tr></table></figure><h4 id="从左向右"><a href="#从左向右" class="headerlink" title="从左向右:"></a>从左向右:</h4><p><strong>截取第一个//后的字符串</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word#*//&#125;</span><br><span class="line"># master-01://httpab</span><br></pre></td></tr></table></figure><p><strong>截取最后一个//后的字符串</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word##*//&#125; </span><br><span class="line">httpab</span><br></pre></td></tr></table></figure><a id="more"></a><h4 id="从右向左"><a href="#从右向左" class="headerlink" title="从右向左: %"></a>从右向左: %</h4><p><strong>截取第一个//后的字符串</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word%//*&#125; </span><br><span class="line">abcd-//master-01:</span><br></pre></td></tr></table></figure><p><strong>截取第二个//后的字符串</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word%%//*&#125; </span><br><span class="line">abcd-</span><br></pre></td></tr></table></figure><h4 id="截取特定序列位置的字符"><a href="#截取特定序列位置的字符" class="headerlink" title="截取特定序列位置的字符"></a>截取特定序列位置的字符</h4><p><strong>前3个字符</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word:0:3&#125;</span><br></pre></td></tr></table></figure><p><strong>第2到5的字符</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word:1:4&#125;</span><br><span class="line">bcd-</span><br></pre></td></tr></table></figure><p><strong>从第二个字符到末尾</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word:1&#125;</span><br><span class="line">bcd-//master-01://httpab</span><br></pre></td></tr></table></figure><h3 id="替换-before-after"><a href="#替换-before-after" class="headerlink" title="替换:/before/after"></a>替换:/before/after</h3><h4 id="将第一个ab替换为AB"><a href="#将第一个ab替换为AB" class="headerlink" title="将第一个ab替换为AB"></a>将第一个ab替换为AB</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word/#ab/AB&#125; </span><br><span class="line">或 echo $&#123;word/ab/AB&#125; </span><br><span class="line">ABcd-//master-01://httpab</span><br></pre></td></tr></table></figure><h4 id="从左到右，匹配第一个，替换-为cd"><a href="#从左到右，匹配第一个，替换-为cd" class="headerlink" title="从左到右，匹配第一个，替换//为cd"></a>从左到右，匹配第一个，替换//为cd</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word/\/\//cd&#125;</span><br><span class="line">abcd-cdmaster-01://httpab</span><br></pre></td></tr></table></figure><h4 id="将所有匹配的-替换为cd"><a href="#将所有匹配的-替换为cd" class="headerlink" title="将所有匹配的//替换为cd"></a>将所有匹配的//替换为cd</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $&#123;word//\/\//cd&#125;</span><br><span class="line">abcd-cdmaster-01:cdhttpab</span><br></pre></td></tr></table></figure><h4 id="后缀匹配"><a href="#后缀匹配" class="headerlink" title="后缀匹配"></a>后缀匹配</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">word=abcd-//master-01://httpab</span><br><span class="line">echo $&#123;word/%http*/xy&#125; </span><br><span class="line"># 输出:abcd-//master-01://xy</span><br><span class="line">echo $&#123;word/%ab/xy&#125;</span><br><span class="line"># 输出:abcd-//master-01://httpxy</span><br><span class="line">echo $&#123;word/%ab*/xy&#125;</span><br><span class="line"># 出现*，会从起始匹配</span><br><span class="line"># 输出:xy</span><br></pre></td></tr></table></figure><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 删除前3个字符</span><br><span class="line">echo $&#123;word#*$&#123;word:0:3&#125;&#125; </span><br><span class="line"># 删除后3个字符</span><br><span class="line">echo $&#123;word%*$&#123;word:(-3)&#125;&#125;</span><br><span class="line"># 删除第一个ab</span><br><span class="line">echo $&#123;word/ab/&#125; </span><br><span class="line">删除所有ab</span><br><span class="line">echo $&#123;word//ab/&#125;</span><br></pre></td></tr></table></figure><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://blog.csdn.net/qq_23091073/article/details/83066518" target="_blank" rel="noopener">https://blog.csdn.net/qq_23091073/article/details/83066518</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> text processing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>不同服务器间以及服务器与本地的文件传输</title>
      <link href="/2020/06/28/28636.html"/>
      <url>/2020/06/28/28636.html</url>
      
        <content type="html"><![CDATA[<p>前提是在同一网络下，可以使用 <code>scp</code> 命令。</p><p>如：</p><h3 id="两服务器间的传输"><a href="#两服务器间的传输" class="headerlink" title="两服务器间的传输"></a>两服务器间的传输</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp user1@server_addess_ip:/file_adderess user2@server2_address_ip</span><br><span class="line">## eg:</span><br><span class="line">scp root@192.168.8.138:/home/ligh/index.php root@192.168.8.139:/root</span><br></pre></td></tr></table></figure><h3 id="服务器和本地间的传输"><a href="#服务器和本地间的传输" class="headerlink" title="服务器和本地间的传输"></a>服务器和本地间的传输</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">user1@server_addess_ip:/file_adderess /d</span><br><span class="line"></span><br><span class="line">## eg:</span><br><span class="line">scp root@192.168.8.138:/home/ligh/index.php /d/data</span><br></pre></td></tr></table></figure><h3 id="指定端口非22的传输"><a href="#指定端口非22的传输" class="headerlink" title="指定端口非22的传输"></a>指定端口非22的传输</h3><p>使用  <code>P</code> 参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -P 223  root@192.168.8.13e:/home/strains.tar.gz ./</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> shell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pandas库</title>
      <link href="/2020/06/28/45881.html"/>
      <url>/2020/06/28/45881.html</url>
      
        <content type="html"><![CDATA[<p>Pandas库是基于Numpy库来创建的，Numpy主要用于矩阵操作，而Pandas主要用于数据处理。</p><p>Pandas主要有两种重要的数据结构：Series和DataFrame.</p><ul><li><p>Series: 类似一个一维数组，一个Series对应DataFrame的一列</p></li><li><p>DataFrame:类似一个二维数组，一个DataFrame由几个Series列构成。</p><p><img src="/2020/06/28/45881/fig1.png" style="zoom:50%;"></p></li></ul><p><img src="/2020/06/28/45881/fig1.png" alt="image.png"></p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://zhuanlan.zhihu.com/p/40373125" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/40373125</a></li><li><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html" target="_blank" rel="noopener">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NumPy介绍</title>
      <link href="/2020/06/28/49844.html"/>
      <url>/2020/06/28/49844.html</url>
      
        <content type="html"><![CDATA[<p>Pandas库是基于Numpy库来创建的，Numpy主要用于矩阵操作，而Pandas主要用于数据处理。</p><p>Pandas主要有两种重要的数据结构：Series和DataFrame.</p><ul><li>Series: 类似一个一维数组，一个Series对应DataFrame的一列</li><li>DataFrame:类似一个二维数组，一个DataFrame由几个Series列构成。</li></ul><a id="more"></a><p><img src="/2020/06/28/49844/1591819950732-0cf02f6a-c25b-4ca1-8876-17dc2e63dd9e-20200628202724030.png" alt="image.png"></p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://zhuanlan.zhihu.com/p/40373125" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/40373125</a></li><li><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html" target="_blank" rel="noopener">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>R语言中读取含有空白内容的数据</title>
      <link href="/2020/06/28/64095.html"/>
      <url>/2020/06/28/64095.html</url>
      
        <content type="html"><![CDATA[<p><strong>数据内容</strong></p><p><img src="/2020/06/28/64095/1592293564053-baa557ba-9fdb-46ea-b659-dd2b941c6a24.png" alt="image.png"></p><p><strong>导入数据：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test &lt;-read.table(&quot;filename.txt&quot;,header=TRUE）</span><br></pre></td></tr></table></figure><p>  会出现错误：Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, :3行没有2元素</p><p><strong>修改：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test &lt;-read.table(&quot;filename.txt&quot;,header=TRUE,fill=TRUE）</span><br></pre></td></tr></table></figure><p><strong>空值设为NA</strong></p><p><strong><code>na.strings = &quot;&quot;</code></strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test &lt;-read.table(&quot;filename.txt&quot;,header=TRUE, fill=TRUE, na.strings = &quot;&quot;)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> R </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>apply家族函数的用法</title>
      <link href="/2020/06/28/12691.html"/>
      <url>/2020/06/28/12691.html</url>
      
        <content type="html"><![CDATA[<h3 id="apply家族函数"><a href="#apply家族函数" class="headerlink" title="apply家族函数"></a>apply家族函数</h3><p>apply函数族是R语言中数据处理的一组核心函数，通过使用apply函数，我们可以实现对数据的循环、分组、过滤、类型控制等操作。</p><p><img src="/2020/06/28/12691/fig1.png" style="zoom:50%;"></p><a id="more"></a><h3 id="apply-函数的用法"><a href="#apply-函数的用法" class="headerlink" title="apply 函数的用法"></a>apply 函数的用法</h3><p>常用的apply族函数有apply和sapply。apply函数是最常用的代替for循环的函数。apply函数可以对矩阵、数据框、数组(二维、多维)，按行或列进行循环计算，对子元素进行迭代，并把子元素以参数传递的形式给自定义的FUN函数中，并以返回计算结果。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apply(X, MARGIN, FUN, ...)</span><br></pre></td></tr></table></figure><p>参数列表：</p><ul><li>X:数组、矩阵、数据框</li><li>MARGIN: 按行计算或按按列计算，1表示按行，2表示按列</li><li>FUN: 自定义的调用函数</li><li>…: 更多参数，可选</li></ul><p>如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; x&lt;-matrix(1:12,ncol=3)</span><br><span class="line">&gt; apply(x,1,sum)</span><br><span class="line">[1] 15 18 21 24</span><br></pre></td></tr></table></figure><h3 id><a href="#" class="headerlink" title=" "></a> </h3><h3 id="lapply-函数的用法"><a href="#lapply-函数的用法" class="headerlink" title="lapply 函数的用法"></a>lapply 函数的用法</h3><p>lapply函数是一个最基础循环操作函数之一，用来对list、data.frame数据集进行循环，并返回和X长度同样的list结构作为结果集，通过lapply的开头的第一个字母’l’就可以判断返回结果集的类型。</p><p>函数定义：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lapply(X, FUN, ...)</span><br></pre></td></tr></table></figure><p>参数列表：</p><ul><li>X:list、data.frame数据</li><li>FUN: 自定义的调用函数</li><li>…: 更多参数，可选</li></ul><h3 id="sapply函数的用法"><a href="#sapply函数的用法" class="headerlink" title="sapply函数的用法"></a>sapply函数的用法</h3><p>sapply函数是一个简化版的lapply，sapply增加了2个参数simplify和USE.NAMES，主要就是让输出看起来更友好，返回值为向量，而不是list对象。</p><p>函数定义：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sapply(X, FUN, ..., simplify=TRUE, USE.NAMES = TRUE)</span><br></pre></td></tr></table></figure><p>参数列表：</p><ul><li>X:数组、矩阵、数据框</li><li>FUN: 自定义的调用函数</li><li>…: 更多参数，可选</li><li>simplify: 是否数组化，当值array时，输出结果按数组进行分组</li><li>USE.NAMES: 如果X为字符串，TRUE设置字符串为数据名，FALSE不设置</li></ul><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li>掌握R语言中的apply函数族 <a href="http://blog.fens.me/r-apply/" target="_blank" rel="noopener">http://blog.fens.me/r-apply/</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> R </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在R语言中替换空值</title>
      <link href="/2020/06/28/6918.html"/>
      <url>/2020/06/28/6918.html</url>
      
        <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>如下图所示，想替换无任何字符，又不是NA的值，替换为0</p><p><img src="/2020/06/28/6918/1590757573945-fb0f1f16-10ad-4e49-8aee-9449b8f23b80.png" alt="image.png"></p><a id="more"></a><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><ul><li>最初的思路是想匹配两个双引号，但是发现这里的双引号是表示观测值是字符串的数据类型，而不是该字符串本身的字符，尝试了很久也没有匹配成功。</li><li>然后想着将nothing的字符串转为NA，然后将NA转换为0，又因为该数据集是matrix类型，方便整列操作，首先将数据转换为数据框</li></ul><p><img src="/2020/06/28/6918/1590758057421-48ea7d94-d247-4ad0-a826-a26bd633c7f4.png" alt="image.png"></p><p>然后将nothing替换为NA</p><p><img src="/2020/06/28/6918/1590758121879-42bed638-730a-4315-b8cc-a10224feb883.png" alt="image.png"></p><p>最后替换为0，但是发现替换不了，虽然这些值确实是NA</p><p><img src="/2020/06/28/6918/1590760122629-c60cffa8-a98d-4e6d-ad9d-5953ef7265bd.png" alt="image.png"></p><p>检查数据格式，这些<na>是factor，所以这里无法替换</na></p><p><img src="/2020/06/28/6918/1590760226503-08c32bea-6295-4149-bcf1-000d74c2393c.png" alt="image.png"></p><p>最终明白问题出现在将matrix转换为data.frame，应该在此时加上 <code>stringsAsFactors = F</code> 的参数</p><p><img src="/2020/06/28/6918/1590760463196-ca4183f7-b955-4a97-b616-fb9ce2635451.png" alt="image.png"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>在读入数据框或者转换为数据框时，记得加上<code>stringsAsFactors = F</code> 的参数</li><li>匹配特定观测值，然后重新赋值，df[df==”value”] &lt;- newvalue</li><li>R处理数据时要注意数据格式</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> R </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>正则表达式初体验</title>
      <link href="/2020/06/28/44637.html"/>
      <url>/2020/06/28/44637.html</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>正则表达式(Regular Expression)在字符串模式匹配，在字符串搜索和替换中展现强大的功能。</p><p>常用的正则表达式语法我将其总结为7类：</p><p>先看一个概括的整理</p><p><img src="/2020/06/28/44637/1590761619931-4e3ce7f4-d158-4883-bb04-ac35bc16f566.png" alt="image.png"></p><a id="more"></a><ul><li><p>字符类**</p></li><li><ul><li><code>\w</code> : 匹配数字和字符</li><li><code>.</code> : 匹配除换行符 \n 之外的任何单字符</li><li><code>[a-z]</code>  和 <code>[A-Z]</code> :匹配从a到z或者A到Z的任意字符</li><li><code>[0-9]</code> : 匹配0到9的任意数字</li></ul></li><li><p><strong>数值类</strong></p></li><li><ul><li><code>\d</code> ：匹配数字</li></ul></li><li><p>分隔符类</p></li><li><ul><li><code>\s</code> : 匹配white space(包括空格、tab等)</li></ul></li><li><p><strong>定位类：在字符类和数值类前面</strong></p></li><li><ul><li><code>^</code> : 字符开头</li><li><code>$</code> ：字符结尾</li><li><code>\b</code> : 单词结界符</li></ul></li><li><p><strong>定量类，包含数值型和特殊符类，放在字符类和数值类后面</strong></p></li><li><ul><li>数值型：{}， 大括号里加数字</li><li><code>*</code> : 0次或多次</li><li><code>+</code> : 1次或多次</li><li><code>?</code> :  0或1次</li></ul></li><li><p><strong>逻辑关系类</strong></p></li><li><ul><li><code>[]</code> ：表示逻辑关系或，比如[abc]表示a或者b或c</li><li><code>(|)</code> :  () 和 | 结合也表示逻辑关系或</li></ul></li><li><p><strong>分组类</strong></p></li><li><ul><li><code>**()**</code> : 用于分组</li></ul></li></ul><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>R语言可以结合gsub使用正则匹配语法</p><p>gsub语法： <code>gsub(&quot;old value 或 pattern&quot;,&quot;new value&quot;,data)</code> </p><p><img src="/2020/06/28/44637/1590763067379-cde65a24-d421-46ef-ab59-c6b5cac4b771.png" alt="image.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> text processing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习中如何处理分类变量的不均衡</title>
      <link href="/2020/06/28/35362.html"/>
      <url>/2020/06/28/35362.html</url>
      
        <content type="html"><![CDATA[<p>Imbalanced classes put “accuracy” out of business. This is a surprisingly common problem in machine learning (specifically in classification), occurring in datasets with a disproportionate ratio of observations in each class</p><ul><li><p>Up-sample the minority class</p></li><li><ul><li>resample module with <code>replace = True</code></li></ul></li><li><p>Down-sample the majority class</p></li><li><ul><li>resample module with <code>replace = False</code></li></ul></li><li><p>Change your performance metric</p></li><li><ul><li><strong>Area Under ROC Curve</strong> (AUROC)</li><li><code>from sklearn.metrics import roc_auc_score</code></li></ul></li><li><p>Penalize algorithms (cost-sensitive training)</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SVC(kernel=&apos;linear&apos;, </span><br><span class="line">            class_weight=&apos;balanced&apos;, # penalize</span><br><span class="line">            probability=True)</span><br></pre></td></tr></table></figure><ul><li><p>Use tree-based algorithms</p></li><li><ul><li><code>from sklearn.ensemble import RandomForestClassifier</code></li></ul></li></ul><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn import svm</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.metrics import accuracy_score</span><br><span class="line">from sklearn.utils import resample</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">input = pd.read_csv(&apos;trime_skinput.csv&apos;) # row.names equls numbers</span><br><span class="line">input.trimethoprim_sulfamethoxazole.value_counts()</span><br><span class="line">input_major = input[input.trimethoprim_sulfamethoxazole == &quot;R&quot;]</span><br><span class="line">input_minor = input[input.trimethoprim_sulfamethoxazole == &quot;S&quot;]</span><br><span class="line"></span><br><span class="line">input_minor_upsampled = resample(input_minor,</span><br><span class="line">                                 replace = True,</span><br><span class="line">                                 n_samples = 67,</span><br><span class="line">                                random_state=123)</span><br><span class="line"></span><br><span class="line">input_upsampled = pd.concat([input_major,input_minor_upsampled])</span><br><span class="line">input_upsampled.trimethoprim_sulfamethoxazole.value_counts()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X = input_upsampled.iloc[:,0:19277]</span><br><span class="line">y = input_upsampled.iloc[:,19277:19278]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)</span><br><span class="line"></span><br><span class="line">### train model</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">svclassifier = SVC(kernel=&apos;linear&apos;)</span><br><span class="line"></span><br><span class="line">svclassifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">## predict </span><br><span class="line">y_pred = svclassifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"># evaluation </span><br><span class="line">from sklearn.metrics import classification_report, confusion_matrix</span><br><span class="line">print(confusion_matrix(y_test,y_pred))</span><br><span class="line">print(classification_report(y_test,y_pred))</span><br><span class="line"># upsampling</span><br><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           R       1.00      0.88      0.93        16</span><br><span class="line">           S       0.85      1.00      0.92        11</span><br><span class="line"></span><br><span class="line">    accuracy                           0.93        27</span><br><span class="line">   macro avg       0.92      0.94      0.93        27</span><br><span class="line">weighted avg       0.94      0.93      0.93        27</span><br><span class="line"></span><br><span class="line">## don&apos;t do anything</span><br><span class="line">                precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           R       0.88      1.00      0.93        14</span><br><span class="line">           S       0.00      0.00      0.00         2</span><br><span class="line"></span><br><span class="line">    accuracy                           0.88        16</span><br><span class="line">   macro avg       0.44      0.50      0.47        16</span><br><span class="line">weighted avg       0.77      0.88      0.82        16</span><br></pre></td></tr></table></figure><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li>How to Handle Imbalanced Classes in Machine Learning：<a href="https://elitedatascience.com/imbalanced-classes" target="_blank" rel="noopener">https://elitedatascience.com/imbalanced-classes</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Python与Scikit-learn实现随机森林分析</title>
      <link href="/2020/06/28/25483.html"/>
      <url>/2020/06/28/25483.html</url>
      
        <content type="html"><![CDATA[<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li>Understanding Random Forests Classifiers in Python<a href="https://www.datacamp.com/community/tutorials/random-forests-classifier-python" target="_blank" rel="noopener">: //www.datacamp.com/community/tutorials/random-forests-classifier-python</a></li><li>Random Forest Algorithm with Python and Scikit-Learn<a href="https://stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/" target="_blank" rel="noopener">: //stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/</a></li><li>Random Forest in Python<a href="https://towardsdatascience.com/random-forest-in-python-24d0893d51c0" target="_blank" rel="noopener">: //towardsdatascience.com/random-forest-in-python-24d0893d51c0</a></li></ul><h3 id="随机森林（RandomForest）算法"><a href="#随机森林（RandomForest）算法" class="headerlink" title="随机森林（RandomForest）算法"></a>随机森林（RandomForest）算法</h3><p>随机森林属于集成学习（Ensemble Learning）的一类算法，结合了多种相同类型的算法，即多个决策树，从而形成了一个随机森林树。</p><blockquote><p>随即森林是用随机的方式建立一个森林，森林里面有很多的决策树组成，随机森林的每一棵决策树之间是没有关联的。上世纪八十年代Breiman等人发明分类树的算法（Breiman et al. 1984），通过反复二分数据进行分类或回归，计算量大大降低。2001年Breiman把分类树组合成随机森林（Breiman 2001a），即在变量（列）的使用和数据（行）的使用上进行随机化，生成很多分类树，再汇总分类树的结果。随机森林在运算量没有显著提高的前提下提高了预测精度。随机森林对多元公线性不敏感，结果对缺失数据和非平衡的数据比较稳健，可以很好地预测多达几千个解释变量的作用（Breiman 2001b），被誉为当前最好的算法之一（Iverson et al. 2008）。</p><p>参考：<a href="https://zhuanlan.zhihu.com/p/22097796" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/22097796</a></p></blockquote><a id="more"></a><h3 id="随机森林工作原理"><a href="#随机森林工作原理" class="headerlink" title="随机森林工作原理"></a>随机森林工作原理</h3><p><img src="/2020/06/28/25483/1591801985780-f9e9e5e3-2124-4f44-97a6-11217dc66dee.png" alt="image.png"></p><h3 id="随机森林优缺点"><a href="#随机森林优缺点" class="headerlink" title="随机森林优缺点"></a>随机森林优缺点</h3><p><strong>优点</strong></p><ul><li>准确度高</li><li>没有过拟合问题</li><li>可用于分类和回归问题</li><li>可以处理缺失值，一是用中位数代替连续变量，二是计算缺失值的近似加权平均值；也可用于没有归一化的问题</li></ul><p><strong>缺点</strong></p><ul><li>速度慢</li><li>与决策树相比较难解释</li></ul><h3 id="随即森林与决策树"><a href="#随即森林与决策树" class="headerlink" title="随即森林与决策树"></a>随即森林与决策树</h3><ul><li>随机森林是一组多决策树。</li><li>深度决策树可能会出现过拟合，但随机森林通过在随机子集上创建树来防止过拟合。</li><li>决策树的计算速度更快。</li><li>随机森林很难解释，而决策树很容易解释，可以转换为规则。</li></ul><h3 id="利用Scikit-learn实现随即森林的分析"><a href="#利用Scikit-learn实现随即森林的分析" class="headerlink" title="利用Scikit-learn实现随即森林的分析"></a>利用Scikit-learn实现随即森林的分析</h3><p>随机森林通过 <code>RandomForestClassifier</code>实现<strong>分类</strong>问题</p><p>随机森林通过 <code>RandomForestRegressor</code> 实现<strong>回归</strong>问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br></pre></td></tr></table></figure><h3 id="随机森林解决回归问题"><a href="#随机森林解决回归问题" class="headerlink" title="随机森林解决回归问题"></a>随机森林解决回归问题</h3><ul><li>问题</li></ul><p>根据汽油税（美分），人均收入（美元），已铺设的高速公路（以英里为单位）和驾驶执照人口与汽油税的比例，来预测美国48个州的汽油消耗量（百万加仑）。</p><p>数据链接：<a href="https://drive.google.com/file/d/1mVmGNx6cbfvRHC_DvF12ZL3wGLSHD9f_/view" target="_blank" rel="noopener">https://drive.google.com/file/d/1mVmGNx6cbfvRHC_DvF12ZL3wGLSHD9f_/view</a></p><ul><li>读入数据</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset = pd.read_csv(&apos;petrol_consumption.csv&apos;)</span><br><span class="line">dataset.head()</span><br></pre></td></tr></table></figure><p><img src="/2020/06/28/25483/1592223752291-004d252c-0cc7-4d36-90bd-8653ab0932d2.png" alt="image.png"></p><ul><li>数据前处理</li></ul><p>提取’attributes’ 和 ‘label’; 拆分测试数据和训练数据集</p><p>注意：<code>random_state</code> 设置随机数种子，以保证多次运行的结果相同</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X = dataset.iloc[:, 0:4].values</span><br><span class="line">y = dataset.iloc[:, 4].values</span><br><span class="line"></span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)</span><br></pre></td></tr></table></figure><ul><li>数据归一化（Feature Scaling）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Feature Scaling</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">sc = StandardScaler()</span><br><span class="line">X_train = sc.fit_transform(X_train)</span><br><span class="line">X_test = sc.transform(X_test)</span><br></pre></td></tr></table></figure><ul><li>训练模型</li></ul><p>注意：重要参数 <strong><code>n_estimators</code></strong> , 表示随机森林树的数目</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestRegressor</span><br><span class="line"></span><br><span class="line">regressor = RandomForestRegressor(n_estimators=20, random_state=0)</span><br><span class="line">regressor.fit(X_train, y_train)</span><br><span class="line">y_pred = regressor.predict(X_test)</span><br></pre></td></tr></table></figure><ul><li>模型评估</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import metrics</span><br><span class="line"></span><br><span class="line">print(&apos;Mean Absolute Error:&apos;, metrics.mean_absolute_error(y_test, y_pred))</span><br><span class="line">print(&apos;Mean Squared Error:&apos;, metrics.mean_squared_error(y_test, y_pred))</span><br><span class="line">print(&apos;Root Mean Squared Error:&apos;, np.sqrt(metrics.mean_squared_error(y_test, y_pred)))</span><br></pre></td></tr></table></figure><p><img src="/2020/06/28/25483/1592224214897-36546d34-1651-44db-8102-eb29912fd01a.png" alt="image.png"></p><p>当参数改为200时，模型评估结果提升了<strong><code>n_estimators=200</code></strong></p><p><img src="/2020/06/28/25483/1592224281077-4a7049c2-c4b7-47b6-8d15-e5cf05aa1fe1.png" alt="image.png"></p><h3 id="随机森林解决分类问题"><a href="#随机森林解决分类问题" class="headerlink" title="随机森林解决分类问题"></a>随机森林解决分类问题</h3><ul><li>问题：根据四个属性（即图像小波变换后的图像的方差，偏度，熵和图像的弯曲度）来预测银行纸币是否真实</li></ul><ul><li>数据：<a href="https://drive.google.com/file/d/13nw-uRXPY8XIZQxKRNZ3yYlho-CYm_Qt/view" target="_blank" rel="noopener">https://drive.google.com/file/d/13nw-uRXPY8XIZQxKRNZ3yYlho-CYm_Qt/view</a></li></ul><ul><li>读入数据</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">dataset = pd.read_csv(&quot;D:/Datasets/bill_authentication.csv&quot;)</span><br><span class="line">dataset.head()</span><br></pre></td></tr></table></figure><p><img src="/2020/06/28/25483/1592224457537-501c6246-7a4e-4ef8-8efa-0a931e9a45a4.png" alt="image.png"></p><ul><li>数据预处理</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = dataset.iloc[:, 0:4].values</span><br><span class="line">y = dataset.iloc[:, 4].values</span><br></pre></td></tr></table></figure><p>拆分测试数据和训练数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)</span><br></pre></td></tr></table></figure><ul><li>归一化</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Feature Scaling</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">sc = StandardScaler()</span><br><span class="line">X_train = sc.fit_transform(X_train)</span><br><span class="line">X_test = sc.transform(X_test)</span><br></pre></td></tr></table></figure><ul><li>训练模型</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">regressor = RandomForestClassifier(n_estimators=20, random_state=0)</span><br><span class="line">regressor.fit(X_train, y_train)</span><br><span class="line">y_pred = regressor.predict(X_test)</span><br></pre></td></tr></table></figure><ul><li>模型评估</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import classification_report, confusion_matrix, accuracy_score</span><br><span class="line">print(confusion_matrix(y_test,y_pred))</span><br><span class="line">print(classification_report(y_test,y_pred))</span><br><span class="line">print(accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure><p><img src="/2020/06/28/25483/1592224658958-fa055da7-c285-437a-8580-f3dac49ad06b.png" alt="image.png"></p><p>这里将n_estimators=20 改为200时，结果并没有明显改变</p><p><img src="/2020/06/28/25483/1592224709652-34fa9d3c-e9df-47e6-8001-e99abd86d588.png" alt="image.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Python与Scikit-learn实现逻辑回归分析</title>
      <link href="/2020/06/28/30893.html"/>
      <url>/2020/06/28/30893.html</url>
      
        <content type="html"><![CDATA[<p><a href="https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a" target="_blank" rel="noopener">https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a</a></p><p><img src="/2020/06/28/30893/fig-1.png" alt></p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd  </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">input_Cef = pd.read_csv(<span class="string">"input_Cef.csv"</span>)</span><br><span class="line">input_Cef.head()</span><br><span class="line">   </span><br><span class="line">X = input_Cef.iloc[:,<span class="number">1</span>:<span class="number">6027</span>]</span><br><span class="line">y = input_Cef[<span class="string">"Ceftazidim_S.vs.R"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1. Import the model &amp; Splitting Data into Training and Test Sets</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.20</span>,random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make an instance of the Model</span></span><br><span class="line"><span class="comment"># all parameters not specified are set to their defaults</span></span><br><span class="line"><span class="comment"># Changing the solver had a minor effect on accuracy, but at least it was a lot faster</span></span><br><span class="line">logreg = LogisticRegression(solver = <span class="string">'lbfgs'</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 3. Training the model </span></span><br><span class="line">logreg.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Step 4. Predict labels for new data </span></span><br><span class="line">y_pred = logreg.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step5: Measuring Model Performance</span></span><br><span class="line"><span class="comment"># accuracy , precision, recall, F1 Score, ROC Curve</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## accuracy</span></span><br><span class="line">score = logreg.score(X_test, y_test)</span><br><span class="line">print(score)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## precision, recall, F1 Score</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">print(classification_report(y_test, y_pred))</span><br><span class="line"></span><br><span class="line"><span class="comment">## ROC Curve</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">logit_roc_auc2 = roc_auc_score(y_test, y_pred)</span><br><span class="line">probas = logreg.predict_proba(X_test)[:,<span class="number">1</span>]</span><br><span class="line">fpr2, tpr2, thresholds2 = roc_curve(y_test, probas)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(fpr2, tpr2, label=<span class="string">'Logistic Regression for Ceftazidim (area = %0.2f)'</span> % logit_roc_auc2)</span><br><span class="line"><span class="comment">#plt.plot([0, 1], [0, 1],'r--')</span></span><br><span class="line"><span class="comment">#plt.xlim([0.0, 1.0])</span></span><br><span class="line"><span class="comment">#plt.ylim([0.0, 1.05])</span></span><br><span class="line">plt.xlabel(<span class="string">'False Positive Rate'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'True Positive Rate'</span>)</span><br><span class="line">plt.title(<span class="string">'Receiver operating characteristic'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">"lower right"</span>)</span><br><span class="line">plt.savefig(<span class="string">'./Fig2_Log_ROC_Cef.pdf'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>稀疏矩阵与机器学习</title>
      <link href="/2020/06/28/46638.html"/>
      <url>/2020/06/28/46638.html</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>Introduction to Sparse Matrices for Machine Learning</strong></p></blockquote><h3 id="什么是稀疏矩阵？"><a href="#什么是稀疏矩阵？" class="headerlink" title="什么是稀疏矩阵？"></a>什么是稀疏矩阵？</h3><p>大部分包含零值的矩阵称为稀疏矩阵(sparse Matrices)，相对应的是大多数值非零的密集矩阵(Dense Matrices)。稀疏矩阵在机器学习领域非常常见，如计数类数据，或者one-hot encoding编码的数据等。数据的稀疏性可以通过零值的比例量化（sparsity = count zero elements / total elements）。稀疏矩阵会产生处理时间和存储空间的问题。而<strong>SciPy</strong>提供了很多高效的方法可以直接用于存储和处理稀疏矩阵。</p><p><img src="/2020/06/28/46638/figure-ab.jpg" alt></p><a id="more"></a><h3 id="稀疏矩阵数据处理——SciPy"><a href="#稀疏矩阵数据处理——SciPy" class="headerlink" title="稀疏矩阵数据处理——SciPy"></a>稀疏矩阵数据处理——SciPy</h3><p>SciPy中提供了多种数据结构可以有效处理稀疏矩阵，如：</p><p><strong>Dictionary of Keys:</strong> 一个字典使用行和列索引映射出一个值</p><p><strong>List of Lists:</strong> 每行作为一个list存储，每个list里包含column index和值</p><p><strong>Coordinate List:</strong> 存储一个元组列表，每个元组包含行索引，列索引和值</p><p><strong>Compressed Sparse Row (CSR) :</strong> 使用三个一维数组表示非零值，行范围和列索引。在机器学习中经常使用。</p><p><strong>Compressed Sparse Column:</strong> 对列索引进行压缩并在行索引之前先读取</p><p><img src="/2020/06/28/46638/1593354304703-ea0a7d87-344f-4042-a4fb-63ab1456ed40.png" alt="image.png"></p><p><img src="/2020/06/28/46638/1593354414857-4435ef02-f1c7-41f9-b9af-3959e384200e.png" alt="image.png"></p><h4 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from numpy import array</span><br><span class="line">from scipy import sparse</span><br><span class="line">import numpy as np</span><br><span class="line"># create dense matrix</span><br><span class="line">A = array([[1, 0, 0, 1, 0, 0], [0, 0, 2, 0, 0, 1], [0, 0, 0, 2, 0, 0]])</span><br><span class="line">print(A)</span><br><span class="line"># convert to sparse matrix (CSR method)</span><br><span class="line">S = csr_matrix(A)</span><br><span class="line">print(S)</span><br><span class="line"># reconstruct dense matrix</span><br><span class="line">B = S.todense()</span><br><span class="line">print(B)</span><br><span class="line"># reconstruct numpy array</span><br><span class="line">C = S.toarray()</span><br><span class="line">print(C)</span><br></pre></td></tr></table></figure><h3 id="稀疏矩阵与机器学习"><a href="#稀疏矩阵与机器学习" class="headerlink" title="稀疏矩阵与机器学习"></a>稀疏矩阵与机器学习</h3><p>python的sklearn模块很多模型可以使用sparse数据结构作为输入。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://machinelearningmastery.com/sparse-matrices-for-machine-learning/" target="_blank" rel="noopener">https://machinelearningmastery.com/sparse-matrices-for-machine-learning/</a></p><p><a href="https://docs.scipy.org/doc/scipy/reference/sparse.html" target="_blank" rel="noopener">https://docs.scipy.org/doc/scipy/reference/sparse.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习中的模型验证</title>
      <link href="/2020/06/28/5857.html"/>
      <url>/2020/06/28/5857.html</url>
      
        <content type="html"><![CDATA[<h2 id="model-validation"><a href="#model-validation" class="headerlink" title="model validation"></a>model validation</h2><p>Model validation is important step in machine learning. Cross validation and bootstrapping methods can be used for model validation. Both of them are resampling methods.Cross validation resamples without replacement,bootstrap resamples with replacement.</p><p><strong>reference</strong> - <a href="https://arxiv.org/pdf/1811.12808.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1811.12808.pdf</a></p><a id="more"></a><h3 id="Cross-validation"><a href="#Cross-validation" class="headerlink" title="Cross validation"></a>Cross validation</h3><p>Cross-validation is a series of methods for estimating the true error of a model to ensure that the model being trained is also valid on real data. The methods include:</p><ul><li>Hold-out cross validation</li><li>k-fold cross validation</li><li>leave-one-out cross validation</li></ul><h4 id="hold-out-validation"><a href="#hold-out-validation" class="headerlink" title="hold-out validation"></a>hold-out validation</h4><p>The raw data set is splited into two parts, one is the training set to fit the model and the other one is the validation set to estimate the model error.</p><p>It Usually takes 20% or 30% as the validation set; The sampling is <strong>randomly stratified</strong> with the target variable Y for reducing the bias between the training/test set and the full set (bias).</p><p><strong>Advantages and disadvantages:</strong></p><ul><li>The method is simple, requiring only random partitioning and low computational complexity.</li><li>The effect on the validation set can fluctuate considerably because each partitioning is different.</li></ul><h4 id="k-fold-cross-validation"><a href="#k-fold-cross-validation" class="headerlink" title="k-fold cross validation"></a>k-fold cross validation</h4><p>In k-fold cross-validation, the raw data is randomly splited into k equal sized subdata set. one of subdata set is retained as the testing data, and the remaining k-1 subdata set are used as training data set. The cross-validation process is then repeated k times.</p><p><img src="/2020/06/28/5857/1593367023322-337a099f-600b-4b59-9467-8b9ef49a4fa7.png" alt="image.png"></p><p><strong>Advantages and disadvantages：</strong></p><ul><li>Ultimately all of data are used for fitting the model.</li><li>The estimate of the test error may be high</li><li>If K is too high (e.g., extreme K=n), the error estimate will have high variance; if K is too low (e.g., 2, 3), high bias will occur, Usually K=5 or K=10.</li></ul><h4 id="leave-one-out-cross-validation"><a href="#leave-one-out-cross-validation" class="headerlink" title="leave-one-out cross validation"></a>leave-one-out cross validation</h4><p>A special case of cross-validation in the case of K=n, take n-1 samples at a time for modeling, 1 sample for evaluation, and repeat for n times.</p><h3 id="bootstrapping"><a href="#bootstrapping" class="headerlink" title="bootstrapping"></a>bootstrapping</h3><p>Bootstrap is a resampling method with replacement, and the idea is also used random forests.</p><ul><li>One sample of the original size is repeated with playback to obtain K samples of the same size.</li><li>Calculate the specified statistics (e.g., mean, standard deviation) for each sample, or fit the model to the parameters to obtain a bootstrap distribution of some statistic/parameter similar to the bootstrap distribution obtained by bootstrap sampling from the total.</li><li>Taking the average of the bootstrap distribution is an estimate of the overall parameter.</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用于COVID-19研究的计算机策略大集锦</title>
      <link href="/2020/05/24/50931.html"/>
      <url>/2020/05/24/50931.html</url>
      
        <content type="html"><![CDATA[<p><strong>文章信息</strong></p><p>题目：Computational strategies to combat COVID-19: Useful tools to accelerate SARS-CoV-2 and Coronavirus research                           </p><p>杂志：Preprints</p><p>时间：23 May 2020</p><p>链接: <a href="https://www.preprints.org/manuscript/202005.0376/v1" target="_blank" rel="noopener">https://www.preprints.org/manuscript/202005.0376/v1</a></p><p><strong>figure</strong></p><p><img src="/2020/05/24/50931/1590306372902-96cb47c3-6aa3-48ed-b191-1ebf93d885ec.png" alt="image.png"></p><p><strong>文章介绍</strong></p><p>这篇综述是由欧洲病毒生物信息中心（EVBC）整理的关于COVID-19研究的分析流程和工具。涉及1）SARS-CoV-2的检测，2）测序数据的分析，3）COVID-19流行病学的追踪，4）病毒的进化，5）潜在药物靶标，治疗策略等方面。</p><p>详细的工具列表链接，可以在EVBC网站查看：<a href="http://evbc.uni-jena.de/tools/coronavirus-tools/" target="_blank" rel="noopener">http://evbc.uni-jena.de/tools/coronavirus-tools/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从EBI批量下载数据</title>
      <link href="/2020/05/18/8492.html"/>
      <url>/2020/05/18/8492.html</url>
      
        <content type="html"><![CDATA[<p>ERR地址的规律：差别在于后三个地址，先是ERR number字符串的前6个字符，然后是ERR完整字符串，最后是ERR字符串加上 <code>_1</code> 或 <code>_2</code></p><p>如：</p><p><img src="/2020/05/18/8492/1589790261584-b3c7220e-2691-4b63-92f9-21acf439465a.png" alt="image.png"></p><p>根据此规律批量从EBI下载数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for i in $(cat ERR_numlist);do wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/$&#123;i:0:6&#125;/$i/$i\_*.fastq.gz; done</span><br></pre></td></tr></table></figure><ul><li>首先从excel 表格中提取Lane.accession列，即ERR number列，命名为<strong>ERR_numlist</strong>，然后上传到服务器；</li><li>切记所有从windows上传到服务器的文件最好先进行格式转化，否则由于文件格式，容易报错。 <strong><code>dos2unix ERR_numlist</code></strong> </li><li><code>${i:0:6}</code> ：是指输出字符串i的前6个字符， <code>0</code> :表示从第几位开始， <code>6</code> :表示截取的长度</li></ul><p><img src="/2020/05/18/8492/fig1.png" alt></p>]]></content>
      
      
      
        <tags>
            
            <tag> shell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>t-test和方差分析</title>
      <link href="/2020/05/17/59776.html"/>
      <url>/2020/05/17/59776.html</url>
      
        <content type="html"><![CDATA[<h3 id="t-test"><a href="#t-test" class="headerlink" title="t-test"></a>t-test</h3><p><strong>t-test是比较两组变量的平均值是否有显著性差异</strong></p><p><img src="/2020/05/17/59776/1589702913894-0ff87132-df98-47cc-aa51-d3d6b4127469-20200517103250465.png" alt="image.png" style="zoom:50%;"></p><a id="more"></a><p><strong>类比于线性回归计算t-test的R squared</strong></p><ul><li><strong>1）首先忽略x轴，计算总平均值</strong></li></ul><p><img src="/2020/05/17/59776/1589703098963-a13f78e7-3120-47b1-9902-02ae10aa989a-20200517103250668.png" alt="image.png" style="zoom:33%;"></p><ul><li>2) 计算相对于平均值的偏差平方和</li></ul><p><img src="/2020/05/17/59776/1589703245599-1a324c15-00a1-4696-8837-fb72f47a6262-20200517103250743.png" alt="image.png" style="zoom:33%;"><img src="/2020/05/17/59776/1589703466338-96b36840-acd0-497e-8d21-7635be860718-20200517103250065.png" alt="image.png" style="zoom:33%;"></p><p><strong>3） 拟合模型</strong></p><p> <img src="/2020/05/17/59776/1589703466338-96b36840-acd0-497e-8d21-7635be860718-20200517103250065.png" alt="image.png" style="zoom:33%;"></p><p>4）计算相对于模型line的偏差平方和</p><p><img src="/2020/05/17/59776/1589703384412-7c9ecf7e-9081-4b29-b966-1a02eeb0a589-20200517103250886.png" alt="image.png" style="zoom:33%;"><img src="/2020/05/17/59776/1589703577012-29901c39-6517-4f8d-a27b-72f39a294726-20200517103250846.png" alt="image.png"></p><p><strong>线性回归和t-test的对比总结：</strong></p><p>   <img src="/2020/05/17/59776/1589703577012-29901c39-6517-4f8d-a27b-72f39a294726-20200517103250846.png" alt="image.png" style="zoom:33%;"></p><h3 id="方差分析"><a href="#方差分析" class="headerlink" title="方差分析"></a>方差分析</h3><p>方差分析即Analysis of Variance, 简称ANOVA，是比较多组变量间的平均值是否有显著性差异。是t-test的拓展。</p><p><img src="/2020/05/17/59776/1589703782892-4a90d9f5-4bb3-4879-9d51-d059a144891c-20200517103251076.png" alt="image.png" style="zoom:33%;"></p>]]></content>
      
      
      
        <tags>
            
            <tag> statistics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>逻辑回归</title>
      <link href="/2020/05/17/60504.html"/>
      <url>/2020/05/17/60504.html</url>
      
        <content type="html"><![CDATA[<p><strong>逻辑回归是什么？主要用于解决什么问题？与线性回归有什么关系？如何计算和评估逻辑回归的最佳模型？逻辑回归与概率回归的异同？在R中如何实现？</strong></p><p>首先还是先看wiki对逻辑回归（logisitic regression）的解释</p><blockquote><p>Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable。</p></blockquote><p>逻辑回归（logistic/logit regression）主要应用于解决<strong>二分类</strong>问题，和线性回归都属于线性模型，但是逻辑回归是解决分类问题，而线性回归是解决回归问题。逻辑回归通过最大似然法（Maximum likelihood）寻找最佳模型。可以通过summary()函数的输出结果AIC值对比模型的拟合程度，或者通过sensitivity, specifity评估，既可以以ROC和AUC的结果评估。概率回归也用于二分类问题，和逻辑回归类似。不同的是逻辑回归使用累积逻辑函数（cumulative logistic function），概率回归使用正态累积密度函数（normal cumulative density function）。实际应用两个模型时时可根据自己的爱好选择。逻辑回归在R中的实现以 <strong><code>glm()</code></strong> 函数实现，并指定参数 <code>**family = binomial**</code> , 而概率回归以glm()函数，并指定 <strong><code>family =binomial(link=&quot;probit&quot;)</code></strong> 。</p><a id="more"></a><p><img src="/2020/05/17/60504/1589442464586-dd9e1642-d738-407f-9656-5ce4e1f54b52.png" alt="image.png" style="zoom:33%;"></p><p><img src="/2020/05/17/60504/1589442582323-ba9a09c2-6ab3-4f39-93fd-5bc66333621a.png" alt="image.png" style="zoom:33%;"></p><p><img src="/2020/05/17/60504/1589443161905-b5a2b69c-41f4-46e2-aac4-c146bb467f45.png" alt="image.png" style="zoom:33%;"></p><p><img src="/2020/05/17/60504/1589701563491-be26730c-2d7b-4668-8035-5ca409555214.png" alt="image.png" style="zoom:33%;"></p><p><img src="/2020/05/17/60504/1589701561833-3cec8e36-edf6-4df1-8a80-af7d3fb2230e.png" alt="image.png" style="zoom:33%;"></p><p><img src="/2020/05/17/60504/1589702022864-d99f6c13-a484-493f-a313-8c6a9ab70514.png" alt="image.png" style="zoom:33%;"></p><p><strong>参考资料：</strong></p><p>statquest逻辑回归视频：<a href="https://www.youtube.com/playlist?list=PLblh5JKOoLUKxzEP5HA2d-Li7IJkHfXSe" target="_blank" rel="noopener">https://www.youtube.com/playlist?list=PLblh5JKOoLUKxzEP5HA2d-Li7IJkHfXSe</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> statistics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性回归和线性模型</title>
      <link href="/2020/05/17/31684.html"/>
      <url>/2020/05/17/31684.html</url>
      
        <content type="html"><![CDATA[<p><strong>什么是线性回归和线性模型？他们的关系是什么？如何计算和评估线性回归模型？如何在R中实现？</strong></p><h2 id="线性回归和线性模型"><a href="#线性回归和线性模型" class="headerlink" title="线性回归和线性模型"></a><strong>线性回归和线性模型</strong></h2><p>首先看下wiki给出的解释：</p><blockquote><p>In statistics, linear regression is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression</p></blockquote><p>线性回归即用来寻找变量间的线性关系，属于线性模型的一个分支，通常使用最小二乘法（least squared method)寻找</p><p>最佳模型，并用R suqared( R2 ）评估模型的拟合程度，R2越大表示模型拟合效果越好。在R中以lm()函数实现，代码公式为 <code>lm(dependent varaible ~ independent varaibles, data</code> .</p><a id="more"></a><p><img src="/2020/05/17/31684/1589697274717-c22e4977-8d06-4552-8dda-1906453aa44a.png" alt="image.png" style="zoom:50%;"></p><p><img src="/2020/05/17/31684/1589697479975-0256eaec-3fd1-4829-9bca-4ab84782d79c.png" alt="image.png" style="zoom:50%;"></p><p><strong>p-value矫正：</strong> <strong>Bonferroni Correction和Benjamini and Hochberg method</strong></p><p>Bonferroni Correction是p-value的一个矫正方法，相对严格；FDR是另一种矫正p-value的方法，而Benjamini and Hochberg method（即BH)是FDR的一个计算方法。</p><blockquote><p>We know P-value threshold is set artificially, the samller p-value represents the lower false positive for the result, but not mean it is absolutly true. For example, if the P-value equals 0.05, 10,000 tests are done, the number of false positive results will be 0.05*10,000 = 500. The false positive results will be enlarged with the incresasing the number of tests . Therefor, we need to introduce multiple tests for correction to reduce the number of false positive results. </p><p>There are two main correction methods used:</p><p><strong>1) Bonferroni Correction</strong></p></blockquote><blockquote><p>The Bonferroni method is a simplest and most brutally effective method of correction, which rejects all the possibilities of false pofitive results, and eliminates them by correcting the threshold of the P value. </p></blockquote><blockquote><p>The formula for Bonferroni method is p<em>(1/n), where p is the original P value threshold, and n is the total number of tests. If the original P value is is 0.05, and the number of test is 10,000, then the threshold after Bonferroni correction is equal to 0.05/10,000 = 0.000005, in this case, the number of false positive results in 10,000 test is 10,000 </em> 0.000005 = 0.5, less than 1. </p></blockquote><blockquote><p>But Bonferroni correction is too stringent, it will cause not only false positives are rejected by corrected threshold, but mant positives are also rejected. </p></blockquote><blockquote><p><strong>2) FDR( False Discovery Rate)</strong></p><p>FDR corrects for p-values in a relatively gentle wat compared to Bonferroni. It attempts to get a balance between false positives and false negatives, keeping the false/true positive ratio within a certain range. For example, if we set a threshold of 0.05 for 10,000 tests,the probabilty of false positives remains within 0.05, which is called FDR&lt;0.05.</p></blockquote><blockquote><p>So how to calculate FDR from p value, there are several estimation models. The most used is <strong>Benjamini and Hochberg method,</strong> also known as <strong>BH method</strong>. </p></blockquote><blockquote><p>BH method requires the results of total <strong>m</strong> tests to be ranked in descending order, <strong>k is the rank of p value in one of the results.</strong> </p></blockquote><blockquote><p>find the maximum k value that meets the original threshold α, satisfy P(k) &lt;= α<em>k/m, consider the ranking to be significanand different for all tests from 1 to k, and calculate the corresponding q value as q=p</em>(m/k). </p></blockquote><p><strong>参考资料：</strong></p><p>statquest线性回归视频 : <a href="https://www.youtube.com/playlist?list=PLblh5JKOoLUIzaEkCLIUxQFjPIlapw8nU" target="_blank" rel="noopener">https://www.youtube.com/playlist?list=PLblh5JKOoLUIzaEkCLIUxQFjPIlapw8nU</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> statistics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人肠内分泌细胞的高分辨率mRNA和分泌组图谱</title>
      <link href="/2020/05/13/22345.html"/>
      <url>/2020/05/13/22345.html</url>
      
        <content type="html"><![CDATA[<p><strong>文章信息</strong></p><p>题目：High-Resolution mRNA and Secretome Atlas of Human Enteroendocrine Cells</p><p>杂志：Cell</p><p>时间：May 13, 2020</p><p>链接: <a href="https://doi.org/10.1016/j.cell.2020.04.036" target="_blank" rel="noopener">https://doi.org/10.1016/j.cell.2020.04.036</a></p><p>肠道内分泌细胞（EEC）感知肠道内容物，释放激素，调节胃肠活动、全身代谢和食物摄入量。关于人类肠道内分泌细胞亚型的分子构成和个体激素的分泌调节，目前还不甚了解。在这里，我们描述了一个基于有机体的平台，用于人类EECs的功能研究。EEC的形成是在体外通过NEUROG3的瞬时表达诱导的。设计了一套肠道器质体，其中主要的激素被荧光标记。生成了不同EEC亚型的单细胞mRNA图谱，并通过质谱法记录了其分泌的产物。我们注意到与小鼠EECs的关键差异，包括激素、感觉受体和转录因子。值得注意的是，确定了几种激素类分子。泌素诱导的GLP-1的分泌是EEC间交流的典范。事实上，个别EEC亚型携带着各种EEC激素的受体。本研究为研究人类EEC的发育和功能提供了丰富的资源。</p><p><img src="/2020/05/13/22345/1589400011510-19258e40-16de-43b2-9a27-cd1ec0badc25.jpeg" alt="200513-fig-.jpg" style="zoom:50%;"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>lncRNA的保守和不保守</title>
      <link href="/2020/05/13/52528.html"/>
      <url>/2020/05/13/52528.html</url>
      
        <content type="html"><![CDATA[<p><strong>文章信息</strong></p><p>题目：Distinct Processing of lncRNAs Contributes to Non-conserved Functions in Stem Cells</p><p>杂志：Cell</p><p>时间：6 April 2020</p><p>链接: h<a href="https://doi.org/10.1016/j.cell.2020.03.006" target="_blank" rel="noopener">ttps://doi.org/10.1016/j.cell.2020.03.006</a></p><p><strong>该文章的评论文章：</strong></p><p>题目：The Secret Life of lncRNAs: Conserved, yet Not Conserved</p><p>链接：<a href="https://doi.org/10.1016/j.cell.2020.04.012" target="_blank" rel="noopener">https://doi.org/10.1016/j.cell.2020.04.012</a></p><p><strong>文章介绍</strong></p><p>长非编码RNA（lncRNAs）的进化速度比mRNAs更快。保守的lncRNAs是否经过保守的加工、定位和功能仍未被探索。中科院陈玲玲教授团队报告了人类（h) 和小鼠 (m) 胚胎干细胞（ESCs）中不同的lncRNAs的亚细胞定位。与mESCs相比，在hESCs的细胞质中定位的lncRNAs的比例明显高于mESCs。事实证明，这对hESC的多能性很重要。FAST是一种位置保守的lncRNA，但在加工和定位方面并不保守。在hESCs中，细胞质定位的h FAST与E3泛素连接酶β-TrCP的WD40域结合，并阻止其与磷酸化的β-catenin相互作用，以防止降解，导致激活WNT信号转导，这是多能性所需的。与此相反，m Fast在mESCs中被核保留，其处理被拼接因子PPIE抑制，而PPIE在mESCs中高表达，但在hESCs中没有。这些发现揭示了lncRNA的加工和定位是之前未被重视的作用于快速进化的贡献者。</p><a id="more"></a><p><img src="/2020/05/13/52528/1589397881556-d461906a-a11a-423f-9412-b01efafa4b1a.png" alt="image.png" style="zoom: 33%;"></p><p>Harshita Sharma 对这篇文章的评论：Guo及其同事发现了lncRNA演化的新的复杂性，在人类ESCs中，位置保守的lncRNAs被广泛地拼接并输出到细胞质中，而小鼠的lncRNAs主要是未拼接和核保留。不同的处理导致了物种特异性的lncRNA在多能性维持中的功能。</p><p><img src="/2020/05/13/52528/1589397879457-7fa9fb7d-706c-425e-a71e-235f7c043761.png" alt="image.png" style="zoom:33%;"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> lncRNA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用机器学习模型从全基因组序列中预测胸膜肺炎放线菌抗药性</title>
      <link href="/2020/05/13/47788.html"/>
      <url>/2020/05/13/47788.html</url>
      
        <content type="html"><![CDATA[<p><strong>文章信息</strong></p><p>题目：Evaluation of Machine Learning Models for Predicting Antimicrobial Resistance of Actinobacillus pleuropneumoniae From Whole Genome Sequences</p><p>杂志：Frontiers in Microbiology</p><p>时间：06 February 2020</p><p>链接: <a href="https://doi.org/10.3389/fmicb.2020.00048" target="_blank" rel="noopener">https://doi.org/10.3389/fmicb.2020.00048</a></p><p><img src="/2020/05/13/47788/1588845190895-1ed386ed-9893-4e0e-85a7-551c120d3d77-20200513204949002.png" alt="2020-05-07_fig2.png"></p><p><strong>文章概述</strong></p><p>抗生素耐药性(AMR)正在成为世界各国面临的一个巨大公共安全问题，识别对某些抗生素耐药或易感菌株的新方法对于对抗抗生素耐药病原体至关重要。由于基因组数据集和AST表型越来越多，基于基因型的机器学习方法作为一种诊断工具显示出了巨大的希望。</p><p>本文采用<strong>支持向量机（</strong> <strong>Support Vector Machine</strong>，<strong>SVM）和集覆盖机（**</strong>Set Covering Machine<strong>，</strong>SCM）<strong>模型来学习和预测</strong>五种药物（<strong>四环素类、氨苄西林、磺胺恶唑、曲美沙星和恩诺沙星）的耐药性。</strong>SVM模型利用分离菌的基因组与参比基因之间共存的k-mers的数量来学习和预测细菌对特定抗生素的表型<strong>，</strong>而单片机模型则采用贪婪的方法构造布尔函数的联结或解联，找到最简洁的k-mers集，从而准确预测表型。<strong>对SVM和SCM模型的训练集进行</strong>五倍交叉验证<strong>，选择最佳的超参数值，以避免模型过度拟合。结果表明，无论哪种药物的耐药机制是获得性耐药还是染色体点突变，</strong>5种药物的SVM和SCM模型的训练准确率（平均交叉验证得分）和测试准确率均在90%以上。5种药物的表型与模型预测的相关性结果表明，SVM和SCM模型均能显著地将耐药分离菌从敏感分离菌中分离出来（P&lt;0.01），可作为抗生素耐药性监测和兽药临床诊断的潜在工具。</p><a id="more"></a><p><strong>方法详解</strong></p><p><strong>数据来源：</strong></p><ul><li><p>从<strong>Bosse等人(2017)文章</strong>获得<strong>96株</strong>胸膜肺炎分离菌株的<strong>5种</strong>抗菌药物(四环素、氨苄西林、磺胺恶唑、甲氧苄氨嘧啶和恩罗沙星)的<strong>WGS序列和双耐药表型</strong></p></li><li><ul><li>Study: PRJEB2343</li></ul></li></ul><p>Reference: Whole genome sequencing for surveillance of antimicrobial resistance in <em>Actinobacillus pleuropneumoniae</em>. <em>Front. Microbiol.</em> 8:311. doi: 10.3389/fmicb.2017.00311</p><p><strong>分析方法：</strong></p><ul><li>WGS assemle: Velvet 1.2.08</li><li>AMR genes contig: 从ResFinder 数据库</li><li>matrix of the co-occurring k-mers：Ray Surveyor tool</li><li><strong>Reference-Based SVM Model</strong>：radial basis function kernel，Python sklearn 包实现分析</li><li><strong>Reference-Free SCM Model</strong>：implemented by <strong>Kover</strong>, an open-source software implemented in the Python and C programming languages</li><li>Model Selection and Performance Evaluation: five-fold cross-validation, 评价指标：sensitivity, specificity, accuracy, and precision</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> AMR </tag>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用随机子空间集合的机器学习从三种病原体的泛基因组中识别出抗生素耐药性决定因素</title>
      <link href="/2020/05/13/21825.html"/>
      <url>/2020/05/13/21825.html</url>
      
        <content type="html"><![CDATA[<p><strong>文章信息</strong></p><p>题目：Machine learning with random subspace ensembles identifies antimicrobial resistance determinants from pan-genomes of three pathogens</p><p>杂志：PLOS COMPUTATIONAL BIOLOGY</p><p>时间：March 2, 2020</p><p>链接: <a href="https://doi.org/10.1371/journal.pcbi.1007608" target="_blank" rel="noopener">https://doi.org/10.1371/journal.pcbi.1007608</a></p><p><img src="/2020/05/13/21825/1588841404348-eb669a8a-0061-49bb-83d7-bbfcf683eb24.png" alt="2020-05-07_fig1.png"></p><p><strong>文章概述</strong></p><p>抗菌剂耐药性的演变对全球公共卫生构成了持续的威胁。 测序工作已经获得了数千种耐药微生物分离物的基因组序列，需要强大的计算工具来系统地阐明AMR的遗传基础。</p><p>在这里，文章提出了一种可通用的机器学习工作流程，基于构建的参考菌株诊断泛基因组和训练<strong>随机子空间集合（RSEs）</strong>，用于鉴定驱动AMR的遗传特征。这一工作流程对<strong>三种病原体</strong>的<strong>14种抗菌素</strong>的耐药性谱进行了研究，其中包括<strong>288种金黄色葡萄球菌</strong>、<strong>456种绿脓杆菌和1588种大肠杆菌基因组</strong>。文章发现，与常见的统计学检验和以前的集合方法相比，他们发现通过<strong>特征选择法</strong>检测已知的AMR更可靠，利用该方法共识别出45个已知的AMR基因和等位基因，以及25个由域级注释支持的候选关联。此外，发现来自于RSE方法的结果与现有的氟喹诺酮（FQ) 的理解是一致的。(FQ)抗药性是由于这三种生物体中主要药物靶点gyrA和parC的突变引起的，并表明这些基因在FQ抗药性方面的突变情况是简单的。随着更大的数据集的出现，我们希望这种方法能够更可靠地预测更多微生物病原体的AMR决定因素。</p><a id="more"></a><p><strong>方法详解</strong></p><p><strong>数据来源</strong>：数据集是从PATRIC数据库下载的，共包括288,456和1588个金黄色葡萄球菌、铜绿假单胞菌和大肠杆菌的基因组数据。</p><p><strong>数据预处理</strong>：鉴定开放阅读框，对编码基因进行聚类；由于AMR的致病变异通常存在于个体突变水平，他们对每个泛基因组的每个基因的所有观察到的独特氨基酸序列变异或“等位基因”进行了识别和列举。</p><p><strong>模型选择和训练</strong>：首先基于支持向量机（support vector machine ，SVM)方法训练模型（SVM是通过scikit-learn实现的），训练集来自六种针对金黄色葡萄球菌的抗生素治疗方法。验证是根据从文献和CARD数据库中收集的已知的的AMR基因。</p><p>然后使用相同的特征矩阵和AMR表型，对每个抗生素病例训练了两种类型的SVM合集，以将基因组分类为易感或耐药，由500个SVM组成，每个SVM训练的结果是：1）随机抽取80%的基因组和所有特征的随机样本，得到类似于中的引导合集；或2）随机抽取80%的基因组和50%的特征，得到<strong>随机子空间合集（RSE</strong>），这种调整以前被证明可以提高在高维生物数据上训练的SVM的准确性。类似地，特征按特征权重进行排序。</p><p>最后使用SVM-RSE的方法在P. aeruginosa和E.coli数据集中鉴定已知的AMR基因。</p><p><strong><img src="/2020/05/13/21825/1588838311456-3629ce5d-d5cb-43ed-83cd-77e5a060fe24.png" alt="image.png"></strong></p>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用深度学习从宏基因组数据中预测抗生素抗性基因—DeepARG（方法详解）</title>
      <link href="/2020/05/06/39637.html"/>
      <url>/2020/05/06/39637.html</url>
      
        <content type="html"><![CDATA[<p>​               <img src="/2020/05/06/39637/1588755936726-a2a86d1c-ae3a-40bc-aaa2-974114d7e81f-20200506124808009.png" alt="image.png" style="zoom:50%;"></p><h3 id="方法概述："><a href="#方法概述：" class="headerlink" title="方法概述："></a>方法概述：</h3><p>从CARD,ARDB和UNIPROT 3个数据库分别提取抗性基因（antibiotic resistance genes,ARGs）, 3个数据库分别提取到2161，2290和28108个抗性基因。然后对3个数据库的抗性基因进行注释和分类，CARD和ARDB共鉴定到102个抗生素，包括30个抗生素分类。UNIPROT通过文本挖掘注释，然年再结合CARD和ARDB两个数据库验证。</p><p>得到经过前处理后的数据，利用深度神经网络训练模型，凭借Python中的Theano库的Lasagne模块实现模型训练。分别对短读长序列和长基因序列分开训练，得到deepARG-SS 和 deepARG-LS。</p><p>评估模型通过两个方法：一是UNIPROT的70%数据作为训练数据，30%作为测试验证数据；二是借助MEGARes数据库的数据作为独立的验证数据集，评估模型的表现。</p><a id="more"></a><h3 id="数据来源："><a href="#数据来源：" class="headerlink" title="数据来源："></a>数据来源：</h3><p>数据来自3个数据库：<strong>CARD,ARDB和UNIPROT</strong></p><h3 id="数据前处理"><a href="#数据前处理" class="headerlink" title="数据前处理"></a>数据前处理</h3><p><img src="/2020/05/06/39637/1588754695659-2c3b9a82-cbe0-453a-8663-e0c55346c1f6-20200506124806659.png" alt="image.png"></p><p><img src="/2020/05/06/39637/1588754740918-4ee1605e-db2c-4cfd-906d-7dd74b38da83-20200506124807027.png" alt="image.png"></p><h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><p><img src="/2020/05/06/39637/1588754750458-42a8a187-40da-4df8-b7bb-6c409d3f6853-20200506124807310.png" alt="image.png"></p><h3 id="模型验证"><a href="#模型验证" class="headerlink" title="模型验证"></a>模型验证</h3><p>从模型验证的结果看，似乎模型的效果太好了，不知道是否有过拟合的现象。</p><p><img src="/2020/05/06/39637/1588754581852-30322794-6acc-493f-b457-2985bb53ea91-20200506124807265.png" alt="image.png"></p><h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><p><strong>github代码打不开：</strong></p><p><a href="https://gaarangoa@bitbucket.org/gaarangoa/deeparg-ss.git" target="_blank" rel="noopener">https://gaarangoa@bitbucket.org/gaarangoa/deeparg-ss.git</a></p><p><strong>网站在线分析：</strong></p><p><a href="https://bench.cs.vt.edu/deeparg" target="_blank" rel="noopener">https://bench.cs.vt.edu/deeparg</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> AMR </tag>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>卷积神经网络入门</title>
      <link href="/2020/05/04/48327.html"/>
      <url>/2020/05/04/48327.html</url>
      
        <content type="html"><![CDATA[<p><img src="/2020/05/04/48327/fig1.png" style="zoom:50%;"></p><h3 id="卷积神经网络-CNN-简介"><a href="#卷积神经网络-CNN-简介" class="headerlink" title="卷积神经网络(CNN)简介"></a>卷积神经网络(CNN)简介</h3><p><strong>卷积神经网络即Convolutional Neural Networks (CNN or COnvNet)</strong> 是一种自动化提取特征的深度学习模型。这是一种深度的前馈人工神经网络（ feed-forward artificial neural network），前馈神经网络也称作多层感知机（multi-layer perceptrons，MLPs）。</p><p>CNNs是受生物视觉皮层的启发。视觉皮层有一些小区域的细胞，它们对视野的特定区域很敏感。这个想法是由Hubel和Wiesel在1962年做的一个的实验扩展了这个想法。在这个实验中，研究人员表明，大脑中的一些个别神经元只有在出现垂直或水平边缘等特定方向的边缘时才会激活或发射。但是在2012年，Alex Krizhevsky利用卷积神经网络赢得了当年的ImageNet大赛，将分类误差从26%降到15%，之后CNNs再一次火爆。</p><p>CNNs如今在多个领域都展现出巨大的应用潜能。如：</p><ul><li>图像识别，目标检测，分割，人脸识别</li><li>自动驾驶汽车等</li></ul><a id="more"></a><h3 id="卷积神经网络-CNN-的结构单元"><a href="#卷积神经网络-CNN-的结构单元" class="headerlink" title="卷积神经网络(CNN)的结构单元"></a>卷积神经网络(CNN)的结构单元</h3><p><img src="/2020/05/04/48327/1588619184008-278128ad-0eb0-4470-9a00-e6c030273227.png" alt="fig2.png"></p><h4 id="输入层-input-layer"><a href="#输入层-input-layer" class="headerlink" title="输入层(input layer)"></a>输入层(input layer)</h4><h4 id="卷积层（convolution-layer"><a href="#卷积层（convolution-layer" class="headerlink" title="卷积层（convolution layer)"></a>卷积层（convolution layer)</h4><blockquote><p>权值共享。我们通过卷积核与输入进行卷积运算。通过下图可以理解如何进行卷积运算。卷积核从左到右对输入进行扫描，每次滑动1格（步长为1），下图为滑动一次后，卷积核每个元素和输入中绿色框相应位置的元素相乘后累加，得到输出中绿色框中的0。一般会使用多个卷积核对输入数据进行卷积，得到多个特征图</p></blockquote><p><img src="/2020/05/04/48327/fig3.png" style="zoom:33%;"></p><h4 id="激活层"><a href="#激活层" class="headerlink" title="激活层"></a>激活层</h4><blockquote><p>对卷积层的输出进行一个非线性映射，因为卷积计算是一种线性计算。常见的激活函数有relu、tanh、sigmoid等，一般使用relu。使用relu的原因是在反向传播计算梯度中，使用relu求导明显会比tanh和sigmoid简单，可以<strong>减少计算量</strong></p></blockquote><h4 id="池化层-subsampling-pooling-layer"><a href="#池化层-subsampling-pooling-layer" class="headerlink" title="池化层(subsampling/pooling layer)"></a>池化层(subsampling/pooling layer)</h4><blockquote><p>池化的目的就是减少特征图的维度，减少数据的运算量。池化层是在卷积层之后，对卷积的输出，进行池化运算。池化运算，一般有两种MaxPooling和MeanPooling。</p></blockquote><p><img src="/2020/05/04/48327/fig4.png" style="zoom:33%;"></p><h4 id="全连接层-Fully-connected-layer"><a href="#全连接层-Fully-connected-layer" class="headerlink" title="全连接层(Fully connected layer)"></a>全连接层(Fully connected layer)</h4><blockquote><p>主要是对特征进行重新的拟合，减少特征信息的丢失。通过卷积池化操作后得到的是多个特征矩阵，而全连接层的输入为向量，所以在进行全连接层之前，要将多个特征矩阵“压平”为一个向量。</p></blockquote><h4 id="输出层-output-layer"><a href="#输出层-output-layer" class="headerlink" title="输出层(output layer)"></a>输出层(output layer)</h4><h3 id="卷积神经网络-CNN-代码示例"><a href="#卷积神经网络-CNN-代码示例" class="headerlink" title="卷积神经网络(CNN)代码示例"></a>卷积神经网络(CNN)代码示例</h3><p>这里介绍以Keras实现CNN的代码示例</p><h4 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h4><p>Fashion-MNIST数据集是Zalando的文章图像数据集，包含来自10个类别的70000个时尚产品的28x28灰度图像，每个类别有7000个图像。训练集有60000张图片，测试集有10000张图片。</p><h4 id="数据载入"><a href="#数据载入" class="headerlink" title="数据载入"></a>数据载入</h4><p>首先载入Keras模块，其是基于tensorflow框架的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># install tensorflow</span><br><span class="line">pip install tensorflow</span><br><span class="line">pip install keras</span><br><span class="line">from keras.datasets import fashion_mnist</span><br><span class="line">(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()</span><br></pre></td></tr></table></figure><p><strong>调整像素和图像大小</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from keras.utils import to_categorical</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">print(&apos;Training data shape : &apos;, train_X.shape, train_Y.shape)</span><br><span class="line"></span><br><span class="line">print(&apos;Testing data shape : &apos;, test_X.shape, test_Y.shape)</span><br><span class="line"></span><br><span class="line"># Find the unique numbers from the train labels</span><br><span class="line">classes = np.unique(train_Y)</span><br><span class="line">nClasses = len(classes)</span><br><span class="line">print(&apos;Total number of outputs : &apos;, nClasses)</span><br><span class="line">print(&apos;Output classes : &apos;, classes)</span><br></pre></td></tr></table></figure><p>可以看出输出的类别共包括10（0-9）类</p><p><strong>查看数据集中图像</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=[5,5])</span><br><span class="line"></span><br><span class="line"># Display the first image in training data</span><br><span class="line">plt.subplot(121)</span><br><span class="line">plt.imshow(train_X[0,:,:], cmap=&apos;gray&apos;)</span><br><span class="line">plt.title(&quot;Ground Truth : &#123;&#125;&quot;.format(train_Y[0]))</span><br><span class="line"></span><br><span class="line"># Display the first image in testing data</span><br><span class="line">plt.subplot(122)</span><br><span class="line">plt.imshow(test_X[0,:,:], cmap=&apos;gray&apos;)</span><br><span class="line">plt.title(&quot;Ground Truth : &#123;&#125;&quot;.format(test_Y[0]))</span><br></pre></td></tr></table></figure><p><img src="/2020/05/04/48327/fig5.png" style="zoom:33%;"></p><p>上面两个图的输出看起来像一个短靴，这个类被分配了一个类标签9。同样的，其他的时尚产品会有不同的标签，但是相似的产品会有相同的标签。这意味着所有7000张短靴图片的类别标签都是9。</p><h4 id="数据前处理"><a href="#数据前处理" class="headerlink" title="数据前处理"></a>数据前处理</h4><p>上面的图像可以看出是灰度图像，像素值的范围再0-255,且图像的维度为28*28. </p><ul><li>Step1: 首先将训练数据和测试数据的28<em>28图像转化为28</em>28*1的矩阵</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_X = train_X.reshape(-1, 28,28, 1)</span><br><span class="line">test_X = test_X.reshape(-1, 28,28, 1)</span><br><span class="line">train_X.shape, test_X.shape</span><br></pre></td></tr></table></figure><ul><li>Step2: 现在的数据是int8格式的，因此在将其输入网络之前，需要将其类型转换为float32，还必须重新调整范围为0 - 1(包括1)的像素值。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_X = train_X.astype(&apos;float32&apos;)</span><br><span class="line">test_X = test_X.astype(&apos;float32&apos;)</span><br><span class="line">train_X = train_X / 255.</span><br><span class="line">test_X = test_X / 255.</span><br></pre></td></tr></table></figure><ul><li>Step3: 将类标签转换为一个热编码向量</li></ul><p>机器学习算法不能直接处理分类数据, 故需将分类数据转换为数字向量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Change the labels from categorical to one-hot encoding</span><br><span class="line">train_Y_one_hot = to_categorical(train_Y)</span><br><span class="line">test_Y_one_hot = to_categorical(test_Y)</span><br><span class="line"></span><br><span class="line"># Display the change for category label using one-hot encoding</span><br><span class="line">print(&apos;Original label:&apos;, train_Y[0])</span><br><span class="line">print(&apos;After conversion to one-hot:&apos;, train_Y_one_hot[0])</span><br></pre></td></tr></table></figure><ul><li>拆分训练数据和测试数据集</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)</span><br><span class="line"># check the shape of training and validation set</span><br><span class="line">train_X.shape,valid_X.shape,train_label.shape,valid_label.shape</span><br></pre></td></tr></table></figure><h4 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h4><p>图像的大小是28 x 28。前面将图像矩阵转换为数组，在0和1之间重新调整大小，重塑它的大小为28 x 28 x 28 x 1，然后将其作为网络的输入。</p><p>下面将使用三个卷积层。</p><p>第一层将有32-3×3个滤波器。</p><p>第二层将有64-3×3滤波器和</p><p>第三层将有128-3×3个滤镜。</p><p>此外，还有3个最大pooling层，每个层的大小为2×2。</p><p><img src="/2020/05/04/48327/fig7.png" style="zoom:50%;"></p><h4 id="创建模型"><a href="#创建模型" class="headerlink" title="创建模型"></a>创建模型</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import keras</span><br><span class="line">from keras.models import Sequential,Input,Model</span><br><span class="line">from keras.layers import Dense, Dropout, Flatten</span><br><span class="line">from keras.layers import Conv2D, MaxPooling2D</span><br><span class="line">from keras.layers.normalization import BatchNormalization</span><br><span class="line">from keras.layers.advanced_activations import LeakyReLU</span><br></pre></td></tr></table></figure><p>这里使用64的批处理量，也可以使用128或256的批处理量，这一切都取决于内存。它对确定学习参数的贡献很大，并影响到预测的准确性。你将训练网络的20个时程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">batch_size = 64</span><br><span class="line">epochs = 20</span><br><span class="line">num_classes = 10</span><br></pre></td></tr></table></figure><h4 id="神经网络架构"><a href="#神经网络架构" class="headerlink" title="神经网络架构"></a>神经网络架构</h4><p>在Keras中，可以通过逐一添加所需的图层来堆叠图层。首先用Conv2D()添加第一个卷积层。注意，之所以使用这个函数，是因为在处理图像。 接下来，添加Leaky ReLU激活函数，它可以帮助网络学习非线性决策边界。因为这里的例子有十个不同的类，需要一个非线性决策边界，可以将这十个不能线性分离的类分开。</p><p>更具体地说，添加了Leaky ReLU，因为它们试图修复垂死的整流线性单元（ReLU）问题。ReLU 激活函数在神经网络架构中被大量使用，在卷积网络中，ReLU 激活函数被证明比广泛使用的对数 sigmoid 函数更有效。截止到2017年，这种激活函数是深度神经网络中最流行的一种激活函数。ReLU函数允许将激活函数的阈值设定为零。然而，在训练过程中，ReLU单元可能会 “死亡”。当一个大的梯度流过ReLU神经元时，就会发生这种情况：它可能会导致权重以这样的方式更新，以至于神经元再也不会在任何数据点上激活。如果这种情况发生，那么流经该单元的梯度将永远为零。泄漏的ReLU试图解决这个问题：函数不会为零，而是有一个小的负斜率。</p><p>接下来，用MaxPooling2D()等添加最大池化层。最后一层是Dense层，它有一个软MAX的激活函数，有10个单位，这对于这个多类分类问题是需要的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">fashion_model = Sequential()</span><br><span class="line">fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation=&apos;linear&apos;,input_shape=(28,28,1),padding=&apos;same&apos;))</span><br><span class="line">fashion_model.add(LeakyReLU(alpha=0.1))</span><br><span class="line">fashion_model.add(MaxPooling2D((2, 2),padding=&apos;same&apos;))</span><br><span class="line">fashion_model.add(Conv2D(64, (3, 3), activation=&apos;linear&apos;,padding=&apos;same&apos;))</span><br><span class="line">fashion_model.add(LeakyReLU(alpha=0.1))</span><br><span class="line">fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding=&apos;same&apos;))</span><br><span class="line">fashion_model.add(Conv2D(128, (3, 3), activation=&apos;linear&apos;,padding=&apos;same&apos;))</span><br><span class="line">fashion_model.add(LeakyReLU(alpha=0.1))                  </span><br><span class="line">fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding=&apos;same&apos;))</span><br><span class="line">fashion_model.add(Flatten())</span><br><span class="line">fashion_model.add(Dense(128, activation=&apos;linear&apos;))</span><br><span class="line">fashion_model.add(LeakyReLU(alpha=0.1))                  </span><br><span class="line">fashion_model.add(Dense(num_classes, activation=&apos;softmax&apos;))</span><br></pre></td></tr></table></figure><h4 id="编译模型"><a href="#编译模型" class="headerlink" title="编译模型"></a>编译模型</h4><p>使用Adam optimizer</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=[&apos;accuracy&apos;])</span><br></pre></td></tr></table></figure><p>使用summary函数来可视化在上述步骤中创建的层。这将显示每个层中的一些参数(权重和偏差)以及模型中的总参数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fashion_model.summary()</span><br></pre></td></tr></table></figure><h4 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h4><p>使用Keras的fit()函数训练模型，该模型训练了20个 epochs。fit()函数将返回一个历史对象；通过在fashion_train中讲述这个函数的结果，你可以在以后用它来绘制训练和验证之间的精度和损失函数图，这将帮助你直观地分析你的模型的性能。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fashion_train = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))</span><br></pre></td></tr></table></figure><h4 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_eval = fashion_model.evaluate(test_X, test_Y_one_hot, verbose=0)</span><br><span class="line">print(&apos;Test loss:&apos;, test_eval[0])</span><br><span class="line">print(&apos;Test accuracy:&apos;, test_eval[1])</span><br></pre></td></tr></table></figure><h4 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">accuracy = fashion_train.history[&apos;acc&apos;]</span><br><span class="line">val_accuracy = fashion_train.history[&apos;val_acc&apos;]</span><br><span class="line">loss = fashion_train.history[&apos;loss&apos;]</span><br><span class="line">val_loss = fashion_train.history[&apos;val_loss&apos;]</span><br><span class="line">epochs = range(len(accuracy))</span><br><span class="line">plt.plot(epochs, accuracy, &apos;bo&apos;, label=&apos;Training accuracy&apos;)</span><br><span class="line">plt.plot(epochs, val_accuracy, &apos;b&apos;, label=&apos;Validation accuracy&apos;)</span><br><span class="line">plt.title(&apos;Training and validation accuracy&apos;)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(epochs, loss, &apos;bo&apos;, label=&apos;Training loss&apos;)</span><br><span class="line">plt.plot(epochs, val_loss, &apos;b&apos;, label=&apos;Validation loss&apos;)</span><br><span class="line">plt.title(&apos;Training and validation loss&apos;)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2020/05/04/48327/fig8.png" style="zoom:50%;"></p><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><blockquote><ul><li><a href="http://keraschina.com/keras_cnn/" target="_blank" rel="noopener">CNN讲解及实践</a></li><li><a href="https://www.zhihu.com/question/52668301" target="_blank" rel="noopener">CNN（卷积神经网络）</a></li><li><a href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python" target="_blank" rel="noopener">Convolutional Neural Networks in Python with Keras</a></li><li><a href="https://towardsdatascience.com/convolutional-neural-networks-for-beginners-using-keras-and-tensorflow-2-c578f7b3bf25" target="_blank" rel="noopener">Convolutional Neural Networks for Beginners using Keras and TensorFlow</a></li><li><a href="https://geek-docs.com/deep-learning" target="_blank" rel="noopener">深度学习</a></li></ul></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> CNN </tag>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习练习数据</title>
      <link href="/2020/05/02/25394.html"/>
      <url>/2020/05/02/25394.html</url>
      
        <content type="html"><![CDATA[<p>机器学习可以使用的公共练习数据资源：</p><ul><li><p><a href="https://www.openml.org/" target="_blank" rel="noopener">OpenML</a></p><p><img src="/2020/05/02/25394/fig1.png" style="zoom:50%;"></p></li><li><p><a href="http://archive.ics.uci.edu/ml/datasets.php" target="_blank" rel="noopener">UCL机器学习库</a></p></li><li><p><a href="https://www.kaggle.com/" target="_blank" rel="noopener">kaggle</a></p></li><li><p><a href="https://www.kdnuggets.com/datasets/index.html" target="_blank" rel="noopener">KDnuggets</a></p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>单细胞层面解析鼠大脑甲基化图谱</title>
      <link href="/2020/05/02/15806.html"/>
      <url>/2020/05/02/15806.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>单细胞层面解析鼠大脑甲基化图谱</p><p><strong>文章信息</strong></p><p>题目：DNA Methylation Atlas of Mouse Brain at Single-Cell Resolution</p><p>杂志：bioRxiv</p><p>时间：April 30, 2020</p><p>链接: <a href="https://www.biorxiv.org/content/10.1101/2020.04.30.069377v1" target="_blank" rel="noopener">https://www.biorxiv.org/content/10.1101/2020.04.30.069377v1</a></p><p><strong>figure</strong></p><p><img src="/2020/05/02/15806/fig1.png" style="zoom:50%;"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>哺乳动物大脑细胞在基因表达、解剖学和功能上是有显著差别的，但是目前为止对DNA对其调控作用知之甚少。这篇文章从鼠的45个脑区域，提取出110，294个细胞核，并对其进行单核DNA甲基化测序，从而探讨鼠大脑的甲基化图谱。文章发现了161个细胞群具有不同的空间位置和靶标。从特征基因、调控元件和转录因子的注释结果中观察到潜在的调控图谱支持了假定细胞类型的分配，并揭示了在兴奋性和抑制性细胞中重复使用调控因子来确定亚型。此外，文章中使用人工神经网络模型预测单个神经元细胞类型和脑区域空间位置。文章还通过整合DNA甲基化,单核染色质可及性和染色质高级结构的contracts数据，注释小鼠大脑中数百种细胞类型的调控基因组。为整个小鼠大脑神经元多样性和空间组织奠定了表观遗传学基础。</p><ul><li><p>数据：<a href="https://portal.nemoarchive.org/" target="_blank" rel="noopener">https://portal.nemoarchive.org/</a> </p></li><li><p>可视化：<a href="http://neomorph.salk.edu/mouse_brain.php" target="_blank" rel="noopener">http://neomorph.salk.edu/mouse_brain.php</a></p></li><li><p>代码： <a href="https://cemba-data.readthedocs.io/en/latest/" target="_blank" rel="noopener">https://cemba-data.readthedocs.io/en/latest/</a> </p><ul><li><a href="https://github.com/lhqing/mouse_brain_2020" target="_blank" rel="noopener">https://github.com/lhqing/mouse_brain_2020</a></li></ul></li></ul><p><strong>个人评价：</strong></p><p>单细胞脑组织图谱，在最近两年有多篇研究被报道过，不仅包括鼠，人的脑细胞图谱也有相关文章发表。这篇文章的独特之处在于研究甲基化图谱，同时结合多组学技术，构建大脑更全面表观图谱。随着单细胞技术飞入寻常百姓家，可以看出单细胞多组学的结合是近期的一个发展方向。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> single cell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Scikit-Learn实现SVM</title>
      <link href="/2020/05/01/23441.html"/>
      <url>/2020/05/01/23441.html</url>
      
        <content type="html"><![CDATA[<p><strong>支持向量机SVM（Support Vector Machines)是监督学习中一类算法，可用于分类、回归和异常值检测。</strong></p><p>具体原理可参考 <a href="[http://renyx.top/2020/04/21/Tue%20Apr%2021%202020%2014:41:09%20GMT+0200/](http://renyx.top/2020/04/21/Tue Apr 21 2020 14:41:09 GMT+0200/">SVM从原理到实现</a>)。R和python都有相关包和模块可以实现SVM，这里讨论如何在python中实现SVM。</p><p>python中是借助于<strong>scikit-learn</strong>库实现，<strong>scikit-learn</strong>是python中基于NumPy, SciPy 和matplotlib的一个机器学习库，包含多种功能，可以实现分类、回归、聚类，降维，模型选择和预处理等分析。</p><ul><li><a href="https://scikit-learn.org/stable/index.html" target="_blank" rel="noopener">https://scikit-learn.org/stable/index.html</a></li></ul><p><img src="/2020/05/01/23441/fig1.png" style="zoom:50%;"></p><a id="more"></a><h4 id="安装scikit-learn"><a href="#安装scikit-learn" class="headerlink" title="安装scikit-learn"></a>安装scikit-learn</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U scikit-learn</span><br></pre></td></tr></table></figure><p>检验是否安装成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python -m pip show scikit-learn # to see which version and where scikit-learn is installed</span><br><span class="line">python -m pip freeze # to see all packages installed in the active virtualenv</span><br><span class="line">python -c "import sklearn; sklearn.show_versions()"</span><br></pre></td></tr></table></figure><h4 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h4><p>scikit learn的输入数据支持密集型向量（包括numpy.ndarray和numpy.asarray）和疏散型向量（任何scipy.sparse）。然而，要使用支持向量机对稀疏数据进行预测，它必须适合此类数据。要获得最佳性能，请使用C-ordered numpy.ndarray（密集）或scipy.sparse.csr_matrix（稀疏），dtype=float64。</p><p>输入数据需包括两个数组(array)，<strong>数组X [n_samples,n_features], 数组Y[n_samples]</strong>。</p><p>示例数据：bankdata:</p><p><img src="/2020/05/01/23441/fig2.png" alt></p><p>Class为类别，以0，1表示，其他特征值都是数值。</p><p>首先把特征属性和类别标签分开,得到初始数据X和y.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = bankdata.drop(<span class="string">'Class'</span>, axis=<span class="number">1</span>) </span><br><span class="line">y = bankdata[<span class="string">'Class'</span>]</span><br></pre></td></tr></table></figure><h4 id="训练集和测试集的区分"><a href="#训练集和测试集的区分" class="headerlink" title="训练集和测试集的区分"></a>训练集和测试集的区分</h4><p>Scikit-Learn中的<code>model_selection</code>模块包含的<code>train_test_split</code>函数可以设置训练集和测试集的分割。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.20</span>)</span><br></pre></td></tr></table></figure><h4 id="算法训练"><a href="#算法训练" class="headerlink" title="算法训练"></a>算法训练</h4><p>Scikit-Learn中的SVM模块包含<code>SVC, NuSVC以及LinearSVC</code>函数</p><p>SVC和NuSVC是相似的方法，但接受的参数集略有不同，并且有不同的数学公式。另一方面，LinearSVC是支持向量分类在线性核情况下的另一种实现。注意，LinearSVC不接受关键字kernel，因为这被假定为线性的。它也缺少SVC和NuSVC的一些成员，比如<code>support_.</code>。</p><p>与其他分类器一样，SVC、NuSVC和LinearSVC将两个数组作为输入：一个数组X的大小[n_samples，n_features]包含训练样本，一个数组y的类标签（字符串或整数），大小[n_samples]：</p><p>这里以线性为例，把训练数据传给 SVC 类 <code>fit</code> 方法来训练算法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">svclassifier = SVC(kernel=<span class="string">'linear'</span>)</span><br><span class="line">svclassifier.fit(X_train, y_train)</span><br></pre></td></tr></table></figure><h4 id="预测模型"><a href="#预测模型" class="headerlink" title="预测模型"></a>预测模型</h4><p><code>SVC</code> 类的 <code>predict</code> 方法可以用来预测新的数据的类别</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred = svclassifier.predict(X_test)</span><br></pre></td></tr></table></figure><h4 id="算法评价"><a href="#算法评价" class="headerlink" title="算法评价"></a>算法评价</h4><p>精度、召回率和 F1 是分类任务最常用的一些评价指标.Scikit-Learn 的 <code>metrics</code> 模块中提供了 <code>classification_report</code> 和<code>confusion_matrix</code> 等方法，这些方法可以快速的计算这些评价指标.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report, confusion_matrix</span><br><span class="line">print(confusion_matrix(y_test,y_pred))</span><br><span class="line">print(classification_report(y_test,y_pred))</span><br></pre></td></tr></table></figure><h4 id="评价结果"><a href="#评价结果" class="headerlink" title="评价结果"></a>评价结果</h4><p><img src="/2020/05/01/23441/fig3.png" style="zoom:50%;"></p><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><ul><li><a href="https://juejin.im/post/5b7fd39af265da43831fa136" target="_blank" rel="noopener">用 Scikit-Learn 实现 SVM 和 Kernel SVM</a></li><li><p><a href="https://scikit-learn.org/stable/modules/svm.html" target="_blank" rel="noopener">Support Vector Machines</a></p></li><li><p><a href="https://www.qikegu.com/docs/4065" target="_blank" rel="noopener">Sklearn 教程</a></p></li><li><a href="https://www.cnblogs.com/luyaoblog/p/6775342.html" target="_blank" rel="noopener"><a href="https://www.cnblogs.com/luyaoblog/p/6775342.html" target="_blank" rel="noopener">Python中的支持向量机SVM的使用（有实例）</a></a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> machine learning </tag>
            
            <tag> Scikit-Learn </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python基础知识</title>
      <link href="/2020/04/21/8258.html"/>
      <url>/2020/04/21/8258.html</url>
      
        <content type="html"><![CDATA[<h3 id="Python基础语法"><a href="#Python基础语法" class="headerlink" title="Python基础语法"></a>Python基础语法</h3><p><img src="/2020/04/21/8258/fig0.png" style="zoom:50%;"></p><a id="more"></a><p><strong>书写规则</strong>：</p><p><code>#</code>： 表注释；<code>import</code>: 倒入模块；有缩进之分，通常为4字符</p><p><strong>基础数据类型：</strong></p><ul><li>整数int: 如1, 3, 5</li><li>浮点数float: 如 1.2；3.5</li><li>字符串（str): “8” “python”</li><li>布尔值（bool): True False</li></ul><p>检测数据类型：<code>type()</code>,如type(“8”)  是<code>string</code></p><p>转换数据类型：int(); float(); str(); bool() </p><p><strong>变量的定义和常用操作：</strong></p><p>变量名称通常以字母和下划线开头，中间包括字母、数字和下划线</p><h3 id="序列"><a href="#序列" class="headerlink" title="序列"></a>序列</h3><p><strong>序列的概念</strong></p><ul><li><p>有序的排列；可以通过下标偏移量访问</p></li><li><p>包括字符串，列表和元组</p><p><img src="/2020/04/21/8258/fig1.png" alt="fig1" style="zoom:50%;"></p></li><li><p>字符串可以是单引号或双引号；列表是[]创建；元组是() 创建</p></li></ul><p><strong>序列的基本操作</strong></p><p><img src="/2020/04/21/8258/fig2.png" style="zoom:50%;"></p><p><strong>字符串的定义和常用操作</strong></p><ul><li>切片操作符[]</li><li>成员关系： in ; not in</li><li>连接和重复操作</li></ul><p><strong>元组的定义和常用操作</strong></p><ul><li>包含序列的基本操作</li><li>元组内容不可变更</li></ul><p><strong>列表的定义和常用操作</strong></p><ul><li>包含序列的基本操作</li><li>列表内容可变更，可以增加或移除元素</li><li><code>append</code>末尾添加元素；<code>remove</code>移除元素</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SVM从原理到实现</title>
      <link href="/2020/04/21/3288.html"/>
      <url>/2020/04/21/3288.html</url>
      
        <content type="html"><![CDATA[<h3 id="SVM-简介"><a href="#SVM-简介" class="headerlink" title="SVM 简介"></a>SVM 简介</h3><p><strong>SVM(Support Vector Machines)</strong>支持向量机是机器学习中的一种分类算法，属于监督式学习，也可以同时用于分类和回归问题。SVM的核心思想是找到最大的边际超平面，以最大程度地将数据集划分为类。</p><a id="more"></a><h3 id="SVM原理"><a href="#SVM原理" class="headerlink" title="SVM原理"></a>SVM原理</h3><p><strong>术语</strong></p><ul><li><p><strong>Margin</strong></p><p>边距是最接近的分类点上的两条线之间的间隙。 这是从线到支持向量或最接近点的垂直距离来计算的。 如果两个类之间的边距较大，则认为是良好的边距，较小的边距是较差的边距</p><p><img src="/2020/04/21/3288/fig2.png" style="zoom:50%;"></p></li><li><p><strong>Soft Margin</strong></p><p>允许错误分类，这时观测值和阈值间的距离也称作Soft Margin。使用Cross Validation确定在 Soft Margin错误分类的个数，从而得到最好的分类模型。</p><p><img src="/2020/04/21/3288/fig3.png" style="zoom:50%;"></p></li><li><p><strong>支持向量</strong>（Support Vectors)</p><p>支持向量是最靠近超平面的数据点。 这些点将通过计算边距更好地定义分隔线。 这些点与分类器的构建更相关</p><p><img src="/2020/04/21/3288/fig4.png" style="zoom:50%;"></p><p>当处理的数据是一维时，Support Vector Classifier 是一个单独点；当处理的数据是二维时，Support Vector Classifier是一条线(如下图2-D)；当处理的数据是三维时，<strong>Support Vector Classifier 是一个超平面（hyperplane）</strong>(如下图3-D)</p><p>图2-D：</p><p><img src="/2020/04/21/3288/fig5.png" style="zoom: 25%;"></p><p>图3-D：</p><p><img src="/2020/04/21/3288/fig6.png" style="zoom:25%;"></p></li></ul><p><strong>SVM 背后的原理</strong></p><p>首先以低维数据开始</p><p><img src="/2020/04/21/3288/fig7.png" style="zoom:25%;"></p><p>然后将数据转为更高的维度</p><p><img src="/2020/04/21/3288/fig8.png" alt="fig8" style="zoom:25%;"></p><p>找到一个Support Vector Classifier可以将高维数据分为两类</p><p><img src="/2020/04/21/3288/fig9.png" style="zoom:25%;"></p><p><strong>SVM数学原理</strong></p><p>利用<strong>核函数（Kernel Functions)</strong>找到Support Vector Classifier</p><ul><li><strong>Polynomial Kernel</strong>（多项核）:包含参数d,表示多项式的维度,如d=1,表示1维，d=3,表示3维。</li><li><strong>Radial Kernel</strong>:用于无限维度</li></ul><h3 id="SVM优缺点"><a href="#SVM优缺点" class="headerlink" title="SVM优缺点"></a>SVM优缺点</h3><p><strong>优点：</strong></p><ul><li><strong>High Dimensionality</strong></li><li><strong>Memory Efficiency</strong></li><li><strong>Versatility</strong></li></ul><p><strong>缺点：</strong></p><ul><li><strong>Kernel Parameters Selection</strong></li><li><strong>Non-Probabilistic</strong></li></ul><h3 id="R和Python中实现SVM"><a href="#R和Python中实现SVM" class="headerlink" title="R和Python中实现SVM"></a>R和Python中实现SVM</h3><p><strong>R中实现SVM</strong></p><p>R中可以借助<strong>package <code>e1071</code></strong>，</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Import Library</span></span><br><span class="line"><span class="keyword">require</span>(e1071) <span class="comment">#Contains the SVM </span></span><br><span class="line">Train &lt;- read.csv(file.choose())</span><br><span class="line">Test &lt;- read.csv(file.choose())</span><br><span class="line"><span class="comment"># there are various options associated with SVM training; like changing kernel, gamma and C value.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># create model</span></span><br><span class="line">model &lt;- svm(Target~Predictor1+Predictor2+Predictor3,data=Train,kernel=<span class="string">'linear'</span>,gamma=<span class="number">0.2</span>,cost=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">preds &lt;- predict(model,Test)</span><br><span class="line">table(preds)</span><br><span class="line"></span><br><span class="line">链接：https://www.zhihu.com/question/<span class="number">21094489</span>/answer/<span class="number">392090279</span></span><br></pre></td></tr></table></figure><p>具体参考：<a href="https://www.datacamp.com/community/tutorials/support-vector-machines-r" target="_blank" rel="noopener">https://www.datacamp.com/community/tutorials/support-vector-machines-r</a></p><p><strong>Python中实现SVM</strong></p><p>Python中可以借助scikit-learn库，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Import Library</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="comment">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span></span><br><span class="line"><span class="comment"># Create SVM classification object </span></span><br><span class="line">model = svm.svc(kernel=<span class="string">'linear'</span>, c=<span class="number">1</span>, gamma=<span class="number">1</span>) </span><br><span class="line"><span class="comment"># there is various option associated with it, like changing kernel, gamma and C value. Will discuss more # about it in next section.Train the model using the training sets and check score</span></span><br><span class="line">model.fit(X, y)</span><br><span class="line">model.score(X, y)</span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= model.predict(x_test)</span><br><span class="line"></span><br><span class="line">链接：https://www.zhihu.com/question/<span class="number">21094489</span>/answer/<span class="number">392090279</span></span><br></pre></td></tr></table></figure><p><strong>参考资料</strong></p><ul><li><p><a href="https://www.youtube.com/watch?v=Qc5IyLW_hns&amp;list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&amp;index=51" target="_blank" rel="noopener">Statquest有关SVM视频</a></p></li><li><p><a href="https://www.datacamp.com/community/tutorials/support-vector-machines-r" target="_blank" rel="noopener">Support Vector Machines in R</a></p></li><li><p><a href="https://www.zhihu.com/question/21094489" target="_blank" rel="noopener">支持向量机(SVM)是什么意思</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/31886934" target="_blank" rel="noopener">支持向量机（SVM）——原理篇</a></p></li><li><p><a href="https://www.r-bloggers.com/machine-learning-using-support-vector-machines/" target="_blank" rel="noopener">Machine Learning Using Support Vector Machines</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习在生物医学中的应用</title>
      <link href="/2020/04/18/43215.html"/>
      <url>/2020/04/18/43215.html</url>
      
        <content type="html"><![CDATA[<p><strong>文章信息</strong></p><p>题目：How Machine Learning Will Transform Biomedicine</p><p>杂志：Cell</p><p>时间：April 2,2020</p><p>链接: <a href="https://doi.org/10.1016/j.cell.2020.03.022" target="_blank" rel="noopener">https://doi.org/10.1016/j.cell.2020.03.022</a></p><p><img src="/2020/04/18/43215/fig1.png" style="zoom:50%;"></p><a id="more"></a><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>机器学习在语音识别，自动化驾驶汽车，生物医学等领域展现了巨大的潜在应用。机器学习将如何影响生物医学？这篇综述从机器学习对临床诊断、精准治疗和健康监管3个方面进行讨论。介绍了机器学习在这3个领域成功应用的例子，以及面临的机遇和挑战。此外也对机器学习的基本概念有简单的概述。</p><p><strong>机器学习中的基本概念</strong></p><ul><li><p><strong>监督学习、非监督学习和半监督学习</strong></p><p>监督学习在预测数据时是基于含有标签的过去数据；非监督学习是对没有标签数据进行分析学习，如聚类等；半监督学习首先执行无监督学习，然后从无监督学习中基于认为标记发现结构</p></li><li><p><strong>分类和回归</strong></p><p>都是监督学习的方法，分类是预测离散的类别，如正常与患病；而回归预测实际值的输出，如对治疗的反应</p></li><li><p><strong>集成学习</strong></p><p>集成方法建立了许多模型，并使用所有模型的平均值生成预测。常见的集成方法包括随机森林、梯度增强和叠加/元集成</p></li><li><p><strong>深度学习</strong></p><p>能够学习复杂非线性函数的多层人工神经网络。对于非结构化数据（如图像、语音或文本）非常有用，但通常不提供驱动函数的数据方面的细节</p></li><li><p><strong>贝叶斯学习</strong></p><p>结合先验知识和数据来执行机器学习的方法</p></li><li><p><strong>降维</strong></p><p>通过选择重要特征或组合特征来捕获数据集中的差异，减少数据集的属性或特征数。通常用于提高机器学习模型的性能和帮助可视化</p></li><li><p><strong>联合学习</strong></p><p>从分布在多个位置且不能组合成单个数据集的数据中增量学习的方法。当数据位于多个临床系统中或从敏感的个人数据中学习时，联合学习非常有用</p></li></ul><p><img src="/2020/04/18/43215/fig2.png" style="zoom:50%;"></p><p><strong>机器学习在诊断和治疗中应用例子</strong></p><ul><li><p>The genomic and transcriptomic architecture of 2,000 breast tumours reveals novel subgroups</p><blockquote><p><a href="https://www.nature.com/articles/nature10983" target="_blank" rel="noopener">https://www.nature.com/articles/nature10983</a></p></blockquote></li><li><p>DeepCC: a novel deep learning-based framework for cancer molecular subtype classification</p><blockquote><p><a href="https://www.nature.com/articles/s41389-019-0157-8" target="_blank" rel="noopener">https://www.nature.com/articles/s41389-019-0157-8</a> </p></blockquote></li><li><p>Predicting drug response of tumors from integrated genomic profiles by deep neural networks</p><blockquote><p><a href="https://www.ncbi.nlm.nih.gov/pubmed/30704458" target="_blank" rel="noopener">https://www.ncbi.nlm.nih.gov/pubmed/30704458</a></p></blockquote></li><li><p>A community effort to assess and improve drug sensitivity prediction algorithms</p><blockquote><p><a href="https://www.nature.com/articles/nbt.2877" target="_blank" rel="noopener">https://www.nature.com/articles/nbt.2877</a></p></blockquote></li><li><p>A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: a systematic review and meta-analysis</p><blockquote><p><a href="https://www.thelancet.com/journals/landig/article/PIIS2589-7500(19)30123-2/fulltext" target="_blank" rel="noopener">https://www.thelancet.com/journals/landig/article/PIIS2589-7500(19)30123-2/fulltext</a></p></blockquote></li><li><p>Prediction of gestational diabetes based on nationwide electronic health records</p><blockquote><p><a href="https://www.ncbi.nlm.nih.gov/pubmed/31932807" target="_blank" rel="noopener">https://www.ncbi.nlm.nih.gov/pubmed/31932807</a></p></blockquote></li><li><p>Privacy-Preserving Patient Similarity Learning in a Federated Environment: Development and Analysis</p><blockquote><p><a href="https://www.ncbi.nlm.nih.gov/pubmed/29653917" target="_blank" rel="noopener">https://www.ncbi.nlm.nih.gov/pubmed/29653917</a></p></blockquote></li><li><p>Smartwatch Algorithm for Automated Detection of Atrial Fibrillation</p><blockquote><p><a href="https://www.sciencedirect.com/science/article/pii/S0735109718334867?via%3Dihub" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/pii/S0735109718334867?via%3Dihub</a></p></blockquote></li><li><p>Contactless cardiac arrest detection using smart devices</p><blockquote><p><a href="https://www.nature.com/articles/s41746-019-0128-7" target="_blank" rel="noopener">https://www.nature.com/articles/s41746-019-0128-7</a></p></blockquote></li></ul><p><img src="/2020/04/18/43215/fig3.png" style="zoom:50%;"></p><p>### </p>]]></content>
      
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>接纳自己的不完美</title>
      <link href="/2020/04/12/28831.html"/>
      <url>/2020/04/12/28831.html</url>
      
        <content type="html"><![CDATA[<p><strong>《心灵捕手 Good Will Hunting 》（1997）</strong></p><p><img src="/2020/04/12/28831/心灵捕手.png" style="zoom:50%;"></p><p><strong>豆瓣剧情简介</strong></p><blockquote><p>麻省理工学院的数学教授蓝波在席上公布了一道困难的数学题，却被年轻的清洁工威尔（马特·戴蒙 饰）解了出来。可是威尔却是个问题少年，成天和好朋友查克（本·阿弗莱特 饰）等人四处闲逛，打架滋事。当蓝波找到这个天才的时候，他正因为打架袭警被法庭宣判送进看守所。蓝波向法官求情保释，才使他免于牢狱之灾。蓝波为了让威尔找到自己的人生目标，不浪费他的数学天赋，请了很多心理学专家为威尔做辅导，但是威尔十分抗拒，专家们都束手无策。无计可施之下，蓝波求助于他大学的好友，心理学教授尚恩（罗宾·威廉姆斯 饰），希望能够帮助威尔打开心房。经过蓝波和尚恩的不懈努力，威尔渐渐敞开心胸，而好友查克的一席话，更是让他豁然开朗。</p></blockquote><p>这部电影从表面上可以归类为心里咨询与教育的影片，我更喜欢这部电影映射出的人与人之间相处与交流的原则：彼此坦诚，才可以赢得信任，进而走进对方的内心。以及每个人应该学会与内心的自己相处，正面认识自己，接纳自己的不完美。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 影评 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于微生物组学数据的深度表征学习预测疾病</title>
      <link href="/2020/04/12/34330.html"/>
      <url>/2020/04/12/34330.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>深度表征学习在疾病预测中的应用</p><p><strong>文章信息</strong></p><p>题目：DeepMicro: deep representation learning for disease prediction based on microbiome data</p><p>杂志：Scientific Reports</p><p>时间：7 April, 2020</p><p>链接: <a href="https://www.nature.com/articles/s41598-020-63159-5" target="_blank" rel="noopener">https://www.nature.com/articles/s41598-020-63159-5</a></p><p><strong>figure</strong></p><p><img src="/2020/04/12/34330/fig1.png" style="zoom:50%;"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>微生物组学数据在人类健康和疾病领域中扮演着重要的作用，然而，微生物组学数据的高纬性，以及样本量低等特点使基于机器学习的预测算法面临极大的挑战。这篇文章基于深度表征学习框架，提出了DeepMicro的方法，可使用各种自动编码器成功的将高维数据转换为低维表示，加快了模型训练和超参数优化过程，在基本方法的基础上提高了8-30倍。在5个不同的数据集上的测试显示DeepMicro在疾病预测方面潜在应用。</p><p>DeepMicro的实现环境和使用的工具包有：</p><ul><li>Python 3.5.2</li><li>Numpy 1.16.2, </li><li>Pandas 0.24.2, </li><li>Scipy 1.2.1, </li><li>Scikt-learn 0.20.3, </li><li>Keras 2.2.4</li><li>Tensorflow 1.13.1</li></ul><p>代码：<a href="https://github.com/minoh0201/DeepMicro" target="_blank" rel="noopener">https://github.com/minoh0201/DeepMicro</a></p><blockquote><p><strong>表征学习（representation learning）</strong></p><p>机器学习算法的成功与否不仅仅取决于算法本身，也取决于数据的表示。数据的不同表示可能会导致有效信息的隐藏或是曝露，这也决定了算法是不是能直截了当地解决问题。表征学习的目的是对复杂的原始数据化繁为简，把原始数据的无效信息剔除，把有效信息更有效地进行提炼，形成特征，这也应和了机器学习的一大任务——可解释性。 也正是因为特征的有效提取，使得今后的机器学习任务简单并且精确许多。在我们接触机器学习、深度学习之初，我们就知道有一类任务也是提炼数据的，那就是特征工程。与表征学习不同的是，特征工程是人为地处理数据，也是我们常听的“洗数据”。 而表示学习是借助算法让机器自动地学习有用的数据和其特征。 不过这两个思路都在尝试解决机器学习的一个主要问题——如何更合理高效地将特征表示出来。</p><p>链接：<a href="https://www.zhihu.com/question/37162929" target="_blank" rel="noopener">https://www.zhihu.com/question/37162929</a><br>来源：知乎</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>提取fastq文件中的序列信息</title>
      <link href="/2020/03/30/9271.html"/>
      <url>/2020/03/30/9271.html</url>
      
        <content type="html"><![CDATA[<h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><p>提取fastq文件中的序列信息，并输出为一行</p><p><img src="/2020/03/30/9271/fg1.png" style="zoom:50%;"></p><h3 id="方法一：paste-cut实现"><a href="#方法一：paste-cut实现" class="headerlink" title="方法一：paste + cut实现"></a>方法一：paste + cut实现</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">head CH2500.fq | paste - - - - | cut -f 2 | paste -d '' -s</span><br></pre></td></tr></table></figure><p><img src="/2020/03/30/9271/fg2.png" alt></p><ul><li><code>paste - - - -</code> 将fastq的每4行转化为列，并以空格分割；<code></code>cut -f 2<code>提取第二列信息，即之前的第二行信息，序列信息，然后再利用paste ，</code>-d<code>指定分隔符为无，</code>-s` 合并为一行信息</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> shell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>肿瘤免疫治疗研究的平台——TIDE</title>
      <link href="/2020/02/29/5071.html"/>
      <url>/2020/02/29/5071.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>利用公共数据模拟免疫疗法的效应和耐药性</p><p><strong>文章信息</strong></p><p>题目：Large-scale public data reuse to model immunotherapy response and resistance                           </p><p>杂志：Genome Medicine</p><p>时间：26 February,2020</p><p>链接: <a href="https://doi.org/10.1186/s13073-020-0721-z" target="_blank" rel="noopener">https://doi.org/10.1186/s13073-020-0721-z</a>                       </p><p><strong>figure</strong></p><p><img src="/2020/02/29/5071/resize,w_1500-20200229224559989.png" alt="image.png"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>这是刘小乐老师实验室开发的一个网络平台——TIDE(<a href="http://tide.dfci.harvard.edu/login/" target="_blank" rel="noopener">http://tide.dfci.harvard.edu/login/</a>) （很好奇为什么命名为TIDE，而且网站图标也是来自<a href="https://mall.jd.com/index-1000001829.html" target="_blank" rel="noopener">汰渍</a>），用于推断调节肿瘤免疫的基因的功能，并评估预测免疫检查点抑制剂(immune checkpoint blockade,ICB)临床反应的标记物。</p><p>他们共处理了12项公开发表的ICB临床研究中的998例肿瘤的组学数据，以及8个已发表的用于鉴定参与调节淋巴细胞介导的肿瘤杀伤和免疫治疗的基因CRISPR筛选研究。其中ICB队列的临床数据共有188个肿瘤队列中的33000个样本，这些样本主要来自TCGA,METABRIC和PRECOG数据库，以及实验室内部数据。该网络平台的功能包括3个交互分析模块：将与肿瘤免疫逃逸相关的标记物进行排序，生成假设；然后通过AUC score 和生存曲线对标记物评估；最后根据标记物对患者分类。</p><p>对肿瘤免疫感兴趣的同学可以仔细研究下文章是如何整合公共数据的，以及利用该平台为课题提供一些新思路。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>综述|深度学习框架、应用和发展趋向</title>
      <link href="/2020/02/15/57384.html"/>
      <url>/2020/02/15/57384.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>深度学习框架、应用和发展趋向</p><p><strong>文章信息</strong></p><p>题目：A Review of Deep Learning with Special Emphasis on Architectures, Applications and Recent Trends</p><p>杂志：Knowledge-Based Systems</p><p>时间：6 February 2020</p><p>链接: <a href="https://doi.org/10.1016/j.knosys.2020.105596" target="_blank" rel="noopener">https://doi.org/10.1016/j.knosys.2020.105596</a></p><p><strong>figure</strong></p><p><img src="/2020/02/15/57384/fig1.png" alt></p><p><strong>文章介绍：</strong></p><p>随着公众对深度学习有效性的认识不断提高，利用深度学习解决不同实际问题的愿望也在增加。但是，即使是对专业人员来说，接触该领域所产生的迅速增长的知识体系也是令人望而生畏的。从哪里开始？如何确定特定的深度学习模型是否适用于他们的问题？如何训练和部署这样一个网络？</p><p>这篇综述对组成深度学习的一些关键的多层人工神经网络进行了概述；同时讨论了一些使用多代理方法的自动架构优化方案；此外，由于保证系统的正常运行时间对许多计算机应用来说是至关重要的，我们将介绍如何使用神经网络进行故障检测和随后的缓解；并且对深度学习在不不同领域的应用进行了讨论。</p><p>这篇综述可以作为想涉及深度学习领域的初学者的一篇参考读物。</p>]]></content>
      
      
      
        <tags>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>细菌生物信息资源数据库——PATRIC</title>
      <link href="/2020/02/08/2243.html"/>
      <url>/2020/02/08/2243.html</url>
      
        <content type="html"><![CDATA[<p>PATRIC <a href="https://www.patricbrc.org/" target="_blank" rel="noopener">https://www.patricbrc.org/</a> ：即病理系统资源整合中心，提供了集成的数据资源和分析工具，以支持有关细菌感染性疾病的生物医学研究。</p><blockquote><p><strong>PATRIC</strong>, the Pathosystems Resource Integration Center, provides integrated data and analysis tools to support biomedical research on bacterial infectious diseases.</p></blockquote><p>下面是该网站主页，主要包含3个模块：</p><ul><li>第一个是搜索模块，可以对细菌、古细菌、噬菌体以及真核宿主进行搜索，数据包括基因组、基因、转录组实验、分类学等信息；</li><li>第二个是数据分析模块，可以进行基因组组装、注释、RNA-seq、代谢组的分析等</li><li>第三个是多组学数据资源，如AMR数据，基因组数据，蛋白质家族，特殊基因等数据资源</li></ul><a id="more"></a><p><img src="/2020/02/08/2243/fig1.png" alt></p>]]></content>
      
      
      
        <tags>
            
            <tag> AMR </tag>
            
            <tag> database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>类器官和ATAC-seq技术结合研究人前脑发育图谱</title>
      <link href="/2020/02/08/548.html"/>
      <url>/2020/02/08/548.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>人类前脑发育的染色质可及性动态图谱</p><p><strong>文章信息</strong></p><p>题目：Chromatin accessibility dynamics in a model of human forebrain development                                </p><p>杂志：Science</p><p>时间：24 January 2020</p><p>链接: <a href="http://dx.doi" target="_blank" rel="noopener">http://dx.doi</a>. org/10.1126/ science.aay1645</p><p><strong>figure</strong></p><p><img src="/2020/02/08/548/fig1.png" style="zoom:50%;"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>人类前脑发育在很大程度上是细胞水平研究、直接功能研究或操纵所无法达到的。缺乏初级脑组织样本，特别是在后期，以及传统的体外细胞模型的局限性，阻碍了对健康和疾病状态下皮质激素生成的详细机制性理解。而文中利用干细胞3D定向分化技术形成背侧和腹侧的前脑干细胞作为原始研究组织，更加接近体内真实的发育情况，然后利用ATAC-seq和RNA测序技术绘制了体外20多个月的神经元和胶质细胞系的发育图谱。并对增强子和基因的相互作用，以及每个发育时期特异的转录调控因子进行了探究。然后他们利用这个资源绘制了与精神分裂症和自闭症谱系失调相关的基因和遗传变异图，以区分染色质可及性模式，从而揭示细胞类型和易感期。最后，他们鉴定到在皮质神经发生过程中染色质重构的现象，在此期间四分之一的调节区域是活跃的，并推测这些转录因子可能驱动这些发育变化。</p><p><img src="/2020/02/08/548/fig2.png" style="zoom:50%;"></p><p>关于脑神经发育过程中染色质可及性图谱的文章已有人发表过，这篇文章仍然能发到Science上，借助了一项重要的实验技术——对干细胞进行重编程然后进行3D培养形成人脑的类器官。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> ATACseq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>构建基因调控网络的新算法</title>
      <link href="/2020/01/04/18319.html"/>
      <url>/2020/01/04/18319.html</url>
      
        <content type="html"><![CDATA[<p>基因表达数据被广泛用于推测基因调控网络（Gene regulatory networks, GRNs）。单细胞RNAseq数据包含单个细胞的表达信息，非常有利于调控机制的研究。但是，目前从大量的表达数据中明确转录调控机制仍然面临挑战，而且，重构后的调控网络可能无法捕获主要的调控规则。</p><p>这篇文章提出了一个新的方法——TENET：从scRNAseq数据中通过<strong>传递熵（transfer entropy, TE)</strong> 计算基因间的因果关系，从而构建GRNs<strong>。</strong>他们的结果发现已知的靶基因具有显著高的TE值，且TE值越高的基因受各种干扰的影响越大。与其他方法相比，他们的结果表明TENET优于其他GRN预测算法。还有一个重要的性能是该方法可以鉴定关键的调控因子。将TENET应用于胚胎干细胞向神经细胞分化过程中的scRNAseq数据，他们发现Nme2是2i条件下特异性干细胞自我更新的关键因子。</p><p><img src="/2020/01/04/18319/fig-.png"></p><a id="more"></a><p><strong>一句话评价</strong></p><p>构建基因调控网络的新算法</p><p><strong>文章信息</strong></p><p>题目：Gene network reconstruction using single cell transcriptomic</p><p>data reveals key factors for embryonic stem cell differentiation</p><p>杂志：bioRxiv</p><p>时间：Dec. 21, 2019</p><p>链接: <a href="https://www.biorxiv.org/content/10.1101/2019.12.20.884163v1" target="_blank" rel="noopener">https://www.biorxiv.org/content/10.1101/2019.12.20.884163v1</a></p><blockquote><p>有点遗憾，如果半年前自己上点心的话，可能就能深入这个方向的研究了</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> scRNA-seq </tag>
            
            <tag> regulation network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用多组学数据预测药物组合的驱动网络标记物</title>
      <link href="/2019/12/29/35922.html"/>
      <url>/2019/12/29/35922.html</url>
      
        <content type="html"><![CDATA[<p><strong>文章介绍：</strong></p><p>药物组合不仅可能同时抑制多种肿瘤的驱动信号通路，而且有可能减少药物抵抗性。这篇文章介绍了一个利用多组学数据开发的工具——<strong>DrugComboExplorer</strong>，鉴定药物组合的驱动信号通路，并预测药物组合的协同作用。</p><p>该工具通过处理来自单个癌症患者的DNA测序、基因拷贝数、DNA甲基化和RNA序列数据，使用整合的算法（包括bootstrap aggregating-based Markov random field，WGCNA,监督调控网络学习）流程产生驱动信号网络。</p><p>DrugComboExplorer is available at <a href="https://github.com/Roosevelt-" target="_blank" rel="noopener">https://github.com/Roosevelt-</a> PKU/drugcombinationprediction.</p><p><strong>figure</strong></p><p><img src="/2019/12/29/35922/fig.png" style="zoom:50%;"></p><a id="more"></a><p><strong>文章信息</strong></p><p>题目：Driver network as a biomarker: systematic integration and network modeling of multi-omics data to derive driver signaling pathways for drug combination prediction</p><p>杂志：Bioinformatics,</p><p>时间：15 February 2019</p><p>链接: doi: 10.1093/bioinformatics/btz109</p><blockquote><p>每日文献摘要：第27篇  2019年12月29日 周日</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用全基因组组织表达谱预测疾病相关lncRNA</title>
      <link href="/2019/12/29/55090.html"/>
      <url>/2019/12/29/55090.html</url>
      
        <content type="html"><![CDATA[<p><strong>文章介绍：</strong></p><p>基于机器学习的方法——<strong>DislncRF</strong>，根据组织表达谱从全基因组范围预测疾病相关的lncRNA。<strong>DislncRF</strong>是基于随机森林模型训练已知的与疾病相关的蛋白编码基因（protein-coding genes ，PCGs），从而提取疾病与表达谱的一般模式，然后应用到lncRNA与疾病的关联中，</p><p>代码：<a href="https://github.com/xypan1232/DislncRF" target="_blank" rel="noopener">https://github.com/xypan1232/DislncRF</a></p><p><strong>figure</strong></p><p><img src="/2019/12/29/55090/fig1.png" style="zoom:50%;"></p><a id="more"></a><p><strong>文章信息</strong></p><p>题目：Inferring disease-associated long non-coding RNAs using genome-wide tissue expression profiles</p><p>杂志：Bioinformatics</p><p>时间：2018</p><p>链接: doi.10.1093/bioinformatics/xxxxxx</p><p><strong>碎碎念</strong></p><p>利用蛋白编码基因与疾病的模式训练模型，然后预测lncRNA与疾病的关联，这样选训练集可靠吗？</p><blockquote><p>每日文献摘要：第28篇  2019年12月29日 周日</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> machine learning </tag>
            
            <tag> lncRNA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用多组学数据重构调控网络</title>
      <link href="/2019/12/29/54913.html"/>
      <url>/2019/12/29/54913.html</url>
      
        <content type="html"><![CDATA[<p><strong>文章介绍：</strong></p><p>随着测序技术的发展，生命组学数据和医学数据爆炸式增长，单一组学指标并不能够充分反映疾病或正常的生命发育机制，结合多组学从不同层面揭示调控机制将有助于我们更精确的认识生命过程和疾病病因。这篇综述使用<strong>state-of-the-art techniques</strong>方法概括了调控网络重构的方法，为挖掘多组学数据（基因组、转录组、蛋白质组等）和其他生物数据背后的意义提供了参考。</p><p><strong>figure</strong></p><p>数据整合策略：</p><p><img src="/2019/12/29/54913/fig2.png" style="zoom:50%;"></p><a id="more"></a><p>数据整合方法：</p><p><img src="/2019/12/29/54913/fig1.png" style="zoom:50%;"></p><p><strong>文章信息</strong></p><p>题目：Integrative approaches to reconstruct regulatory networks from multi-omics data: A review of state-of-the-art methods</p><p>杂志：Computational Biology and Chemistry</p><p>时间：August, 2019</p><p>链接: <a href="https://doi.org/10.1016/j.compbiolchem.2019.107120" target="_blank" rel="noopener">https://doi.org/10.1016/j.compbiolchem.2019.107120</a></p><p>每日文献摘要：第29篇  2019年12月29日 周日</p>]]></content>
      
      
      
        <tags>
            
            <tag> multi-omics </tag>
            
            <tag> regulation network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习在遗传变异和表观调控中的应用</title>
      <link href="/2019/12/29/48019.html"/>
      <url>/2019/12/29/48019.html</url>
      
        <content type="html"><![CDATA[<p><strong>文章介绍：</strong></p><p>利用深度学习卷积神经网络的方法，以表观数据和基因组遗产数据作为参考，训练模型，预测遗传变异的影响。</p><p><strong>figure</strong></p><p><img src="/2019/12/29/48019/fig1.png" style="zoom:33%;"></p><a id="more"></a><p><strong>文章信息</strong></p><p>题目：Functional interpretation of genetic variants using deep learning predicts impact on chromatin accessibility and histone modification</p><p>杂志：<em>Nucleic Acids Research</em></p><p>时间：2019</p><p>链接: <em>doi: 10.1093/nar/gkz808</em></p><p>每日文献摘要：第30篇  2019年12月30日 周日</p>]]></content>
      
      
      
        <tags>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>非编码RNA数据库</title>
      <link href="/2019/12/29/39314.html"/>
      <url>/2019/12/29/39314.html</url>
      
        <content type="html"><![CDATA[<p><strong>文章介绍：</strong></p><p><strong>RNAcentral</strong>是一个综合的非编码RNA数据库，包括大量物种所有类型的<strong>非编码RNA序列信息</strong>，同时整合了28个数据库，可以搜索比较不同数据库ncRNA序列信息，也可以与数据库比对检索序列与ncRNA序列的相似性，也可以通过Genome browser可视化ncRNA在基因组区域的注释信息，所有数据可以下载。</p><p>数据库网址：<strong><a href="https://rnacentral.org" target="_blank" rel="noopener">https://rnacentral.org</a></strong></p><p><strong>figure</strong></p><p><img src="/2019/12/29/39314/fig1.png" style="zoom:50%;"></p><p><img src="/2019/12/29/39314/fig2.png" style="zoom:50%;"></p><a id="more"></a><p><strong>文章信息</strong></p><p>题目：RNAcentral: a hub of information for non-coding RNA sequences</p><p>杂志：<em>Nucleic Acids Research,</em></p><p>时间：November, 2019</p><p>链接: <em>doi: 10.1093/nar/gky1034</em></p><blockquote><p>每日文献摘要：第31篇  2019年12月29日 周日</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> lncRNA </tag>
            
            <tag> database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>单细胞分析相关R包汇总</title>
      <link href="/2019/12/29/16231.html"/>
      <url>/2019/12/29/16231.html</url>
      
        <content type="html"><![CDATA[<p><strong>文章介绍：</strong></p><p>Bioconductor是一个针对生物数据分析的以R语言开发的开源软件库，从2001年项目开始至今，提供了很多优秀的分析流程，如bulk-RNA-seq的分析流程，文档非常详细。如今出手整理了单细胞分析的流程，包括软件安装、数据导入、单细胞数据储存、格式转换为下游分析的数据、下游分析、可视化等，非常详细，另外他们提供了<strong>在线book：<a href="https://osca.bioconductor" target="_blank" rel="noopener">https://osca.bioconductor</a> </strong>.，想上手学习单细胞分析的以本书作为一个入门是一个不错的选择。</p><p><strong>figure</strong></p><p><img src="/2019/12/29/16231/fig1.png" style="zoom:50%;"></p><a id="more"></a><p><strong>文章信息</strong></p><p>题目：Orchestrating single-cell analysis with Bioconductor</p><p>杂志：Nature Methods</p><p>时间：02, December, 2019</p><p>链接: <a href="https://www.nature.com/articles/s41592-019-0654-x" target="_blank" rel="noopener">https://www.nature.com/articles/s41592-019-0654-x</a></p><blockquote><p>每日文献摘要：第32篇  2019年12月29日 周日</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> software </tag>
            
            <tag> single cell </tag>
            
            <tag> R </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习在药物基因组学中的学习和数据资源</title>
      <link href="/2019/12/29/24700.html"/>
      <url>/2019/12/29/24700.html</url>
      
        <content type="html"><![CDATA[<p><strong>文章介绍：</strong></p><p>这篇综述介绍了深度学习的基本模型和典型模型架构，同时总结了深度学习（DL）在肿瘤和肿瘤亚型鉴定的应用（即病人的诊断和分诊治疗），在药物对个体的效应和协同作用的预测，以及在机制、治疗研究中药物的发现和定位的应用。他们整合了基因组学数据和药物基因组数据资源，如 TCGA, ICGC等药物数据库，以及P a DEL药物数据库等。系统地描绘了深度学习在肿瘤药物基因组学中应用。</p><p><strong>figure</strong></p><p><img src="/2019/12/29/24700/fig2.png" style="zoom:50%;"></p><a id="more"></a><p><img src="/2019/12/29/24700/fig1.png" style="zoom:50%;"></p><p><strong>文章信息</strong></p><p>题目：Deep learning of pharmacogenomics resources: moving towards precision oncology</p><p>杂志：Briefings in Bioinformatics</p><p>时间：2019</p><p>链接: doi: 10.1093/bib/bbz144</p><blockquote><p>每日文献摘要：第33篇  2019年12月29日 周日</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>新的降维可视化方法</title>
      <link href="/2019/12/29/60502.html"/>
      <url>/2019/12/29/60502.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p><strong>新的高维数据结构和模式的可视化方法——PHATE</strong></p><p><strong>文章信息</strong></p><p>题目：Visualizing structure and transitions in high-dimensional biological data</p><p>杂志：Nature biotechnology</p><p>时间：3 December,2019</p><p>链接: <a href="https://www.nature.com/articles/s41587-019-0336-3" target="_blank" rel="noopener">https://www.nature.com/articles/s41587-019-0336-3</a></p><p><strong>figure</strong></p><p><img src="/2019/12/29/60502/0-20191228212010064.png" style="zoom: 33%;"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>这篇文章提出常见的降维方法如PCA, t-SNE等方法存在对噪音敏感（PCA, Isomap)、扰乱数据结构(t-SNE)、没有为二维可视化优化（PCA &amp; diffusion maps)，计算资源消耗大、依赖于先验知识等不足，他们提出了一种利用数据点之间的信息几何距离(information-geometric distance)同时捕捉局部和全局的非线性结构的可视化方法——PHATE(potential of heat diffusion for affinity-based transition embedding)。与其他常见的降维方法相比，该方法能够更好的保持数据中的一系列结构模式，包括连续的发展进程、分支结构、簇的结构（clusters）。此外，他们定义了一个叫DEMaP的度量，可以更好的去噪。他们在实际数据中验证了该方法的有效性，并且可用于质谱数据、单细胞数据、Hi-C数据、肠道微生物等多种数据类型。</p><blockquote><p>每日文献摘要：第26篇 2019年12月29日 周日</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> software </tag>
            
            <tag> 降维 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>单细胞RNA-seq分析流程的系统评估</title>
      <link href="/2019/12/28/58882.html"/>
      <url>/2019/12/28/58882.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>scRNA-seq分析流程大比拼</p><p><strong>文章信息</strong></p><p>题目：A systematic evaluation of single cell RNA-seq analysis pipelines</p><p>杂志：Nature Communication</p><p>时间：11, October, 2019</p><p>链接: <a href="https://doi.org/10.1038/s41467-019-12266-7" target="_blank" rel="noopener">https://doi.org/10.1038/s41467-019-12266-7</a></p><p><strong>figure</strong></p><p><img src="/2019/12/28/58882/fig1.png" style="zoom: 33%;"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>单细胞RNA-seq是单细胞领域较为成熟的技术，相关的实验方法和计算方法也不断被开发，面临着越来越多的方法和工具，如何选择合适的最佳流程呢？这篇文章从单细胞建库方法，比对、imputation、标准化和差异方法共评估约3000个组合流程。评价结果可以作为选择最佳分析流程的一个参考，不过所谓的最佳流程并不是以一概全指某个特定流程，而是要根据实际研究目的，选择合适的实验方法和分析方法。</p><p>另外还可以参考前不久发表的单细胞RNA-seq最佳分析流程：Current best practices in single‐cell RNA‐seq analysis: a tutorial (<a href="https://doi.org/10.15252/msb.20188746" target="_blank" rel="noopener">https://doi.org/10.15252/msb.20188746</a>)</p><blockquote><p>每日文献摘要：第25篇 2019年12月29日 周日</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> single cell </tag>
            
            <tag> scRNA-seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于R语言绘制坐标轴截断图</title>
      <link href="/2019/12/16/24068.html"/>
      <url>/2019/12/16/24068.html</url>
      
        <content type="html"><![CDATA[<p>画图时经常遇到不同组的数据大小相差很大，大数据就会掩盖小数据的变化规律，这时候可以对Y轴进行截断，从而可以在不同层面（大数据和小数据层面）全面反映数据变化情况，如下图所示。</p><p><img src="/2019/12/16/24068/fig0.png" alt></p><p>搜索截断图绘制的方法，有根据Excel绘制的，但是感觉操作繁琐；这里根据网上资料总结基于R的3种方法：</p><ul><li>分割+组合法，如基于ggplot2, 利用<code>coord_cartesian()</code>将整个图形分割成多个图片,再用grid 包组合分割结果</li><li>plotrix R包</li><li>基本绘图函数+plotrix R包</li></ul><a id="more"></a><h3 id="示例数据"><a href="#示例数据" class="headerlink" title="示例数据"></a>示例数据</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">df &lt;- data.frame(name=c(<span class="string">"AY"</span>,<span class="string">"BY"</span>,<span class="string">"CY"</span>,<span class="string">"DY"</span>,<span class="string">"EY"</span>,<span class="string">"FY"</span>,<span class="string">"GY"</span>),Money=c(<span class="number">1510</span>,<span class="number">1230</span>,<span class="number">995</span>,<span class="number">48</span>,<span class="number">35</span>,<span class="number">28</span>,<span class="number">10</span>))</span><br><span class="line">df</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载 R 包</span></span><br><span class="line"><span class="keyword">library</span>(ggplot2)</span><br><span class="line"><span class="comment"># ggplot画图</span></span><br><span class="line">p0 &lt;- ggplot(df, aes(name,Money,fill = name)) +</span><br><span class="line">  geom_col(position = position_dodge(width = <span class="number">0.8</span>),color=<span class="string">"black"</span>) +</span><br><span class="line">  labs(x = <span class="literal">NULL</span>, y = <span class="literal">NULL</span>) +</span><br><span class="line">  scale_fill_brewer(palette=<span class="string">"Accent"</span>)+</span><br><span class="line">  <span class="comment">#scale_x_discrete(expand = c(0, 0)) +</span></span><br><span class="line">  scale_y_continuous(breaks = seq(<span class="number">0</span>, <span class="number">1600</span>, <span class="number">400</span>), limits = c(<span class="number">0</span>, <span class="number">1600</span>), expand = c(<span class="number">0</span>,<span class="number">0</span>)) +</span><br><span class="line">  theme(axis.text.x = element_text(angle = <span class="number">45</span>, hjust = <span class="number">1</span>), legend.title = element_blank())</span><br></pre></td></tr></table></figure><p><img src="/2019/12/16/24068/fig1.png" alt="fig1" style="zoom:25%;"></p><h3 id="方法一：分割-组合法"><a href="#方法一：分割-组合法" class="headerlink" title="方法一：分割+组合法"></a>方法一：分割+组合法</h3><p>这种方法的思路是分别绘制不同层级大小的图形，然后组合图形。如可一用ggplot2中的<code>coord_cartesian()</code>函数分割，<code>ylim</code>指定y轴的区间范围。</p><blockquote><p>参考：<a href="http://blog.sciencenet.cn/blog-3406804-1156908.html" target="_blank" rel="noopener">http://blog.sciencenet.cn/blog-3406804-1156908.html</a></p></blockquote><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 小数据层级</span></span><br><span class="line">p1 &lt;- p0 + coord_cartesian(ylim = c(<span class="number">0</span>, <span class="number">50</span>)) + </span><br><span class="line">  theme_classic()+</span><br><span class="line">  theme(legend.position=<span class="string">"none"</span>)</span><br><span class="line">  </span><br><span class="line"><span class="comment">### 大数据层级</span></span><br><span class="line"><span class="comment"># 不显示X轴坐标和文本标记</span></span><br><span class="line">p2 &lt;-p0 + coord_cartesian(ylim = c(<span class="number">700</span>, <span class="number">1600</span>)) + </span><br><span class="line">  theme_classic() +</span><br><span class="line">  theme(axis.line.x = element_line(colour=<span class="string">"white"</span>),</span><br><span class="line">        axis.text.x = element_blank(), axis.ticks.x = element_blank(), </span><br><span class="line">        legend.position = c(<span class="number">0.85</span>, <span class="number">0.6</span>))</span><br></pre></td></tr></table></figure><p><code>P1</code></p><p><img src="/2019/12/16/24068/fig2.png" style="zoom: 25%;"></p><p><code>p2</code></p><p><img src="/2019/12/16/24068/fig3.png" style="zoom:25%;"></p><p>grid组合图形, <code>grid.newpage()</code>新建画布, <code>viewport()</code>命令将画板分割为不同的区域。</p><blockquote><p>x和y分别用于指定所放置子图在画板中的坐标，坐标取值范围为0~1，并使用just给定坐标起始位置；width和height用于指定所放置子图在画板中的高度和宽度。</p></blockquote><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(grid)</span><br><span class="line"></span><br><span class="line">grid.newpage() <span class="comment">#新建画布</span></span><br><span class="line">plot_site1 &lt;- viewport(x = <span class="number">0.008</span>, y = <span class="number">0</span>, width = <span class="number">0.994</span>, height = <span class="number">0.4</span>, just = c(<span class="string">'left'</span>, <span class="string">'bottom'</span>))</span><br><span class="line">plot_site2 &lt;- viewport(x = <span class="number">0.008</span>, y = <span class="number">0.4</span>, width = <span class="number">1</span>, height = <span class="number">0.5</span>, just = c(<span class="string">'left'</span>, <span class="string">'bottom'</span>))</span><br><span class="line"><span class="comment">#plot_site3 &lt;- viewport(x = 0, y = 0.7, width = 1, height = 0.3, just = c('left', 'bottom'))</span></span><br><span class="line">print(p1, vp = plot_site1)</span><br><span class="line">print(p2, vp = plot_site2)</span><br></pre></td></tr></table></figure><p><img src="/2019/12/16/24068/fig4.png" style="zoom:50%;"></p><p>这种方法可以得到一个草图，图片对齐等细节调节需要多次尝试，或者可以导出在AI中修改。</p><h3 id="方法二：plotrix-R包"><a href="#方法二：plotrix-R包" class="headerlink" title="方法二：plotrix R包"></a>方法二：plotrix R包</h3><p>plotrix R中包含<code>gap.plot()，gap.barplot() 和 gapboxplot()函数</code>, 可以分别画出坐标轴截断的散点图、柱状图和箱线图。主要参数包括<code>y    ：要截断的数值向量; gap：截断的区间</code>.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 用法如下</span></span><br><span class="line"> gap.barplot(y,gap,xaxlab,xtics,yaxlab,ytics,xlim=<span class="literal">NA</span>,ylim=<span class="literal">NA</span>,xlab=<span class="literal">NULL</span>,</span><br><span class="line">  ylab=<span class="literal">NULL</span>,horiz=<span class="literal">FALSE</span>,col,<span class="keyword">...</span>)</span><br><span class="line"><span class="comment">### Arguments</span></span><br><span class="line">y：要截断的数值向量</span><br><span class="line">gap：截断的区间</span><br><span class="line"></span><br><span class="line">xaxlab：labels <span class="keyword">for</span> the x axis ticks</span><br><span class="line">xtics：position of the x axis ticks</span><br><span class="line">yaxlab：labels <span class="keyword">for</span> the y axis ticks</span><br><span class="line">ytics：position of the y axis ticks</span><br><span class="line">xlim：Optional x limits <span class="keyword">for</span> the plot</span><br><span class="line">ylim：optional y limits <span class="keyword">for</span> the plot</span><br><span class="line">xlab：label <span class="keyword">for</span> the x axis</span><br><span class="line">ylab：label <span class="keyword">for</span> the y axis</span><br><span class="line">horiz：whether to have vertical or horizontal bars</span><br><span class="line">col：color(s) <span class="keyword">in</span> which to plot the values</span><br></pre></td></tr></table></figure><blockquote><p>参考：<a href="http://www.bioon.com.cn/protocol/showarticle.asp?newsid=66061" target="_blank" rel="noopener">http://www.bioon.com.cn/protocol/showarticle.asp?newsid=66061</a></p></blockquote><p>相同的数据，画图如下</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#install.packages ("plotrix")</span></span><br><span class="line"><span class="keyword">library</span> (plotrix)</span><br><span class="line"></span><br><span class="line">gap.barplot(df$Money,gap=c(<span class="number">50</span>,<span class="number">740</span>),xaxlab=df$name,ytics=c(<span class="number">50</span>,<span class="number">700</span>,<span class="number">800</span>,<span class="number">900</span>,<span class="number">1000</span>,<span class="number">1100</span>,<span class="number">1200</span>,<span class="number">1300</span>,<span class="number">1400</span>,<span class="number">1500</span>,<span class="number">1600</span>),</span><br><span class="line">            col=rainbow(<span class="number">7</span>),xlim = c(<span class="number">0</span>,<span class="number">8</span>),width=<span class="number">0.06</span>)</span><br></pre></td></tr></table></figure><p><img src="/2019/12/16/24068/fig5.png" style="zoom:50%;"></p><p>接着使用<code>axis breaks()</code>函数去除中间的两道横线，并添加截断的标记，如<code>//</code>或<code>z</code>。</p><ul><li><code>Axis</code>:1,2,3,4分别代表下、左、上、右方位的坐标轴，即打算截取的坐标轴</li><li><code>breakppos</code>：截断的位置，即截断符号添加的位置</li><li><code>style</code>: gap,slash和z字形</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">axis.break(<span class="number">2</span>,<span class="number">50</span>,breakcol=<span class="string">"snow"</span>,style=<span class="string">"gap"</span>) <span class="comment">##去掉中间的那两道横线；</span></span><br><span class="line">axis.break(<span class="number">2</span>,<span class="number">50</span>*(<span class="number">1</span>+<span class="number">0.02</span>),breakcol=<span class="string">"black"</span>,style=<span class="string">"slash"</span>)<span class="comment">##在左侧Y轴把gap位置换成slash；</span></span><br><span class="line"><span class="comment">#axis.break(4,50*(1+0.02),breakcol="black",style="slash")##在右侧Y轴把gap位置换成slash；</span></span><br></pre></td></tr></table></figure><p><img src="/2019/12/16/24068/fig6.png" style="zoom:50%;"></p><p>这种方法是基于base plot绘图的，但是base plot的许多绘图参数与gap.barplot（）并不兼容，如<code>space和width参数</code>设置离坐标轴距离和bar的宽度。</p><h3 id="方法三：基本绘图函数-plotrix-R包"><a href="#方法三：基本绘图函数-plotrix-R包" class="headerlink" title="方法三：基本绘图函数+plotrix R包"></a>方法三：基本绘图函数+plotrix R包</h3><blockquote><p>参考：<a href="https://blog.csdn.net/u014801157/article/details/24372371" target="_blank" rel="noopener">https://blog.csdn.net/u014801157/article/details/24372371</a></p></blockquote><p>作者ZGUANG@LZU自己编写的函数，可以手动设置断点，也可以由函数自动计算。断点位置的符号表示提供了平行线和zigzag两种，并且可设置背景颜色、大小、线型、平行线旋转角度等。</p><h4 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#' 使用R基本绘图函数绘制y轴不连续的柱形图</span></span><br><span class="line"><span class="comment">#'</span></span><br><span class="line"><span class="comment">#' 绘制y轴不连续的柱形图，具有误差线添加功能。断点位置通过btm和top参数设置，如果不设置，函数可自动计算合适的断点位置。</span></span><br><span class="line"><span class="comment">#' @title gap.barplot function</span></span><br><span class="line"><span class="comment">#' @param df 长格式的data.frame，即数据框中每一列为一组绘图数据。</span></span><br><span class="line"><span class="comment">#' @param y.cols 用做柱形图y值的数据列（序号或名称），一列为一组。</span></span><br><span class="line"><span class="comment">#' @param sd.cols 与y值列顺序对应的误差值的数据列（序号或名称）。</span></span><br><span class="line"><span class="comment">#' @param btm 低位断点。如果btm和top均不设置，程序将自动计算和设置断点位置。</span></span><br><span class="line"><span class="comment">#' @param top 高位断点。</span></span><br><span class="line"><span class="comment">#' @param min.range 自动计算断点的阈值：最大值与最小值的最小比值</span></span><br><span class="line"><span class="comment">#' @param max.fold 自动计算断点时最大值与下方数据最大值的最大倍数比</span></span><br><span class="line"><span class="comment">#' @param ratio 断裂后上部与下部y轴长度的比例。</span></span><br><span class="line"><span class="comment">#' @param gap.width y轴断裂位置的相对物理宽度（非坐标轴实际刻度）</span></span><br><span class="line"><span class="comment">#' @param brk.type 断点类型，可设为normal或zigzag</span></span><br><span class="line"><span class="comment">#' @param brk.bg 断点处的背景颜色</span></span><br><span class="line"><span class="comment">#' @param brk.srt 断点标记线旋转角度</span></span><br><span class="line"><span class="comment">#' @param brk.size 断点标记线的大小（长度）</span></span><br><span class="line"><span class="comment">#' @param brk.col 断点标记线的颜色</span></span><br><span class="line"><span class="comment">#' @param brk.lwd 断点标记线的线宽</span></span><br><span class="line"><span class="comment">#' @param cex.error 误差线相对长度，默认为1</span></span><br><span class="line"><span class="comment">#' @param ... 其他传递给R基本绘图函数barplot的参数</span></span><br><span class="line"><span class="comment">#' @return 返回barplot的原始返回值，即柱形图的x坐标</span></span><br><span class="line"><span class="comment">#' @examples</span></span><br><span class="line"><span class="comment">#' datax &lt;- na.omit(airquality)[,1:4]</span></span><br><span class="line"><span class="comment">#' cols &lt;- cm.colors(ncol(datax))</span></span><br><span class="line"><span class="comment">#' layout(matrix(1:6, ncol=2))</span></span><br><span class="line"><span class="comment">#' set.seed(0)</span></span><br><span class="line"><span class="comment">#' for (ndx in 1:6)&#123;</span></span><br><span class="line"><span class="comment">#'     dt &lt;- datax[sample(rownames(datax), 10), ]</span></span><br><span class="line"><span class="comment">#'     par(mar=c(0.5,2,0.5,0.5))</span></span><br><span class="line"><span class="comment">#'     brkt &lt;- sample(c('normal', 'zigzag'), 1)</span></span><br><span class="line"><span class="comment">#'     gap.barplot(dt, col=cols, brk.type=brkt, max.fold=5, ratio=2)</span></span><br><span class="line"><span class="comment">#' &#125;</span></span><br><span class="line"><span class="comment">#' @author ZG Zhao</span></span><br><span class="line"><span class="comment">#' @export</span></span><br><span class="line">gap.barplot &lt;- <span class="keyword">function</span>(df, y.cols = <span class="number">1</span>:ncol(df), sd.cols = <span class="literal">NULL</span>, btm = <span class="literal">NULL</span>,</span><br><span class="line">                        top = <span class="literal">NULL</span>, min.range = <span class="number">10</span>, max.fold = <span class="number">5</span>, ratio = <span class="number">1</span>, gap.width = <span class="number">1</span>, brk.type = <span class="string">"normal"</span>,</span><br><span class="line">                        brk.bg = <span class="string">"white"</span>, brk.srt = <span class="number">135</span>, brk.size = <span class="number">1</span>, brk.col = <span class="string">"black"</span>, brk.lwd = <span class="number">1</span>,</span><br><span class="line">                        cex.error = <span class="number">1</span>, <span class="keyword">...</span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (missing(df))</span><br><span class="line">    <span class="keyword">stop</span>(<span class="string">"No data provided."</span>)</span><br><span class="line">  <span class="keyword">if</span> (is.numeric(y.cols))</span><br><span class="line">    ycol &lt;- y.cols <span class="keyword">else</span> ycol &lt;- colnames(df) == y.cols</span><br><span class="line">    <span class="keyword">if</span> (!is.null(sd.cols))</span><br><span class="line">      <span class="keyword">if</span> (is.numeric(sd.cols))</span><br><span class="line">        scol &lt;- sd.cols <span class="keyword">else</span> scol &lt;- colnames(df) == sd.cols</span><br><span class="line">        <span class="comment">## Arrange data</span></span><br><span class="line">        opts &lt;- options()</span><br><span class="line">        options(warn = -<span class="number">1</span>)</span><br><span class="line">        y &lt;- t(df[, ycol])</span><br><span class="line">        colnames(y) &lt;- <span class="literal">NULL</span></span><br><span class="line">        <span class="keyword">if</span> (missing(sd.cols))</span><br><span class="line">          sdx &lt;- <span class="number">0</span> <span class="keyword">else</span> sdx &lt;- t(df[, scol])</span><br><span class="line">        sdu &lt;- y + sdx</span><br><span class="line">        sdd &lt;- y - sdx</span><br><span class="line">        ylim &lt;- c(<span class="number">0</span>, max(sdu) * <span class="number">1.05</span>)</span><br><span class="line">        <span class="comment">## 如果没有设置btm或top，自动计算</span></span><br><span class="line">        <span class="keyword">if</span> (is.null(btm) | is.null(top)) &#123;</span><br><span class="line">          autox &lt;- .auto.breaks(dt = sdu, min.range = min.range, max.fold = max.fold)</span><br><span class="line">          <span class="keyword">if</span> (autox$flag) &#123;</span><br><span class="line">            btm &lt;- autox$btm</span><br><span class="line">            top &lt;- autox$top</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            xx &lt;- barplot(y, beside = <span class="literal">TRUE</span>, ylim = ylim, <span class="keyword">...</span>)</span><br><span class="line">            <span class="keyword">if</span> (!missing(sd.cols))</span><br><span class="line">              errorbar(xx, y, sdu - y, horiz = <span class="literal">FALSE</span>, cex = cex.error)</span><br><span class="line">            box()</span><br><span class="line">            <span class="keyword">return</span>(invisible(xx))</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">## Set up virtual y limits</span></span><br><span class="line">        halflen &lt;- btm - ylim[<span class="number">1</span>]</span><br><span class="line">        xlen &lt;- halflen * <span class="number">0.1</span> * gap.width</span><br><span class="line">        v_tps1 &lt;- btm + xlen  <span class="comment"># virtual top positions</span></span><br><span class="line">        v_tps2 &lt;- v_tps1 + halflen * ratio</span><br><span class="line">        v_ylim &lt;- c(ylim[<span class="number">1</span>], v_tps2)</span><br><span class="line">        r_tps1 &lt;- top  <span class="comment"># real top positions</span></span><br><span class="line">        r_tps2 &lt;- ylim[<span class="number">2</span>]</span><br><span class="line">        <span class="comment">## Rescale data</span></span><br><span class="line">        lmx &lt;- summary(lm(c(v_tps1, v_tps2) ~ c(r_tps1, r_tps2)))</span><br><span class="line">        lmx &lt;- lmx$coefficients</span><br><span class="line">        sel1 &lt;- y &gt; top</span><br><span class="line">        sel2 &lt;- y &gt;= btm &amp; y &lt;= top</span><br><span class="line">        y[sel1] &lt;- y[sel1] * lmx[<span class="number">2</span>] + lmx[<span class="number">1</span>]</span><br><span class="line">        y[sel2] &lt;- btm + xlen/<span class="number">2</span></span><br><span class="line">        sel1 &lt;- sdd &gt; top</span><br><span class="line">        sel2 &lt;- sdd &gt;= btm &amp; sdd &lt;= top</span><br><span class="line">        sdd[sel1] &lt;- sdd[sel1] * lmx[<span class="number">2</span>] + lmx[<span class="number">1</span>]</span><br><span class="line">        sdd[sel2] &lt;- btm + xlen/<span class="number">2</span></span><br><span class="line">        sel1 &lt;- sdu &gt; top</span><br><span class="line">        sel2 &lt;- sdu &gt;= btm &amp; sdu &lt;= top</span><br><span class="line">        sdu[sel1] &lt;- sdu[sel1] * lmx[<span class="number">2</span>] + lmx[<span class="number">1</span>]</span><br><span class="line">        sdu[sel2] &lt;- btm + xlen/<span class="number">2</span></span><br><span class="line">        <span class="comment">## bar plot</span></span><br><span class="line">        xx &lt;- barplot(y, beside = <span class="literal">TRUE</span>, ylim = v_ylim, axes = <span class="literal">FALSE</span>, names.arg = <span class="literal">NULL</span>,</span><br><span class="line">                      <span class="keyword">...</span>)</span><br><span class="line">        <span class="comment">## error bars</span></span><br><span class="line">        <span class="keyword">if</span> (!missing(sd.cols))</span><br><span class="line">          errorbar(xx, y, sdu - y, horiz = <span class="literal">FALSE</span>, cex = cex.error)</span><br><span class="line">        <span class="comment">## Real ticks and labels</span></span><br><span class="line">        brks1 &lt;- pretty(seq(<span class="number">0</span>, btm, length = <span class="number">10</span>), n = <span class="number">4</span>)</span><br><span class="line">        brks1 &lt;- brks1[brks1 &gt;= <span class="number">0</span> &amp; brks1 &lt; btm]</span><br><span class="line">        brks2 &lt;- pretty(seq(top, r_tps2, length = <span class="number">10</span>), n = <span class="number">4</span>)</span><br><span class="line">        brks2 &lt;- brks2[brks2 &gt; top &amp; brks2 &lt;= r_tps2]</span><br><span class="line">        labx &lt;- c(brks1, brks2)</span><br><span class="line">        <span class="comment">## Virtual ticks</span></span><br><span class="line">        brks &lt;- c(brks1, brks2 * lmx[<span class="number">2</span>] + lmx[<span class="number">1</span>])</span><br><span class="line">        axis(<span class="number">2</span>, at = brks, labels = labx)</span><br><span class="line">        box()</span><br><span class="line">        <span class="comment">## break marks</span></span><br><span class="line">        pos &lt;- par(<span class="string">"usr"</span>)</span><br><span class="line">        xyratio &lt;- (pos[<span class="number">2</span>] - pos[<span class="number">1</span>])/(pos[<span class="number">4</span>] - pos[<span class="number">3</span>])</span><br><span class="line">        xlen &lt;- (pos[<span class="number">2</span>] - pos[<span class="number">1</span>])/<span class="number">50</span> * brk.size</span><br><span class="line">        px1 &lt;- pos[<span class="number">1</span>] - xlen</span><br><span class="line">        px2 &lt;- pos[<span class="number">1</span>] + xlen</span><br><span class="line">        px3 &lt;- pos[<span class="number">2</span>] - xlen</span><br><span class="line">        px4 &lt;- pos[<span class="number">2</span>] + xlen</span><br><span class="line">        py1 &lt;- btm</span><br><span class="line">        py2 &lt;- v_tps1</span><br><span class="line">        rect(px1, py1, px4, py2, col = brk.bg, xpd = <span class="literal">TRUE</span>, border = brk.bg)</span><br><span class="line">        x1 &lt;- c(px1, px1, px3, px3)</span><br><span class="line">        x2 &lt;- c(px2, px2, px4, px4)</span><br><span class="line">        y1 &lt;- c(py1, py2, py1, py2)</span><br><span class="line">        y2 &lt;- c(py1, py2, py1, py2)</span><br><span class="line">        px &lt;- .xy.adjust(x1, x2, y1, y2, xlen, xyratio, angle = brk.srt * pi/<span class="number">90</span>)</span><br><span class="line">        <span class="keyword">if</span> (brk.type == <span class="string">"zigzag"</span>) &#123;</span><br><span class="line">          x1 &lt;- c(x1, px1, px3)</span><br><span class="line">          x2 &lt;- c(x2, px2, px4)</span><br><span class="line">          <span class="keyword">if</span> (brk.srt &gt; <span class="number">90</span>) &#123;</span><br><span class="line">            y1 &lt;- c(y1, py2, py2)</span><br><span class="line">            y2 &lt;- c(y2, py1, py1)</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            y1 &lt;- c(y1, py1, py1)</span><br><span class="line">            y2 &lt;- c(y2, py2, py2)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (brk.type == <span class="string">"zigzag"</span>) &#123;</span><br><span class="line">          px$x1 &lt;- c(pos[<span class="number">1</span>], px2, px1, pos[<span class="number">2</span>], px4, px3)</span><br><span class="line">          px$x2 &lt;- c(px2, px1, pos[<span class="number">1</span>], px4, px3, pos[<span class="number">2</span>])</span><br><span class="line">          mm &lt;- (v_tps1 - btm)/<span class="number">3</span></span><br><span class="line">          px$y1 &lt;- rep(c(v_tps1, v_tps1 - mm, v_tps1 - <span class="number">2</span> * mm), <span class="number">2</span>)</span><br><span class="line">          px$y2 &lt;- rep(c(v_tps1 - mm, v_tps1 - <span class="number">2</span> * mm, btm), <span class="number">2</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        par(xpd = <span class="literal">TRUE</span>)</span><br><span class="line">        segments(px$x1, px$y1, px$x2, px$y2, lty = <span class="number">1</span>, col = brk.col, lwd = brk.lwd)</span><br><span class="line">        options(opts)</span><br><span class="line">        par(xpd = <span class="literal">FALSE</span>)</span><br><span class="line">        invisible(xx)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">## 绘制误差线的函数</span></span><br><span class="line">errorbar &lt;- <span class="keyword">function</span>(x, y, sd.lwr, sd.upr, horiz = <span class="literal">FALSE</span>, cex = <span class="number">1</span>, <span class="keyword">...</span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (missing(sd.lwr) &amp; missing(sd.upr))</span><br><span class="line">    <span class="keyword">return</span>(<span class="literal">NULL</span>)</span><br><span class="line">  <span class="keyword">if</span> (missing(sd.upr))</span><br><span class="line">    sd.upr &lt;- sd.lwr</span><br><span class="line">  <span class="keyword">if</span> (missing(sd.lwr))</span><br><span class="line">    sd.lwr &lt;- sd.upr</span><br><span class="line">  <span class="keyword">if</span> (!horiz) &#123;</span><br><span class="line">    arrows(x, y, y1 = y - sd.lwr, length = <span class="number">0.1</span> * cex, angle = <span class="number">90</span>, <span class="keyword">...</span>)</span><br><span class="line">    arrows(x, y, y1 = y + sd.upr, length = <span class="number">0.1</span> * cex, angle = <span class="number">90</span>, <span class="keyword">...</span>)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    arrows(y, x, x1 = y - sd.lwr, length = <span class="number">0.1</span> * cex, angle = <span class="number">90</span>, <span class="keyword">...</span>)</span><br><span class="line">    arrows(y, x, x1 = y + sd.upr, length = <span class="number">0.1</span> * cex, angle = <span class="number">90</span>, <span class="keyword">...</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">.xy.adjust &lt;- <span class="keyword">function</span>(x1, x2, y1, y2, xlen, xyratio, angle) &#123;</span><br><span class="line">  xx1 &lt;- x1 - xlen * cos(angle)</span><br><span class="line">  yy1 &lt;- y1 + xlen * sin(angle)/xyratio</span><br><span class="line">  xx2 &lt;- x2 + xlen * cos(angle)</span><br><span class="line">  yy2 &lt;- y2 - xlen * sin(angle)/xyratio</span><br><span class="line">  <span class="keyword">return</span>(list(x1 = xx1, x2 = xx2, y1 = yy1, y2 = yy2))</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">## 自动计算断点位置的函数</span></span><br><span class="line">.auto.breaks &lt;- <span class="keyword">function</span>(dt, min.range, max.fold) &#123;</span><br><span class="line">  datax &lt;- sort(as.vector(dt))</span><br><span class="line">  flags &lt;- <span class="literal">FALSE</span></span><br><span class="line">  btm &lt;- top &lt;- <span class="literal">NULL</span></span><br><span class="line">  <span class="keyword">if</span> (max(datax)/min(datax) &lt; min.range)</span><br><span class="line">    <span class="keyword">return</span>(list(flag = flags, btm = btm, top = top))</span><br><span class="line">  m &lt;- max(datax)</span><br><span class="line">  btm &lt;- datax[<span class="number">2</span>]</span><br><span class="line">  i &lt;- <span class="number">3</span></span><br><span class="line">  <span class="keyword">while</span> (m/datax[i] &gt; max.fold) &#123;</span><br><span class="line">    btm &lt;- datax[i]</span><br><span class="line">    flags &lt;- <span class="literal">TRUE</span></span><br><span class="line">    i &lt;- i + <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (flags) &#123;</span><br><span class="line">    btm &lt;- btm + <span class="number">0.05</span> * btm</span><br><span class="line">    x &lt;- <span class="number">2</span></span><br><span class="line">    top &lt;- datax[i] * (x - <span class="number">1</span>)/x</span><br><span class="line">    <span class="keyword">while</span> (top &lt; btm) &#123;</span><br><span class="line">      x &lt;- x + <span class="number">1</span></span><br><span class="line">      top &lt;- datax[i] * (x - <span class="number">1</span>)/x</span><br><span class="line">      <span class="keyword">if</span> (x &gt; <span class="number">100</span>) &#123;</span><br><span class="line">        flags &lt;- <span class="literal">FALSE</span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span>(list(flag = flags, btm = btm, top = top))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="示例数据-1"><a href="#示例数据-1" class="headerlink" title="示例数据"></a>示例数据</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">datax &lt;- na.omit(airquality)[, <span class="number">1</span>:<span class="number">4</span>]</span><br><span class="line">cols &lt;- terrain.colors(ncol(datax) - <span class="number">1</span>)</span><br><span class="line">layout(matrix(<span class="number">1</span>:<span class="number">4</span>, ncol = <span class="number">2</span>))</span><br><span class="line">set.seed(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> (ndx <span class="keyword">in</span> <span class="number">1</span>:<span class="number">4</span>) &#123;</span><br><span class="line">  dt &lt;- datax[sample(rownames(datax), <span class="number">10</span>), ]</span><br><span class="line">  dt &lt;- cbind(dt, dt[, -<span class="number">1</span>] * <span class="number">0.1</span>)</span><br><span class="line">  par(mar = c(<span class="number">1</span>, <span class="number">3</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))</span><br><span class="line">  brkt &lt;- sample(c(<span class="string">"normal"</span>, <span class="string">"zigzag"</span>), <span class="number">1</span>)</span><br><span class="line">  gap.barplot(dt, y.cols = <span class="number">2</span>:<span class="number">4</span>, sd.cols = <span class="number">5</span>:<span class="number">7</span>, col = cols, brk.type = brkt,</span><br><span class="line">              brk.size = <span class="number">0.6</span>, brk.lwd = <span class="number">2</span>, max.fold = <span class="number">5</span>, ratio = <span class="number">2</span>, cex.error = <span class="number">0.3</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/2019/12/16/24068/fig7.png" style="zoom:50%;"></p><h4 id="实际数据"><a href="#实际数据" class="headerlink" title="实际数据"></a>实际数据</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gap.barplot(df, y.cols = <span class="number">2</span>, brk.type = <span class="string">"normal"</span>,col = rainbow(<span class="number">7</span>),</span><br><span class="line">            brk.size = <span class="number">0.6</span>, brk.lwd = <span class="number">2</span>, max.fold = <span class="number">5</span>, ratio = <span class="number">2</span>, cex.error = <span class="number">0.3</span>)</span><br></pre></td></tr></table></figure><p><img src="/2019/12/16/24068/fig8.png" style="zoom:50%;"></p><p>第3种方法可以直接计算截断值，另外可以添加error bar, 可以修改的细节处更多，而且包装成函数，整个分析时间也加快。</p>]]></content>
      
      
      
        <tags>
            
            <tag> R </tag>
            
            <tag> visualization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习揭示体内肿瘤的转移和抗体靶向治疗效率</title>
      <link href="/2019/12/14/35098.html"/>
      <url>/2019/12/14/35098.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>基于透明化的成像技术和深度学习算法快速、准确检测微量肿瘤细胞的转移</p><p><strong>文章信息</strong></p><p>题目：Deep Learning Reveals Cancer Metastasis and Therapeutic Antibody Targeting in the Entire Body</p><p>杂志：Cell</p><p>时间：December 12, 2019</p><p>链接: <a href="https://doi.org/10.1016/j.cell.2019.11.013" target="_blank" rel="noopener">https://doi.org/10.1016/j.cell.2019.11.013</a></p><p><img src="/2019/12/14/35098/abstarct.jpg" alt></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>肿瘤转移是癌症病人产生治疗抵抗和死亡率升高的一个原因，高效、准确的检测肿瘤的转移具有重要的意义。但是目前技术上有两方面的限制：一是成像技术，可以在体内准确检测所有肿瘤细胞转移的成像技术，二是缺乏对大规模图像数据进行快速、准确定量的算法。这项研究针对这两个瓶颈问题，开发了解决方案。</p><p>成像的原理主要是基于对荧光蛋白的标记，但是由于鼠体内很多组织有高度的自发荧光会干扰对单个肿瘤细胞或者少量细胞群的荧光信号检测。因此，他们采用使小鼠变得透明的<strong>vDISCO技术</strong>，使肿瘤细胞的荧光信号在透明的组织中增强超过100倍，从而既可以检测大规模的转移，也可以准确检测微量的转移。</p><blockquote><p><strong>vDISCO技术</strong>：一种压力驱动、基于纳米体的全身免疫标记技术，可将荧光蛋白的信号增强两个数量级。</p><p><a href="https://www.nature.com/articles/s41593-018-0301-3" target="_blank" rel="noopener">https://www.nature.com/articles/s41593-018-0301-3</a></p></blockquote><p>针对算法问题，他们基于卷积神经网络开发了<strong>DeepMACT</strong>(deep learning-enabled metastasis analysis in cleared tissue)的算法，可以自动化、快速的注释癌症转移的情况，以及抗体药物靶向的效率。</p><p>想进一步了解这个算法的可参考：<strong>DeepMACT handbook</strong>：<a href="http://discotechnologies.org/DeepMACT/" target="_blank" rel="noopener">http://discotechnologies.org/DeepMACT/</a></p><p><strong>figure</strong></p><p><img src="/2019/12/14/35098/fig1.png" style="zoom:50%;"></p><p><strong>碎碎念</strong></p><p>透明化这种技术可以用于体内追踪药物、细胞转移等轨迹，用途太多了，再加上深度学习算法的加持，这篇文章不愧是cell封面文章。</p><blockquote><p>每日文献摘要：第24篇  2019年12月14日 周六</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>单细胞多组学联合分析scRNAseq+scATACseq</title>
      <link href="/2019/12/12/41047.html"/>
      <url>/2019/12/12/41047.html</url>
      
        <content type="html"><![CDATA[<p>单细胞发展至今，多组学整合是其发展的一个方向，关于scRNAseq与scATACseq整合的方法也有很多文章报道，这篇文章是由表观学大牛任兵实验室开发的，主要优点体现在通量上，可用于并行分析数百万个单细胞转录组和可访问染色质。</p><p><img src="/2019/12/12/41047/fig1.png" alt></p><a id="more"></a><p><strong>一句话评价</strong></p><p>单细胞ATAC-seq和RNA-seq联合分析方法</p><p><strong>文章信息</strong></p><p>题目：An ultra high-throughput method for single-cell joint analysis of open chromatin and transcriptome</p><p>杂志：NAtuRe StRuCtuRAL &amp; MoLeCuLAR BIoLogY</p><p>时间：2019，NOVEMBER</p><p>链接: <a href="http://www.nature.com/nsmb" target="_blank" rel="noopener">www.nature.com/nsmb</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> ATACseq </tag>
            
            <tag> single cell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>玉米赤霉烯酮对猪小肠上皮细胞转录组和染色质可及性的影响</title>
      <link href="/2019/12/12/12336.html"/>
      <url>/2019/12/12/12336.html</url>
      
        <content type="html"><![CDATA[<p>这篇文章主要想研究非编码RNA与染色质可及性对玉米赤霉烯酮对猪小肠上皮细胞的影响，思路较简单，分析也过于简单，文章也没有得到特定的结论。思路如下图b所示，分析ATAC-seq得到peaks,然后注释peaks的基因，分析RNA-seq得到miRNA,lncRNA，然后预测这些非编码RNA的靶基因，并将非编码RNA的靶基因与peak注释到的基因整合，进行功能注释。</p><p><img src="/2019/12/12/12336/fig1.png" alt></p><a id="more"></a><p>题目：transcriptome and chromatin accessibility in porcine intestinal epithelial cells upon Zearalenone exposure</p><p>杂志：Scientific DATA</p><p>时间：Dec 3, 2019</p><p>链接: <a href="https://doi.org/10.1038/s41597-019-0313-1" target="_blank" rel="noopener">https://doi.org/10.1038/s41597-019-0313-1</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> ATACseq </tag>
            
            <tag> lncRNA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用深度学习进行宏基因组物种分类</title>
      <link href="/2019/11/25/17714.html"/>
      <url>/2019/11/25/17714.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>深度学习在宏基因组分析的物种鉴定中的应用</p><p><strong>文章信息</strong></p><p>题目：DeepMicrobes: taxonomic classification for metagenomics with deep learning</p><p>杂志：BioRxiv</p><p>时间：Jul,8, 2019</p><p>链接: <a href="http://dx.doi.org/10.1101/694851" target="_blank" rel="noopener">http://dx.doi.org/10.1101/694851</a></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>物种分类是宏基因组分析中重要的一个环节，虽然有很多相关的工具。但是利用深度学习的框架进行物种鉴定分类的报道还相对较少，作者这里基于recurrent neural network的架构开发了<strong>DeepMicrobes</strong>用于物种分类研究，与其他工具相比发现DeepMicrobes的假阳性率相对较低。</p><p>软件地址：<a href="https://github.com/MicrobeLab/DeepMicrobes" target="_blank" rel="noopener">https://github.com/MicrobeLab/DeepMicrobes</a></p><p><strong>figure</strong></p><p><img src="/2019/11/25/17714/fig1.png" alt></p><blockquote><p>每日文献摘要：第21篇  2019年11月25日 周一</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> deep learning </tag>
            
            <tag> metagenomics </tag>
            
            <tag> 16s rRNA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>lncRNA-chromatin相互作用的全面分析揭示了lncRNA通过结合不同的调控元件发挥功能</title>
      <link href="/2019/11/24/61765.html"/>
      <url>/2019/11/24/61765.html</url>
      
        <content type="html"><![CDATA[<p>之前分享过哈尔滨医科大学李霞老师实验室开发的lncRNA-chromatin相互作用数据库——<strong>LnChrom</strong> (<a href="http://biocc.hrbmu.edu.cn/LnChrom/index.jsp" target="_blank" rel="noopener">http://biocc.hrbmu.edu.cn/LnChrom/index.jsp</a>) 。这次详细解读数据库背后所做的分析，同时总结文章的思路、结论和成果以及对其他研究的启发。</p><p><img src="/2019/11/24/61765/abstract.jpg" alt></p><a id="more"></a><h3 id="文章信息"><a href="#文章信息" class="headerlink" title="文章信息"></a>文章信息</h3><p>题目：Comprehensive analysis of lncRNA-chromatin interactions reveals lncRNA functions dependent on binding diverse regulatory elements</p><p>杂志：Journal of Biological Chemistry</p><p>时间：Sept.4, 2019</p><p>链接：<a href="http://www.jbc.org/content/294/43/15613" target="_blank" rel="noopener">http://www.jbc.org/content/294/43/15613</a></p><h3 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h3><p>lncRNA在人类正常生命活动和疾病中扮演者重要的角色，其可以与染色质相互作用，然后招募蛋白质复合物改变染色质状态，进而调控基因表达。然而，lncRNA与染色质相互作用是如何影响并调节生物功能还并不清晰。基于此作者从人类和小鼠数据集中收集了<strong>188,647</strong>个lncRNA-chromatin相互作用对。他们的结果发现lncRNA在其结合位点展现了不同的表观修饰方式，尤其是在有增强子活动标记的区域。进而对lncRNA的靶基因的功能分析发现lncRNA即可以通过结合启动子调控元件发挥功能，也可以通过结合增强子发挥功能，尤其是在远端调控区域的调控元件。</p><h3 id="文章思路"><a href="#文章思路" class="headerlink" title="文章思路"></a>文章思路</h3><h3 id="数据资源"><a href="#数据资源" class="headerlink" title="数据资源"></a>数据资源</h3><table><thead><tr><th>物种</th><th>数据类型</th><th>数据量</th></tr></thead><tbody><tr><td>人</td><td>ChIRP-,CHOP-CHART-seq</td><td>27 lncRNA-chromatin interaction for 12 lncRNAs</td></tr><tr><td></td><td>ChIP-seq (H3K4me1, H3K4me3, H3K27ac, H3K27me3 and H3K36me3)</td><td>52</td></tr><tr><td></td><td>DNase-Seq</td><td>8</td></tr><tr><td>鼠</td><td>ChIRP-,CHOP-CHART-seq</td><td>25 lncRNA-chromatin interaction for 10 lncRNAs</td></tr><tr><td></td><td>ChIP-seq (H3K4me1, H3K4me3, H3K27ac, H3K27me3 and H3K36me3)</td><td>42</td></tr></tbody></table><p><strong>数据来源：</strong></p><ul><li><p><strong>文献收集（ChIRP-,CHOP-，RAP-, CHART-seq）</strong></p><ul><li>Chu, C., et al., Genomic maps of long noncoding RNA occupancy reveal principles of RNA-chromatin interactions. Mol Cell, 2011. 44(4): p. 667-78.</li><li>Simon, M.D., et al., The genomic binding sites of a noncoding RNA. Proc Natl Acad Sci U S A, 2011. 108(51): p. 20497-502.</li><li>Engreitz, J.M., et al., The Xist lncRNA exploits three-dimensional genome architecture to spread across the X chromosome. Science, 2013.341(6147): p. 1237973.</li><li>Mondal, T., et al., MEG3 long noncoding RNA regulates the TGF-beta pathway genes through formation of RNA-DNA triplex structures. Nat Commun, 2015. 6: p. 7743.</li></ul></li><li><p><strong>数据库</strong></p></li></ul><p><img src="/2019/11/24/61765/fig1.png" alt></p><p><strong>补充知识</strong></p><ul><li><p>ChIRP-seq</p><p>与CHART-seq技术类似，都是研究nc-RNA结合的基因组位点，以及作用的蛋白质。</p></li></ul><blockquote><p>参考：<a href="https://www.illumina.com/science/sequencing-method-explorer/kits-and-arrays/chirp-seq.html" target="_blank" rel="noopener">https://www.illumina.com/science/sequencing-method-explorer/kits-and-arrays/chirp-seq.html</a></p><p>ChIRP, also commonly referred to as ChIRP-seq, is a protocol to detect the locations on the genome where ncRNAs, such as lncRNAs, and their proteins are bound. In this method, samples are first crosslinked and sonicated. Biotinylated tiling oligos are hybridized to the RNAs of interest, and the complexes are captured with streptavidin magnetic beads. After treatment with RNase H, the DNA is extracted and sequenced. Deep sequencing can determine the lncRNA/protein interaction site at single-base resolution.</p><h6 id="Pros"><a href="#Pros" class="headerlink" title="Pros:"></a>Pros:</h6><ul><li>Identifies binding sites anywhere on the genome</li><li>Enables discovery of new binding sites</li><li>Allows selection of specific RNAs of interest</li></ul><h6 id="Cons"><a href="#Cons" class="headerlink" title="Cons:"></a>Cons:</h6><ul><li>Nonspecific oligonucleotide interactions can lead to misinterpretation of binding sites</li><li>Chromatin can be disrupted during the preparation stage</li><li>The sequence of the RNA of interest must be known</li></ul></blockquote><ul><li><p>CHART-seq</p><p>CHART-seq用于鉴定nc-RNA结合的基因组位点，同时可以鉴定与其作用的蛋白质。</p><p>参考Illumina官网：<a href="https://www.illumina.com/science/sequencing-method-explorer/kits-and-arrays/chart.html" target="_blank" rel="noopener">https://www.illumina.com/science/sequencing-method-explorer/kits-and-arrays/chart.html</a></p><p><img src="/2019/11/24/61765/fig10.png" alt></p></li></ul><blockquote><p>CHART maps genomic binding sites of ncRNAs by isolating and sequencing the DNA regions where the crosslinked RNA-DNA-protein complexes are bound. CHART differs from other crosslinked-complex purification techniques, such as ChIRP, due to the use of biotinylated 24 nt oligonucleotides (C-oligos) that are highly sensitive and unique to the ncRNA of interest.</p><p>An RNase H mapping assay is used to design the 24 nt sequence of the C-oligos. First, nuclei samples are crosslinked and fragmented. Next, C-oligos are hybridized to the complex and bound to streptavidin beads. The mixture is washed and the complex eluted. The DNA is isolated and sequenced, and the proteins involved in the complex are isolated and analyzed by Western blots.</p><h6 id="Pros-1"><a href="#Pros-1" class="headerlink" title="Pros:"></a>Pros:</h6><ul><li>Maps genomic binding sites of lncRNAs</li><li>Simultaneously identify proteins associated with the lncRNA complex</li></ul><h6 id="Cons-1"><a href="#Cons-1" class="headerlink" title="Cons:"></a>Cons:</h6><ul><li>Needs large amount of nuclei (1x109 cells)</li></ul></blockquote><ul><li>RAP-seq</li></ul><blockquote><p>RAP isolates lncRNAs and maps the sequence of their target DNA through a probe-capture mechanism. First, the cells are crosslinked and lysed before DNase I chromatin digestion to 100–300 bp DNA fragments. Biotinylated RNA probes, antisense to the lncRNA, are hybridized and captured with streptavidin. The biotin-RNA probes are 120 nt and are tiled every 15 nt over the span of the lncRNA. The captured complexes are eluted and prepared for sequencing. RNA library preparation is done through RAP-RNA, and DNA library preparation by standard chromatin immuniprecipitation (ChIP).</p><h6 id="Pros-2"><a href="#Pros-2" class="headerlink" title="Pros:"></a>Pros:</h6><ul><li>Genomic mapping of lncRNA targets</li><li>Possible to sequence RNA and DNA from the purification products</li><li>Long RNA probe length provides high binding affinity to the target lncRNA1</li><li>Minimal amplification steps during RNA sequencing after purification of the lncRNA complex</li></ul><h6 id="Cons-2"><a href="#Cons-2" class="headerlink" title="Cons:"></a>Cons:</h6><ul><li>Requires RNA sequence to be known</li></ul></blockquote><ul><li>ChOP-seq</li></ul><blockquote><p>Detection of RNA–DNA binding sites in long noncoding RNAs</p><p><a href="https://doi.org/10.1093/nar/gkz037" target="_blank" rel="noopener">https://doi.org/10.1093/nar/gkz037</a></p></blockquote><hr><p><strong>鉴定lncRNA结合位点</strong></p><ul><li><p><strong>方法</strong></p><blockquote><p>方法参考文献：West, J.A., et al., The long noncoding RNAs NEAT1 and MALAT1 bind active chromatin sites. Mol Cell, 2014. 55(5): p. 791-802.</p></blockquote><p>文章中认为lncRNA的结合位点即lncRNA-chromatin interaction对个数，方法是参考以上文献，该文献利用CHART-seq技术鉴定lncRNA结合位点以及相互作用的蛋白质。</p></li><li><p><strong>结果</strong></p><p>去除掉缺少“even”和“odd”样本的lncRNA、低富集度和在GENCODE v27中缺乏注释的lncRNA，最终在人类和鼠中分别鉴定到77,031和111,616个lncRNA-chromatin interaction（lncRNA-chromatin interaction可以理解为lncRNA结合位点）。</p><p>每个结合位点的大小平均小于1kb,除了SRA (在2kb左右) （图B）。</p></li></ul><p>  下图A展示的是人中的lncRNA-chromatin interaction, 横坐标包含l ncRNA和细胞系，图中展示的是11个lncRNA，其中一个lncRNA应该是由于缺少“even”和“odd”样本被过滤了</p><p>  <img src="/2019/11/24/61765/fig2.png" style="zoom:50%;"></p><p><strong>结合位点的基因组分布特征</strong></p><ul><li><strong>方法</strong></li></ul><p>基因组分布特征即在启动子、远端等区域的结合，Homer软件注释可以得到该结果，ChIPseeker也可以做类似的分析。</p><ul><li><strong>结果</strong></li></ul><p>大多lncRNA的结合位点位于其最邻近基因的转录起始位点（TSS）的远端（Distal）区域。该结论在多个研究中都有提及，lncRNA大部分是位于其转录位点的远端区域，与蛋白质相互作用的方式通常是反式作用。</p><p><img src="/2019/11/24/61765/fig3.png" style="zoom:50%;"></p><p><strong>lnCRANs结合位点的保守性</strong></p><ul><li><p><strong>方法</strong></p><p>保守性评估采用的是2005年发表的方法——phastCons,这篇文章至今已有3000+的引用，该模型是基于一个二态系统发育隐马尔可夫模型（phylo HMM），phastCons通过最大似然法拟合一个phylo HMM的数值，跨物种校准模型，然后基于该模型预测保守元件</p><blockquote><p>文献：doi: <a href="https://dx.doi.org/10.1101%2Fgr.3715005" target="_blank" rel="noopener">10.1101/gr.3715005</a> ； PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/16024819" target="_blank" rel="noopener">16024819</a></p><p>Evolutionarily conserved elements in vertebrate, insect, worm, and yeast genomes.</p></blockquote></li><li><p><strong>结果</strong></p><p>他们发现人类的lncRNAs结合位点与DHSs（DNase I hypersensitive sites）相比有更高的保守性。</p><p><img src="/2019/11/24/61765/fig4.png" style="zoom:50%;"></p></li></ul><p><strong>lnCRANs结合位点的motif分析</strong></p><ul><li><p><strong>方法</strong></p><p>HOMER</p></li><li><p><strong>结果</strong></p><p>de novo DNA-binding motifs的结果与之前的发现一致，如HOTAIR 和 MEG3结合位点富集在GA嘌呤处。而且发现有些motif可以与lncRNA的序列匹配，表明这些lncRNA可能形成DNA:RNA三螺旋结构。</p><p><img src="/2019/11/24/61765/fig5.png" style="zoom:50%;"></p></li></ul><p><strong>lncRNA结合位点与表观修饰的关联</strong></p><ul><li><p><strong>方法</strong></p><p>genome association tool (GAT) : 该方法是评估两个基因组片段的相关性，如ChIP-seq和RNA-seq的重合的区域是否显著相关。</p><blockquote><p><strong>Motivation:</strong> A common question in genomic analysis is whether two sets of genomic intervals overlap significantly. This question arises, for example, when interpreting ChIP-Seq or RNA-Seq data in functional terms. Because genome organization is complex, answering this question is non-trivial.</p><p><strong>Summary:</strong> We present Genomic Association Test (GAT), a tool for estimating the significance of overlap between multiple sets of genomic intervals. GAT implements a null model that the two sets of intervals are placed independently of one another, but allows each set’s density to depend on external variables, for example, isochore structure or chromosome identity. GAT estimates statistical significance based on simulation and controls for multiple tests using the false discovery rate.</p><p><strong>Availability:</strong> GAT’s source code, documentation and tutorials are available at <a href="http://code.google.com/p/genomic-association-tester" target="_blank" rel="noopener">http://code.google.com/p/genomic-association-tester</a>.</p></blockquote></li></ul><p>  选择了5种组蛋白修饰数据类型:H3K4me3, H3K4me1,H3K27me3, H3K36me3, H3K27ac</p><ul><li><p>promotor: high H3K4me3</p></li><li><p>enchancer: high H3K4me1and low  H3K4me3</p></li><li>repressed: H3K27me3 </li><li>transcription elongation : high H3K36me3</li><li>quiescent: low H3K36me3</li></ul><ul><li><strong>结果</strong></li></ul><p>只有lncRNA的数据同时包含相对应的细胞系至少两个表观修饰数据的lncRNA最后被保留用于这部分的分析。人类和鼠分别是9个和8个lncRNA。lncRNA结合位点与染色质修饰的关联多种多样，所有的lncRNA在H3K4me1 和 H3K27ac mark区域显著富集。</p><p>为了进一步探究lncRNA结合位点的表观修饰模式，作者观察了lncRNA结合位点2kb以内的染色质可及性。发现lncRNA在其结合位点展现不同的表观修饰模式，如可以结合在启动子、增强子、抑制子等。</p><p><img src="/2019/11/24/61765/fig6.png" style="zoom:50%;"></p><p><strong>lncRNA结合区域与其潜在的靶基因</strong></p><ul><li><p><strong>方法</strong></p><p>如果一个基因的TSS上下游1kb与lncRNA结合位点区域重合，就定义为该基因为此lncRNA的promoter 靶基因；</p><p>当lncRNA结合位点与远端（distal）调控元件作用（&gt;2kb to nearest TSSs）时，同时结合 来自4D genome database 的long-range 染色质相互作用数据，鉴定到lncRNA的distal 靶基因</p></li><li><p><strong>结果</strong></p><p>不同的lncRNA靶基因数目差异很大，平均每个lncRNA的蛋白编码靶基因为3100个。其中LncRNA 7SK有8051个蛋白编码靶基因（最多）。同时，他们观察到一些lncRNA的promoter和distal 靶基因有显著的重合，表明lncRNA与启动子和远端调控元件结合靶向于相同的基因。</p></li></ul><p><strong>lncRNA结合区域与其潜在的靶基因的功能</strong></p><ul><li><p><strong>方法</strong></p><p>对每个lncRNA的靶基因进行GO/KEGG功能注释</p><p>clusterProfiler</p></li><li><p>结果</p></li></ul><p>功能注释结果发现这些lncRNA都能富集到其已知的功能，如cancer-related lncRNA NEAT1 富集到细胞分化、细胞周期和细胞死亡。</p><p><img src="/2019/11/24/61765/fig7.png" style="zoom:50%;"></p><p>为了进一步确定lncRNA是如何参与通路的调控，他们将lncRNA的靶基因与富集通路匹配对应。发现lncRNA既可以结合启动子调控元件发挥功能，也可以结合远端调控元件发挥功能。</p><p><img src="/2019/11/24/61765/fig8.png" style="zoom:50%;"></p><p><strong>lncRNA-target genes在人类肿瘤预后诊断中的应用</strong></p><ul><li><p><strong>方法</strong></p><p>生存分析: Kaplan-Meier method</p></li><li><p><strong>结果</strong></p><p><img src="/2019/11/24/61765/fig9.png" style="zoom:50%;"></p></li></ul><p>从TCGA中收集了3肿瘤类型1330个癌症病人的基因表达数据（包括蛋白编码和lncRNA)，根据lncRNA表达的中位数，将病人分为high-risk group和low-risk group. </p>]]></content>
      
      
      
        <tags>
            
            <tag> lncRNA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多组学数据联合展示、且可以交互的基因组浏览器——trackViewer</title>
      <link href="/2019/11/23/41059.html"/>
      <url>/2019/11/23/41059.html</url>
      
        <content type="html"><![CDATA[<p>常见的可视化基因组track的Bioconductor package有<strong>rtracklayer</strong> 和 <strong>Gviz</strong>。rtracklayer提供了交互的基因组浏览器和相关tracks的注释；Gviz可以用于tracks覆盖度和注释的可视化。<strong>trackViewer</strong>是一个更轻量级的工具，且可以产生交互的可视化结果。可用于RNA-seq,ChIP-seq/ATAC-seq,miRNA-seq,DNA-seq,methylation等各种NGS组学数据的覆盖度和注释tracks的可视化展示，而且可以绘制发表级的棒棒糖图和蒲公英图。</p><p>先展示下极好看可视化效果</p><p><img src="/2019/11/23/41059/fig.png" alt></p><p>使用方法可以参考文档：</p><ul><li><p>详细文档：<a href="http://127.0.0.1:31580/library/trackViewer/doc/trackViewer.html" target="_blank" rel="noopener">http://127.0.0.1:31580/library/trackViewer/doc/trackViewer.html</a></p></li><li><p>Web app: <a href="https://github.com/jianhong/trackViewer.documentation/tree/master/trackViewerShinyApp" target="_blank" rel="noopener">https://github.com/jianhong/trackViewer.documentation/tree/master/trackViewerShinyApp</a></p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> ATACseq </tag>
            
            <tag> R </tag>
            
            <tag> visualization </tag>
            
            <tag> ChIPseq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度卷积神经网络分析低质量的ATAC-seq数据</title>
      <link href="/2019/11/23/10406.html"/>
      <url>/2019/11/23/10406.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>一个基于深度卷积神经网络分析低覆盖度和低质量ATAC-seq的工具</p><p><strong>文章信息</strong></p><p>题目：AtacWorks: A deep convolutional neural network toolkit for epigenomics</p><p>杂志：bioRxiv</p><p>时间：Nov. 4, 2019</p><p>链接: doi: <a href="http://dx.doi.org/10.1101/829481" target="_blank" rel="noopener">http://dx.doi.org/10.1101/829481</a>.</p><a id="more"></a><p><strong>文章介绍：</strong></p><p>这篇文章介绍了一个基于深度卷积神经网络的方法解析低覆盖度或低质量ATAC-seq数据的工具包——<strong>AtacWorks</strong> 。使用的架构是Resnet (residual neural network) 。训练模型的数据来自4个血细胞类型，之后利用得到的模型分析HSC，鉴定了差异调控元件、转录因子印迹。</p><p>工具介绍：<a href="https://github.com/clara-genomics/AtacWorks" target="_blank" rel="noopener">https://github.com/clara-genomics/AtacWorks</a></p><p><strong>安装方法：</strong></p><p><img src="/2019/11/23/10406/fig3.png" alt></p><p><strong>流程：</strong></p><p><img src="/2019/11/23/10406/fig2.png" alt></p><p><strong>figure</strong></p><p><img src="/2019/11/23/10406/fig1.png" alt></p><p><strong>碎碎念</strong></p><p>还看不懂深度学习的算法，一些基本概念都不理解</p><blockquote><p>每日文献摘要：第20篇  2019年11月23日 周六</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> ATACseq </tag>
            
            <tag> software </tag>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scATAC-seq与scRNA-seq的整合分析系统——MAESTRO</title>
      <link href="/2019/11/23/17068.html"/>
      <url>/2019/11/23/17068.html</url>
      
        <content type="html"><![CDATA[<p>单细胞技术是目前比较火热的一个领域，从单细胞转录组、基因组扩展到单细胞表观组，如scATAC-seq, scHiC, scmethylation等，促使着相关的分析工具也不断涌出。单细胞领域相关工具的开发大致有两个方向：一是从本质上如算法、统计学方法入手开发新的分析工具；一种是整合多种基础工具，开发出具有功能全面，易用等特征的工具。</p><p><img src="/2019/11/23/17068/fig2.png" style="zoom: 50%;"></p><a id="more"></a><p><strong>MAESTRO</strong>(Model-based AnalysEs of Single-cell Transcriptome and RegulOme)是刘小乐实验室基于snakemake新开发的用于分析scRNA-seq和scATAC-seq的工具。MAESTRO主要是打包了一些工具和软件包，目前可以实现的功能包括：对scRNA-seq和scATAC-seq数据的比对、质量控制、细胞过滤、标准化、非监督聚类、差异分析、peak calling、细胞类型注释和转录调控分析。支持 Smart-seq2, 10x-genomics, Drop-seq, SPLiT-seq for scRNA-seq protocols; microfudics-based, 10x-genomics and sci-ATAC-seq for scATAC-seq protocols.</p><p>提供的有docker镜像，<strong>安装可以参考软件介绍：<a href="https://github.com/liulab-dfci/MAESTRO/" target="_blank" rel="noopener">https://github.com/liulab-dfci/MAESTRO/</a></strong> </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh</span><br><span class="line">bash Miniconda3-latest-Linux-x86_64.sh</span><br><span class="line"></span><br><span class="line">conda config --add channels defaults</span><br><span class="line">conda config --add channels bioconda</span><br><span class="line">conda config --add channels conda-forge</span><br><span class="line">conda create -n MAESTRO maestro -c liulab-dfci</span><br></pre></td></tr></table></figure><p><strong>Installing the MAESTRO R package</strong></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">R</span><br><span class="line">&gt; <span class="keyword">library</span>(devtools)</span><br><span class="line">&gt; install_github(<span class="string">"liulab-dfci/MAESTRO"</span>)</span><br></pre></td></tr></table></figure><p>另外依赖的cell ranger, RABIT/LISA等软件需要自行单独安装。</p><p>每种类型的数据的详细分析教程可以在原工具介绍网页点击下面每幅图查看</p><p><img src="/2019/11/23/17068/fig1.png" alt></p><blockquote><p>PS: 目前还没有看到相关文章发表</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> software </tag>
            
            <tag> single cell </tag>
            
            <tag> scRNA-seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>叶酸与高血压、脑卒中精准防治的研究</title>
      <link href="/2019/11/22/61469.html"/>
      <url>/2019/11/22/61469.html</url>
      
        <content type="html"><![CDATA[<p>昨天组会，同学分享了北京大学第一人民医院霍勇老师关于<strong>脑卒中精准防治的研究</strong>。</p><p><img src="/2019/11/22/61469/fig2.png" alt></p><a id="more"></a><p>脑卒中想必大家都不陌生，周围有的时候会听到某人因为脑卒中突然离世。给我的感觉就是发病急，没有特别明显的发病前症状，但是一旦发病了，往往就是不可救治。</p><p>有研究也报道脑卒中是中国人的第一位死因，发病率居世界首位。脑卒中的危险因素中高血压、膳食和年龄占权重较大。霍老师的研究发现中国高血压患者75%为H型高血压（即伴有HCY升高的高血压），而低等叶酸摄入显著增加高血压患者脑卒中的风险。进而发现叶酸缺乏与MTHFR C677T位点的多态性有关，MTHFR基因是叶酸代谢中的一个关键酶，C677T位点的多态性存在3种基因型：CC型（野生型）、CT型（杂合突变型）和TT型（纯合突变型）。</p><p>叶酸人体是无法自己合成的，主要从食物中获取。叶酸缺乏有两种类型，一种是膳食中摄入量不足，通过补充可以轻易恢复正常水平；另一种是MTHFR基因的突变，导致叶酸利用率低，即使摄入得很多，但是利用的却很少。而叶酸代谢异常既而可引起高同型半胱氨酸血症，血液异常凝固等，从而引起脑卒中、冠心病、血栓。而且易造成新生儿缺陷等疾病。<br><img src="/2019/11/22/61469/1240-20191122123751293.png" alt></p><p>根据这一发现，他们提出了高血压患者叶酸治疗的研究（CSPPT），对20,702例45-75岁无心脑血管疾病的高血压患者随访4.5年，MTHFR的3种基因型每都类分为两组，分别用依那普利和依那普利叶酸治疗，他们最后的发现是<strong>与单纯使用依那普利降压比较，依那普利叶酸片（依叶）显著降低21%脑卒中风险</strong></p><p>这个治疗措施在山东荣成地区已经成为转化应用示范基地，据国家卫计委估计如果CSPPT（即高血压患者叶酸治疗的研究）研究成果广泛应用，每年可预防111万（30%）脑卒中发生。</p><blockquote><p>总结一下就是叶酸缺乏可能会引起脑卒中、高血压、新生儿缺陷等风险的增加</p></blockquote><p>听完之后，想起了自己的基因检测报告好像有叶酸营养需求的报告，打开一看</p><p><img src="/2019/11/22/61469/1240-20191122123752093.png" alt></p><p>中招了，而且基因型还是AA<br><img src="/2019/11/22/61469/1240.png" style="zoom:50%;"></p><p><img src="/2019/11/22/61469/fig1.png" style="zoom:50%;"></p><p>看来以后要多补充叶酸了</p><hr><blockquote><p><strong>文献：</strong> 2015，JAMA, Efficacy of folic acid therapy in primary prevention of stroke among adults with hypertension in China: the CSPPT randomized clinical trial.</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> chronic disease </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>宏基因组物种鉴定工具</title>
      <link href="/2019/11/22/34317.html"/>
      <url>/2019/11/22/34317.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>宏基因组物种鉴定工具集锦</p><p><strong>文章信息</strong></p><p>题目：Benchmarking Metagenomics Tools for Taxonomic Classification</p><p>杂志：Cell</p><p>时间：August 8,2019</p><p>链接: <a href="https://doi.org/10.1016/j.cell.2019.07.010" target="_blank" rel="noopener">https://doi.org/10.1016/j.cell.2019.07.010</a></p><p><img src="/2019/11/22/34317/abstract.png" alt></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>鉴定物种分类是宏基因组分析的一个必要和基础步骤，相关工具也是层出不穷，如何评价物种分类工具的性能，主要从鉴定的准确性、速度和所需要的计算资源这几方面考虑。</p><p>这篇文章针对20种常见的物种鉴定工具进行评估，并描述了如何评价工具性能。</p><p>下图展示了宏基因组的复杂的样本到物种鉴定和丰度计算的过程</p><p><strong>figure</strong></p><p><img src="/2019/11/22/34317/fig1.png" alt></p><h3 id="参考数据库"><a href="#参考数据库" class="headerlink" title="参考数据库"></a>参考数据库</h3><p>宏基因组的物种鉴定依赖于数据库，常见的数据库有<strong>RefSeq, blast nt和nr，以及16S rRNA特有的数据库SILVA</strong>。</p><h3 id="评价物种分类工具性能的方法"><a href="#评价物种分类工具性能的方法" class="headerlink" title="评价物种分类工具性能的方法"></a>评价物种分类工具性能的方法</h3><p>召回率（Recall）和准精确度（Precision）是宏基因组物种鉴定中重要的两个度量概念，这两个概念也是统计学中经常见到的。</p><blockquote><p>其中精度是检索出相关文档数与检索出的文档总数的比率，衡量的是检索系统的<strong>查准率</strong>；召回率是指检索出的相关文档数和文档库中所有的相关文档数的比率，衡量的是检索系统的<strong>查全率</strong>。</p></blockquote><p>召回率 = 提取出的正确信息条数 /  样本中的信息条数  </p><p>精确度= 提取出的正确信息条数 /  提取出的信息条数 </p><p><strong>两者取值在0和1之间，数值越接近1，查准率或查全率就越高。</strong></p><p>F值  = 正确率 <em> 召回率 </em> 2 / (正确率 + 召回率) （F 值即为正确率和召回率的调和平均值）</p><p><strong>F值是Precision和Recall加权调和平均</strong></p><p><strong>AUPR:</strong>是指precision和recal曲线下面的面积，也是一个综合考虑P-R两者来评估结果准确性的一个度量值。</p><p><strong>L2 distance:</strong>是为了评估丰度准确性的参数值，通过计算在给定的分类水平上，每个已识别分类单元的ground-truth丰度和标准丰度计数之间的成对距离。</p><p><img src="/2019/11/22/34317/fig2.png" alt></p><p>###物种分类工具和其性能</p><p>这里他们比较了20种宏基因组物种鉴定工具，利用相同的数据库 分别比较了他们的precision, recall, F1, 速度和其他值。包括DAN-DNA鉴定，DNA-protein鉴定，和基于marker的鉴定方法。</p><p><img src="/2019/11/22/34317/fig3.png" alt></p><p><strong>AUPR值如下：</strong>值越接近1越好</p><p><img src="/2019/11/22/34317/fig4.png" alt></p><p><strong>L2 distance</strong>: 值越小越好</p><p><img src="/2019/11/22/34317/fig5.png" alt></p><p><strong>运行时间</strong></p><p><img src="/2019/11/22/34317/fig6.png" alt></p><p><strong>碎碎念</strong></p><p>没有做过宏基因组分析实际项目，看着这些软件名字完全没有感觉，也记不住，后续研究若用到的话可以参考这里做选择。</p><blockquote><p>每日文献摘要：第19篇  2019年11月22日 周五</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> software </tag>
            
            <tag> metagenomics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>非编码RNA在肿瘤中扮演的角色</title>
      <link href="/2019/11/17/55583.html"/>
      <url>/2019/11/17/55583.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>关于非编码RNA在肿瘤中作用的综述</p><p><strong>文章信息</strong></p><p>题目：The Role of Non-coding RNAs in Oncology</p><p>杂志：Cell</p><p>时间：November 14, 2019</p><p>链接: <a href="https://doi.org/10.1016/j.cell.2019.10.017" target="_blank" rel="noopener">https://doi.org/10.1016/j.cell.2019.10.017</a></p><p><img src="/2019/11/17/55583/abstract.jpg" style="zoom:50%;"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p><strong>非编码RNA作为致癌因子或抑癌因子的总结</strong></p><p>（且有体内实验验证）</p><p><img src="/2019/11/17/55583/fig1.png" alt></p><p><img src="/2019/11/17/55583/fig2.png" alt></p><p><img src="/2019/11/17/55583/fig3.png" alt></p><p><img src="/2019/11/17/55583/fig4.png" alt></p><p><img src="/2019/11/17/55583/fig5.png" alt></p><p><strong>不同类型的致癌ncRNAs和癌症发生的机制</strong></p><p><img src="/2019/11/17/55583/fig6.png" alt></p><p><strong>不同类型的抑癌ncRNAs和阻碍癌症发展的通路</strong></p><p><img src="/2019/11/17/55583/fig7.png" alt></p><p><strong>非编码RNA作为肿瘤标志物</strong></p><p><img src="/2019/11/17/55583/fig8.png" alt></p><p><img src="/2019/11/17/55583/fig9.png" alt></p><blockquote><p>每日文献摘要：第18篇  2019年11月17日 周日</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> lncRNA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>准确聆听、有效沟通</title>
      <link href="/2019/11/16/7121.html"/>
      <url>/2019/11/16/7121.html</url>
      
        <content type="html"><![CDATA[<p>有效沟通始于准确聆听</p><p><img src="/2019/11/16/7121/abstract.png" alt></p><a id="more"></a><p>以前觉得自己还是个好的聆听者，当与别人交流时会很认真的听，然后作出回应，但今天发现我并没有做到一个好的聆听者，也没有达到有效的沟通。往往没有了解清晰的状况、只是为了回应而回应，随便地给出评价或建议；或者无论对方说什么，都会联想到自己，开始说自己的事说个没完，陷入了典型的<strong>自传式回应</strong>沟通。</p><blockquote><p>A: “我这个周末要加班……” </p><p>B: “辞了辞了！对自己这么苛刻干嘛？”</p><p>A: “我妈妈不同意我去其他城市发展…..”</p><p>B:”我爸妈对我没有要求，无论我做什么都特别支持，而且我爸妈…..(ba la ba la说自己的事情没有完)”</p></blockquote><p><strong>自传式回应</strong>常见的现象有这样几种：</p><ul><li><p>价值判断–表示肯定或否定</p><p>如，你这样做是不对的哦；你肯定小时候怎么样；</p></li><li><p>追根究底–依据自己的立场，探究别人的隐私</p><p>这个貌似也经常触碰，问的有点多，忽略了别人的隐私</p></li><li><p>好为人师–以个人生活经验指导他人</p><p>经常会和别人说，我曾经怎么怎么的，你应该怎样做等</p></li><li><p>自以为是–根据自己的行为动机判断别人的</p></li></ul><p>如何做到准确聆听，一种做法是<strong>移情式聆听</strong>，即代入倾诉者的角色，感同深受地了解对方此番谈话的真正目的，并掌握准确清晰的事实，再通过对对方情感的客观反馈，来实现有效的沟通。</p><p><strong>记住，说出对方的感受，而不要判断。</strong></p><p><strong>更要切记，让别人说出感受，而不是陷入自传式的回应</strong></p>]]></content>
      
      
      <categories>
          
          <category> life </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 胡思 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>lncRNA-染色质相互作用数据库</title>
      <link href="/2019/11/16/35697.html"/>
      <url>/2019/11/16/35697.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>lncRNA和染色质相互作用数据库</p><p><strong>文章信息</strong></p><p>题目：LnChrom: a resource of experimentally validated lncRNA–chromatin interactions in human and mouse</p><p>杂志：Database</p><p>时间：23 March 2018</p><p>链接: doi: 10.1093/database/bay039</p><p><strong>figure</strong></p><p><img src="/2019/11/16/35697/abstract.png" alt></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>lncRNA作用机制多样，可以与DNA、RNA和蛋白质相互作用，也是参与染色质调控的重要组成部分。许多lncRNA通过招募染色质修饰因子调控染色质状态，进而影响基因表达过程。作者对已经过实验验证的lncRNA-chromatin相互作用的数据资源进行整理，开发了lnChrom数据库。该数据库目前包括人类和鼠共382743个lncRNA-chromatin相互作用对，另外还收集了每个作用对的染色质修饰因子、表观标记特征、靶基因以及与疾病的关联信息。</p><p><img src="/2019/11/16/35697/fig1.png" alt></p><p>LnChrom提供了友好的交互界面，可以通过输入lncRNA ID或靶基因快速检索， 也可以通过选择物种、染色质修饰类型、染色质相关因子，以及基因名字进行高级检索 ，同时可以通过输入感兴趣的染色质区域进行region检索。搜索结果以一个概览的表格和相互作用网络图展示。用户点击某一感兴趣的相互作用对，可以了解到更多细节结果，包括详细的注释信息、Genome Browser，TF Co-occupancy和Cancer Exploration。</p><p>网站：<a href="http://biocc.hrbmu.edu.cn/LnChrom/" target="_blank" rel="noopener">http://biocc.hrbmu.edu.cn/LnChrom/</a></p><p><img src="/2019/11/16/35697/fig2.png" alt></p><blockquote><p>每日文献摘要：第17篇  2019年11月16日 周六</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> lncRNA </tag>
            
            <tag> database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微生物组学研究的相关概念</title>
      <link href="/2019/11/10/23172.html"/>
      <url>/2019/11/10/23172.html</url>
      
        <content type="html"><![CDATA[<p>这篇文章主要对微生物组学研究中常出现的概念进行整理，</p><p>资料摘抄原文如下：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/72013570" target="_blank" rel="noopener">细菌16s rDNA微生物多样性研究中可变区的选择</a></li><li><a href="https://www.cnblogs.com/leezx/p/7053199.html" target="_blank" rel="noopener">16S 基础知识、分析工具和分析流程详解</a></li><li><a href="http://www.bgitechsolutions.com/sequencing/32" target="_blank" rel="noopener">16S/18S/ITS 扩增子测序</a></li><li><a href="https://www.cnblogs.com/nkwy2012/p/9961611.html" target="_blank" rel="noopener">微生物组学数据分析工具综述 | 16S+宏基因组＋宏病毒组＋宏转录组–转载</a></li></ul><h3 id="微生物组学的常见分类"><a href="#微生物组学的常见分类" class="headerlink" title="微生物组学的常见分类"></a>微生物组学的常见分类</h3><p>建立在高通量测序基础上的微生物群落研究，当前主要有三大类：</p><ul><li><strong>基于16S/18S/ITS等扩增子做物种分类的Metataxanomics、</strong></li><li><strong>鸟枪法打断全基因组DNA序列的Metagenomics</strong></li><li><strong>和基于mRNA信息的宏转录组方法Meta-transcriptomics。</strong></li></ul><p><img src="/2019/11/10/23172/abstract.png" alt></p><a id="more"></a><p>###16S/18S/ITS扩增子测序</p><p>16S rDNA是细菌分类学研究中最常用的“分子钟”，其序列包含9个可变区（Variable region）和10个保守区（constant region）。可变区因细菌而异，且变异程度与细菌的系统发育密切相关。通过检测16S rDNA的序列变异和丰度，可以了解环境样品中群落多样性信息。基于16S rDNA的分析在微生物分类鉴定、微生态研究等方面起到重要作用。</p><p><strong>16S rDNA结构：</strong>16s rRNA基因的序列（约1500bp）有10个保守区和9个高变区（v1-v9：长度分布范围约30~100bp）之分；保守区为所有细菌共有，细菌间无差别，能反映生物物种的亲缘关系，可变区具有属或种的特异性，序列则随菌间的亲缘关系不同而有一定的差异，所以能揭示生物物种的特征核酸序列，被认为是最适于细菌系统发育和分类鉴定的指标。根据保守区设计引物位点，扩增可变区获得的序列可以用于菌种鉴定。一种快速、廉价的菌种鉴定方法。</p><p><img src="/2019/11/10/23172/fig1.png" alt></p><p><strong>16s rRNA基因可变区考虑因素：</strong></p><p><img src="/2019/11/10/23172/fig2.png" alt></p><p><strong>16s rRNA基因数据库</strong></p><p>SILVA; GreenGenes, RDP, EzTaxon-e</p><p><img src="/2019/11/10/23172/fig3.png" alt></p><blockquote><p><strong>几个概念：</strong></p><p><strong>核糖体</strong>：Ribosome，由 RNA(rRNA）和蛋白质 组成，配合 tRNA 来翻译 mRNA。核糖体按沉降系数来分类，S就是沉降系数，原核70S，真核80S。我们一般研究微生物，70S，由50S和30S两个亚基组成。再细分为 5S、16S、23S，我们的 16S 就是指核糖体的亚基的一个组分，16S rRNA。（记住，这是原核生物核糖体的一个组分）</p><p><strong>16S rRNA</strong>：这并不是我们的研究对象，因为我们测序的不是它，而是它对应在DNA双链上的基因序列，</p></blockquote><blockquote><p><strong>16S rDNA</strong>。可以这样理解，我们所说的16S 就是指 <strong>16S rDNA。</strong></p><p><strong>分子钟</strong>：即氨基酸在单位时间以同样的速度进行置换。16S 的进化具有良好的时钟性质，在结构与功能上具有高度的保守性，在大多数原核生物中rDNA都具有多个拷贝，5S、16S、23S rDNA的拷贝数相同。16S rDNA由于大小适中，约1.5Kb左右，既能体现不同菌属之间的差异，又能利用测序技术较容易地得到其序列，故被细菌学家和分类学家接受。（来源百度）</p></blockquote><blockquote><p><strong>OTU</strong>：即Operational Taxonomic Units的缩写（千万表手滑写成OUT，否则就OUT了），在系统发生学或群体遗传学研究中，为了便于进行分析，人为给某一个分类单元（品系，属，种、分组等）设置的同一标志。理论上一个OTU代表一个微生物物种。</p><p>通过测序获得的大量reads，如何才能转变为我们需要的物种信息呢？首先需要对这些reads进行归类（cluster），通常在97%的相似水平划分为不同的OTU，将OTU代表序列与相应的微生物数据库比对（Silva、RDP、Greengene等），得到每个样本所含的物种信息，进而进行后续生物信息统计分析。</p></blockquote><blockquote><p><strong>Alpha多样性</strong>：用于度量群落生态单样本的物种多样性，是反映丰富度和均匀度的综合指标。</p><p>菌群丰富度（Community richness）指数有：Chao、Ace，Chao或Ace指数越大，说明菌群丰富度越高。  </p><p>菌群多样性（Community diversity）指数有：Shannon、Simpson，Shannon值越大，说明群落多样性越高；Simpson指数值越大，说明菌群多样性越低。</p><p>根据各样本生成的OTU，对样本序列进行随机取样，以取出的序列数及这些序列所能代表的OTU数构建曲线，计算样本的Alpha多样性。</p><p><strong>Beta-diversity：</strong> Beta多样性用于不同生态系统之间多样性的比较，利用各样本序列间的进化关系及丰度信息来计算样本间距离，反映样本（组）间是否具有显著的微生物群落差异。目前应用比较多的是PCA、PCoA、NMDS分析等。由于微生物多样性研究通常会涉及到大样本数量的样本，因此通过Beta-diversity分析可以直观地反映样本组间的差异情况。距离越远，微生物群落差异越大，即相似性越高。</p></blockquote><blockquote><p><strong>LEfSe</strong><br>LEfSe分析即LDA Effect Size分析，多用于多个分组（≧2）之间的比较，或者进行亚组比较分析，进而找到组间在丰度上有显著差异的物种（biomaker）。</p><p>基本过程是首先在多组样本中采用非参数因子Kruskal-Wallis秩和检验检测不同分组间丰度差异显著的物种；然后基于获得的显著差异物种，利用成组的Wilcoxon秩和检验进行组间差异分析；最后采用线性判别分析（LDA）对数据进行降维并评估差异显著的物种的影响力大小（即LDA score）。</p></blockquote><p>18S rDNA或ITS（Internal Transcribed Spacer）被广泛应用在真菌分类鉴定中。18S rDNA在系统发育研究中较适用于种级以上阶元的分类；ITS属于中度保守区域，利用它可研究种及种以下的分类阶元。 </p><p><strong>局限性</strong></p><p>16S虽然是一种相对快速和经济适用的方法，但是PCR导致了偏好的产生，这就降低了注释准确度。此外，由于原核、真核生物的“分类标签”完全不同，即使细菌和古菌的16S也相去甚远，以进化快著称的病毒更难以捕获。</p><p><strong>常规分析流程</strong></p><p>下机数据经过数据过滤，滤除低质量的reads，剩余高质量的Clean data方可用于后期分析；通过reads之间的Overlap关系将reads拼接成Tags；在给定的相似度下将Tags聚成OTU，然后通过OTU与数据库比对，对OTU进行物种注释；基于OTU和物种注释结果进行样品物种复杂度分析以及组间物种差异分析。</p><p><img src="/2019/11/10/23172/fig4.png" alt></p><hr><h3 id="宏基因组"><a href="#宏基因组" class="headerlink" title="宏基因组"></a>宏基因组</h3><p>宏基因组有效避免了扩增偏差，由于是直接打断，理论上不限制物种（细菌、真菌、古菌、真核生物等，事实上当前宏基因组测序多还是以细菌为主），可能组装获得新基因乃至新物种信息，但根据取样情况可能存在少量或大量的宿主污染，因需组装，数据量要求大，成本贵、周期长。</p><p><strong>宏基因组经典流程：</strong>环境微生物样本–Total DNA提取–文库构建–上机测序（经典短读长: illumina系列；长读长选择: PB, ONT）–数据质控（去除低质量和接头等，去除宿主基因组等干扰信息）–宏基因组组装–Contig Binning–基因组重建–分类注释（可基于reads、contig、bins、还原出来的基因组做物种注释）–其他下游分析。</p><hr><h3 id="宏转录组"><a href="#宏转录组" class="headerlink" title="宏转录组"></a>宏转录组</h3><p>宏转录组的好处是，跳出了DNA层面的束缚，可以获得实时活跃的、真正对群落有贡献的基因和通路，然而mRNA不如DNA稳定,此外多纯化和扩增的步骤也可能引入错误。</p><p>宏转录组也迎来了自己的专属软件–IMSA+A ( <a href="https://github.com/JeremyCoxBMI/IMSA-A" target="_blank" rel="noopener">https://github.com/JeremyCoxBMI/IMSA-A</a> )。IMSA+A在17年1月发表于Microbiome，是一种可应用于任意读长宏转录组学数据、可高效在同一份样品中鉴定出细菌、真菌、病毒的准确的分类分析的方法。</p>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> metagenomics </tag>
            
            <tag> 16s rRNA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>追踪非小细胞肺癌的进化</title>
      <link href="/2019/11/05/30182.html"/>
      <url>/2019/11/05/30182.html</url>
      
        <content type="html"><![CDATA[<p>小时候觉得癌症这个词离自己很远很远，知道它很可怕，但实际上并不知道它具体是什么，只天真的觉得它永远也不会出现在我的身边。</p><p>高三时大奶从被检出肝癌晚期到去世不到两周，她在去世的前两天都不是特别清楚自己的病情，直到去世的前一天病情的加重，她才明白。</p><p>从高三到硕士毕业，7年的时间，大姑和婶婶接连也因为癌症去世。而爷爷今天也被检出贲门癌。爷爷是一个闲不住的人，虽然80多岁了，种地比我们家都多，大概是从4月份的时候开始吃东西容易打嗝，以前他每次从地里干完活回家总要吃两个馒头，现在基本吃不了馒头，只能吃些面条和粥。家里人一直劝他去医院检查，他总是不愿意去，最近才被说服去医院检查，却没想道是癌症。</p><p>真的很害怕，以前觉得不会出现在身边的癌症，却不断地夺走亲人的生命。我虽然是研究生命科学的，经常关注癌症相关方面的研究，但是我还是不知道为什么现在的癌症越来越多，我经常怀疑我每天的研究有什么意义，在面对真正的癌症时有什么帮助，似乎大多时候我们依然无能为力！</p><p>但是，没有这些基础研究的推动，临床上治疗又怎么能提升？</p><p><img src="/2019/11/05/30182/absract.jpg" alt></p><a id="more"></a><p><strong>一句话评价</strong></p><p>用尽量简短的一句话说清文章亮点或者你的推荐理由。越短越好</p><p><strong>文章信息</strong></p><p>题目：Tracking the Evolution of Non–Small-Cell Lung Cancer</p><p>杂志：<em>The</em> new england journal <em>of</em> medicine</p><p>时间：June 1, 2017</p><p>链接: <a href="https://www.nejm.org/doi/full/10.1056/NEJMoa1616288" target="_blank" rel="noopener">https://www.nejm.org/doi/full/10.1056/NEJMoa1616288</a></p><p><strong>figure</strong></p><p><img src="/2019/11/05/30182/fig1.png" style="zoom:50%;"></p><p><strong>文章介绍：</strong></p><blockquote><p><strong>BACKGROUND</strong></p><p>Among patients with non–small-cell lung cancer (NSCLC), data on intratumor heterogeneity and cancer genome evolution have been limited to small retrospective cohorts. We wanted to prospectively investigate intratumor heterogeneity in relation to clinical outcome and to determine the clonal nature of driver events and evolutionary processes in early-stage NSCLC.</p><p><strong>METHODS</strong></p><p>In this prospective cohort study, we performed multiregion whole-exome sequencing on 100 early-stage NSCLC tumors that had been resected before systemic therapy. We sequenced and analyzed 327 tumor regions to define evolutionary histories, obtain a census of clonal and subclonal events, and assess the relationship between intratumor heterogeneity and recurrence-free survival.</p><p><strong>RESULTS</strong></p><p>We observed widespread intratumor heterogeneity for both somatic copy-number altera- tions and mutations. Driver mutations in <em>EGFR</em>, <em>MET</em>, <em>BRAF</em>, and <em>TP53</em> were almost always clonal. However, heterogeneous driver alterations that occurred later in evolution were found in more than 75% of the tumors and were common in <em>PIK3CA</em> and <em>NF1</em> and in genes that are involved in chromatin modification and DNA damage response and repair. Genome doubling and ongoing dynamic chromosomal instability were associated with intratumor heterogeneity and resulted in parallel evolution of driver somatic copy-number alterations, including amplifications in <em>CDK4</em>, <em>FOXA1</em>, and <em>BCL11A</em>. Elevated copy-number heterogeneity was associated with an increased risk of recurrence or death (hazard ratio, 4.9; P=4.4×10−4), which remained significant in multivariate analysis.</p><p><strong>CONCLUSIONS</strong></p><p>Intratumor heterogeneity mediated through chromosome instability was associated with an increased risk of recurrence or death, a finding that supports the potential value of chromosome instability as a prognostic predictor. (Funded by Cancer Research UK and others; TRACERx ClinicalTrials.gov number, NCT01888601.)</p></blockquote><blockquote><p>每日文献摘要：第17篇 2019年11月05日 周二</p><p>今天没时间看了，改天再仔细看</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> tumor evolution </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>抗微生物耐药性(Anti-microbial Resistance,AMR)</title>
      <link href="/2019/11/05/27645.html"/>
      <url>/2019/11/05/27645.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>一篇研究抗微生物药物耐药性的测序方法和资源的超全综述</p><p><strong>文章信息</strong></p><p>题目：Sequencing-based methods and resources to study antimicrobial resistance</p><p>杂志：Nature Review Genetics</p><p>时间：<a href="https://www.nature.com/articles/s41576-019-0108-4#article-info" target="_blank" rel="noopener">18 March 2019</a></p><p>链接: <a href="https://doi.org/10.1038/s41576-019-0108-4" target="_blank" rel="noopener">https://doi.org/10.1038/s41576-019-0108-4</a></p><p><strong>figure</strong></p><p><img src="/2019/11/05/27645/fig2.png" alt></p><a id="more"></a><p><strong>文章介绍：</strong></p><blockquote><p><strong>抗微生物药物耐药性(antimicrobial resistance)指微生物（如细菌、病毒和某些寄生虫）阻止抗微生物药物（如抗生素、抗病毒药物和抗疟药物）对其产生作用的能力，致使标准治疗方法失去效力，感染持续存在并可能传播给他人。</strong></p><p>参考：<a href="https://www.who.int/antimicrobial-resistance/zh/" target="_blank" rel="noopener">https://www.who.int/antimicrobial-resistance/zh/</a></p></blockquote><p>日常生活中我们可能大多听说过抗生素耐药性，由于抗生素的过度使用或其他原因，导致细菌对用以治疗细菌感染（如尿道感染、肺炎、血流感染）的抗生素发生反应并改变，使治疗失去效果。</p><p>抗微生物药物耐药性是一个含义更为广泛的术语，包括对治疗由寄生虫（如疟疾或蠕虫）、病毒（如艾滋病毒）及真菌（如念珠菌）等其它微生物引起的感染的药物耐药。</p><p>抗微生物耐药性已经成为影响各个国家生命健康的重要隐患之一。2019年4月29日，联合国、国际机构和有关专家发布了联合行动，防止可能出现的灾难性耐药危机。其中报告中警告说，如果不采取行动，到2050年，耐药性疾病每年可能导致1000万人死亡，对经济造成的灾难性损失将堪比2008-2009年全球金融危机。到2030年，抗微生物药物耐药性问题可能会使多达2400万人陷入极端贫困。</p><p>这篇综述发表于2019年3月的Nature Review Genetics，文中对抗微生物耐药性的监测和鉴定方法做了详尽的概括，包括传统的基于培养的易感性监测、基于测序的监测、以及目前具有前景的深度学习的方法。对基于测序的方法还对相关的工具和数据库也做了详尽的总结。最后对每种方法的优缺点做了讨论，并对未来发展方向做了展望。</p><p><img src="/2019/11/05/27645/fig1.png" alt></p><p><strong>碎碎念</strong></p><p><strong>做相关研究的，这篇综述绝对值得细读！不做相关研究的也可以根据这篇综述简单了解该领域。</strong></p><blockquote><p>每日文献摘要：第16篇 2019年11月04日 周日</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> AMR </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用深度学习从宏基因组数据中预测抗生素抗性基因——DeepARG</title>
      <link href="/2019/11/03/52372.html"/>
      <url>/2019/11/03/52372.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>利用深度学习从宏基因组数据中预测抗生素抗性基因</p><p><strong>文章信息</strong></p><p>题目：DeepARG: a deep learning approach for predicting antibiotic resistance genes from metagenomic data</p><p>杂志：Microbiome</p><p>时间：2018</p><p>链接: DOI： 10.1186/s40168-018-0401-z</p><p><strong>figure</strong></p><p><img src="/2019/11/03/52372/abstract.jpg" alt></p><p><img src="/2019/11/03/52372/fig1.png" alt></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>随着抗生素耐药率的不断上升，人类面临着需要扩大和全面的全球监测，尤其需要的是改进监测环境介质（如废水、农业废弃物、食品和水）的方法，以确定新的抗生素抗性基因（antibiotic resistance genes (ARGs）的潜在来源、基因交换的热点以及ARGs的传播和人类接触的途径。二代测序现在能够直接访问和剖析总宏基因组DNA，其中ARGs通常基于对现有数据库的序列搜索的“best hits”来识别或预测。但是，这种方法产生了很高的假阴性率。为了解决这些限制，作者在这里提出一种深度学习方法，使用所有已知的ARGs类别创建的不同矩阵。分别针对短读长序列和全基因长度序列构建了两种深度学习模型：DeepARG-SS 和DeepARG-LS。</p><p>对30个抗生素耐药类别的深度学习模型的评价表明，DeepARG模型可以同时预测高精度的ARGs（&gt;0.97）和召回率（&gt;0.90）。与典型的best hits方法相比，该模型显示出一个优势，产生的假阴性率始终较低，因此整体召回率较高（&gt;0.9）。随着越来越多的数据可用于表示ARGs类别，由于底层神经网络的性质，DeepARG模型的性能有望进一步提高。他们最新开发的ARG数据库DeepARG-DB包含了高度可信的预测的ARGs和广泛的手动检查，极大地扩展了当前的ARG存储库。</p><p>DeepARG的模型和数据库网址：</p><p><a href="http://bench.cs.vt.edu/deeparg" target="_blank" rel="noopener">http://bench.cs.vt.edu/deeparg</a>.</p><p><strong>碎碎念</strong></p><p>各个领域都开始探索使用深度学习的方法解决问题了。深度学习、抗生素抗性、宏基因组三个热点方向，但是相关文章好像并不多。</p><blockquote><p>每日文献摘要：第15篇 2019年11月03日 周日</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> AMR </tag>
            
            <tag> deep learning </tag>
            
            <tag> metagenomics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scATACseq分析方法评估</title>
      <link href="/2019/11/02/61363.html"/>
      <url>/2019/11/02/61363.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>scATAC-seq分析方法评估</p><p><img src="/2019/11/02/61363/abstract.jpg" style="zoom: 25%;"></p><a id="more"></a><p><strong>文章信息</strong></p><p>题目：Assessment of computational methods for the analysis of single-cell ATAC-seq data</p><p>杂志：bioRxiv</p><p>时间：Aug.18,2019</p><p>链接:  DOI: <a href="http://dx.doi.org/10.1101/739011" target="_blank" rel="noopener">http://dx.doi.org/10.1101/739011</a>.</p><p><strong>文章介绍：</strong></p><p>scATAC-seq技术目前广泛应用于不同领域转录调控的研究，伴随着很多计算方法相继被开发，用于分析、解释scATAC-seq数据背后的生物学意义。这篇文章对scATAC-seq分析的<strong>10个工具</strong>在<strong>13个数据集中</strong>(包括3个真实数据集和10个合成数据集)进行了测评。</p><p><strong>10个工具分别是：</strong></p><ol><li>BROCKMAN<ul><li>de Boer, C.G. and A. Regev, <em>BROCKMAN: deciphering variance in epigenomic regulators by k-mer factorization.</em> BMC Bioinformatics, <strong>2018. </strong>19(1): p. 253.</li></ul></li><li>chromVAR<ul><li>Schep, A.N., et al., chromVAR: inferring transcription-factor-associated accessibility from single-cell epigenomic data. Nat Methods, <strong>2017.</strong> 14(10): p. 975-978.</li></ul></li><li>Cicero<ul><li>Pliner, H.A., et al., Cicero Predicts cis-Regulatory DNA Interactions from Single-Cell Chromatin Accessibility Data. Mol Cell, <strong>2018.</strong> 71(5): p. 858-871 e8.</li></ul></li><li>cisTopic<ul><li>Bravo González-Blas, C., et al., cisTopic: cis-regulatory topic modeling on single-cell ATAC-seq data. Nature Methods, <strong>2019.</strong></li></ul></li><li>Cusanovich2018<ul><li>Cusanovich, D.A., et al., A Single-Cell Atlas of In Vivo Mammalian Chromatin Accessibility. Cell, <strong>2018.</strong> 174(5): p. 1309-1324 e18.</li><li>Cusanovich, D.A., et al., The cis-regulatory dynamics of embryonic development at single-cell resolution. Nature, <strong>2018.</strong> 555(7697): p. 538-542.</li><li>Cusanovich, D.A., et al., Multiplex single cell profiling of chromatin accessibility by combinatorial cellular indexing. Science, <strong>2015. </strong>348(6237): p. 910-4.</li></ul></li><li>Gene Scoring<ul><li>Lareau, C.A., et al., Droplet-based combinatorial indexing for massive scale single-cell epigenomics. bioRxiv, <strong>2019</strong>: p. 612713.</li></ul></li><li>scABC<ul><li>Zamanighomi, M., et al., Unsupervised clustering and epigenetic classification of single cells. Nat Commun, <strong>2018.</strong> 9(1): p. 2410.</li></ul></li><li>Scasat<ul><li>Baker, S.M., et al., <em>Classifying cells with Scasat, a single-cell ATAC-seq analysis tool.</em>Nucleic Acids Res, <strong>2019. </strong>47(2): p. e10.</li></ul></li><li>SCRAT<ul><li>Ji, Z., W. Zhou, and H. Ji, Single-cell regulome data analysis by SCRAT. Bioinformatics, <strong>2017. </strong>33(18): p. 2930-2932.</li></ul></li><li>SnapATAC<ul><li>Fang, R., et al., Fast and Accurate Clustering of Single Cell Epigenomes Reveals Cis- Regulatory Elements in Rare Cell Types. BioRxiv, <strong>2019</strong>.</li></ul></li></ol><p><strong>测评方法：</strong></p><p>利用收集到的3个公共数据集和10个合成模仿的不同覆盖度和噪音水平的数据集，从<code>bam</code>格式的比对文件开始，1）根据10种scATAC-seq工具原文提供的方法构建下游分析所需的特征矩阵；2）然后用3种常见的聚类方法<strong>K-means、Louvain、Hierarchical clustering</strong>和UMAP找出潜在的亚群，并可视化每种方法的细胞间相似性；3）对聚类结果进行评估，有FACS分选标记和有金标准的组织采用ARI(adjusted random)、AMI(adjusted mutual information)和H(homogeneity)的方法评估聚类结果，当只知道已知的marker 基因，采用RAGI (Gini-index-based metric called Residual Average Gini Index)的方法评估。4）最后对基于第3步得到的值，对每种方法的聚类效果进行打分排序。流程如下图所示：</p><p><img src="/2019/11/02/61363/fig2.png" style="zoom:50%;"></p><p><strong>测评结果：</strong></p><p>他们的测评结果显示SnapATAC、cisTopic和Cusanovich2018是性能最好的对scATAC-seq数据<strong>聚类分析</strong>方法。另外基于peak-level（cisTopic, Cusanovich2018, Scasat）和bin-level（SnapATAC）保存信息的方法优于motif/k-mer level (chromVAR,BROCKMAN, SCRAT)或gene-body (Cicero, Gene Scoring) 。实现降维步骤的方法（BROCKMAN、cisTopic、Cusanovich2018、Scasat、SnapATAC）通常比没有这个重要步骤的其他方法显示出优势。此外，SnapATAC是最具伸缩性的方法,它是唯一能够处理超过80000个细胞的方法。CusanovicH2018是平衡分析性能和运行时间的最佳方法。下图展示了每种方法的聚类效果评估等级和时间需求。</p><p><img src="/2019/11/02/61363/fig3.png" alt="fig3"></p><p><strong>参考价值：</strong></p><ul><li><p><strong>概述了scATAC-seq常见的分析流程</strong></p><p>如，建库方法常用的两种策略：Droplet-based(10X genomics, BioRad), split-pool(sciATA-seq)。<strong>下游常见分析：可视化、聚类、轨迹分析、差异可及性分析、顺式调控网络。</strong></p><p><img src="/2019/11/02/61363/fig1.png" style="zoom: 33%;"></p></li><li><p><strong>比较了10种scATAC-seq分析方法，为选择合适的方法提供了重要的参考依据</strong></p></li><li><p><strong>github提供了作者的100多个测试流程Jupyter笔记本，不仅可以复现作者的测评结果，还可以学习每种scATAC-seq的分析方法</strong></p></li></ul><p><strong>github:</strong> <a href="https://github.com/pinellolab/scATAC-benchmarking/" target="_blank" rel="noopener">https://github.com/pinellolab/scATAC-benchmarking/</a></p><p><strong>不足：</strong></p><p>本文的测评主要基于不同方法对scATAC-seq数据的聚类效果，但是，实际项目中可能不仅关注聚类分群，还关注谱系发育轨迹、转录因子结合位点、重要的marker基因以及他们的调控方式。</p><p>作者在讨论中也对测评的局限性做了讨论，如，chromVAR更适合于轨迹预测，chromVAR，Cicero, Gene Scoring的设计主要是为了确定关键marker基因以及他们的调控方式等。所以具体选择哪种方法，还要结合实际的研究目的决定。</p><p><strong>碎碎念</strong></p><p><strong>找时间实践下github上给出的几种scATAC-seq方法</strong></p><blockquote><p>每日文献摘要：第15篇 2019年11月02日 周六</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> ATACseq </tag>
            
            <tag> software </tag>
            
            <tag> single cell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>英语学习的网站资源</title>
      <link href="/2019/11/02/34718.html"/>
      <url>/2019/11/02/34718.html</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>The only safe thing is to take a chance.</strong></p><p>唯一稳妥的事是去冒险试一试。</p></blockquote><p><img src="/2019/11/02/34718/abstract.png"></p><a id="more"></a><h3 id="1-TED"><a href="#1-TED" class="headerlink" title="1.  TED"></a>1.  TED</h3><ul><li><a href="https://www.ted.com/" target="_blank" rel="noopener">https://www.ted.com/</a></li></ul><p>关于不同话题的talks，一方面可以了解相关话题的观点，另一方面锻炼听力，学习其演讲式的表达。</p><p><img src="/2019/11/02/34718/fig1.png" alt></p><h3 id="2-雅思口语预测"><a href="#2-雅思口语预测" class="headerlink" title="2.  雅思口语预测"></a>2.  雅思口语预测</h3><ul><li>慎小嶷口语预测博客：blog.sina.com.cn/ieltsguru</li></ul><p>实时更新口语题库，及时了解，可以准备相关的topics</p><h3 id="3-英语线上交流学习网站"><a href="#3-英语线上交流学习网站" class="headerlink" title="3.  英语线上交流学习网站"></a>3.  英语线上交流学习网站</h3><ul><li><a href="http://www.topics-mag.com" target="_blank" rel="noopener">http://www.topics-mag.com</a></li></ul><p><img src="/2019/11/02/34718/fig2.png" style="zoom:50%;"></p><h3 id="4-podcast"><a href="#4-podcast" class="headerlink" title="4.  podcast"></a>4.  podcast</h3><p>在google上 搜索 <code>podcast English</code> ,会有有很多的英语听力资源，如<a href="https://www.podcastsinenglish.com/" target="_blank" rel="noopener">https://www.podcastsinenglish.com/</a></p><h3 id="5-全面的常考口语话题"><a href="#5-全面的常考口语话题" class="headerlink" title="5. 全面的常考口语话题"></a>5. 全面的常考口语话题</h3><ul><li>idebate.org/debatabase</li></ul><p>这是一个相当酷的辩论网站，覆盖了几乎所有的常用口语讨论话题。在页面中选择<code>Education,Culture,Enviroment &amp; Animals,Welfare</code>等主题后，就可以在<code>This house believes that</code>的后面看到各种各样的辩论话题。</p><p><img src="/2019/11/02/34718/fig3.png" style="zoom:50%;"></p><h3 id="6-练习发音的网站"><a href="#6-练习发音的网站" class="headerlink" title="6.  练习发音的网站"></a>6.  练习发音的网站</h3><ul><li><a href="http://www.bbc.co.uk/worldservice/learningenglish/grammar/pron" target="_blank" rel="noopener">www.bbc.co.uk/worldservice/learningenglish/grammar/pron</a></li><li><a href="http://www.howjsay.com" target="_blank" rel="noopener">www.howjsay.com</a></li><li><a href="http://www.inogolo.com" target="_blank" rel="noopener">www.inogolo.com</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Language </category>
          
          <category> English </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 每日英语 </tag>
            
            <tag> 学习资源 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RNA速度-RNA velocity是什么</title>
      <link href="/2019/11/01/21139.html"/>
      <url>/2019/11/01/21139.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>通过动态模型评估细胞瞬间状态的RNA速度</p><p><strong>文章信息</strong></p><p>题目：Generalizing RNA velocity to transient cell states through dynamical modeling</p><p>杂志：bioRxiv</p><p>时间：Oct. 29,2019</p><p>链接: <a href="http://dx.doi.org/10.1101/820936" target="_blank" rel="noopener">http://dx.doi.org/10.1101/820936</a>.</p><p><strong>figure</strong></p><p>下图是作者利用该方法对胰腺内分泌发育构建的动态图谱</p><p><img src="/2019/11/01/21139/abstract.png" style="zoom:67%;"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>这篇文章介绍了利用一个新的模型—<strong>动态模型</strong>对细胞瞬间态的<strong>RNA速度（RNA velocity）</strong>进行评估计算。关键词动态模型和RNA速度，这里对动态模型的算法和实现过程暂不详细解释，主要了解<strong>RNA速度</strong>的概念和应用以及这篇文章中开发的方法的优点。</p><ul><li><strong>RNA velocity的概念</strong></li></ul><p><strong>RNA velocity, 我直译为RNA速度</strong>，这一概念是18年由瑞典卡罗林斯卡医学院的Sten Linnarsson和 Peter V. Kharchenko两个实验室提出的，相关研究成果发表Nature(<em>2018, August, Nature</em>)。RNA丰度是单个细胞状态的一个有力指标。单细胞测序技术可以灵敏、准确地揭示RNA的丰度。然而，这种方法仅能捕获在某个时间点的静态快照，使得分析随着时间动态变化的现象面临挑战（如胚胎发生或组织再生）。这里他们提出的<strong>RNA速度（RNA velocity）—可以理解为通过对unspliced(nascent) 和spliced(mature) mRNA丰度的评估在时间维度上揭示转录本动态变化的一个指标。</strong></p><ul><li><strong>RNA velocity应用</strong></li></ul><p>RNA velocity是一个转录本动态变化的指标，能预测细胞未来的状态变化。可以用于细胞分化、谱系发育、肿瘤微环境中细胞成分的动态变化等研究。张泽民老师实验室刚发表的肝癌免疫图谱的文章中就有通过RNA velocity的分析揭示肿瘤微环境中巨噬细胞的迁移(<em>2019,October,Cell</em>) （张老师实验室用的是Scanpy方法分析的RNA velocity）。</p><ul><li><strong>scVelo</strong>—以动态模型对细胞瞬间态的<strong>RNA velocity</strong>进行评估计算的方法</li></ul><p>回到这篇文章，作者认为现有的计算RNA velocity的模型在一些情况下存在不足，他称这种模型为<strong>稳态模型(steady-state model)</strong>, 这种模型有个两个基本的假设：即（i）在基因水平上，所有具有转录诱导、抑制和稳态mRNA水平的完整剪接动力学被捕捉到；（ii）在细胞水平上，所有基因具有共同的剪接率。但是，当一个种群包含多个具有不同动力学的异质亚种群时，这些假设常常被违背。</p><p>所以，他们开发的seVelo，一个基于<strong>似然的动力学模型(likelihood-based dynamical model)</strong>，它解决了以上提出的全基因转录动力学的问题，从而将RNA速度估计推广到瞬态系统和具有非均匀亚种群动力学的系统。scVelo提供了两种扩展：一种是包含二阶矩的随机模型，另一种是捕获全剪接动力学的动力学模型。与scanpy也兼容。</p><p>网址：scVelo: <a href="https://scvelo.org" target="_blank" rel="noopener">https://scvelo.org</a></p><p><strong>碎碎念</strong></p><p>评估科学研究的重要性通常有3方面：新的概念、新的方法、新的发现。18年Nature的那篇文章是提出了新的概念，这篇文章是开发了新的方法，我们还可以应用新的概念和新的方法，为自己关注的领域带来新的发现。</p><blockquote><p><strong>相关文献：</strong></p><ul><li>2018, August, Nature, RNA velocity of single cells：DOI: 10.1038/s41586-018-0414-6</li><li>2019, October,Cell,Landscape and Dynamics of Single Immune Cells in Hepatocellular Carcinoma. <a href="https://doi.org/10.1016/j.cell.2019.10.003" target="_blank" rel="noopener">https://doi.org/10.1016/j.cell.2019.10.003</a>. </li></ul></blockquote><blockquote><p>每日文献摘要：第14篇 2019年11月01日 周五</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> single cell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人类红细胞生成过程中的转录组和表观图谱</title>
      <link href="/2019/10/28/33171.html"/>
      <url>/2019/10/28/33171.html</url>
      
        <content type="html"><![CDATA[<p>十月最后的一天，这一年还有两个月就又结束了。</p><p>对于小孩来说两三个月可能如两三年一样长，对于长大的人来说两三年就如两三天一样快。</p><p><img src="/2019/10/28/33171/abstract.jpg" style="zoom:50%;"></p><a id="more"></a><p><strong>一句话评价</strong></p><p>ATAC-seq和RNA-seq联合分析策略</p><p><strong>文章信息</strong></p><p>题目：Transcriptional States and Chromatin Accessibility Underlying Human Erythropoiesis</p><p>杂志：Cell Report</p><p>时间：2019 June 11</p><p>链接: DOI: 10.1016/j.celrep.2019.05.046</p><p><strong>figure</strong></p><p><img src="/2019/10/28/33171/ab.png" style="zoom:50%;"></p><p><strong>文章介绍：</strong></p><p><img src="/2019/10/28/33171/01-chromatin state transcriptomics erythroisis GWAS.png" alt></p><p><strong>碎碎念</strong></p><p>虽然idea相似，但是这篇文章总体的逻辑更强，或者说写作的连贯性更强与自己。还有就是图做的也漂亮。</p><blockquote><p>每日文献摘要：第13篇 2019年10月31日 周四</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ATACseq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Smart-seq3问世</title>
      <link href="/2019/10/27/59256.html"/>
      <url>/2019/10/27/59256.html</url>
      
        <content type="html"><![CDATA[<p>单细胞技术发展的如火如荼，实验方法、算法、分析工具不断迭代更新和完善。瑞典Karolinska Institute 的Rickard Sandberg实验室14年发表了Smart-seq和Smart-seq2，是至今较为流行的单细胞实验方法之一，由于其具有全长转录本覆盖度的优点，由此可以用于研究可变剪接、变异、等位基因、转录本亚型等转录后调控。但是由于其通量低，价格较贵，限制了其广泛的推广应用。而10X Genomics的出现，由于通量高，价格低，迅速占领了单细胞技术的大部分市场。</p><p><img src="/2019/10/27/59256/abstract.jpg" style="zoom:67%;"></p><a id="more"></a><p><strong>Smart-seq3相比Smart-seq2具有什么改进呢？</strong></p><p>最显著的改进特点就是整合了5‘-UMI定量计数的策略，使通量大幅提高。同时还保留Smart-seq2的优点，就是全长转录本的覆盖度。因此，依然在等位基因和转录本亚型层次上具有巨大的应用。</p><p><img src="/2019/10/27/59256/fig1.png" style="zoom: 67%;"></p><hr><p><strong>一句话评价</strong></p><p>Smart-seq3——等位基因和亚型分辨率的单细胞RNA 计数</p><p><strong>文章信息</strong></p><p>题目：Single-cell RNA counting at allele- and isoform-resolution using Smart-seq3</p><p>杂志：bioRxiv </p><p>时间：Oct. 25, 2019</p><p>链接:  <a href="https://www.biorxiv.org/content/biorxiv/early/2019/10/25/817924.full.pdf" target="_blank" rel="noopener">https://www.biorxiv.org/content/biorxiv/early/2019/10/25/817924.full.pdf</a></p><p><strong>figure</strong></p><p><img src="/2019/10/27/59256/fig2.png" style="zoom:50%;"></p><p><strong>文章介绍：</strong></p><p>瑞典Karolinska Institute 的Rickard Sandberg实验室于10月25日在bioRxiv上发表了Smart-seq3，在等位基因和转录本亚型的研究中具有独特的优点。为大家熟知的Smart-seq2也是由Rickard实验室开发，具有全长转录本的覆盖度的优点，可以进行等位基因表达谱分析等问题，但是由于通量低，价格昂贵，应用推广也受到一定的限制。Smart-seq3针对Smart-seq2的限制性特点做了改进，依然保留全长转录本覆盖度的优点，同时结合5‘ UMI（unique molecular identifier）的RNA计数策略，与Smart-seq2相比通量显著提高，可以达到每个细胞比Smart-seq2多检测出上千个基因。</p><p>另外与全长转录本测序相比，虽然长read测序技术可以直接定量等位基因和亚型的表达水平，但是测序深度阻碍了其大范围应用。而Smart-seq3不仅克服了Smart-seq2的缺点，也克服了长读长测序的缺点，采用灵敏的短读长测序、整合5‘UMI和全长转录本覆盖度的优点，可以在单细胞层面上检测等位基因和亚型的变化，通量显著提高，且价格合理（一个测序细胞文库成本约为0.5-1欧元），可以在普通的分子实验室实现该protocol (dx.doi.org/10.17504/protocols.io.7dnhi5e), 不需要特殊的设备。</p><p>期待其他实验室对该方法的尝试和验证，预测该方法在转录后调控研究中将有巨大潜在的应用。</p><blockquote><p>每日文献摘要：第12篇 2019年10月27日 周日</p><p>捧一杯咖啡，听着咖啡屋淡淡的音乐，打开电脑，专注工作～时光静好</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> single cell </tag>
            
            <tag> scRNA-seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基因组结构变异</title>
      <link href="/2019/10/26/37551.html"/>
      <url>/2019/10/26/37551.html</url>
      
        <content type="html"><![CDATA[<h3 id="基因组变异"><a href="#基因组变异" class="headerlink" title="基因组变异"></a>基因组变异</h3><p>这里重温下基因组变异的知识，尤其是结构变异的知识点：</p><blockquote><ul><li>单碱基变异，即单核苷酸多态性(SNP)，最常见也最简单的一种基因组变异形式；</li><li>很短的Insertion 和 Deletion，也常被我们合并起来称为Indel。主要指在基因组某个位置上发生较短长度的<strong>线性片段</strong>插入或者删除的现象。强调<strong>线性</strong>的原因是，这里的插入和删除是<strong>有前后顺序的</strong>与下述的结构性变异不同。Indel长度通常在50bp以下，更多时候甚至是不超过10bp，这个长度范围内的序列变化可以通过Smith-Waterman 的局部比对算法来<strong>准确</strong>获得，并且也能够在目前短读长的测序数据中较好地检测出来</li><li>基因组结构性变异**（Structure Variantions，简称SVs），这篇文章的重点，通常就是指基因组上大长度的序列变化和位置关系变化。类型很多，包括长度在50bp以上的长片段序列插入或者删除（Big Indel）、串联重复（Tandem repeate）、染色体倒位（Inversion）、染色体内部或染色体之间的序列易位（Translocation）、拷贝数变异（CNV）以及形式更为复杂的嵌合性变异。</li></ul></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> SV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用前列腺癌早期的分子进化特征鉴定前列腺癌的风险标志物和临床发展过程</title>
      <link href="/2019/10/26/1866.html"/>
      <url>/2019/10/26/1866.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>肿瘤的分子进化特征为肿瘤的早期诊断提供参考</p><p><strong>文章信息</strong></p><p>题目：Molecular Evolution of Early-Onset Prostate Cancer Identifies Molecular Risk Markers and Clinical Trajectories</p><p>杂志：Cancer Cell</p><p>时间：December 10, 2018</p><p>链接: <a href="https://doi.org/10.1016/j.ccell.2018.10.016" target="_blank" rel="noopener">https://doi.org/10.1016/j.ccell.2018.10.016</a></p><p><strong>figure</strong></p><p><img src="/2019/10/26/1866/abstract.png" style="zoom:50%;"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>这篇文章发表于2018年12月，由丹麦哥本哈根大学和德国海德堡大学主导完成，文章利用前列腺癌早期的分子进化特征鉴定前列腺癌不同等级风险的标志物和临床发展轨迹，主要结果包括4个方面：</p><ul><li>APOBEC3的类时钟（clock-like）突变过程介导了前列腺癌（Prostate Cancer，PC）的早期突变</li><li>鉴定出能够区分中等危险疾病（intermediate-risk）的四个分子亚群</li><li><em>ESRP1</em>位点的重排与癌症的侵袭性和增殖性相关</li><li>开发了利用DNA测序数据预测PC临床轨迹的方法</li></ul><p>文中用到的数据包括WGS，450K 甲基化以及RNA-seq共292个前列腺癌样本，当然不同数据类型的样本并不是一一对应的，另外还用到了公共的Hi-C数据（具体数据来源在文中还没有找到）。</p><blockquote><p>注：EOPC(early-onset PC): 早期前列腺癌； LOPC(late-onset PC): 晚期前列腺癌</p></blockquote><table><thead><tr><th>数据类型</th><th>EOPC 样本数</th><th>LOPC样本数</th></tr></thead><tbody><tr><td>WGS</td><td>184</td><td>85</td></tr><tr><td>Methylomes(450K)</td><td>203</td><td>45</td></tr><tr><td>mRNA-seq</td><td>96</td><td></td></tr><tr><td>Hi-C data</td><td></td></tr></tbody></table><h3 id="作者利用这些数据进行了什么分析呢"><a href="#作者利用这些数据进行了什么分析呢" class="headerlink" title="作者利用这些数据进行了什么分析呢"></a>作者利用这些数据进行了什么分析呢</h3><h4 id="首先鉴定EOPC的体细胞突变模式"><a href="#首先鉴定EOPC的体细胞突变模式" class="headerlink" title="首先鉴定EOPC的体细胞突变模式"></a>首先鉴定EOPC的体细胞突变模式</h4><p><strong>通过somatic和germline的call变异流程，分析SNVs、InDels和SVs。</strong> 从SNVs的结果来看，与以前研究的结果一致，前列腺癌的SNVs非常低；EOPC与LOPC相比，EOPC的SNVs数量低于LOPC(平均每M b的SNVs数量，EOPC=0.47,LOPC=0.53)，其中EOPC中<em>TP53</em>的变异率最高。SVs是前列腺癌出现频率较高的变异，SVs常与PC中肿瘤抑制基因的反复融合的形成或丢失有关。基于此作者鉴定了<strong>复发性基因组变异位点（recurrent genomic altered loci ，RGA)</strong>，结果揭示70%的EOPC携带的SV与ETS融合基因的形成有关，EOPC中第二、三易变异的位点分别是8号染色体的<em>NKX3-1</em>和3号染色体的<em>FOXP1</em>基因附近。为了鉴定RGAs与年龄的关系（即RGAs与前列腺癌发展的早期阶段和晚期阶段的关联），作者继续对LOPC做了对应的基因组变异分析，结果显示LOPC中RGAs的整体比例高于EOPC，另外EOPC中展现出较高的单克隆结构，表明EOPC可能主要与克隆起源有关。</p><p><strong>肿瘤发展的过程常伴随这表观结构的变异，如DNA双链的开放和紧密压缩状态的改变。</strong>实验室之前的研究发现EOPC基因组中<strong>断裂点(breakpoits)</strong>常出现在雄性激素受体结合位点(AR-binding sites)附近，这增加了年龄相关的染色质状态改变影响断点发生的可能性。因此，他们整合公共的Hi-C数据检测与特定染色质区域相关的EOPC基因组断裂点，发现断裂点与染色质loop和H3K27ac peaks的数量显著相关。表明EOPC的断裂点主要出现在染色质开放区域，与活性元件相关；LOPC断裂点主要出现在异染色质区域。</p><p><img src="/2019/10/26/1866/fig1.png" style="zoom:50%;"></p><blockquote><p><strong>小结：</strong>这一部分主要利用基因组数据分析前列腺癌早期和晚期的变异特征（SNVs,InDels和SVs）。展示了EOPC和LOPC中断裂点的不同的分布特征，以及与染色质状态的变化。</p></blockquote><blockquote><p><strong>疑问：</strong>有两个概念不怎么理解，一个是RGA，一个是breakpoints，而这两个概念又是这篇文中分析的重点内容。</p></blockquote><blockquote><ul><li>RGAs(recurrent genomic altered loci ): 字面意思<em>反复出现的基因组变异位点</em>，文中说SVs常与PC中肿瘤抑制基因的反复融合的形成或丢失有关，基于此作者鉴定了RGAs。RGAs是否是染色质结构变异中的DNA重排呢？与SV以及融合基因有什么关联？如何鉴定RGAs呢？</li><li>Genome Breakpoints：基因组断裂点。B图（瀑布图）中对变异类型的描述中有个break，可能和Genome Breakpoints有关，是一个变异类型？那么和loss, gain，mutation有什么区别呢？查阅资料发现breakpoints结各种结构变异类型分析中的一个概念</li><li>另外文中说做了germline和somatic的call变异，但只提供了WGS数据，为什么没有WES数据？只用WGS进行的somatic variants的分析吗？</li></ul></blockquote><h4 id="DNA重排分析"><a href="#DNA重排分析" class="headerlink" title="DNA重排分析"></a>DNA重排分析</h4><p><strong>DNA重排是结构变异的一个形式。作者鉴定到EOPC中有两个RGAs位于13q22和8q22。</strong> 13q22的最小重叠峰区域以KLF5为中心，以往的研究表明KLF5编码一个参与抑制细胞增殖的转录激活因子, 13q22的丢失与KLF5 mRNA水平的降低以及SV和SNV负荷的整体增加有关。该研究发现KLF5与<em>SPOP</em>（有一个鼠的胚胎干细胞研究中发现<em>SPOP</em>是KLF5的一个靶基因，是一个泛素连接酶基因） mRNA表达水平呈正相关关系，但是与<em>SPOP</em>的突变无关。</p><p>8q22处的一个区域显示以<em>ESRP1</em>为中心的反复基因组复制，最小重叠峰区域在<em>MYC</em>附近。这些重复与<em>ESRP1</em>和<em>MYC</em>都有重叠，但只有<em>ESRP1</em>在PC样本中显示出显著的mRNA水平增加。此外，<em>ESRP1</em>重排与格里森评分（GS，前列腺癌评估的一个重要指标）升高显著相关。ESRP1蛋白水平的升高与增殖率升高相关。另外发现其可以作为一个独立的预后标志物。</p><blockquote><p><strong>小结：</strong> 根据DNA重排分析，发现ESRP1重排与ESRP1蛋白表达增加、细胞增殖水平升高、GS和肿瘤分期升高有关，并证明ESRP1表达是PC中一个独立的预后生物标记物。</p></blockquote><blockquote><p><strong>基因组变异的背景知识</strong></p><ul><li>单碱基变异，即单核苷酸多态性(SNP)，最常见也最简单的一种基因组变异形式；</li><li>很短的Insertion 和 Deletion，也常被我们合并起来称为Indel。主要指在基因组某个位置上发生较短长度的<strong>线性片段</strong>插入或者删除的现象。强调<strong>线性</strong>的原因是，这里的插入和删除是<strong>有前后顺序的</strong>与下述的结构性变异不同。Indel长度通常在50bp以下，更多时候甚至是不超过10bp，这个长度范围内的序列变化可以通过Smith-Waterman 的局部比对算法来<strong>准确</strong>获得，并且也能够在目前短读长的测序数据中较好地检测出来</li><li><strong>基因组结构性变异</strong>（Structure Variantions，简称SVs），这篇文章的重点，通常就是指基因组上大长度的序列变化和位置关系变化。类型很多，包括长度在50bp以上的长片段序列插入或者删除（Big Indel）、串联重复（Tandem repeate）、染色体倒位（Inversion）、染色体内部或染色体之间的序列易位（Translocation）、拷贝数变异（CNV）以及形式更为复杂的嵌合性变异。</li></ul><p><strong>参考来源</strong>：碱基矿工黄树嘉老师的文章—<a href="https://zhuanlan.zhihu.com/p/40290546" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/40290546</a></p><p><strong>经典的SVs综述：</strong></p><ul><li>Alkan, C., Coe, B. P. &amp; Eichler, E. E. Genome structural variation discovery and genotyping. <em>Nature reviews. Genetics**</em>12**, 363–76.</li></ul></blockquote><p><img src="/2019/10/26/1866/fig2.png" style="zoom:50%;"></p><h4 id="突变特征（mutational-signature-分析"><a href="#突变特征（mutational-signature-分析" class="headerlink" title="突变特征（mutational signature)分析"></a>突变特征（mutational signature)分析</h4><p><strong>突变信号(mutational signature)可以用来描述作用于肿瘤细胞的内源性和外源性介导的突变过程。</strong>通过突变特征的分析发现APOBEC3的类时钟（clock-like）突变过程介导了PC的早期突变，APOBEC3蛋白是一种胞苷脱氨酶，在单链DNA复制周期中起到限制反转录因子的作用，但也可以诱导癌症基因组的突变。</p><p><img src="/2019/10/26/1866/fig3.png" style="zoom:50%;"></p><blockquote><p><strong>背景知识</strong></p><p><strong>mutaional signature: </strong> 下文内容来自：作者-ksxg ，公众号BioKSXG，文章题目：看文献，详解Mutational signatures（突变指标/签名/特征）</p><p>不同的体细胞突变过程会产生各种结果，不同的突变过程产生突变类型的独特组合,称为“Mutational Signatures”。截止到2018年已经有30种定义的Mutational Signatures：</p><table><thead><tr><th style="text-align:left">Signature</th><th style="text-align:left">涉及的癌症种类</th><th style="text-align:left">病因学</th><th style="text-align:left">额外的突变特征</th><th style="text-align:left">Comments</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left">所有癌症，大部分样品</td><td style="text-align:left">5-甲基胞嘧啶脱氨基作用自发的内源性突变过程导致</td><td style="text-align:left">小数量的小插入和在大多数组织类型的删除</td><td style="text-align:left">与诊断年龄相关</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left">主要在子宫癌和膀胱癌</td><td style="text-align:left">AID/APOBEC家族的胞嘧啶核苷脱氨酶的活动</td><td style="text-align:left">观察到外显子中转录链偏差的突变,但是在内含子中不存在或者较弱</td><td style="text-align:left">2和13常在同一样本中被鉴定出，常伴随kataegis突变机制</td></tr><tr><td style="text-align:left">3</td><td style="text-align:left">乳腺癌、卵巢癌、胰腺癌</td><td style="text-align:left">通过同源重组的DNA双链断裂修复</td><td style="text-align:left">断点连接中活跃的大片段（大于3bp）插入和删除，伴随着重叠的微同源序列</td><td style="text-align:left">乳腺癌、胰腺癌和卵巢癌中生殖系和体细胞的BRCA1和BRCA2突变，特别是胰腺癌中铂疗法</td></tr><tr><td style="text-align:left">4</td><td style="text-align:left">头颈癌、肝癌、肺腺癌、肺鳞癌、小细胞肺癌、食道癌</td><td style="text-align:left">吸烟相关，烟草诱变剂</td><td style="text-align:left">偏向C &gt;A突变,也与CC &gt; AA二核苷酸替换相关</td><td style="text-align:left">29也与烟草咀嚼相关癌症有关，但是与4不同</td></tr><tr><td style="text-align:left">5</td><td style="text-align:left">所有癌症，大部分样品</td><td style="text-align:left">未知</td><td style="text-align:left">T &gt; C替换（ApTpN）</td><td style="text-align:left">无</td></tr><tr><td style="text-align:left">6</td><td style="text-align:left">17种癌症，但主要在结直肠和子宫癌症</td><td style="text-align:left">DNA错配修复缺陷和微卫星不稳定的肿瘤</td><td style="text-align:left">单核/多核苷酸重复中活跃的小片段（小于3bp）的插入和删除</td><td style="text-align:left">4和15、20、26属于DNA错配修复缺陷相关的四大mutational signature</td></tr><tr><td style="text-align:left">7</td><td style="text-align:left">皮肤癌,头部和口腔鳞状上皮癌</td><td style="text-align:left">紫外线暴露</td><td style="text-align:left">大量的CC &gt; TT二核苷酸突变，被转录的核苷酸切除修复嘧啶突变</td><td style="text-align:left">无</td></tr><tr><td style="text-align:left">8</td><td style="text-align:left">乳腺癌和成神经管细胞瘤</td><td style="text-align:left">微弱的C &gt;A替换,与双核苷酸替换,尤其是CC &gt; AA相关</td><td style="text-align:left">未知</td><td style="text-align:left">无</td></tr><tr><td style="text-align:left">9</td><td style="text-align:left">慢性淋巴细胞白血病和恶性B细胞淋巴瘤</td><td style="text-align:left">聚合酶η引起的突变模式，涉及体细胞超突变的活动</td><td style="text-align:left">未知</td><td style="text-align:left">9中，与那些没有超突变的免疫球蛋白基因相比，具有免疫球蛋白基因超突变(IGHV-mutated)的慢性淋巴细胞白血病有大量突变</td></tr><tr><td style="text-align:left">10</td><td style="text-align:left">六种癌症,尤其是肠癌和子宫癌,通常会在一小部分样品中产生大量的突变</td><td style="text-align:left">容易出错的聚合酶极的活动，10中有大量的复发性杆体细胞突变,即Pro286Arg Val411Leu</td><td style="text-align:left">C &gt;A突变(TpCpT)和T &gt; G突变(TpTpT)</td><td style="text-align:left">与大部分突变的癌症样本相关，这个mutational signature定义为ultra-hypermutators（超-超突变子？不懂）</td></tr><tr><td style="text-align:left">11</td><td style="text-align:left">黑色素瘤和胶质母细胞瘤</td><td style="text-align:left">类似于烷化剂的突变模式</td><td style="text-align:left">强烈的C &gt; T替换，能被转录的核苷酸切除有效修复</td><td style="text-align:left">无</td></tr><tr><td style="text-align:left">12</td><td style="text-align:left">肝癌</td><td style="text-align:left">未知</td><td style="text-align:left">强烈的T &gt; C替换</td><td style="text-align:left">12在肝癌样本中突变率较小（&lt;20%）</td></tr><tr><td style="text-align:left">13</td><td style="text-align:left">22种癌症中，常见于宫颈和膀胱癌</td><td style="text-align:left">AID/ APOBEC家族的胞嘧啶核苷脱氨酶将胞嘧啶转化为尿嘧啶活动引起的，尤其是APOBEC1, APOBEC3A 和/或者 APOBEC3B，13导致显著的C &gt; G突变</td><td style="text-align:left">观察到外显子中转录链偏差的突变,但是在内含子中不存在或者较弱</td><td style="text-align:left">经常和2在同一样品中被鉴定出，病毒感染、逆转录转座子跳跃或组织炎症引起的AID/ APOBEC胞嘧啶核苷脱氨酶激活，常伴随kataegis突变机制</td></tr><tr><td style="text-align:left">14</td><td style="text-align:left">四种子宫癌症和一种成人轻度神经胶质瘤样本</td><td style="text-align:left">未知</td><td style="text-align:left">未知</td><td style="text-align:left">在所有样本中都有较高的体细胞突变数（每MB大于200个突变）</td></tr><tr><td style="text-align:left">15</td><td style="text-align:left">几种胃癌症和一种小细胞肺癌</td><td style="text-align:left">DNA错配修复缺陷相关</td><td style="text-align:left">单核/多核苷酸重复中活跃的小片段（小于3bp）的插入和删除</td><td style="text-align:left">15和6、20、26属于DNA错配修复缺陷相关的四大mutational signature</td></tr><tr><td style="text-align:left">16</td><td style="text-align:left">肝癌</td><td style="text-align:left">未知</td><td style="text-align:left">强烈的T &gt; C替换</td><td style="text-align:left">无</td></tr><tr><td style="text-align:left">17</td><td style="text-align:left">食管肿瘤、乳腺癌、肝癌、肺腺癌,B细胞淋巴瘤、胃癌和黑色素瘤</td><td style="text-align:left">未知</td><td style="text-align:left">未知</td><td style="text-align:left">无</td></tr><tr><td style="text-align:left">18</td><td style="text-align:left">神经母细胞瘤。此外还在乳腺癌和胃癌癌被观察到</td><td style="text-align:left">未知</td><td style="text-align:left">未知</td><td style="text-align:left">无</td></tr><tr><td style="text-align:left">19</td><td style="text-align:left">只在纤维状细胞的星形细胞瘤</td><td style="text-align:left">未知</td><td style="text-align:left">未知</td><td style="text-align:left">无</td></tr><tr><td style="text-align:left">20</td><td style="text-align:left">胃和乳腺癌</td><td style="text-align:left">DNA错配修复缺陷相关</td><td style="text-align:left">单核/多核苷酸重复中活跃的小片段（小于3bp）的插入和删除</td><td style="text-align:left">20和6、15、26属于DNA错配修复缺陷相关的四大mutational signature</td></tr><tr><td style="text-align:left">21</td><td style="text-align:left">只在胃癌</td><td style="text-align:left">未知</td><td style="text-align:left">未知</td><td style="text-align:left">只在来自同一测序中心的四个样本中被发现，与26有一些类似，只在有15和20的样本中被发现，可能与微卫星不稳定的肿瘤相关</td></tr><tr><td style="text-align:left">22</td><td style="text-align:left">肾盂移行细胞癌</td><td style="text-align:left">发现于马兜铃酸癌症样本</td><td style="text-align:left">活跃的T&gt;A突变，表明腺嘌呤损伤被转录的核苷酸切除修复</td><td style="text-align:left">移行细胞癌中突变很高，但在肝癌很低</td></tr><tr><td style="text-align:left">23</td><td style="text-align:left">仅在一例肝癌样品中</td><td style="text-align:left">未知</td><td style="text-align:left">强烈的C &gt; T替换</td><td style="text-align:left">无</td></tr><tr><td style="text-align:left">24</td><td style="text-align:left">肝癌的子集</td><td style="text-align:left">黄曲霉毒素暴露</td><td style="text-align:left">活跃的C &gt;A突变，表明鸟嘌呤损伤被转录的核苷酸切除修复</td><td style="text-align:left">无</td></tr><tr><td style="text-align:left">25</td><td style="text-align:left">霍奇金淋巴瘤</td><td style="text-align:left">未知</td><td style="text-align:left">活跃的T&gt;A突变</td><td style="text-align:left">仅在何杰金氏细胞系中被鉴定出，没有原发霍奇金淋巴瘤的数据</td></tr><tr><td style="text-align:left">26</td><td style="text-align:left">乳腺癌、宫颈癌、胃癌、子宫癌</td><td style="text-align:left">DNA错配修复缺陷相关</td><td style="text-align:left">单核/多核苷酸重复中活跃的小片段（小于3bp）的插入和删除</td><td style="text-align:left">26和6、15、20属于DNA错配修复缺陷相关的四大mutational signature</td></tr><tr><td style="text-align:left">27</td><td style="text-align:left">肾透明细胞癌的子集</td><td style="text-align:left">未知</td><td style="text-align:left">活跃的T&gt;A突变，断点连接中活跃的大片段（大于3bp）插入和删除，伴随着重叠的微同源序列</td><td style="text-align:left">无</td></tr><tr><td style="text-align:left">28</td><td style="text-align:left">胃癌的子集</td><td style="text-align:left">未知</td><td style="text-align:left">未知</td><td style="text-align:left">无</td></tr><tr><td style="text-align:left">29</td><td style="text-align:left">仅在齿龈颊口腔鳞状细胞癌</td><td style="text-align:left">烟草咀嚼习惯相关的样本</td><td style="text-align:left">偏向C &gt;A突变,也与CC &gt; AA二核苷酸替换相关</td><td style="text-align:left">4也与烟草咀嚼相关癌症有关，但是与29不同</td></tr><tr><td style="text-align:left">30</td><td style="text-align:left">乳腺癌一小部分子集</td><td style="text-align:left">未知</td><td style="text-align:left">未知</td><td style="text-align:left">无</td></tr></tbody></table></blockquote><h4 id="肿瘤纯度与甲基化联合分析"><a href="#肿瘤纯度与甲基化联合分析" class="headerlink" title="肿瘤纯度与甲基化联合分析"></a>肿瘤纯度与甲基化联合分析</h4><p>正常人前列腺组织由基底细胞、管腔细胞和基质细胞组成，而PC则失去基底细胞，获得肿瘤特异性管腔（T-管腔）细胞和浸润性免疫细胞。考虑到DNA甲基化图谱是细胞类型（cell type,ct）特异性的，作者试图通过使用可用的参考甲基化图谱来解释甲基化分析中ct组成的差异。为此，他们从良性前列腺增生患者和前列腺癌患者中获取了额外的切除样本，并进行荧光激活细胞分类，以识别前列腺癌中存在的主要ct，这使他们能够识别前列腺癌基因组中每个甲基化位点的ct特征。</p><p>他们发现在高GS肿瘤中，基底细胞和管腔细胞向T管腔细胞和浸润性免疫细胞的反复转移。鉴于T-管腔和免疫细胞含量在鉴别高级别肿瘤中的相关性，他们将此信息合并为前列腺癌肿瘤侵袭性的经纯度调整的表观遗传指数（PEPCI）。他们发现高PEPCI与高pt、高GS和BCR风险增高密切相关。此外，PEPCI能够对中等风险病例进行分层，并且他们在主要LOPC样本的TCGA队列中验证了这一点。最后，我们的PEPCI评分也能够独立预测GS和BCR。</p><p><img src="/2019/10/26/1866/fig4.png" style="zoom:50%;"></p><blockquote><p>小结：将肿瘤纯度分析与甲基化分析结合分析，提出经纯度调整的表观遗传指数值（PEPCI），证明了PEPCI可以区别不同等级风险PC。</p></blockquote><blockquote><p><strong>需补充的知识：</strong></p><ul><li>肿瘤纯度的分析</li><li>这篇文章提出的PEPCI</li></ul></blockquote><h4 id="整合分析鉴定肿瘤发展的分子亚型"><a href="#整合分析鉴定肿瘤发展的分子亚型" class="headerlink" title="整合分析鉴定肿瘤发展的分子亚型"></a>整合分析鉴定肿瘤发展的分子亚型</h4><p>他们利用CLICK算法对96个病人的mRNA-seq数据进行分析，将共表达基因共分成7个不同的CLICK clusters(CC)。然后整合CC表达谱与ct比例以及PEPCI的信息的综合分析将患者分为四个与预后相关的亚组，其在生物学通路的表达上有明显差异。</p><p><img src="/2019/10/26/1866/fig5.png" style="zoom:50%;"></p><blockquote><p>需补充的知识：</p><ul><li>CLICK的聚类方法</li></ul></blockquote><h4 id="预测肿瘤演化顺序的计算方法"><a href="#预测肿瘤演化顺序的计算方法" class="headerlink" title="预测肿瘤演化顺序的计算方法"></a>预测肿瘤演化顺序的计算方法</h4><p>他们开发了一种基于条件概率的网络模型PRESCIENT (prediction of sequential changes in the evolution of nascent tumors——预测新生肿瘤演化的顺序变化），用于预测PC和相关临床outcom中体细胞事件的时间序列。</p><p><img src="/2019/10/26/1866/fig6.png" style="zoom:50%;"></p><blockquote><p>需补充的知识：理解PRESCIENT模型</p></blockquote><p><strong>碎碎念</strong></p><ul><li><p>最后再对这篇文章做一个总结：</p><p>这篇文章通过292个前列腺癌样本的WGS，450K 甲基化以及RNA-seq数据以及公共的Hi-C数据，发现早期前列腺癌的分子进化特征可以鉴定前列腺癌不同等级风险的标志物和临床发展轨迹。1）文中首先利用基因组数据分析前列腺癌早期和晚期的变异特征（包括SNVs,InDels和SVs），展示了EOPC和LOPC中断裂点的不同分布特征，以及与染色质状态的变化。2）由于SVs是前列腺癌出现频率较高的变异，所以文中主要做的是SVs相关的分析。基因组重排的分析主要结果是发现了<em>ESRP1</em>位点的重排与癌症的侵袭性和增殖性相关。3）mutational signature的分析发现APOBEC3的类时钟（clock-like）突变过程介导了前列腺癌（Prostate Cancer，PC）的早期突变。4）将肿瘤纯度分析与甲基化分析结合，提出经纯度调整的表观遗传指数值的方法（PEPCI），证明了PEPCI可以区别不同等级风险PC。5）利用CLICK算法对96个病人的mRNA-seq数据进行共表达基因聚类分析，然后整合细胞纯度分析以及PEPCI的信息，将患者分为四个与预后相关的亚组，其在生物学通路的表达上有明显差异。6）开发了一种基于条件概率的网络模型PRESCIENT (prediction of sequential changes in the evolution of nascent tumors——预测新生肿瘤演化的顺序变化），用于预测PC和相关临床outcom中体细胞事件的时间序列。</p><p>开发的预测新生肿瘤演化顺序的方法——PRESCIENT ：</p><ul><li>PRESCIENT：<a href="https://bitbucket.org/weischenfeldt/prescient/src/master/" target="_blank" rel="noopener">https://bitbucket.org/weischenfeldt/prescient/src/master/</a></li></ul></li></ul><p>总之，这篇文章可以作为对肿瘤分子进化特征与肿瘤早期诊断研究感兴趣的参考，文中涉及的方法和开发的新方法也值得学习。</p><ul><li><p>断断续续花了两天时间才看懂了这篇文章的思路框架，方法部分还没有认真细看。粗略估计看懂这篇cancer cell的文章，包括文章思路和结果以及方法，可能需要一个星期的时间。另外一个对我来说这篇文章难于理解的原因是背景知识的缺乏，如结构变异（SVs）的理解，分析原理和方法，以及肿瘤相关方面的背景知识缺乏，我之前是不知道mutaion signature的，也不知道肿瘤中常见的肿瘤纯度，肿瘤进化等是如何分析的，虽然听说过这几个概念，也常见这样的帖子，但是都没有细看。不过认真看一篇文章，学到的知识点真多，以后再看相关的其他文章就有了背景知识。</p></li><li><p>方法学下次更新</p></li></ul><p>> 每日文献摘要：第11篇 2019年10月26日 周六</p>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tumor evolution </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基础常见的条形图</title>
      <link href="/2019/10/24/2586.html"/>
      <url>/2019/10/24/2586.html</url>
      
        <content type="html"><![CDATA[<p>今天已进入24节气中的霜降，《二十四节气解》中说：“气肃而霜降，阴始凝也。”可见“霜降”表示天气逐渐变冷，开始降霜。北京的天气也格外应景，从早上就开始淅淅沥沥下雨，呆在屋里，甚至窝在被窝里，都感觉凉凉的。时间过得真快，刚毕业的时候还是三伏天的夏季，转眼又在北京迎来了冬季～</p><p><img src="/2019/10/24/2586/abstract2.jpg" style="zoom:50%"></p><a id="more"></a><p>条形图是常见的一种数据可视化方式，常用于表示类变量（x)对应的数值（y）。这里以ggplot2示例展示如何设置绘制简单的bar plot，如何设置其他图形参数，以及进阶的bar plot示例展示。</p><p><strong>ggplot2中绘制条形图的函数有<code>geom_col()</code>和<code>geom_bar()</code></strong>。</p><h3 id="条形图的填充色，边框色，背景色和背景框线的设置"><a href="#条形图的填充色，边框色，背景色和背景框线的设置" class="headerlink" title="条形图的填充色，边框色，背景色和背景框线的设置"></a>条形图的填充色，边框色，背景色和背景框线的设置</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 简单的条形图 (左图)</span></span><br><span class="line">ggplot(pg_mean, aes(x = group, y = weight)) +</span><br><span class="line">  geom_col()</span><br><span class="line"></span><br><span class="line"><span class="comment">## 条形的填充色，边框，背景色和框线的设置 （右图）</span></span><br><span class="line">ggplot(pg_mean, aes(x = group, y = weight)) +</span><br><span class="line">  geom_col(fill=<span class="string">"lightblue"</span>, colour = <span class="string">"black"</span>) + <span class="comment">#设置条形的填充颜色fill, 边框颜色colour</span></span><br><span class="line">  theme_bw() +  <span class="comment"># 去掉背景颜色                          </span></span><br><span class="line">  theme( panel.grid.major.x = element_blank(),  <span class="comment"># 去掉背景框线</span></span><br><span class="line">         panel.grid.major.y = element_blank()</span><br><span class="line">         )</span><br></pre></td></tr></table></figure><p><img src="/2019/10/24/2586/fig1.png" style="zoom:50%;"></p><h3 id="填充色设置和变量排序"><a href="#填充色设置和变量排序" class="headerlink" title="填充色设置和变量排序"></a>填充色设置和变量排序</h3><p>非默认的填充色设置可以借助<code>scale_fill_brewer()</code> 或 <code>scale_fill_manual()</code>， 对变量的排序:<code>reorder()</code>函数，这里是基于<code>Change</code>的变化对<code>Abb</code>排序。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 输入数据处理</span></span><br><span class="line"><span class="keyword">library</span>(gcookbook) <span class="comment"># Load gcookbook for the uspopchange data set</span></span><br><span class="line"><span class="keyword">library</span>(dplyr)</span><br><span class="line">upc &lt;- uspopchange %&gt;%</span><br><span class="line">  arrange(desc(Change)) %&gt;%</span><br><span class="line">  slice(<span class="number">1</span>:<span class="number">10</span>)</span><br><span class="line"><span class="comment">## fill()函数以Region 因子变量填充bar的颜色</span></span><br><span class="line">ggplot(upc, aes(x = Abb, y = Change, fill = Region)) +</span><br><span class="line">  geom_col()</span><br><span class="line"></span><br><span class="line"><span class="comment">## scale_fill_brewer() or scale_fill_manual()选择其他颜色，reorder对Abb</span></span><br><span class="line">ggplot(upc, aes(x = reorder(Abb, Change), y = Change, fill = Region)) +</span><br><span class="line">  geom_col(colour = <span class="string">"black"</span>) +</span><br><span class="line">  scale_fill_manual(values = c(<span class="string">"#669933"</span>, <span class="string">"#FFCC66"</span>)) +</span><br><span class="line">  xlab(<span class="string">"State"</span>)</span><br></pre></td></tr></table></figure><p><img src="/2019/10/24/2586/fig2.png" alt></p><h3 id="不同颜色表示正负数值的变化"><a href="#不同颜色表示正负数值的变化" class="headerlink" title="不同颜色表示正负数值的变化"></a>不同颜色表示正负数值的变化</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ggplot(climate_sub, aes(x = Year, y = Anomaly10y, fill = pos)) +</span><br><span class="line">  geom_col(position = <span class="string">"identity"</span>, colour = <span class="string">"black"</span>, size = <span class="number">0.25</span>) +   <span class="comment"># 边框线的颜色colour和宽度size</span></span><br><span class="line">  scale_fill_manual(values = c(<span class="string">"#CCEEFF"</span>, <span class="string">"#FFDDDD"</span>), guide = <span class="literal">FALSE</span>) <span class="comment"># scale_fill_manual() 设置颜色， guide = FALSE 去除legend</span></span><br></pre></td></tr></table></figure><p><img src="/2019/10/24/2586/fig3.png" style="zoom: 33%;"></p><h3 id="一对变量，调整bar的宽度和空间"><a href="#一对变量，调整bar的宽度和空间" class="headerlink" title="一对变量，调整bar的宽度和空间"></a>一对变量，调整bar的宽度和空间</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 一对变量水平同时展示 dodge</span></span><br><span class="line">ggplot(cabbage_exp, aes(x = Date, y = Weight, fill = Cultivar)) +</span><br><span class="line">  geom_col(position = <span class="string">"dodge"</span>, colour = <span class="string">"black"</span>) + <span class="comment"># dodge 映射要填充的变量</span></span><br><span class="line">  scale_fill_brewer(palette = <span class="string">"Pastel1"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 调整bar width 和 dodge位置，默认是0.9</span></span><br><span class="line">ggplot(cabbage_exp, aes(x = Date, y = Weight, fill = Cultivar)) +</span><br><span class="line">  geom_col(width = <span class="number">0.5</span>, colour = <span class="string">"black"</span>,position = position_dodge(<span class="number">0.7</span>)) + </span><br><span class="line">  scale_fill_brewer(palette = <span class="string">"Pastel1"</span>)</span><br></pre></td></tr></table></figure><p><img src="/2019/10/24/2586/fig4.png" style="zoom:50%"></p><h3 id="堆积图"><a href="#堆积图" class="headerlink" title="堆积图"></a>堆积图</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## position_stack(reverse = FALSE) 堆积图的顺序调整，guide_legend(reverse = TRUE)：legend顺序调整</span></span><br><span class="line">ggplot(cabbage_exp, aes(x = Date, y = Weight, fill = Cultivar)) +</span><br><span class="line">  geom_col(position = position_stack(reverse = <span class="literal">FALSE</span>),colour = <span class="string">"black"</span>) +</span><br><span class="line">  guides(fill = guide_legend(reverse = <span class="literal">TRUE</span>))+</span><br><span class="line">  scale_fill_brewer(palette = <span class="string">"Pastel1"</span>)</span><br><span class="line"><span class="comment">## geom_col(position = "fill") 以比例展示每个类型的堆积，堆积图总分值是1</span></span><br><span class="line">ggplot(cabbage_exp, aes(x = Date, y = Weight, fill = Cultivar)) +</span><br><span class="line">  geom_col(position = <span class="string">"fill"</span>,colour = <span class="string">"black"</span>) +</span><br><span class="line">  guides(fill = guide_legend(reverse = <span class="literal">TRUE</span>))+</span><br><span class="line">  scale_fill_brewer(palette = <span class="string">"Pastel1"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## scale_y_continuous(labels = scales::percent) 以百分制表示比例</span></span><br><span class="line">ggplot(cabbage_exp, aes(x = Date, y = Weight, fill = Cultivar)) +</span><br><span class="line">  geom_col(colour = <span class="string">"black"</span>, position = <span class="string">"fill"</span>) +</span><br><span class="line">  scale_y_continuous(labels = scales::percent) +</span><br><span class="line">  scale_fill_brewer(palette = <span class="string">"Pastel1"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## geom_text添加文本</span></span><br><span class="line">ggplot(cabbage_exp, aes(x = Date, y = Weight, fill = Cultivar)) +</span><br><span class="line">  geom_col() +</span><br><span class="line">  geom_text(aes(label = Weight), vjust = <span class="number">2</span>)</span><br></pre></td></tr></table></figure><p><img src="/2019/10/24/2586/fig5.png" style="zoom:50%;"></p><h3 id="圈圈图-Dot-plot"><a href="#圈圈图-Dot-plot" class="headerlink" title="圈圈图 Dot plot"></a>圈圈图 Dot plot</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 图1；dot plot: geom_point()</span></span><br><span class="line"><span class="keyword">library</span>(gcookbook) <span class="comment"># Load gcookbook for the tophitters2001 data set</span></span><br><span class="line">tophit &lt;- tophitters2001[<span class="number">1</span>:<span class="number">25</span>, ] <span class="comment"># Take the top 25 from the tophitters data set</span></span><br><span class="line"></span><br><span class="line">ggplot(tophit, aes(x = avg, y = name)) +</span><br><span class="line">  geom_point()</span><br><span class="line"></span><br><span class="line"><span class="comment">## 图2 排序:reorder</span></span><br><span class="line">ggplot(tophit, aes(x = avg, y = reorder(name, avg))) +</span><br><span class="line">  geom_point(size = <span class="number">3</span>) +  <span class="comment"># Use a larger dot</span></span><br><span class="line">  theme_bw() +</span><br><span class="line">  theme(</span><br><span class="line">    panel.grid.major.x = element_blank(),</span><br><span class="line">    panel.grid.minor.x = element_blank(),</span><br><span class="line">    panel.grid.major.y = element_line(colour = <span class="string">"grey60"</span>, linetype = <span class="string">"dashed"</span>)</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"><span class="comment">## 图3 置换坐标方向</span></span><br><span class="line">ggplot(tophit, aes(x = reorder(name, avg), y = avg)) +</span><br><span class="line">  geom_point(size = <span class="number">3</span>) +  <span class="comment"># Use a larger dot</span></span><br><span class="line">  theme_bw() +</span><br><span class="line">  theme(</span><br><span class="line">    panel.grid.major.y = element_blank(),</span><br><span class="line">    panel.grid.minor.y = element_blank(),</span><br><span class="line">    panel.grid.major.x = element_line(colour = <span class="string">"grey60"</span>, linetype = <span class="string">"dashed"</span>),</span><br><span class="line">    axis.text.x = element_text(angle = <span class="number">60</span>, hjust = <span class="number">1</span>)</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"><span class="comment">## 图4 添加分类颜色</span></span><br><span class="line"><span class="comment"># Get the names, sorted first by lg, then by avg</span></span><br><span class="line">nameorder &lt;- tophit$name[order(tophit$lg, tophit$avg)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Turn name into a factor, with levels in the order of nameorder</span></span><br><span class="line">tophit$name &lt;- factor(tophit$name, levels = nameorder)</span><br><span class="line"></span><br><span class="line">ggplot(tophit, aes(x = avg, y = name)) +</span><br><span class="line">  geom_segment(aes(yend = name), xend = <span class="number">0</span>, colour = <span class="string">"grey50"</span>) +</span><br><span class="line">  geom_point(size = <span class="number">3</span>, aes(colour = lg)) +</span><br><span class="line">  scale_colour_brewer(palette = <span class="string">"Set1"</span>, limits = c(<span class="string">"NL"</span>, <span class="string">"AL"</span>)) +</span><br><span class="line">  theme_bw() +</span><br><span class="line">  theme(</span><br><span class="line">    panel.grid.major.y = element_blank(),   <span class="comment"># No horizontal grid lines</span></span><br><span class="line">    legend.position = c(<span class="number">1</span>, <span class="number">0.55</span>),           <span class="comment"># Put legend inside plot area</span></span><br><span class="line">    legend.justification = c(<span class="number">1</span>, <span class="number">0.5</span>)</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"><span class="comment">## 图5 分面 facet_grid</span></span><br><span class="line">ggplot(tophit, aes(x = avg, y = name)) +</span><br><span class="line">  geom_segment(aes(yend = name), xend = <span class="number">0</span>, colour = <span class="string">"grey50"</span>) +</span><br><span class="line">  geom_point(size = <span class="number">3</span>, aes(colour = lg)) +</span><br><span class="line">  scale_colour_brewer(palette = <span class="string">"Set1"</span>, limits = c(<span class="string">"NL"</span>, <span class="string">"AL"</span>), guide = <span class="literal">FALSE</span>) +</span><br><span class="line">  theme_bw() +</span><br><span class="line">  theme(panel.grid.major.y = element_blank()) +</span><br><span class="line">  facet_grid(lg ~ ., scales = <span class="string">"free_y"</span>, space = <span class="string">"free_y"</span>)</span><br></pre></td></tr></table></figure><p><img src="/2019/10/24/2586/fig6.png" style="zoom: 33%;"></p><p><img src="/2019/10/24/2586/fig7.png" style="zoom: 33%;"></p><p><img src="/2019/10/24/2586/fig8.png" style="zoom: 33%;"></p>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> R </tag>
            
            <tag> 每日一图 </tag>
            
            <tag> visualization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>base plot与ggplot2语法比较</title>
      <link href="/2019/10/23/19911.html"/>
      <url>/2019/10/23/19911.html</url>
      
        <content type="html"><![CDATA[<p>通过base plot和ggplot2的简单实例，直接感受下base plot和ggplot2的语法差别。</p><p><img src="/2019/10/23/19911/abstract.png" style="zoom: 33%;"></p><a id="more"></a><h3 id="条形图"><a href="#条形图" class="headerlink" title="条形图"></a>条形图</h3><ul><li><strong>基本绘图</strong></li></ul><p><strong><code>barplot()</code></strong>是基本绘图中绘制条形图的函数，需要一个向量参数指定bar的高度（必须），每个bar的label是可选参数。</p><p><img src="/2019/10/23/19911/" style="zoom:30%"></p><p><img src="/2019/10/23/19911/" style="zoom:30%"></p><p><img src="/2019/10/23/19911/fig1.png" style="zoom:50%"></p><ul><li><strong>ggplot2</strong></li></ul><p>ggplot2中绘制bar plot使用<strong><code>geom_col</code>或<code>geom_bar</code></strong>, 注意这里使用factor将x变量转换为离散变量。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(ggplot2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Bar graph of values. This uses the BOD data frame, with the</span></span><br><span class="line"><span class="comment"># "Time" column for x values and the "demand" column for y values.</span></span><br><span class="line">ggplot(BOD, aes(x = Time, y = demand)) +</span><br><span class="line">  geom_col()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert the x variable to a factor, so that it is treated as discrete</span></span><br><span class="line">ggplot(BOD, aes(x = factor(Time), y = demand)) +</span><br><span class="line">  geom_col()</span><br></pre></td></tr></table></figure><p><img src="/2019/10/23/19911/fig2.png" style="zoom:50%"></p><p><img src="/2019/10/23/19911/fig3.png" style="zoom:50%"></p><h3 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h3><ul><li><strong>基本绘图</strong></li></ul><p><strong><code>hist</code></strong>是基本绘图中直方图的函数。</p><p><img src="/2019/10/23/19911/fig4.png" style="zoom:50%"></p><ul><li><strong>ggplot2</strong></li></ul><p>ggplot2中绘制直方图使用<strong><code>geom_histogram()</code></strong></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(ggplot2)</span><br><span class="line">ggplot(mtcars, aes(x = mpg)) +</span><br><span class="line">  geom_histogram()</span><br><span class="line"><span class="comment">#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># With wider bins</span></span><br><span class="line">ggplot(mtcars, aes(x = mpg)) +</span><br><span class="line">  geom_histogram(binwidth = <span class="number">4</span>)</span><br></pre></td></tr></table></figure><p><img src="/2019/10/23/19911/fig5.png" style="zoom:50%"></p><h3 id="箱线图"><a href="#箱线图" class="headerlink" title="箱线图"></a>箱线图</h3><ul><li><strong>基本绘图</strong></li></ul><p>箱线图可以直接用<strong><code>plot()</code></strong>函数（如果x变量是factor，会自动产生bo x plot)， 当然也可以用<strong><code>boxplot()</code></strong>函数。如果想在X轴展示两个变量，也是可以的。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plot(ToothGrowth$supp, ToothGrowth$len)</span><br><span class="line"><span class="comment"># Formula syntax</span></span><br><span class="line">boxplot(len ~ supp, data = ToothGrowth)</span><br></pre></td></tr></table></figure><p><img src="/2019/10/23/19911/fig6.png" style="zoom: 33%;"></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Put interaction of two variables on x-axis</span></span><br><span class="line">boxplot(len ~ supp + dose, data = ToothGrowth)</span><br></pre></td></tr></table></figure><p><img src="/2019/10/23/19911/fig7.png" style="zoom: 33%;"></p><ul><li><strong>ggplot2</strong></li></ul><p>ggplot2使用<strong><code>geom_boxplot()</code></strong> 函数，x轴展示两个变量时可以用<strong><code>interaction()</code></strong>函数</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(ggplot2)</span><br><span class="line">ggplot(ToothGrowth, aes(x = supp, y = len)) +</span><br><span class="line">  geom_boxplot()</span><br></pre></td></tr></table></figure><p><img src="/2019/10/23/19911/fig8.png" style="zoom: 33%;"></p><p><strong>x轴展示两个变量</strong></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ggplot(ToothGrowth, aes(x = interaction(supp, dose), y = len)) +</span><br><span class="line">  geom_boxplot()</span><br></pre></td></tr></table></figure><p><img src="/2019/10/23/19911/fig9.png" style="zoom: 33%;"></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li><p><strong>条形图、直方图、箱线图的区别</strong></p><p>条形图x和y变量是一对一的关系，绘图时必须传递y变量。直方图是频率分布图，箱线图x变量对应的y变量有多个值。</p></li><li><p>Base plot和ggpplot2的绘图特征</p><p>Base plot直接指定变量参数即可，ggplot2的语法通常包括3个部分，首先是数据框，然后以aes指定参数变量，再加上图形的类型，如geom_boxplot等</p></li><li><p>箱线图展示一对变量的特征</p></li></ul><p>如果用base plot实现，可以直接在x参数变量后加上另一个参数，如果是ggplot2，借助interaction()将一对变量添加。</p><p>个人感觉这里base plot画的图更简单好看。</p>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> R </tag>
            
            <tag> 每日一图 </tag>
            
            <tag> visualization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>千里之行始于足下_R Basics</title>
      <link href="/2019/10/22/60156.html"/>
      <url>/2019/10/22/60156.html</url>
      
        <content type="html"><![CDATA[<p>坚持做一件事很难，总会被最初的意外和后来的惰性扰乱而半路放弃。今天看到几句话，感觉说到心窝里了:</p><p><strong>规律地做一些事情，据说可以增加对生活的掌控感，从而缓解焦虑。</strong></p><p><strong>对时间最好的利用，就是做自己想做的事情，并且全身心的享受每一刻。</strong></p><p><img src="/2019/10/22/60156/abstract.jpg" style="zoom:30%"> </p><a id="more"></a><p>这里就立一个Flag：<strong>每日一图</strong>，每天至少专注的做一件自己喜欢做的想做的事情。</p><p>这里就以<a href="https://mp.weixin.qq.com/s/CX_fwbuyPTelOgaj7852qg" target="_blank" rel="noopener">推荐三本学习R画图的免费好书</a>推荐的第一本书起航吧：<strong>R G raphics Cookbook</strong></p><p>这本书主要基于ggplot2的绘图语法，以及tidyverse的数据清理方法。书中使用的数据和例子整合在<strong>gcookbook</strong></p><h4 id="所以首先安装载入需要的R包"><a href="#所以首先安装载入需要的R包" class="headerlink" title="所以首先安装载入需要的R包"></a>所以首先安装载入需要的R包</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">install.packages(c(<span class="string">"ggplot2"</span>, <span class="string">"gcookbook"</span>, <span class="string">"MASS"</span>, <span class="string">"dplyr"</span>,<span class="string">"tidyverse"</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">library</span>(tidyverse)</span><br><span class="line"><span class="keyword">library</span>(gcookbook)</span><br><span class="line"><span class="keyword">library</span>(ggplot2)</span><br><span class="line"><span class="keyword">library</span>(dplyr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># update</span></span><br><span class="line">update.packages()</span><br></pre></td></tr></table></figure><h4 id="base-plot与ggplot2的简单实例对比"><a href="#base-plot与ggplot2的简单实例对比" class="headerlink" title="base plot与ggplot2的简单实例对比"></a>base plot与ggplot2的简单实例对比</h4><p><strong>Scatter plot</strong> </p><p>使用plot函数，仅需传递给plot两个变量：<strong>x, y</strong></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot(mtcars$wt, mtcars$mpg)</span><br></pre></td></tr></table></figure><p>使用ggplot2, 首先创建一个plot 对象，然后加一个点的图层。ggplot2通常以数据框为画图对象（<code>mtcars</code>)，然后指明哪列是<code>x</code>, 哪列是<code>y</code>。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(ggplot2)</span><br><span class="line">ggplot(mtcars, aes(x = wt, y = mpg)) +</span><br><span class="line">  geom_point()</span><br></pre></td></tr></table></figure><p><img src="/2019/10/22/60156/fig1.png" alt></p><p><strong>Line Graph</strong></p><p>Base plot新增line时，第一次以plot函数，第二次lines函数</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 左图</span></span><br><span class="line">plot(pressure$temperature, pressure$pressure, type = <span class="string">"l"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 右图</span></span><br><span class="line">plot(pressure$temperature, pressure$pressure, type = <span class="string">"l"</span>)</span><br><span class="line">points(pressure$temperature, pressure$pressure)</span><br><span class="line"></span><br><span class="line">lines(pressure$temperature, pressure$pressure/<span class="number">2</span>, col = <span class="string">"red"</span>)</span><br><span class="line">points(pressure$temperature, pressure$pressure/<span class="number">2</span>, col = <span class="string">"red"</span>)</span><br></pre></td></tr></table></figure><p><img src="/2019/10/22/60156/fig2.png" alt></p><p>ggplot2对图像的图形的选择需加上geom_line()，或者geom_point()</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 左图</span></span><br><span class="line"><span class="keyword">library</span>(ggplot2)</span><br><span class="line">ggplot(pressure, aes(x = temperature, y = pressure)) +</span><br><span class="line">  geom_line()</span><br><span class="line"><span class="comment"># 右图，加points</span></span><br><span class="line">ggplot(pressure, aes(x = temperature, y = pressure)) +</span><br><span class="line">  geom_line() +</span><br><span class="line">  geom_point()</span><br></pre></td></tr></table></figure><p><img src="/2019/10/22/60156/fig3.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> R </tag>
            
            <tag> 每日一图 </tag>
            
            <tag> visualization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scATAC-seq和深度学习联合揭示2型糖尿病的调控特征</title>
      <link href="/2019/09/28/864.html"/>
      <url>/2019/09/28/864.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>scATAC-seq和深度学习联合揭示2型糖尿病的调控特征</p><p><strong>文章信息</strong></p><p>题目：Single cell ATAC-seq in human pancreatic islets and deep learning upscaling of rare cells reveals cell-specific type 2 diabetes regulatory signature</p><p>杂志：bioRxiv</p><p>时间：Sep. 7, 2019</p><p>链接: DOI: <a href="http://dx.doi.org/10.1101/749283" target="_blank" rel="noopener">http://dx.doi.org/10.1101/749283</a></p><p><strong>figure</strong></p><p><img src="/2019/09/28/864/abstrat-fig.png" style="zoom:50%"> </p><a id="more"></a><p><strong>文章介绍：</strong></p><p>II型糖尿病(T2D)是一种以胰岛功能障碍、胰岛素抵抗和血糖紊乱为特征的复杂疾病。全基因组关联研究（GWAS）已经鉴定出超过400个编码遗传倾向的独立信号。超过90%相关的单核苷酸多态性（SNP）定位于非编码区，并富集在染色质定义的胰岛增强子元件中。另外胰岛包含不同的细胞类型，每种细胞类型都有可能参与T2D的转录调控，bulk-seq的方法会掩盖了细胞异质性的特点。所以这里文章采取sci-ATAC-seq (single-cell-combinatorial-indexing ATAC-seq) 的方法，观察到α、β和δ细胞群并识别T2D的细胞特异性的调控信号；另外，他们发现T2D GWAS SNPs显著富集在β细胞，和α或δ细胞与其他细胞类型跨细胞型差异的开放染色质。此外，他们基于U-Net架构还开发了一个深度学习模型用于准确地预测在稀有细胞群体中的开放染色质峰值。</p><p>深度学习的代码： <a href="https://github.com/ParkerLab/PillowNet" target="_blank" rel="noopener">https://github.com/ParkerLab/PillowNet</a>. </p><p>其他代码在：<a href="https://github.com/ParkerLab/islet_sci-ATAC-seq_2019" target="_blank" rel="noopener">https://github.com/ParkerLab/islet_sci-ATAC-seq_2019</a></p><p><strong>碎碎念</strong></p><p>这篇文章结合scATAC-seq和深度学习的方法探究疾病的转录调控特征的思路和以及文章用到的方法值得学习。</p><blockquote><p>每日文献摘要：第10篇 2019年09月28日 周六</p><p>持久确实是一件不易的事！</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> single cell </tag>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>蛋白质体外液液相分离数据库</title>
      <link href="/2019/09/26/13822.html"/>
      <url>/2019/09/26/13822.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>蛋白质体外液液相分离数据库—— LLPSDB</p><p><strong>文章信息</strong></p><p>题目：LLPSDB: a database of proteins undergoing liquid–liquid phase separation in vitro</p><p>杂志：Nucleic Acids Research</p><p>时间：August 28, 2019</p><p>链接: DOI: 10.1093/nar/gkz778</p><p><strong>figure</strong></p><p><img src="/2019/09/26/13822/fig1.png" style="zoom:50%"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>之前分享过一篇文章 <a href="https://www.jianshu.com/p/74bda9d18b35" target="_blank" rel="noopener">火起来的相分离是什么</a>, </p><blockquote><p>相分离/相变（Phase separation）描述的是一种细胞里不同成分间相互碰撞、融合形成液滴，从而使一些成分被包裹在液滴内，一些成分被阻隔在液滴外的现象，类似于水油相混，或者可以想象成下雨天伞上的雨滴逐渐滴落的过程。这种现象在液体之间是常见的，但是，2009年，Brangwynne和Hyman关于线虫P颗粒的研究，发现P颗粒（一种蛋白质）并非像我们通常认为的是一种固体，而是像液滴一样，相互碰撞融合，剧烈摇晃后会分散成很小的液滴，而后又很快地融合形成大液滴。之后科学家发现细胞内的许多无膜细胞器——核仁、Cajal bodies、stress granules、miRISC，及突触的细胞骨架——都是特定的蛋白质/RNA的相变。</p></blockquote><blockquote><p>相分离/相变（Phase separation，Phase Transition）是目前比较火的一个研究领域，已有的研究表明相分离在细胞中普遍存在，与基因组的组装、转录调控可能密切相关，相分离的失调可能是一些疾病（如神经/肌肉退行性疾病）发生的病因，相关领域的科学家也开始通过相分离这个视角重新审视相关疾病，通过干扰异常“相分离”来达到治疗相关疾病的目的。</p></blockquote><p>刚刚明白过相分离是什么，这里已经有人整理出了液液相分离体外蛋白质数据库（(LLPS,Liquid-liquid phase separation)——<a href="http://bio-comp. ucas.ac.cn/llpsdb" target="_blank" rel="noopener"> <strong>LLPSDB </strong></a> </p><p>该数据库提供全面、精心收集的与LLPS有关的蛋白质，以及相应的体外实验条件。<strong>LLPSDB </strong> 目前开放的版本包含<strong>1182个条目，273个独立蛋白和2394个特定条件</strong>。数据库提供多种数据，包括生物分子信息（蛋白质序列、蛋白质修饰、核酸等）、特定相分离信息（实验条件、相行为描述等）和综合注释。<strong>LLPSDB </strong> 是第一个专门为LLPS相关蛋白设计的数据库。它为探索蛋白质序列与相变行为之间的关系提供了大量有价值的资源，并将促进相分离预处理方法的发展，为进一步全面了解LLPS在细胞功能中的作用以及相关疾病提供更多的视角。</p><p><strong>LLPSDB网址</strong>:</p><ul><li><a href="http://bio-comp.ucas.ac.cn/llpsdb" target="_blank" rel="noopener">http://bio-comp.ucas.ac.cn/llpsdb</a></li><li><a href="http://bio-comp.org.cn/llpsdb" target="_blank" rel="noopener">http://bio-comp.org.cn/llpsdb</a></li></ul><blockquote><p>每日文献摘要：第9篇 2019年09月27日 周五</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> database </tag>
            
            <tag> 相分离 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>摘要-单细胞多组学揭示混合表型急性白血病的恶性调控特征</title>
      <link href="/2019/09/26/16514.html"/>
      <url>/2019/09/26/16514.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>单细胞多组学联合分析急性白血病的恶性调控特征</p><p><strong>文章信息</strong></p><p>题目：A single cell framework for multi-omic analysis of disease identifies malignant regulatory signatures in mixed phenotype acute leukemia</p><p>杂志：bioRxiv</p><p>时间：Jul. 9, 2019</p><p>链接: DOI: <a href="http://dx.doi.org/10.1101/696328" target="_blank" rel="noopener">http://dx.doi.org/10.1101/696328</a></p><p><strong>figure</strong></p><p><img src="/2019/09/26/16514/fig-abstract.png" style="zoom:50%"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>单细胞转录组和表观组的整合方法示例，通过比较正常样本和疾病样本转录组和表观组的差异，鉴定调控疾病发生特征。这里以混合表型急性白血病（mixed phenotype acute leukemia，MPAL)为例。首先从健康的外周血和骨髓单个核细胞建立造血发育的免疫表型、转录组和表观遗传学单细胞图。同时在一组混合表型急性白血病（MPAL）临床样本中，从单个细胞中鉴定出癌症特异性转录和染色质特征。测序方法包括droplet-based <strong>CITE-seq</strong> (single-cell antibody derived tag and RNA sequencing) 和 <strong>scATAC-seq </strong>(single-cell chromatin accessibility profiling),以及<strong>scRNA-seq</strong>和<strong>scADT-seq</strong>（antibody derived tag sequencing）</p><p><strong>碎碎念</strong></p><p>借助技术和方法的创新，William J. Greenleaf1对造血系统的正常发育和异常疾病的研究可真多。</p><blockquote><p>每日文献摘要：第8篇 2019年09月27日 周五</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> single cell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>摘要-揭示RNA相关染色质构象的方法——HiChIRP</title>
      <link href="/2019/09/26/60324.html"/>
      <url>/2019/09/26/60324.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>研究RNA与染色质构象相互作用的方法</p><p><strong>文章信息</strong></p><p>题目：HiChIRP reveals RNA-associated chromosome conformation</p><p>杂志：Nature Method</p><p>时间：2019 June</p><p>链接: DOI:10.1038/s41592-019-0407-x</p><p><strong>figure</strong></p><p><img src="/2019/09/26/60324/abstract.png" style="zoom:50%"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>lncRNA作用方式多样，其中有许多lncRNA可以利用它们的模块化结构域结合蛋白质、DNA或其他RNA，使它们能够进行长距离的染色质相互作用。尽管在RNA与染色质相互作用的研究中已取得进展，开发了如<strong><a href="https://www.ncbi.nlm.nih.gov/pubmed/?term=28922346" target="_blank" rel="noopener">GRID-seq</a></strong>、<strong><a href="https://elifesciences.org/articles/27024" target="_blank" rel="noopener">ChAR-seq</a></strong>等方法，但是这些方法只适用于大量的RNA。这里提出的<strong>HiChIRP</strong>方法是利用靶向技术，只关注感兴趣的RNA与染色质的相互作用。</p><p><strong>HiChIRP</strong>用RNA纯化（ChIRP）富集的染色质分离代替HiChIP方案中的染色质免疫沉淀步骤来识别RNA相关的染色质contracts。由于ChIRP（和类似的方法）需要生物素化探针捕获RNA，因此我们在染色体构象捕获(3C)期间将azido修饰的核苷酸并入染色质contacts中，并且在生物素化探针富集RNA之后，含叠氮的染色质contacts受到无铜二苯并环辛(DIBO)“点击”化学作用从而共价结合生物素进行后续的contracts富集。</p><blockquote><p>每日文献摘要：第7篇 2019年09月27日 周五</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scRNA-seq最佳实践分析教程</title>
      <link href="/2019/09/20/63860.html"/>
      <url>/2019/09/20/63860.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>scRNA-seq目前最佳实践分析教程</p><p><strong>文章信息</strong></p><p>题目：<strong>Current best practices in single-cell RNA-seq analysis: a tutorial</strong></p><p>杂志：Molecular systems biology</p><p>时间：Jul. 13, 2019</p><p>链接: doi: <a href="http://dx.doi.org/10.1101/701680" target="_blank" rel="noopener">http://dx.doi.org/10.1101/701680</a></p><p><strong>figure</strong></p><p><img src="/2019/09/20/63860/abstract-fig.png" style="zoom:50%"></p><a id="more"></a><p><strong>文章介绍</strong></p><p>这篇文章通过对单细胞方法的总结，提出了一个目前最佳的实践分析流程，代码在<a href="https://github.com/theislab/single-cell-tutorial。" target="_blank" rel="noopener">https://github.com/theislab/single-cell-tutorial。</a></p><p>单细胞上游分析：raw data 经过处理得到Count 矩阵，然后进行质量控制，标准化，数据矫正，特征选择和可视化</p><p>单细胞下游分析：聚类，marker基因的鉴定，注释，轨迹预测，差异基因，基因调控网络，模块组成等</p><p>常见平台：</p><ul><li>命令行平台：<ul><li>Scater</li><li>Seurat</li><li>Scanpy</li></ul></li><li>图形用户交互平台：<ul><li>Granatum</li><li>ASAP</li><li>FASTGenmics</li></ul></li></ul><p>常用的方法工具：</p><ul><li>Scater: <a href="https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html" target="_blank" rel="noopener">https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html</a></li><li>Seurat:<a href="https://satijalab.org/seurat/vignettes.html" target="_blank" rel="noopener">https://satijalab.org/seurat/vignettes.html</a></li><li>Scanpy: <a href="https://scanpy.readthedocs.io/en/stable/tutorials.html" target="_blank" rel="noopener">https://scanpy.readthedocs.io/en/stable/tutorials.html</a></li></ul><p>教程：</p><ul><li><p>Analysis of single-cell RNA-seq data with R and Bioconductor</p><ul><li><a href="https://github.com/drisso/bioc2016singlecell" target="_blank" rel="noopener">https://github.com/drisso/bioc2016singlecell</a></li></ul></li><li><p>Analysis of single cell RNA-seq data</p><ul><li><a href="https://scrnaseq-course.cog.sanger.ac.uk/website/index.html" target="_blank" rel="noopener">https://scrnaseq-course.cog.sanger.ac.uk/website/index.html</a></li></ul></li><li>Current best-practices in single-cell RNA-seq: a tutorial<ul><li><a href="https://github.com/theislab/single-cell-tutorial" target="_blank" rel="noopener">https://github.com/theislab/single-cell-tutorial</a></li></ul></li></ul><p><strong>碎碎念</strong></p><p>方法更新太快，这里推荐的最佳流程不一定在任何时候都适合，还是要根据目的和具体情况选择</p><blockquote><p>每日文献摘要：第6篇 2019年09月20日 周五</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> single cell </tag>
            
            <tag> scRNA-seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>摘要-单细胞空间转录组整合分析和可视化流程_Giotto</title>
      <link href="/2019/09/20/27557.html"/>
      <url>/2019/09/20/27557.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>单细胞空间转录组分析和可视化流程</p><p><strong>文章信息</strong></p><p>题目：<strong>Giotto, a pipeline for integrative analysis and visualization of single-cell spatial transcriptomic data</strong></p><p>杂志：bioRxiv</p><p>时间：Jul. 13, 2019</p><p>链接: doi: <a href="http://dx.doi.org/10.1101/701680" target="_blank" rel="noopener">http://dx.doi.org/10.1101/701680</a></p><p><strong>figure</strong></p><p><img src="/2019/09/20/27557/fig-abstract.png" style="zoom:50%"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>空间转录组技术有助于研究细胞与其原生的微环境的相互作用，对于理解组织中细胞的身份和功能至关重要。2016年，来自瑞典卡罗琳斯卡研究所和皇家理工学院等机构的研究人员首先开发出空间转录组学（spatial transcriptomics）的高分辨率方法（<a href="https://science.sciencemag.org/content/353/6294/78" target="_blank" rel="noopener">Visualization and analysis of gene expression in tissue sections by spatial transcriptomics</a> ）。2017年，景乃禾研究员和彭广敦研究员研发的空间转录组学技术——Geo-seq发表在《Nature Protocols》。</p><blockquote><p>Geo-seq技术是通过整合与优化单细胞测序和激光显微切割，构建的一种能够获得少量细胞转录组信息、同时保留细胞原有空间位置信息的测序方法。该技术通过激光显微切割可以直观地在组织上直接捕获细胞，每个获取的样本（此技术可以获取低至5个细胞）都保留了位置信息，然后与单细胞转录组测序技术结合，从而完成了高效率、高分辨率的空间转录组分析。</p></blockquote><p>空间转录组学的技术伴随着单细胞技术不断发展，相关分析工具也被相继开发，这篇文章介绍的是对单细胞空间转录组数据进行整合分析和可视化的流程——<strong>Giotto</strong>.</p><p><strong>Giotto</strong>包括两个部分，第一部分是分析空间单细胞转录组数据的详细流程，第二部分是空间单细胞转录组数据的可视化浏览。</p><p>分析部分需要的输入数据是<strong>gene-by-cell count matrix</strong>和每个细胞的空间坐标。分析的内容包括单细胞的常规分析，如：数据预处理、特征选择、降维、聚类等。最重要的是整合了基因表达和空间位置信息。</p><p>可视化部分提供了交互的工作环境，既可以探索分析结果，也可以可视化其他信息如细胞形态、转录本位置等。</p><p><img src="/2019/09/20/27557/fig-2.png" alt></p><p>使用教程：<a href="http://spatial.rc.fas.harvard.edu/giotto-viewer/tutorial.html" target="_blank" rel="noopener">http://spatial.rc.fas.harvard.edu/giotto-viewer/tutorial.html</a></p><p><strong>碎碎念</strong></p><p>空间转录组结合单细胞技术是一个新的热点研究方向</p><blockquote><p>每日文献摘要：第5篇 2019年08月28日 周三</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> single cell </tag>
            
            <tag> spatial transcriptomics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>肿瘤基质边界的酸性微环境与肿瘤迁徙</title>
      <link href="/2019/08/30/26191.html"/>
      <url>/2019/08/30/26191.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>酸性环境改变转录组的变化影响肿瘤的恶性发展</p><p><strong>文章信息</strong></p><p>题目：Acidification of Tumor at Stromal Boundaries Drives Transcriptome Alterations Associated with Aggressive Phenotypes</p><p>杂志：Cancer research</p><p>时间：April 15, 2019</p><p>链接: DOI: 10.1158/0008-5472.CAN-18-1604</p><p><strong>figure</strong></p><p><img src="/2019/08/30/26191/fig-abstract.png" alt></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>肿瘤微环境的3大特征：</p><ul><li>异质性</li><li>缺氧</li><li>酸性</li></ul><p><strong>异质性</strong>我们听到的报道可能很多，肿瘤微环境不是仅仅有肿瘤细胞组成，还包括免疫细胞、基质细胞等各种成分。</p><p><strong>缺氧</strong>我们可能也不难理解，肿瘤细胞的快速繁殖使肿瘤微环境中的血管化异常以及血液供应的异常，导致缺氧的环境。</p><p><strong>酸性环境</strong>如果是做肿瘤代谢的肯定不会陌生，因为著名的瓦博格效应，即大家广泛认同的肿瘤酸性环境产生的原因，认为肿瘤在无氧环境中的糖酵解产生大量乳酸，导致了肿瘤的酸性环境。</p><p><strong>酸性环境对肿瘤有什么影响？</strong></p><p>常见的研究有：酸性环境影响肿瘤的恶性发展、基因组和表观组的变化、肿瘤的转移、药物的抵抗性等。</p><p><img src="/2019/08/30/26191/review-acidic-TME.png" alt></p><p>这篇文章介绍的是酸性环境影响基因的表达以及可变剪接，进而影响肿瘤的恶性发展。</p><blockquote><p>每日文献摘要：第<strong>4</strong>篇 2019年08月27日 周二</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scATAC的一篇经典文献-研究人细胞发育和肿瘤内T细胞耗竭</title>
      <link href="/2019/08/26/40650.html"/>
      <url>/2019/08/26/40650.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>学习scATAC-seq的必读文献</p><p><strong>文章信息</strong></p><p>题目：Massively parallel single-cell chromatin landscapes of human immune cell development and intratumoral T cell exhaustion</p><p>杂志：Nature biotechnology</p><p>时间：August, 2019</p><p>链接: <a href="https://www.nature.com/articles/s41587-019-0206-z" target="_blank" rel="noopener">https://www.nature.com/articles/s41587-019-0206-z</a></p><p><strong>figure</strong></p><p><img src="/2019/08/26/40650/fig1-method.png" style="zoom:50%"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>利用商业化10X Genomics平台进行scATAC-seq测序，同时研究健康人的血液细胞发育和肿瘤内T细胞的耗竭。共得到200,000个单细胞的染色质可及性图谱。</p><p>在血液细胞发育中的应用，得到的结果包括：</p><ul><li>鉴定到细胞特异的cis- 和trans调控元件</li><li>疾病相关的enhancer活动</li><li>细胞分化发育轨迹</li></ul><p>在肿瘤基底细胞中的应用，结果包括：</p><ul><li>构建了肿瘤微环境中的基底细胞、恶性细胞和免疫细胞的调控网络</li><li>发现一些染色质调控因子或许可作为免疫治疗的靶标</li></ul><p><img src="/2019/08/26/40650/fig2-造血谱系发育.png" alt></p><p><strong>碎碎念</strong></p><p>William J. Greenleaf 和 Howard Y. Chang合作的又一篇巨作文章，值得细细解读，一是学习scATAC-seq的分析方法，重现文章的部分分析；二是总结文章思路，思考如何利用该数据资源做进一步挖掘，对其他课题的借鉴意义</p><ul><li><p>数据资源：scATAC-seq处理前的数据和处理后的数据都提供在10X平台</p><p><a href="https://support.10xgenomics.com/single-cell-atac/datasets" target="_blank" rel="noopener">https://support.10xgenomics.com/single-cell-atac/datasets</a>. </p></li><li><p>代码：<a href="https://github.com/GreenleafLab/10x-scATAC-2019" target="_blank" rel="noopener">https://github.com/GreenleafLab/10x-scATAC-2019</a>.</p></li></ul><blockquote><p>每日文献摘要：第<strong>4</strong>篇 2019年08月27日 周二</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> ATACseq </tag>
            
            <tag> single cell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>awk基本命令使用</title>
      <link href="/2019/08/25/4461.html"/>
      <url>/2019/08/25/4461.html</url>
      
        <content type="html"><![CDATA[<p>awk是一个处理文本文件的程序，也是一门强大的编程语言。awk是把文件逐行的读入，以空格为默认分隔符将每行分割，切开的部分再进行各种分析处理，非常适用于每行格式相同的文本文件。</p><p><img src="/2019/08/25/4461/fig-head.png" alt></p><a id="more"></a><p><strong>示例数据：</strong></p><p>DEseq2得到的差异表达矩阵<strong>(dfdata)</strong>作为示例数据：</p><p>包括9列数据，分别为<code>id</code>, <code>baseMeanA</code>, <code>baseMeanB</code>,<code>baseMean</code>,  <code>log2FoldChange</code>,<code>lfcSE</code>,<code>stat</code>,<code>pvalue</code>,<code>padj</code></p><p><img src="/2019/08/25/4461/fig1-rawdata.png" alt></p><h3 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h3><ul><li><strong>输出文件内容</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 格式</span></span><br><span class="line">$ awk <span class="string">'&#123;动作&#125;'</span> 文件名</span><br><span class="line"><span class="comment"># 示例</span></span><br><span class="line">$ head dfdata | awk <span class="string">'&#123;print $0&#125;'</span></span><br></pre></td></tr></table></figure><p>将输出差异基因结构的前5行</p><ul><li><p><strong>提取基因ID，log2FoldChange, pvalue三列信息</strong></p><p><code>awk</code>会根据空格和制表符等分隔符，将每一行分成若干字段，依次用<code>$1</code>、<code>$2</code>、<code>$3</code>代表第一个字段、第二个字段、第三个字段等，<code>$1, $2</code>可以理解为被分隔符分割的第一列，第二列</p><p><code>-F</code> ：输入分隔符，这里是<code>\t</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将输出差异基因前10行的第1、5和8列，默认是以空格分割，所以输出结果</span></span><br><span class="line">head dfdata | awk -F <span class="string">'\t'</span> <span class="string">'&#123;print $1,$5,$8&#125;'</span></span><br></pre></td></tr></table></figure><p><img src="/2019/08/25/4461/fig-eg1.png" style="zoom:50%"></p><p><code>OFS</code>: 输出分隔符</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以tab分割输出</span></span><br><span class="line">head dfdata | awk -F <span class="string">'\t'</span> <span class="string">'&#123;print $1,$5,$8&#125;'</span> OFS=<span class="string">'\t'</span></span><br></pre></td></tr></table></figure><p><img src="/2019/08/25/4461/fig-eg2.png" style="zoom:50%"></p></li></ul><p><strong>其他变量</strong></p><ul><li><code>FILENAME</code>：当前文件名</li><li><code>FS</code>：字段分隔符，默认是空格和制表符。</li><li><code>RS</code>：行分隔符，用于分割每一行，默认是换行符。</li><li><code>OFS</code>：输出字段的分隔符，用于打印时分隔字段，默认为空格。</li><li><code>ORS</code>：输出记录的分隔符，用于打印时分隔记录，默认为换行符。</li><li><code>OFMT</code>：数字输出的格式，默认为<code>％.6g</code></li></ul><h3 id="条件"><a href="#条件" class="headerlink" title="条件"></a>条件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk <span class="string">'条件 &#123;动作&#125;'</span> 文件名</span><br></pre></td></tr></table></figure><p>可以结合正则表达式规则使用</p><ul><li><strong>输出特定基因ID的行</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">awk -F <span class="string">'\t'</span> <span class="string">'/id/ &#123;print $0&#125;'</span> dfdata</span><br><span class="line"><span class="comment"># idbaseMeanAbaseMeanBbaseMeanlog2FoldChangelfcSEstatpvaluepadj</span></span><br></pre></td></tr></table></figure><h3 id="if语句"><a href="#if语句" class="headerlink" title="if语句"></a>if语句</h3><p>判断语句和执行语句必须用在<code>{}</code>中，且判断语句用<code>()</code>扩起来 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk <span class="string">'&#123;if () action; else action&#125;'</span> file</span><br></pre></td></tr></table></figure><ul><li>输出 |log2FoldChange | &gt; 1且pvalue &lt; 0.05的所有信息</li></ul><p><strong>符合|log2FoldChange | &gt; 1且pvalue &lt; 0.05的基因有多少个</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk <span class="string">'&#123;if ($5&gt;1 || $5 &lt; -1 &amp;&amp; $8&lt;0.05 ) print $0&#125;'</span> dfdata | wc</span><br></pre></td></tr></table></figure><p><strong>且同时输出header</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">awk <span class="string">'/id/ &#123;print $0&#125;; &#123;if ($5&gt;1 || $5 &lt; -1 &amp;&amp; $8&lt;0.05 ) print $0&#125;'</span> dfdata | less -S</span><br><span class="line"><span class="comment"># 两个完整语句间用分号分割</span></span><br></pre></td></tr></table></figure><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><ul><li><code>tolower()</code>：字符转为小写。</li><li><code>length()</code>：返回字符串长度。</li><li><code>substr()</code>：返回子字符串。</li><li><code>sin()</code>：正弦。</li><li><code>cos()</code>：余弦。</li><li><code>sqrt()</code>：平方根。</li><li><code>rand()</code>：随机数</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">awk <span class="string">'/id/ &#123;print $0&#125; dfdata</span></span><br><span class="line"><span class="string"># idbaseMeanAbaseMeanBbaseMeanlog2FoldChangelfcSEstatpvaluepadj</span></span><br><span class="line"><span class="string">awk '</span>/id/ &#123;<span class="built_in">print</span> toupper(<span class="variable">$0</span>)&#125;<span class="string">' rawcount </span></span><br><span class="line"><span class="string"># IDBASEMEANABASEMEANBBASEMEANLOG2FOLDCHANGELFCSESTATPVALUEPADJ</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> text processing </tag>
            
            <tag> awk </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scRNA-seq数据预处理</title>
      <link href="/2019/08/25/30272.html"/>
      <url>/2019/08/25/30272.html</url>
      
        <content type="html"><![CDATA[<p>scRNA-seq的上游处理与bulk RNA-seq有相似的地方，也有不同的地方。相似的地方如：对原始数据的质控检测、去除低质量的reads、adpter、比对。不同的地方如scRNA-seq数据有的需要考虑<strong>Demultiplexing</strong>。而且scRNA-seq根据采用的不同的protocols，产生的数据和处理方法也有不同。</p><p>这里提供的练习数据是SMART-seq2建库，SMRT-seq2建库的测序数据上游分析与bulk RNA-seq相似，如这节课内容中的分析方法：</p><ul><li>FastQC 对原始数据进行质控检测</li><li>Trim Galore 质控</li><li>STAR或Kallisto比对</li></ul><a id="more"></a><h3 id="练习数据"><a href="#练习数据" class="headerlink" title="练习数据"></a>练习数据</h3><p>mouse ESC的单细胞数据(Kolodziejczyk et al. <a href="https://scrnaseq-course.cog.sanger.ac.uk/website/processing-raw-scrna-seq-data.html#ref-Kolodziejczyk2015-xy" target="_blank" rel="noopener">2015</a>)，数据下载位置：<a href="https://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-2600/samples/" target="_blank" rel="noopener">https://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-2600/samples/</a></p><p>直接点击下载按钮即可下载fastq的数据。</p><ul><li>ERR522959_1.fastq</li><li>ERR522959_2.fastq</li></ul><h3 id="质控"><a href="#质控" class="headerlink" title="质控"></a>质控</h3><ul><li>FastQC</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir fastqc_results</span><br><span class="line">fastqc -o fastqc_results Share/ERR522959_1.fastq Share/ERR522959_2.fastq</span><br></pre></td></tr></table></figure><ul><li>Trim galore 是一个自动识别adpter的质控软件</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir fastqc_trimmed_results</span><br><span class="line">trim_galore --nextera -o fastqc_trimmed_results Share/ERR522959_1.fastq Share/ERR522959_2.fastq</span><br></pre></td></tr></table></figure><h3 id="Demultiplexing"><a href="#Demultiplexing" class="headerlink" title="Demultiplexing"></a>Demultiplexing</h3><p>不同的protocol和pipeline决定了demultiplexing的方法也不同，最灵活的方法是<strong>zUMI</strong>,可以用于大多的demultiplexing和基于UMI的protocols。SMARTseq2直接提供的是已经demultiplexing的数据。</p><p><strong>如何理解demultiplexing？</strong></p><p>demultiplexing的过程即识别并移除cell barcode序列。</p><p>scRNA-seq质控中需要考虑的另一个因素是不包含细胞或包含两个细胞的<strong>droplets</strong>。</p><h3 id="STAR比对"><a href="#STAR比对" class="headerlink" title="STAR比对"></a>STAR比对</h3><p>STAR比对的优点有考虑到了剪切体，输出文件内容丰富，（可以进行下游融合基因的分析，bulk seq可以）缺点是耗费计算资源。</p><p>比对的步骤首先需要构建参考基因组或转录组的index文件，由于考虑到练习运行时间，这里提供的代码是比对到参考转录本</p><ul><li>Make index</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir indices</span><br><span class="line">mkdir indices/STAR</span><br><span class="line">STAR --runThreadN 4 --runMode genomeGenerate --genomeDir indices/STAR --genomeFastaFiles Share/2000_reference.transcripts.fa</span><br></pre></td></tr></table></figure><ul><li><p>alingment</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir results</span><br><span class="line">mkdir results/STAR</span><br><span class="line"></span><br><span class="line">STAR --runThreadN 4 --genomeDir indices/STAR --readFilesIn Share/ERR522959_1.fastq Share/ERR522959_2.fastq --outFileNamePrefix results/STAR/</span><br></pre></td></tr></table></figure></li></ul><h3 id="Kallisto-比对（Pseudo-Alignment）"><a href="#Kallisto-比对（Pseudo-Alignment）" class="headerlink" title="Kallisto 比对（Pseudo-Alignment）"></a>Kallisto 比对（Pseudo-Alignment）</h3><p>Kallisto比对也称为pseudo-alignment（假比对）,即它的比对方法和STAR不同，不是将完整reads比对到参考转录本上，而是将<strong>kmer(特定长度的序列)</strong>比对到参考转录本上。</p><p><strong>k-mers和reads相比的特点是</strong>：</p><ul><li>快</li><li>处理测序error的能力强于传统的比对工具</li><li>与STAR不同的另一点Kallisto是比对到转录本的</li></ul><p><strong>Kallisto’s pseudo mode</strong></p><p>专门为scRNA-seq设计的，</p><p><strong>index</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir indices/Kallisto</span><br><span class="line">kallisto index -i indices/Kallisto/transcripts.idx Share/2000_reference.transcripts.fa</span><br></pre></td></tr></table></figure><p><strong>Kallisto Pseudo-Alignment</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir results/Kallisto</span><br><span class="line">kallisto pseudo -i indices/Kallisto/transcripts.idx -o results/Kallisto -b batch.txt</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> single cell </tag>
            
            <tag> scRNA-seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>摘要-scRNAseq探究健康人胰岛和T2D的转录组图谱</title>
      <link href="/2019/08/25/58382.html"/>
      <url>/2019/08/25/58382.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>健康人胰岛和T2D的单细胞转录组图谱</p><p><strong>文章信息</strong></p><p>题目：Single-Cell Transcriptome Profiling of Human Pancreatic Islets in Health and Type 2 Diabetes</p><p>杂志：Cell Metabolism</p><p>时间：October 11, 2016</p><p>链接: <a href="http://dx.doi.org/10.1016/j.cmet.2016.08.020" target="_blank" rel="noopener">http://dx.doi.org/10.1016/j.cmet.2016.08.020</a></p><p><strong>figure</strong></p><p><img src="/2019/08/25/58382/fig1-abstract.png" style="zoom:50%"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>利用单细胞RNA技术探究健康人胰岛和T2D的转录组图谱。数据来源于6个健康人和4个T2D病人，利用SMRT2-seq的方法得到2,209个单细胞。主要分析包括对<strong>1）细胞分群</strong>；<strong>2）鉴定alpha 和beta细胞亚群</strong> ；<strong>3）肥胖或T2D相关基因与BMI的关联</strong>；<strong>4）T2D的基因变异</strong></p><p><strong>碎碎念</strong></p><ol><li><p>与16年发表在Cell systerm上的文章相比，这篇文章的分析相对丰富些，一是数据即包括健康人胰腺又包括糖尿病，二是不仅对细胞进行了分群和标记物的鉴定，还将T2D基因和肥胖基因与BMI关联，以及通过与正常组比较发现了T2D的基因变异。将健康和疾病的对照研究，凸显了鉴定的靶标具有重要的临床意义。</p></li><li><p>Rickard Sandberg实验室发表的文章，SMRT-seq2的开发者，分析方法可以学习</p></li><li><p>数据资源：<strong>E-MTAB-5061， E-MTAB-5060</strong></p></li></ol><blockquote><p>每日文献摘要：第<strong>3</strong>篇 2019年08月26日 周一</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> single cell </tag>
            
            <tag> scRNA-seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>摘要-scRNA-seq探究人胰腺转录组图谱</title>
      <link href="/2019/08/25/21112.html"/>
      <url>/2019/08/25/21112.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>人胰腺单细胞转录组图谱</p><p><strong>文章信息</strong></p><p>题目：A Single-Cell Transcriptome Atlas of the Human Pancreas</p><p>杂志：Cell Systems</p><p>时间：October 26, 2016</p><p>链接: <a href="http://dx.doi.org/10.1016/j.cels.2016.09.002" target="_blank" rel="noopener">http://dx.doi.org/10.1016/j.cels.2016.09.002</a></p><p><strong>figure</strong></p><p><img src="/2019/08/25/21112/fig1-abstarct.png" style="zoom:50%"></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>利用scRNA-seq对人胰腺的组成进行分群以及鉴定特定细胞群的标记基因。样本来自4个过亡的捐赠者，scRNA-seq采用CEL-Seq2 protocol结合FACS分选和机器学技术。所做的分析包括两个方面，首先利用StemID算法对细胞分群，然后鉴定特定细胞亚群的标记基因和转录因子。主要结果有：鉴定到<strong>CD24</strong>和<strong>TM4SF4</strong>可以作为alpha 和beta 细胞的标记基因。</p><p><strong>碎碎念</strong></p><ol><li>只进行了分群和细胞标记基因的鉴定，所做的分析很少，可以利用该数据进行进一步的挖掘</li><li>数据资源：<strong>GSE85241</strong>提供了表达矩阵</li></ol><blockquote><p>每日文献摘要：第2篇 2019年08月25日 周日</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> single cell </tag>
            
            <tag> scRNA-seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>摘要-scRNA-seq揭示胰腺导管癌的肿瘤内部抑制性和恶性发展过程</title>
      <link href="/2019/08/24/37639.html"/>
      <url>/2019/08/24/37639.html</url>
      
        <content type="html"><![CDATA[<p><strong>一句话评价</strong></p><p>胰腺导管癌(PDAC)异质性和恶性发展的单细胞研究</p><p><strong>文章信息</strong></p><p>题目：Single-cell RNA-seq highlights intra-tumoral heterogeneity and malignant progression in pancreatic ductal adenocarcinoma</p><p>杂志：Cell Research</p><p>时间：04 July 2019</p><p>链接: <a href="https://www.nature.com/articles/s41422-019-0195-y" target="_blank" rel="noopener">https://www.nature.com/articles/s41422-019-0195-y</a></p><p><strong>figure</strong></p><p><img src="/2019/08/24/37639/fig1-abstract.png" alt></p><a id="more"></a><p><strong>文章介绍：</strong></p><p>利用单细胞RNA-seq技术对胰腺导管癌的肿瘤内部异质性和恶性发展进行探究。样本量包括24个肿瘤样本和11个对照样本，利用droplet建库的方法，得到57,530个细胞。主要分析包括：首先对细胞进行<strong>1）分群</strong>，鉴定到10个群，其中有2个导管细胞型群分别具有异常和恶性基因表达特征，然后又对两个导管细胞群进行亚群分析。<strong>2）细胞轨迹分析（拟时间分析）</strong>揭示了PDAC恶性发展过程中的相关的通路和转录因子。<strong>3）免疫浸润分析</strong>：结合TCGA胰腺癌相关的公共数据发现了肿瘤浸润T细胞失活状态相关的基因，为肿瘤免疫治疗提供了参考靶点。</p><p><strong>碎碎念</strong></p><ol><li><p>细胞分群是单细胞数据分析的常规步骤</p></li><li><p>拟时间分析这里用于探究肿瘤恶性程度的发展值得借鉴</p></li><li><p>另外如何从拟时间分析得到了相关的转录因子呢？（细看原文）</p></li><li><p>最后与肿瘤免疫扯上关系，升华了研究的价值和意义</p></li></ol><blockquote><p>每日文献摘要：第1篇  2019年08月24日 周六 </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> single cell </tag>
            
            <tag> scRNA-seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scRNA-seq基础知识扫盲篇</title>
      <link href="/2019/08/24/50344.html"/>
      <url>/2019/08/24/50344.html</url>
      
        <content type="html"><![CDATA[<h2 id="Bulk-RNA-seq与scRNA-seq的优势和局限性"><a href="#Bulk-RNA-seq与scRNA-seq的优势和局限性" class="headerlink" title="Bulk RNA-seq与scRNA-seq的优势和局限性"></a>Bulk RNA-seq与scRNA-seq的优势和局限性</h2><h4 id="Bulk-RNA-seq"><a href="#Bulk-RNA-seq" class="headerlink" title="Bulk RNA-seq"></a>Bulk RNA-seq</h4><ul><li>20世纪末即芯片技术后的又一个突破性技术，之后被广泛应用，逐渐替代芯片</li><li>评估测量<strong>一个大群体内所有细胞的平均表达量水平</strong></li><li>适用于比较转录组学，如不同物种相同组织的不同样本间的转录表达差异比较；或者用于评估疾病等表达量特征</li><li>不适用于研究系统的异质性，如早期胚胎发育、复杂组织（脑）</li><li>不能提供基因表达量的随机特征</li></ul><h4 id="scRNA-seq"><a href="#scRNA-seq" class="headerlink" title="scRNA-seq"></a>scRNA-seq</h4><ul><li>2009年出现 (Tang et al. <a href="https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html#ref-Tang2009-bu" target="_blank" rel="noopener">2009</a>)</li><li>伴随着新的protocols和测序成本的降低，2014年左右被广泛推广</li><li>适用于检测一群细胞的表达量分布水平；细胞特异性变化等（如鉴定细胞类型、细胞应激的异质性，基因表达的随机性、推测细胞间的基因调控网络</li><li>数据集从10<em>2～  10 </em>8细胞，且逐年增长</li><li>目前的使用的protocols：SMART-seq2 (Picelli et al. <a href="https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html#ref-Picelli2013-sb" target="_blank" rel="noopener">2013</a>), CELL-seq (Hashimshony et al. <a href="https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html#ref-Hashimshony2012-kd" target="_blank" rel="noopener">2012</a>) and Drop-seq (Macosko et al. <a href="https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html#ref-Macosko2015-ix" target="_blank" rel="noopener">2015</a>)</li><li>商业平台：<a href="https://www.fluidigm.com/products/c1-system" target="_blank" rel="noopener">Fluidigm C1</a>, <a href="https://www.wafergen.com/products/icell8-single-cell-system" target="_blank" rel="noopener">Wafergen ICELL8</a> and the <a href="https://www.10xgenomics.com/single-cell/" target="_blank" rel="noopener">10X Genomics Chromium</a></li><li>Bulk RNA-seq的一些方法也适合于scRNA-seq，大多情况需要新的方法</li></ul><a id="more"></a><h2 id="单细胞RNA测序流程"><a href="#单细胞RNA测序流程" class="headerlink" title="单细胞RNA测序流程"></a>单细胞RNA测序流程</h2><p><img src="/2019/08/24/50344/fig1-workflow.png" style="zoom:50%"></p><h2 id="分析方法"><a href="#分析方法" class="headerlink" title="分析方法"></a>分析方法</h2><p>scRNA-seq上游分析方法与bulk 相同，对测序数据进行<strong>质控、比对、比对结果的质控（黄色部分）</strong>，接着是细胞质控、标准化，这一部分与bulk有相同的也有不同的地方，下游分析就是解释实际生物学问题，包括差异分析、聚类、网络分析等，所用的方法一般都是scRNA特有的算法。</p><p><img src="/2019/08/24/50344/fig2-analysis.png" style="zoom:50%"></p><blockquote><p>scRNA-seq 分析的综述：(Stegle, Teichmann, and Marioni <a href="https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html#ref-Stegle2015-uv" target="_blank" rel="noopener">2015</a>)</p></blockquote><ul><li><a href="https://github.com/VCCRI/Falco/" target="_blank" rel="noopener">Falco</a> ：云端处理scRNA-seq分析.</li><li><a href="https://github.com/YosefLab/scone" target="_blank" rel="noopener">SCONE</a> (Single-Cell Overview of Normalized Expression), scRNA-seq质控和标准化的R包</li><li><a href="http://satijalab.org/seurat/" target="_blank" rel="noopener">Seurat</a> ：scRNA-seq分析的常用的四大R包之一，包括对数据的质控、分析等</li><li><a href="https://asap.epfl.ch/" target="_blank" rel="noopener">ASAP</a> (Automated Single-cell Analysis Pipeline) ：scRNA-seq交互分析的网络平台</li></ul><h2 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h2><p>bulk RNA-seq与scRNA-seq最主要的不同是scRNA-seq的每个测序文库代表一个细胞而不是一群细胞。文库的不同来源于：</p><ul><li>扩增 (达到1 million倍)</li><li>Gene ‘dropouts’：指一个细胞在一个细胞中是中等表达水平，但是在另一个细胞中没有被检测到</li></ul><p>上面的差异主要来自于RNA的起始量很低，因此提高转录本的捕获率、降低扩增偏差是一个热门的研究方向。</p><h2 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h2><p>发展新的scRNA-seq protocol也是一个热门领域，目前已有的方法包括：</p><ul><li>CEL-seq (Hashimshony et al. <a href="https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html#ref-Hashimshony2012-kd" target="_blank" rel="noopener">2012</a>)</li><li>CEL-seq2 (Hashimshony et al. <a href="https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html#ref-Hashimshony2016-lx" target="_blank" rel="noopener">2016</a>)</li><li>Drop-seq (Macosko et al. <a href="https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html#ref-Macosko2015-ix" target="_blank" rel="noopener">2015</a>)</li><li>InDrop-seq (Klein et al. <a href="https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html#ref-Klein2015-kz" target="_blank" rel="noopener">2015</a>)</li><li>MARS-seq (Jaitin et al. <a href="https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html#ref-Jaitin2014-ko" target="_blank" rel="noopener">2014</a>)</li><li>SCRB-seq (Soumillon et al. <a href="https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html#ref-Soumillon2014-eu" target="_blank" rel="noopener">2014</a>)</li><li>Seq-well (Gierahn et al. <a href="https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html#ref-Gierahn2017-es" target="_blank" rel="noopener">2017</a>)</li><li>Smart-seq (Picelli et al. <a href="https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html#ref-Picelli2014-ic" target="_blank" rel="noopener">2014</a>)</li><li>Smart-seq2 (Picelli et al. <a href="https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html#ref-Picelli2014-ic" target="_blank" rel="noopener">2014</a>)</li><li><a href="http://www.clontech.com/US/Products/cDNA_Synthesis_and_Library_Construction/Next_Gen_Sequencing_Kits/Total_RNA-Seq/Universal_RNA_Seq_Random_Primed" target="_blank" rel="noopener">SMARTer</a></li><li>STRT-seq (Islam et al. <a href="https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html#ref-Islam2014-cn" target="_blank" rel="noopener">2013</a>)</li></ul><p><img src="/2019/08/24/50344/fig3-expre-method.png" style="zoom:50%"></p><p>不同的方法实现方式不同，其中<strong>定量</strong>和<strong>捕获</strong>是最重要的两个方面</p><p><strong>定量有两种类型：</strong></p><ul><li>全长（full length): <ul><li>致力于实现每个转录本一致的read coverage</li><li>理论上的一致的coverage很难实现，经常会存在偏差</li></ul></li><li>基于标签(tag-based):<ul><li>只捕获RNA的5‘ 端或3’端，</li><li>可以和UMI(unique molecular identifiers )结合提高定量准确性</li><li>由于只捕获单端RNA可能会降低比对率</li><li>很难鉴定isoforms</li></ul></li></ul><p><strong>捕获</strong>：</p><p>捕获策略决定了测序通量，以及得到细胞的方式和其他信息。常用的捕获策略有：</p><ul><li><p><strong>microwell-based</strong></p><p>使用吸液管或激光捕获等方法分离细胞，并将其放置在微流体管中。该方法的优缺点是：</p><ul><li><p>优点是：可以与FACS分选结合使用，从而可以根据细胞表面marker筛选感兴趣的特定类型的细胞，同时在分选时可以拍摄细胞。图像可以用于识别受损细胞或dublets。</p></li><li><p>缺点是：通量低、耗时费工</p><p><img src="/2019/08/24/50344/fig4-microwell.png" style="zoom:30%"></p></li></ul></li></ul><ul><li><p><strong>microfluidic-based</strong></p><ul><li><p>如Fluidigm’s C1，提供了一个更为集成的系统，用于捕捉细胞和进行建库准备所需的反应。</p></li><li><p>优点是：通量比microwell-based 高</p></li><li><p>缺点是：捕获效率低，只有10%的细胞可以被捕获，因此不适用于细胞类型罕见或者输入细胞量少的研究；另外芯片价格相对贵</p><p><img src="/2019/08/24/50344/fig5-fluidigm.png" style="zoom:30%"></p></li></ul></li><li><p><strong>droplet- based</strong></p><ul><li><p>将每一个细胞封装在一个毫微升的液滴中，并加上一个珠子（bead), bead中含有建库所需的酶和唯一的条形码（barcode)，条形码可以将reads来自于哪个细胞关联。因此，所有的液滴都可以汇集起来，排序在一起，然后根据条形码将reads分配给原始细胞。</p></li><li><p>优点是：通量最高</p></li><li><p>缺点是：测序成本、低覆盖率 (Ziegenhain et al. <a href="https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html#ref-Ziegenhain2017-cu" target="_blank" rel="noopener">2017</a>)</p><p><img src="/2019/08/24/50344/fig6-drop-seq.png" alt></p></li></ul></li></ul><h2 id="如何选择合适的平台"><a href="#如何选择合适的平台" class="headerlink" title="如何选择合适的平台"></a>如何选择合适的平台</h2><p>如何选择合适的protocols，只有根据研究的生物学问题。如果感兴趣一个组织的组成，那么droplet-based的方法可以得到大量的细胞，或许是最适合的；如果研究的是罕见细胞，并且知道细胞marker,那么结合FACS富集，测少量的细胞也可以实现目的。</p><p>全长转录本适合于对不同亚型感兴趣的研究，tagged的protocols可以和UMI结合，适用于基因水平的定量。</p><p><img src="/2019/08/24/50344/fig7-comparison-methods.png" style="zoom:40%"></p><blockquote><p>内容来自<em>Hemberg</em> lab’s 单细胞课程学习笔记 ： </p><p>Introduction to single-cell RNA-seq：</p><p><a href="https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html" target="_blank" rel="noopener">https://scrnaseq-course.cog.sanger.ac.uk/website/introduction-to-single-cell-rna-seq.html</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> single cell </tag>
            
            <tag> scRNA-seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用BETA整合分析ATAC-seq/ChIP-seq和RNA-seq数据</title>
      <link href="/2019/08/23/50753.html"/>
      <url>/2019/08/23/50753.html</url>
      
        <content type="html"><![CDATA[<p><strong><a href="http://cistrome.dfci.harvard.edu/BETA/tutorial.html" target="_blank" rel="noopener">BETA 网址</a></strong>: <a href="http://cistrome.dfci.harvard.edu/BETA/tutorial.html" target="_blank" rel="noopener">http://cistrome.dfci.harvard.edu/BETA/tutorial.html</a></p><h3 id="功能介绍"><a href="#功能介绍" class="headerlink" title="功能介绍"></a>功能介绍</h3><p><img src="https://upload-images.jianshu.io/upload_images/8242255-df9dfd4f7834cee4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><a id="more"></a><h3 id="数据准备："><a href="#数据准备：" class="headerlink" title="数据准备："></a>数据准备：</h3><ul><li><p>peak bed file</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># chr str end</span><br><span class="line">$head mep_ebDfpeak_deseq2_sig.bed</span><br><span class="line">chr8    12050808        12052743</span><br><span class="line">chr9    66492999        66494729</span><br><span class="line">chr4    125632449       125634758</span><br><span class="line">chr4    10182030        10183501</span><br></pre></td></tr></table></figure></li><li><p>df expression file</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># symbol log2FC pvalue</span><br><span class="line">$head mep_eb_dfexpre</span><br><span class="line">MELK    6.23721078699297        5.47784458574045e-218</span><br><span class="line">RAD51AP1        4.17541170218602        2.86774188064759e-217</span><br><span class="line">HMGN5   5.98876520905166        7.49359285750074e-216</span><br><span class="line">ZWILCH  3.74468061674801        2.42032701371558e-204</span><br><span class="line">HNRNPA2B1       2.76252025379004        3.05116228100538e-190</span><br><span class="line">HLA-DRA -5.19413815362273       2.27680965999626e-188</span><br></pre></td></tr></table></figure></li></ul><h3 id="软件下载安装"><a href="#软件下载安装" class="headerlink" title="软件下载安装"></a>软件下载安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget http://cistrome.dfci.harvard.edu/BETA/src/BETA_1.0.7.zip</span><br><span class="line">unzip BETA_1.0.7.zip</span><br><span class="line">cd BETA_1.0.7/</span><br><span class="line">sudo python setup.py install</span><br></pre></td></tr></table></figure><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><h5 id="BETA-Basic"><a href="#BETA-Basic" class="headerlink" title="BETA Basic"></a>BETA Basic</h5><p>BETA Basic 预测调控因子的功能（激活或抑制）和靶基因<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BETA basic –p 3656_peaks.bed –e AR_expr.xls –k LIM –g hg19 --da500 –n basic</span><br></pre></td></tr></table></figure></p><p><strong>参数：</strong><br><code>-p</code> ： peak bed file (必需参数）<br><code>-e</code>：df expression file (必需参数）<br><code>-k</code>：表达量文件格式是limma的标准格式（根据实际情况修改）<br><code>-g</code>：基因组文件，如hg19,hg38,mm10,mm9<br><code>-n</code>：输出文件前缀，BETA默认是<strong>NA</strong><br><code>-da</code>：选择显著性变化（上调和下调的）表达数据（根据实际情况修改）</p><p><strong>其他格式(不是limma和cuffdif标准格式）的差异表达文件格式：</strong></p><ul><li>需设置参数<code>--info</code>, geneID如果是smbol需要设置<code>--gname2</code></li></ul><h5 id="BETA-Plus"><a href="#BETA-Plus" class="headerlink" title="BETA Plus"></a>BETA Plus</h5><p>BETA Plus 预测调控因子的功能（激活或抑制）和靶基因，以及靶向区域的motif分析</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BETA plus –p 3656_peaks.bed –e AR_expr.xls –k LIM –g hg19 --gs hg19.fa --bl</span><br></pre></td></tr></table></figure><p><strong>参数：</strong></p><p><code>--gs</code> : motif分析需要的参数, 基因组fasta格式<br><code>--bl</code> :可选参数，当考虑boundary（如CTCF）时需要的参数</p><h4 id="BETA-Minus"><a href="#BETA-Minus" class="headerlink" title="BETA Minus"></a>BETA Minus</h4><p>BETA Minus 只根据peak bed数据基于调控潜能值预测靶基因<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BETA minus -p 3656_peaks.bed --bl -g hg19</span><br></pre></td></tr></table></figure></p><h5 id="其他可选参数"><a href="#其他可选参数" class="headerlink" title="其他可选参数"></a>其他可选参数</h5><p><code>-n</code>：结果文件的名字<br><code>-o</code>:输出文件路径<br><code>--gname2</code>：geneID如果是smbol需要设置<code>--gname2</code><br><code>--info</code>：其他格式(不是limma和cuffdif标准格式）的差异表达文件格式：需设置参数<code>--info</code>,<br><code>--pn</code>:peak 数目，默认是10，000<br><code>-d DISTANCE,--distance</code> 距离TSS的距离. DEFAULT=100000 (100kb)<br><code>--df DIFF_FDR</code> : 输入0-1的数值，表示统计的阈值，如FDR等，默认是1.<br><code>--da DIFF_AMOUNT</code>; 取显著表达的基因，0-1表示比例，大于1表示个数。如2000，表示去top 2000个上调和下调的差异基因；0.5表示取50%上调和下调的基因，默认是0.5。<br><code>-c CUTOFF, --cutoff</code>： 0~1的一个阈值。默认是1e-3。<br><code>-r REFERENCE, --reference</code>： 当参考基因组不是hg19,或mm9时使用此参数。<br><code>--bl BOUNDARY</code> :LIMIT Boolean Value. Whether or not use CTCF boundary to get a peak’s associated gene, DEFAULT=FALSE<br><code>-bf BOUNDARYFILE</code> : Some BED format boundary file, use this only when You set –bl and the genome is neither hg19 nor mm9</p><h3 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h3><p><strong>文章</strong>Wang, S., Sun, H., Ma, J., Zang, C., Wang, C., Wang, J., … &amp; Liu, X. S. (2013). Target analysis by integration of transcriptome and ChIP-seq data with BETA. Nature protocols, 8(12), 2502-2515.<br><strong>PMID:</strong> 24263090<br><strong>网址：</strong> <a href="http://cistrome.org/BETA/index.html" target="_blank" rel="noopener">http://cistrome.org/BETA/index.html</a></p><h3 id="使用代码"><a href="#使用代码" class="headerlink" title="使用代码"></a>使用代码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/software/biosoft/software/python/python2.7/bin/BETA plus -P mep_ebDfpeak_deseq2_sig.bed --info -e mep_eb_dfexpre --gname2 -g hg 19 --gs hg19.fa --bl</span><br></pre></td></tr></table></figure><h3 id="几点疑问"><a href="#几点疑问" class="headerlink" title="几点疑问"></a>几点疑问</h3><p>BETA最初的设计主要是用于ChIP-Seq和RNA-seq的整合分析，最终可以预测特定一个转录因子的靶基因，以及这些基因是激活还是抑制的功能。但是对于ATAC-seq，它得到的信号整个基因组范围转录因子的信号，那么与转录组整合分析得到的结果怎么解释？只能知道一些基因的功能是激活的或抑制的，但是并不能知道这些基因是哪些转录因子的靶基因。所以BETA是否适合ATAC-seq和与RNA-seq的整合分析？如果可以，整合分析的结果能得到哪些有价值的信息？</p>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ATACseq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>转录因子足迹分析+启动子处染色质可及性与基因表达不一定成正相关</title>
      <link href="/2019/08/23/9634.html"/>
      <url>/2019/08/23/9634.html</url>
      
        <content type="html"><![CDATA[<h3 id="题目：Identification-of-transcription-factorbinding-sites-using-ATAC-seq"><a href="#题目：Identification-of-transcription-factorbinding-sites-using-ATAC-seq" class="headerlink" title="题目：Identification of transcription factorbinding sites using ATAC-seq"></a>题目：Identification of transcription factorbinding sites using ATAC-seq</h3><p>DOI: 10.1186/s13059-019-1642-2<br>杂志/日期：Genome Biol. , 26 Feb 2019<br>关键词：ATAC-seq; Computational footprinting  </p><p>日期：2019年2月17日——2019-Week8</p><h3 id="主要内容："><a href="#主要内容：" class="headerlink" title="主要内容："></a>主要内容：</h3><p>这篇文章考虑到ATAC-seq实验的人工误差提出了第一个转录因子足迹的分析方法——HINT-ATAC，使用位置依赖模型探究转座酶的裂解偏好，观察到由局部核小体结构决定的转录因子结合位点周围的特异剪接模式，因此，HINT-ATAC可以更好的预测转录因子的结合位点。</p><a id="more"></a><p><img src="https://upload-images.jianshu.io/upload_images/8242255-c303940cae18172b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p><h3 id="题目：Combined-analysis-of-dissimilar-promoter-accessibility-and-gene-expression-profiles-identifies-tissue-specific-genes-and-actively-repressed-networks"><a href="#题目：Combined-analysis-of-dissimilar-promoter-accessibility-and-gene-expression-profiles-identifies-tissue-specific-genes-and-actively-repressed-networks" class="headerlink" title="题目：Combined analysis of dissimilar promoter accessibility and gene expression profiles identifies tissue-specific genes and actively repressed networks"></a>题目：Combined analysis of dissimilar promoter accessibility and gene expression profiles identifies tissue-specific genes and actively repressed networks</h3><p>DOI: <a href="https://doi.org/10.1186/s13072-019-0260-2" target="_blank" rel="noopener">https://doi.org/10.1186/s13072-019-0260-2</a><br>杂志/日期：Epigenetics &amp; Chromatin, 12 Feb 2019<br>关键词：ATAC-seq; promoter  </p><p>日期：2019年2月17日——2019-Week8</p><h3 id="主要内容：-1"><a href="#主要内容：-1" class="headerlink" title="主要内容："></a>主要内容：</h3><p>许多研究都报道了启动子处的染色质可及性与基因表达成正相关，而这篇文章发现了一个不一样的趋势。他们发现相关性最强（高表达，强的染色质可及性）的可能与管家基因功能相关。组织特异性基因表达量高，但是染色质可及性仅为中低水平的coverage。此外，他们预测到中、低表达的、但是有高启动子覆盖的基因被积极抑制。</p>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ATACseq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scATAC-seq分析工具</title>
      <link href="/2019/08/23/59677.html"/>
      <url>/2019/08/23/59677.html</url>
      
        <content type="html"><![CDATA[<h3 id="题目：Destin-toolkit-for-single-cell-analysis-of-chromatin-accessibility"><a href="#题目：Destin-toolkit-for-single-cell-analysis-of-chromatin-accessibility" class="headerlink" title="题目：Destin: toolkit for single-cell analysis of chromatin accessibility"></a>题目：Destin: toolkit for single-cell analysis of chromatin accessibility</h3><blockquote><p>DOI: <a href="https://doi.org/10.1093/bioinformatics/btz141" target="_blank" rel="noopener">https://doi.org/10.1093/bioinformatics/btz141</a><br>杂志/日期： Bioinformatics, 01 March 2019<br>关键词：  scATAC-seq，GWAS<br>分类：「工具」<br>日期：2019年2月10日——2019-Week7</p></blockquote><h3 id="主要内容："><a href="#主要内容：" class="headerlink" title="主要内容："></a>主要内容：</h3><p><strong>「Destin」</strong>用于scATAC-seq分析的一个R工具包，其中的一个亮点是分析GWAS结果是否与特定细胞类型集群中染色质可及性的增加有关，这里他们采用的是最初用于scRNA -seq表达的两种方法:ECWE和MAGMA。除此之外还包括：</p><ul><li>从bam文件获取实验信息</li><li>peaks的注释区域</li><li>质控</li><li>确定分群数量</li><li>差异可及性染色质<br>（其中输入文件是peaks，cell的bam文件）</li></ul><a id="more"></a><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>「Destin」用于sc-ATAC分析的一个R工具包，包括分群，与gwas关联，差异peaks分析等。</p><h3 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h3><ul><li>github : <a href="https://github.com/urrutiag/destin" target="_blank" rel="noopener">https://github.com/urrutiag/destin</a></li></ul><hr><h3 id="题目：-A-rapid-and-robust-method-for-single-cell-chromatin-accessibility-profiling"><a href="#题目：-A-rapid-and-robust-method-for-single-cell-chromatin-accessibility-profiling" class="headerlink" title="题目： A rapid and robust method for single cell chromatin accessibility profiling"></a>题目： A rapid and robust method for single cell chromatin accessibility profiling</h3><blockquote><p>DOI: <a href="https://www.nature.com/articles/s41467-018-07771-0" target="_blank" rel="noopener">https://www.nature.com/articles/s41467-018-07771-0</a><br>杂志/日期： Nature Communications, 17 December 2018<br>关键词： scATAC-seq，<br>分类：「工具」<br>日期：2019年2月10日——2019-Week7</p></blockquote><h3 id="主要内容：-1"><a href="#主要内容：-1" class="headerlink" title="主要内容："></a>主要内容：</h3><p>plate-based的scATAC-seq方法，结合了前期bulk Tn5单核分选标签。</p><h3 id="相关资料："><a href="#相关资料：" class="headerlink" title="相关资料："></a>相关资料：</h3><p>代码：<a href="https://github.com/dbrg77/plate_scATAC-seq" target="_blank" rel="noopener">https://github.com/dbrg77/plate_scATAC-seq</a>.<br>数据：bulk ATAC 和scATAC-seq :<a href="http://genome-euro.ucsc.edu/cgi-bin/hgTracks?hgS_doOtherUser=submit&amp;hgS_otherUserName=dbrg77&amp;hgS_otherUserSessionName=mSpleen_scATAC_cluster" target="_blank" rel="noopener">http://genome-euro.ucsc.edu/cgi-bin/hgTracks?hgS_doOtherUser=submit&amp;hgS_otherUserName=dbrg77&amp;hgS_otherUserSessionName=mSpleen_scATAC_cluster</a>.</p>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献摘要 </tag>
            
            <tag> ATACseq </tag>
            
            <tag> single cell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>esATAC_一个ATAC-seq分析的R包</title>
      <link href="/2019/08/23/6223.html"/>
      <url>/2019/08/23/6223.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>日期：2019年1月13日——2019-Week2<br>分类：「工具」<br>题目：esATAC: An Easy-to-use Systematic pipeline for ATAC-seq data analysis<br>DOI: 10.1093/bioinformatics/bty141<br>杂志：Bioinformatics，2018 Aug<br>关键词： ATAC; chromatin accessibility; transcription factor; regulatory network</p></blockquote><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>之前介绍过中科大Kun Qu老师实验室开发的用于bulk ATAC-seq分析的工具包 —— <a href="https://www.jianshu.com/p/df239acc1e62" target="_blank" rel="noopener">「ATAC-pipe」</a>，虽然个人并不推荐依赖使用这种打包工具包。但是他们的分析方法和原理还是值得了解和学习的。这里再介绍一个ATAC-seq分析的工具包——<strong>esATAC</strong>，是由清华大学Xiaowo Wang老师实验室开发的一个R/Bioconductor包，它的功能包括如下几方面：</p><ul><li>原始数据的质控和比对</li><li>peak calling</li><li>富集分析</li><li>转录因子足迹分析</li></ul><a id="more"></a><p><strong>具体分析方法参考vignettes:</strong><br><a href="https://www.bioconductor.org/packages/release/bioc/vignettes/esATAC/inst/doc/esATAC-Introduction.html" target="_blank" rel="noopener">https://www.bioconductor.org/packages/release/bioc/vignettes/esATAC/inst/doc/esATAC-Introduction.html</a></p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-7618934170793d38.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><h3 id="数据分析流程"><a href="#数据分析流程" class="headerlink" title="数据分析流程"></a>数据分析流程</h3><ul><li>初始数据：可以直接处理fastq格式的测序数据</li><li>质控：多种质控方法，包括测序质量，read length分布等</li><li>去接头：AdapterRemoval</li><li>比对：Bowtie2</li><li>鉴定开放染色质peak：<strong>F-seq？？</strong><br>仔细了解(Boyle, et al., 2008,Koohy, et al., 2014)</li><li>peak的注释：ChIPseeker包</li><li>TF分析：结合JASPAR数据库</li><li>适用物种：人和鼠</li></ul><hr><p><strong>单细胞RNA-seq、ATAC-seq分析教程、工具大集锦:</strong> <a href="https://github.com/seandavi/awesome-single-cell" target="_blank" rel="noopener">https://github.com/seandavi/awesome-single-cell</a> </p>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ATACseq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ATAC-pipe_ATAC-seq分析的工具包</title>
      <link href="/2019/08/23/24749.html"/>
      <url>/2019/08/23/24749.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>日期：2019年1月6日——2019-Week1<br>分类：「工具」<br>题目：ATAC-pipe: general analysis of genome-wide chromatin accessibility<br>DOI: 10.1093/bib/bby056<br>杂志：Briefings in Bioinformatics<br>关键词： ATAC; chromatin accessibility; transcription factor; regulatory network</p></blockquote><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>ATAC-pipe是中科大Kun Qu实验室开发的一个打包软件包，用于分析bulk ATAC-Seq。主要功能包括：</p><ul><li>鉴定显著差异的开放染色质区域</li><li>motif分析及相关的TFs对转录调控的影响</li><li>TF和motif的足迹分析以及核小体占位的可视化</li><li>基于相关性的细胞聚类分析</li><li>构建TF调控网络，评估TFs和基因间的相互作用</li></ul><a id="more"></a><p><strong>详细用法参考：</strong> <a href="https://github.com/QuKunLab/ATAC-pipe" target="_blank" rel="noopener">https://github.com/QuKunLab/ATAC-pipe</a><br>或者 manual for ATAC-pipe:<br><a href="https://github.com/QuKunLab/ATAC-pipe/blob/master/Manual_for_ATAC-pipe.pdf" target="_blank" rel="noopener">https://github.com/QuKunLab/ATAC-pipe/blob/master/Manual_for_ATAC-pipe.pdf</a><br><img src="https://upload-images.jianshu.io/upload_images/8242255-6a010cefce1de392.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><h3 id="材料和方法"><a href="#材料和方法" class="headerlink" title="材料和方法"></a>材料和方法</h3><h4 id="1-流程和算法"><a href="#1-流程和算法" class="headerlink" title="1. 流程和算法"></a>1. 流程和算法</h4><p>ATAC-pipe是基于其他工具和软件包的，需要在Linux/MAC OS平台安装 requires Bowtie2, Picard, MACS2, HOMER, Python和R的环境，以及相关的参考基因组和DESeq R包。</p><ul><li>比对: Bowtie2</li><li>去重: Picard</li><li>peak calling: MACS2</li><li>count标准化和差异分析：DESeq</li><li>聚类和热图：Cluster 3.0 和 Treeview</li><li>TF motifs分析: Homer and msCentipede</li><li>序列迁移，TSS富集值和分布，V-plot, TF调控网络：他们自己实验室写的代码</li></ul><h4 id="2-与其他工具的比较"><a href="#2-与其他工具的比较" class="headerlink" title="2. 与其他工具的比较"></a>2. 与其他工具的比较</h4><p>他们的介绍是「ATAC-pipe功能多，其他工具可能只是包含QC，比对，peak calling等基本步骤，但是ATAC-pipe还包含样本聚类，motif 搜索，足迹验证、核小体占位分析和TF调控网络分析，而且更重要的是可以鉴定显著差异开放染色质区域和这些区域的TF motif富集, 另外所需时间与其他工具相比较少」。<br>（他们介绍的优点了解下即可，其实很多工具都可以实现相同的功能,其他工具的功能和原理也要了解一下）<br><img src="https://upload-images.jianshu.io/upload_images/8242255-00e3a65dc7a94075.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="ATAC-pipe与其他工具的比较"></p><h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>看一下这个流程包可以给出哪些结果</p><h4 id="结果1：质控"><a href="#结果1：质控" class="headerlink" title="结果1：质控"></a>结果1：质控</h4><p><img src="https://upload-images.jianshu.io/upload_images/8242255-15f9acb35786f78c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="测序质量QC"><br><img src="https://upload-images.jianshu.io/upload_images/8242255-5a9da9e0aa35587e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="实验QC"></p><h4 id="结果2：相关性和差异peaks分析"><a href="#结果2：相关性和差异peaks分析" class="headerlink" title="结果2：相关性和差异peaks分析"></a>结果2：相关性和差异peaks分析</h4><p><img src="https://upload-images.jianshu.io/upload_images/8242255-3f34efca235a3415.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="相关性和差异peaks分析"></p><h4 id="结果3：TF-富集分析"><a href="#结果3：TF-富集分析" class="headerlink" title="结果3：TF 富集分析"></a>结果3：TF 富集分析</h4><p><img src="https://upload-images.jianshu.io/upload_images/8242255-f4447516f707f93d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="差异开放染色质区域和这些区域的motif富集分析"></p><h4 id="结果4：TF-motif足迹分析和核小体占位分析"><a href="#结果4：TF-motif足迹分析和核小体占位分析" class="headerlink" title="结果4：TF motif足迹分析和核小体占位分析"></a>结果4：TF motif足迹分析和核小体占位分析</h4><p><img src="https://upload-images.jianshu.io/upload_images/8242255-9a61f22dbaed9e14.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="TF motif足迹分析和核小体占位分析"></p><h4 id="结果5：TF驱动调控网络"><a href="#结果5：TF驱动调控网络" class="headerlink" title="结果5：TF驱动调控网络"></a>结果5：TF驱动调控网络</h4><h2 id><a href="#" class="headerlink" title></a><img src="https://upload-images.jianshu.io/upload_images/8242255-eeda0fad3ba7c092.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="TF驱动调控网络"></h2><h3 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h3><p>使用他人打包的工具包有人可能觉得省时方便，但是会有很多限制，不够灵活。而且他们这个工具包本身需要安装很多工具，最终是包装成python模块，使用时是需要有linux和python基础的。他们的分析结果有很多工具和方法可以实现，对于这篇文章也就是了解下他们进行ATAC-seq分析时使用的方法，同时了解下文章中做比较时提到其他工具。</p><p>如果想实现个性化和弹性化的分析，还是需要自己了解掌握每一步的分析流程，具体方法可以参考之前的帖子:</p><ul><li><a href="https://mp.weixin.qq.com/s/iVMY_0Su278OfWc2r2_brQ" target="_blank" rel="noopener">ATAC-Seq入门加高阶传送门，文末点击可进入交流群</a><br><a href="https://mp.weixin.qq.com/s/iVMY_0Su278OfWc2r2_brQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/iVMY_0Su278OfWc2r2_brQ</a></li><li><a href="https://mp.weixin.qq.com/s/7k2GEmPmnkVfmzegpxabQA" target="_blank" rel="noopener">第10篇：ATAC-Seq、ChIP-Seq、RNA-Seq整合分析（内附目录）</a><br><a href="https://mp.weixin.qq.com/s/7k2GEmPmnkVfmzegpxabQA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/7k2GEmPmnkVfmzegpxabQA</a></li><li><a href="https://mp.weixin.qq.com/s/XQITfdnS6Zn6iTBtuladPw" target="_blank" rel="noopener">给学徒的ATAC-seq数据实战（附上收费视频）</a><br><a href="https://mp.weixin.qq.com/s/XQITfdnS6Zn6iTBtuladPw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/XQITfdnS6Zn6iTBtuladPw</a></li></ul><hr><p>另外记得在去年苏州单细胞会议的海报展示，Kun Qu老师实验室展示了一个用于sc-ATAC分析的工具包APEC（不知道发表没）。<br><img src="https://upload-images.jianshu.io/upload_images/8242255-a706382e4acfb3e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br>APEC的文章已在预印版上发出：<a href="https://www.biorxiv.org/content/early/2019/05/23/646331.full.pdf" target="_blank" rel="noopener">https://www.biorxiv.org/content/early/2019/05/23/646331.full.pdf</a> </p>]]></content>
      
      
      <categories>
          
          <category> literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ATACseq </tag>
            
            <tag> software </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第10篇：ATAC-Seq、ChIP-Seq、RNA-Seq整合分析</title>
      <link href="/2019/08/23/4060.html"/>
      <url>/2019/08/23/4060.html</url>
      
        <content type="html"><![CDATA[<p>由于基因表达调控机制的复杂性，多种组学数据的整合分析，从不同的层面探究生物问题越来越重要。从RNA-Seq层面，我们可以探究哪些基因具有显著差异，上调或下调；从ChIP-Seq层面，我们可以研究某个特定转录因子的调控作用；从ATAC-Seq我们可以了解到染色质可及性的动态变化，由于染色质的可及性与调控元件或转录因子的结合密切相关，在转录调控中发挥着重要的作用。因此，整合分析可以进一步探究调控某一生物学过程的关键因子（包括顺式调控元件和转录因子），以及哪个转录因子调控了感兴趣的基因，以及感兴趣的转录因子的靶基因等。<br>目前，好像并没有标准化的方法用来整合比较这三种数据。不过在文献中可以看到有很多相同的或不同的思路和方法做整合分析，大家可以在学习交流群中推荐文献，一起解读学习。</p><a id="more"></a><p>下面的内容主要介绍这一节课程中RNA-Seq和ChIP-Seq的整合分析中提到的两种方法：<br><strong>一是直接比较</strong>，即首先得到差异基因与ChIP-Seq靶基因的overlap，然后选择一些关键基因比较一下谱图。<br><img src="https://upload-images.jianshu.io/upload_images/8242255-3a8682b8a3260f0c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Gao et. al, Nature 2014，doi: 10.1038/nature13921"><br><strong>课程中提到的另一种方法是使用BETA工具：</strong><br><strong>BETA (Binding and Expression Target Analysis)</strong>是 Shirley Liu实验室开发的工具，通过整合转录因子或染色质调控因子的ChIP-Seq与差异基因的表达直接预测靶基因，而且有可能发现增强子区的蛋白质的靶基因。<br>BETA有三个功能：</p><ul><li>预测转录因子的功能是激活还是抑制</li><li>预测转录因子的靶基因</li><li>鉴定转录因子的motif以及调控转录因子激活或抑制的其他因子</li></ul><p>BETA包括三个命令取决于输入数据格式和想要的输出数据（可以参考嘉因的帖子<a href="https://mp.weixin.qq.com/s/Nm47ZMbdlIx-OI5j5wo4nA" target="_blank" rel="noopener">ChIP-seq和RNA-seq整合分析，BETA最擅长 | 自己分析数据的完美解决方案</a>）</p><ul><li>BETA basic: 预测转录因子的功能是激活还是抑制，直接检测靶标</li><li>BETA plus：BETA basic + 靶标区域的motif分析</li><li>BETA minus：只基于结合数据的调控潜能的值预测TF靶基因</li></ul><p><img src="https://upload-images.jianshu.io/upload_images/8242255-126e213bad02247c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Nat Protoc. 2013 Dec; 8(12): 2502–2515."></p><p><strong>工作原理</strong></p><ul><li>每个基因的调控潜能值是通过计算基因TSS的指定范围内的所有结合位点来计算的</li><li>调控潜能是基因受因子调节的可能性，取决于TSS范围的结合位点数以及与结合位点与TSS之间的距离</li><li>BETA minus按照调控潜能值对基因排序来鉴定靶标</li><li>BETA basic需要特定格式的差异分析结果和显著性的结果。它使用CDF来判断上调基因和下调基因是否与NON-DE不同，这是用来识别激活和抑制功能。使用调控潜能和差异统计量计算每一个基因的得分排序，该得分排序可以用于识别靶标。<h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3></li></ul><ol><li><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/blob/master/sessionV/lessons/integrating_rna-seq_and_chip-seq.md" target="_blank" rel="noopener">哈佛深度NGS数据分析课程，10-Integrating RNA-seq and ChIP-seq</a></li><li><a href="https://mp.weixin.qq.com/s/-7Bx29H5nM-LQJiu9hbYjw" target="_blank" rel="noopener">大牛新宠，转录调控研究神器！找关键转录因子、推测转录因子-靶基因关系</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ATACseq </tag>
            
            <tag> ChIPseq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第9篇：差异peaks分析——DiffBind</title>
      <link href="/2019/08/23/42300.html"/>
      <url>/2019/08/23/42300.html</url>
      
        <content type="html"><![CDATA[<h3 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h3><ul><li><p>学习用DiffBind流程评估两个样本间的差异结合区域</p></li><li><p>用PCA评估样本间的关系</p></li><li><p>评估不同工具得到的差异peaks的一致性</p><a id="more"></a></li></ul><h3 id="评估差异peaks富集的工具"><a href="#评估差异peaks富集的工具" class="headerlink" title="评估差异peaks富集的工具"></a>评估差异peaks富集的工具</h3><p>ATAC-Seq下游分析的另一个重点是差异peaks分析。如分析不同的实验条件、多个时间节点、不同的发育时期等的差异区域。鉴定这些差异peaks区域在生物医学研究中也具有重要意义，目前也有多种相关的工具被开发：<br><img src="https://upload-images.jianshu.io/upload_images/8242255-78b2f423dc7b0fa8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br><strong>选择合适的工具需考虑以下几个因素：</strong></p><ul><li>所用的软件不需要大量的代码移植，该工具是否被维护和频繁更新。</li><li>用户需要提供什么样的输入文件，是否与peaks calling所用工具可以衔接。</li><li>信号分布的基础统计模型是什么？是基于泊松分布或更灵活的负二项分布。</li><li>一些工具是专门针对特定的ATAC-seq或ChIP-seq 数据（信号类型）设计的，如组蛋白修饰或转录因子（TF）结合。</li></ul><p>具体选择哪种工具决定于实验设计，下面的决策树可以帮助缩小你的选择范围。</p><h2 id><a href="#" class="headerlink" title></a><img src="https://upload-images.jianshu.io/upload_images/8242255-3f133ad5e0d5b6e2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></h2><h3 id="DiffBind"><a href="#DiffBind" class="headerlink" title="DiffBind"></a>DiffBind</h3><p>DiffBind是鉴定两个样本间差异结合位点的一个R包。主要用于peak数据集，包括对peaks的重叠和合并的处理，计算peaks重复间隔的测序reads数，并基于结合亲和力鉴定具有统计显著性的差异结合位点。适用的统计模型有DESeq、DESeq2、edgeR。详细内容可参考DiffBind的文档：<a href="http://bioconductor.org/packages/release/bioc/vignettes/DiffBind/inst/doc/DiffBind.pdf" target="_blank" rel="noopener">http://bioconductor.org/packages/release/bioc/vignettes/DiffBind/inst/doc/DiffBind.pdf</a></p><h3 id="使用方法："><a href="#使用方法：" class="headerlink" title="使用方法："></a>使用方法：</h3><h4 id="1-下载安装DiffBind"><a href="#1-下载安装DiffBind" class="headerlink" title="1. 下载安装DiffBind"></a>1. 下载安装DiffBind</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">source</span>(<span class="string">"https://bioconductor.org/biocLite.R"</span>)</span><br><span class="line">biocLite(<span class="string">"DiffBind"</span>)</span><br><span class="line"><span class="comment"># view documentation</span></span><br><span class="line">browseVignettes(<span class="string">"DiffBind"</span>)</span><br></pre></td></tr></table></figure><h4 id="2-准备输入文件"><a href="#2-准备输入文件" class="headerlink" title="2. 准备输入文件"></a>2. 准备输入文件</h4><p>需要准备一个SampleSheet文件，与<a href="（https://www.jianshu.com/p/a11147808d14）">ChIPQC</a>的方法一样。SampleSheet文件是根据实验设计和数据存储地址等信息创建的一个csv格式文件，包含的表头信息有<strong>“SampleID”、 “Tissue”、 “Factor”、 “Condition” 、”Treatment”、”Replicate” 、”bamReads” 、”ControlID”、 “bamControl” “Peaks”、 “PeakCaller”</strong>（bam,peak文件分别在比对和call peak的步骤产生）。<br><img src="https://upload-images.jianshu.io/upload_images/8242255-e5e43bc02d122cc8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><h4 id="3-差异peaks分析"><a href="#3-差异peaks分析" class="headerlink" title="3. 差异peaks分析"></a>3. 差异peaks分析</h4><p><strong>读入文件</strong><br>一旦读入了peaksets，合并函数就找到所有重叠的peaks，并导出一致性的peaksets。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(DiffBind)</span><br><span class="line">dbObj &lt;- dba(sampleSheet=<span class="string">"SampleSheet.csv"</span>)</span><br></pre></td></tr></table></figure></p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-b45f2ad5b70f46af.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br><strong>亲和结合矩阵</strong><br>计算每个peaks/regions的count信息。先对一致性的peaks数据集进行标准化，然后根据他们的峰值（point of greatest read overlap）再次中心化并修剪一些peaks，最终得到更加标准的peak间隔。使用函数dba.count()，参数<code>bUseSummarizeOverlaps</code>可以得到更加标准的计算流程。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dbObj &lt;- dba.count(dbObj, bUseSummarizeOverlaps=TRUE)</span><br><span class="line">dba.plotPCA(dbObj,  attributes=DBA_FACTOR, label=DBA_ID)</span><br><span class="line">plot(dbObj)</span><br></pre></td></tr></table></figure><p>结果中同时计算了FRiP (质量评估的一个标准，可以参考<a href="https://www.jianshu.com/p/a11147808d14" target="_blank" rel="noopener">第5篇：对ATAC-Seq/ChIP-seq的质量评估（二）——ChIPQC</a>)。<br><img src="https://upload-images.jianshu.io/upload_images/8242255-bda08e59563ab91a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br>样本间的聚类:<br><img src="https://upload-images.jianshu.io/upload_images/8242255-d806500399a287b6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br>Venn图展示样本间peaks的重合<br><img src="https://upload-images.jianshu.io/upload_images/8242255-d68a6b35c676e047.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br><strong>差异分析</strong><br>差异分析是DiffBind的核心功能，默认情况是基于DEseq2, 可以设置参数<code>method=DBA_EDGER</code>选择edgeR，或者设置<code>method=DBA_ALL_METHODS</code>。每种方法都会评估差异结果的p-vaue和FDR。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Establishing a contrast </span><br><span class="line">dbObj &lt;- dba.contrast(dbObj, categories=DBA_FACTOR,minMembers = 2)</span><br><span class="line">dbObj &lt;- dba.analyze(dbObj, method=DBA_ALL_METHODS)</span><br><span class="line">#  summary of results</span><br><span class="line">dba.show(dbObj, bContrasts=T)</span><br><span class="line">#  overlapping peaks identified by the two different tools (DESeq2 and edgeR)</span><br><span class="line">dba.plotVenn(dbObj,contrast=1,method=DBA_ALL_METHODS)</span><br></pre></td></tr></table></figure><p><img src="https://upload-images.jianshu.io/upload_images/8242255-22e7d87169ae0a19.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br><strong>提取结果</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">comp1.edgeR &lt;- dba.report(dbObj, method=DBA_EDGER, contrast = 1, th=1)</span><br><span class="line">comp1.deseq &lt;- dba.report(dbObj, method=DBA_DESEQ2, contrast = 1, th=1)</span><br></pre></td></tr></table></figure><p>结果文件包含所有位点的基因组坐标，以及差异富集的统计数据包括fold change、p值和FDR。<br>其中<code>Conc</code>的表示read的平均浓度，即对peak 的read counts进行log2标准化</p><blockquote><p>The value columns show the mean read concentration over all the samples (the default calculation uses log2 normalized ChIP read counts with control read counts subtracted) and the mean concentration over the first (Resistant) group and second (Responsive) group.</p></blockquote><p><img src="https://upload-images.jianshu.io/upload_images/8242255-9cbf839407929d40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br><strong>保存文件</strong></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># EdgeR</span></span><br><span class="line">out &lt;- as.data.frame(comp1.edgeR)</span><br><span class="line">write.table(out, file=<span class="string">"results/Nanog_vs_Pou5f1_edgeR.txt"</span>, sep=<span class="string">"\t"</span>, quote=<span class="literal">F</span>, col.names = <span class="literal">NA</span>)</span><br><span class="line"><span class="comment"># DESeq2</span></span><br><span class="line">out &lt;- as.data.frame(comp1.deseq)</span><br><span class="line">write.table(out, file=<span class="string">"results/Nanog_vs_Pou5f1_deseq2.txt"</span>, sep=<span class="string">"\t"</span>, quote=<span class="literal">F</span>, col.names = <span class="literal">NA</span>)</span><br></pre></td></tr></table></figure><p><strong>以bed格式保存显著性的差异结果</strong><br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create bed files for each keeping only significant peaks (p &lt; 0.05)</span></span><br><span class="line"><span class="comment"># EdgeR</span></span><br><span class="line">out &lt;- as.data.frame(comp1.edgeR)</span><br><span class="line">edge.bed &lt;- out[ which(out$FDR &lt; <span class="number">0.05</span>), </span><br><span class="line">                 c(<span class="string">"seqnames"</span>, <span class="string">"start"</span>, <span class="string">"end"</span>, <span class="string">"strand"</span>, <span class="string">"Fold"</span>)]</span><br><span class="line">write.table(edge.bed, file=<span class="string">"results/Nanog_vs_Pou5f1_edgeR_sig.bed"</span>, sep=<span class="string">"\t"</span>, quote=<span class="literal">F</span>, row.names=<span class="literal">F</span>, col.names=<span class="literal">F</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># DESeq2</span></span><br><span class="line">out &lt;- as.data.frame(comp1.deseq)</span><br><span class="line">deseq.bed &lt;- out[ which(out$FDR &lt; <span class="number">0.05</span>), </span><br><span class="line">                 c(<span class="string">"seqnames"</span>, <span class="string">"start"</span>, <span class="string">"end"</span>, <span class="string">"strand"</span>, <span class="string">"Fold"</span>)]</span><br><span class="line">write.table(deseq.bed, file=<span class="string">"results/Nanog_vs_Pou5f1_deseq2_sig.bed"</span>, sep=<span class="string">"\t"</span>, quote=<span class="literal">F</span>, row.names=<span class="literal">F</span>, col.names=<span class="literal">F</span>)</span><br></pre></td></tr></table></figure></p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li><a href="http://bioconductor.org/packages/release/bioc/vignettes/DiffBind/inst/doc/DiffBind.pdf" target="_blank" rel="noopener">DiffBind文档</a></li><li><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/blob/master/sessionV/lessons/09_differential_peaks.md" target="_blank" rel="noopener">哈佛深度NGS数据分析课程， 09- Differential Peak calling using DiffBind</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ATACseq </tag>
            
            <tag> ChIPseq </tag>
            
            <tag> 差异分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第8篇：用网页版工具做功能分析和motif分析</title>
      <link href="/2019/08/23/31208.html"/>
      <url>/2019/08/23/31208.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>上一篇介绍了使用ChIPseeker对peaks的分布和邻近基因的注释。除此之外，下游分析通常还包括<strong>鉴定我们感兴趣的蛋白质结合的motif；鉴定这些结合区域的基因以及这些基因的富集通路或网络。</strong></p></blockquote><h3 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h3><ul><li><strong>功能富集分析: [GREAT]</strong>(<a href="http://bejerano.stanford.edu/great/public/html/index.php" target="_blank" rel="noopener">http://bejerano.stanford.edu/great/public/html/index.php</a>)</li><li><strong>motif分析:MEME套件，如DREME(<a href="http://meme-suite.org/tools/dreme)" target="_blank" rel="noopener">http://meme-suite.org/tools/dreme)</a>, MEME-ChIP (<a href="http://meme-suite.org/tools/meme-chip" target="_blank" rel="noopener">http://meme-suite.org/tools/meme-chip</a>)</strong> </li></ul><a id="more"></a><p><img src="https://upload-images.jianshu.io/upload_images/8242255-8e8c5b7121002686.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p><h3 id="准备文件"><a href="#准备文件" class="headerlink" title="准备文件"></a>准备文件</h3><p><strong>提取IDR结果文件的前3列</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cut -f 1,2,3 Nanog-idr-merged.bed  &gt; Nanog-idr-merged-great.bed</span><br></pre></td></tr></table></figure></p><p><strong>使用<code>bedtools getfasta</code>提取peaks的序列</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bedtools getfasta -<span class="keyword">fi</span> \</span><br><span class="line">ref_genome.fa \</span><br><span class="line">-bed Nanog-idr-merged-great.bed \</span><br><span class="line">-fo Nanog-idr-merged-dreme.fasta</span><br></pre></td></tr></table></figure></p><h3 id="富集分析"><a href="#富集分析" class="headerlink" title="富集分析"></a>富集分析</h3><p>GREAT(<a href="http://bejerano.stanford.edu/great/public/html/index.php)对peaks的功能注释是对peaks临近基因的注释。" target="_blank" rel="noopener">http://bejerano.stanford.edu/great/public/html/index.php)对peaks的功能注释是对peaks临近基因的注释。</a><br><strong>方法：</strong></p><ul><li>1.打开GREAT网站：<a href="http://bejerano.stanford.edu/great/public/html/index.php" target="_blank" rel="noopener">http://bejerano.stanford.edu/great/public/html/index.php</a> 。上传<code>Nanog-idr-merged-great.bed</code>文件，选择参考基因组，选择<code>Whole genome</code>作为背景区域，然后点击<code>Submit</code>。<br><img src="https://upload-images.jianshu.io/upload_images/8242255-28d362bcb09d151b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></li><li><ol start="2"><li>点开<code>Job Description</code>,选择<code>View all genomic region-gene associations</code>，结果中的两个表给出peaks注释到的基因，一个是基因组区域和基因关联的表，一个是基因和基因组关联的表：<br><img src="https://upload-images.jianshu.io/upload_images/8242255-c858a398d92b19a1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></li></ol></li><li><ol start="3"><li><code>Region-Gene Association Graphs</code><br>这栏内容对结合位点的基因数和转录起始位点相关的基因做了图形展示。<br><img src="https://upload-images.jianshu.io/upload_images/8242255-5e49b7856b712239.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></li></ol></li><li><ol start="4"><li><code>Global Controls</code><br>选择想注释的信息，如GO注释<br><img src="https://upload-images.jianshu.io/upload_images/8242255-34e46431f660ae7a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></li></ol></li><li><ol start="5"><li>探究Nanog结合位点相关的GO BP term<br><img src="https://upload-images.jianshu.io/upload_images/8242255-f20dd9477422c904.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></li></ol></li><li><ol start="6"><li>选择某个term,查看具体信息<br><img src="https://upload-images.jianshu.io/upload_images/8242255-752f9bd3f211869b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></li></ol></li><li><ol start="7"><li>打开<code>This term&#39;s genomic region-gene association tables (140 regions, 116 genes)</code>，查看注释到的GO term相关的基因，可以下载表格。<br><img src="https://upload-images.jianshu.io/upload_images/8242255-ac6510b361c9db44.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></li></ol></li><li><ol start="8"><li>在<code>This term&#39;s gene -&gt; genomic region association table</code>中点击基因相关的regions，可以在UCSC浏览器上直接查看结合区域。</li></ol></li></ul><hr><h3 id="找Motif"><a href="#找Motif" class="headerlink" title="找Motif"></a>找Motif</h3><p>motif是比较有特征的短序列，会多次出现的，并被假设拥有生物学功能。而且，经常是一些具有序列特异性的蛋白的结合位点（如转录因子）或者是涉及到重要生物过程的（如，RNA 起始，RNA 终止， RNA 剪切等等）。<br>有很多网页版工具提供了找motif的方法，2014年的一篇综述列出了目前常用的网页工具（<a href="https://doi.org/10.1186/1745-6150-9-4" target="_blank" rel="noopener">https://doi.org/10.1186/1745-6150-9-4</a> ）：<br><img src="https://upload-images.jianshu.io/upload_images/8242255-4e6d85633c68e1d4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br>最常用的有MEME工具套件，下面主要介绍DREME。<strong>DREME</strong>适用于大批量的ChIP-Seq数据找真核转录因子短的（4nt或8nt）核心DNA结合基序。</p><h4 id="DREME"><a href="#DREME" class="headerlink" title="DREME"></a>DREME</h4><ul><li>打开DREME网页 <a href="http://meme-suite.org/tools/dreme" target="_blank" rel="noopener">http://meme-suite.org/tools/dreme</a> ，只要输入fasta序列<code>Nanog-idr-merged-dreme.fasta</code>即可，同时可以写上email和每个任务的描述，任务完成时如右图所示，可以打开DREAM_HTML_output查看结果。<br><img src="https://upload-images.jianshu.io/upload_images/8242255-f7d4e747bf2f1644.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br>DREME’s HTML展示的结果包括找到的motif的序列logo和表示显著性的E-value。点击<code>More</code>可以查看更多的信息。<br><img src="https://upload-images.jianshu.io/upload_images/8242255-da950ecc30a57391.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br><strong>Tomtom</strong><br>为了确定鉴定到的motif与已知转录因子的motif是否相似，可以将找到的motif再提交到<strong>Tomtom</strong>，与已知的转录因子数据库搜索匹配，同时还会给出motif-motif相似性的统计评估。<br>在DREAM’s HTML结果中选择某个预测到的motif，点击<code>Submit / Download</code>,然后选择<code>Tomtom</code>，点击<code>Submit</code>，在新打开的Tomtom界面可以选择转录因子的参考数据库，保持默认参数不变，也可以再添加其他参数，输入邮箱和任务描述就可以开始搜索。<br><img src="https://upload-images.jianshu.io/upload_images/8242255-d9aa88cd750c93ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><h4 id="MEME-ChIP"><a href="#MEME-ChIP" class="headerlink" title="MEME-ChIP"></a>MEME-ChIP</h4>MEME-ChIP是MEME套件中的另一个工具，可以实现DREAM和Tomtom的分析功能，还可以评估motifs的中心富集性并整合相关的motifs合成相似性簇。MEME-ChIP能够鉴定更长的motifs（&lt;30bp）,但是运行时间比较长。<br><img src="https://upload-images.jianshu.io/upload_images/8242255-1da222fab1a31f81.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br>另外可以用Homer找motif，详细用法参考<a href="https://vip.biotrainee.com/d/388-motif" target="_blank" rel="noopener">找个motif嘛，简单</a>。<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3></li></ul><ol><li><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/blob/master/sessionV/lessons/08_functional_analysis.md" target="_blank" rel="noopener">哈佛深度NGS数据分析课程, 08-Web-based functional analysis and motif discovery</a></li><li><a href="https://vip.biotrainee.com/d/388-motif" target="_blank" rel="noopener">找个motif嘛，简单</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ATACseq </tag>
            
            <tag> ChIPseq </tag>
            
            <tag> motif </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第7篇：用Y叔的ChIPseeker对peaks进行注释和可视化</title>
      <link href="/2019/08/23/12181.html"/>
      <url>/2019/08/23/12181.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>上一步骤（<a href="https://www.jianshu.com/p/d8a7056b4294" target="_blank" rel="noopener">第6篇：重复样本的处理——IDR</a>）用IDR对重复样本peaks的一致性进行了评估，同时得到了merge后的一致性的peaks——<code>sample-idr</code>，接下来就是对peaks的注释。这篇主要介绍用Y叔的R包<strong><a href="http://www.bioconductor.org/packages/release/bioc/vignettes/ChIPseeker/inst/doc/ChIPseeker.html" target="_blank" rel="noopener">ChIPseeker</a>对peaks的位置（如peaks位置落在启动子、UTR、内含子等）以及peaks临近基因的注释</strong>。</p></blockquote><h3 id="ChIPseeker"><a href="#ChIPseeker" class="headerlink" title="ChIPseeker"></a>ChIPseeker</h3><p>ChIPseeker虽然最初是为了ChIP-seq注释而写的一个R包，但它不只局限于ChIP-seq，也可用于ATAC-Seq等其他富集peaks注释，也可用于lincRNA注释、DNA breakpoints的断点位置注释等所有genomic coordination的注释，另外提供了丰富的可视化功能。<br>ChIPseeker的强大功能请参考Y叔的<a href="(https://mp.weixin.qq.com/mp/homepage?__biz=MzI5NjUyNzkxMg==&amp;hid=11&amp;sn=c22229f28bd00c3efd2c89cdadd63315&amp;scene=18&amp;devicetype=android-23&amp;version=26070238&amp;lang=zh_CN&amp;nettype=3gnet&amp;ascene=7&amp;session_us=gh_ba0578f6322d">ChIP-Seq系列文章</a>)，如：<br><a href="https://mp.weixin.qq.com/s/vWTf59KDs1lp_sQXjEhI_g" target="_blank" rel="noopener">CS3: peak注释</a><br><a href="https://mp.weixin.qq.com/s/_OPzvaEAbiMolCA2mqJXLw" target="_blank" rel="noopener">CS4：关于ChIPseq注释的几个问题</a><br><a href="https://mp.weixin.qq.com/s/MqpfgkMJSFj0pYwcEjV9kQ" target="_blank" rel="noopener">CS6: ChIPseeker的可视化方法（中秋节的视觉饕餮）</a></p><a id="more"></a><p><img src="https://upload-images.jianshu.io/upload_images/8242255-ed9f825cf93a7fa8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p><h3 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h3><p>使用ChIPseeker需要准备两个文件：一个就是要注释的peaks的文件，需满足BED格式。另一个就是注释参考文件，即需要一个包含注释信息的TxDb对象。Bioconductor提供了30个TxDb包，如果其中有研究的物种就可以直接下载安装此物种的TxDb信息。如果研究的物种没有已知的TxDb，可以使用GenomicFeatures包的函数（makeTxDbFromUCSC，makeTxDbFromBiomart）制作TxDb对象：</p><blockquote><p>makeTxDbFromUCSC： 通过UCSC在线制作TxDb<br>makeTxDbFromBiomart: 通过ensembl在线制作TxDb<br>makeTxDbFromGRanges：通过GRanges对象制作TxDb<br>makeTxDbFromGFF：通过解析GFF文件制作TxDb</p></blockquote><p><strong>制作TxDb方法示例（<a href="https://mp.weixin.qq.com/s/_OPzvaEAbiMolCA2mqJXLw" target="_blank" rel="noopener">CS4：关于ChIPseq注释的几个问题</a>）：</strong></p><ul><li><p>如用人的参考基因信息来做注释，从UCSC生成TxDb:</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(GenomicFeatures)</span><br><span class="line">hg19.refseq.db &lt;- makeTxDbFromUCSC(genome=<span class="string">"hg19"</span>, table=<span class="string">"refGene"</span>)</span><br></pre></td></tr></table></figure></li><li><p>用GFF文件做裂殖酵母的注释</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">download.file(<span class="string">"ftp://ftp.ebi.ac.uk/pub/databases/pombase/pombe/Chromosome_Dumps/gff3/schizosaccharomyces_pombe.chr.gff3"</span>, <span class="string">"schizosaccharomyces_pombe.chr.gff3"</span>)<span class="keyword">require</span>(GenomicFeatures)</span><br><span class="line">spombe &lt;- makeTxDbFromGFF(<span class="string">"schizosaccharomyces_pombe.chr.gff3"</span>)</span><br></pre></td></tr></table></figure></li></ul><p><strong>具体步骤如下：</strong></p><h3 id="第1步：下载安装ChIPseeker注释相关的包"><a href="#第1步：下载安装ChIPseeker注释相关的包" class="headerlink" title="第1步：下载安装ChIPseeker注释相关的包"></a>第1步：下载安装ChIPseeker注释相关的包</h3><p>从Bioconductor直接下载，或从github安装最新版本<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">source</span> (<span class="string">"https://bioconductor.org/biocLite.R"</span>)</span><br><span class="line">biocLite(<span class="string">"ChIPseeker"</span>)</span><br><span class="line"><span class="comment"># 下载人的基因和lincRNA的TxDb对象</span></span><br><span class="line">biocLite(<span class="string">"org.Hs.eg.db"</span>)</span><br><span class="line">biocLite(<span class="string">"TxDb.Hsapiens.UCSC.hg19.knownGene"</span>)</span><br><span class="line">biocLite(<span class="string">"TxDb.Hsapiens.UCSC.hg19.lincRNAsTranscripts"</span>)</span><br><span class="line">biocLite(<span class="string">"clusterProfiler"</span>)</span><br><span class="line"><span class="comment">#载入各种包</span></span><br><span class="line"><span class="keyword">library</span>(<span class="string">"ChIPseeker"</span>)</span><br><span class="line"><span class="keyword">library</span>(clusterProfiler)</span><br><span class="line"><span class="keyword">library</span>(<span class="string">"org.Hs.eg.db"</span>)</span><br><span class="line"><span class="keyword">library</span>(TxDb.Hsapiens.UCSC.hg19.knownGene)</span><br><span class="line">txdb &lt;- TxDb.Hsapiens.UCSC.hg19.knownGene</span><br><span class="line"><span class="keyword">library</span>(<span class="string">"TxDb.Hsapiens.UCSC.hg19.lincRNAsTranscripts"</span>)</span><br><span class="line">lincRNA_txdb=TxDb.Hsapiens.UCSC.hg19.lincRNAsTranscripts</span><br></pre></td></tr></table></figure></p><h3 id="第2步：读入peaks文件"><a href="#第2步：读入peaks文件" class="headerlink" title="第2步：读入peaks文件"></a>第2步：读入peaks文件</h3><p>函数<code>readPeakFile</code>读入peaks文件<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nanog &lt;- readPeakFile(<span class="string">"./idr_out.bed/nanog_idr-bed"</span>)</span><br><span class="line">pou5f1 &lt;- readPeakFile(<span class="string">"./idr_out.bed/pou5f1_idr-bed"</span>)</span><br></pre></td></tr></table></figure></p><h3 id="第3步：注释peaks"><a href="#第3步：注释peaks" class="headerlink" title="第3步：注释peaks"></a>第3步：注释peaks</h3><p>peaks的注释是用的<code>annotatePeak</code>函数，可以单独对每个peaks文件进行注释，也可以将多个peaks制作成一个list，进行比较分析和可视化。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 制作多个样本比较的list</span></span><br><span class="line">peaks &lt;- list(Nanog=nanog,Pou5f1=pou5f1)</span><br><span class="line"><span class="comment"># promotor区间范围可以自己设定</span></span><br><span class="line">promoter &lt;- getPromoters(TxDb=txdb, upstream=<span class="number">3000</span>, downstream=<span class="number">3000</span>)</span><br><span class="line">tagMatrixList &lt;- lapply(peaks, getTagMatrix, windows=promoter)</span><br><span class="line"><span class="comment">#annotatePeak传入annoDb参数,可进行基因ID转换（Entrez，ENSEMBL，SYMBOL，GENENAME）</span></span><br><span class="line">peakAnnoList &lt;- lapply(peaks, annotatePeak, TxDb=txdb,tssRegion=c(-<span class="number">3000</span>, <span class="number">3000</span>), verbose=<span class="literal">FALSE</span>,addFlankGeneInfo=<span class="literal">TRUE</span>, flankDistance=<span class="number">5000</span>,annoDb=<span class="string">"org.Hs.eg.db"</span>)</span><br></pre></td></tr></table></figure></p><p><strong>annotatePeak传入annoDb参数,即可进行基因ID转换，将Entrez ID转化为ENSEMBL，SYMBOL，GENENAME</strong>，peakAnnoList的结果如下：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">seqnamesstartendwidthstrandannotationgeneChrgeneStartgeneEndgeneLengthgeneStrandgeneIdtranscriptIddistanceToTSSENSEMBLSYMBOLGENENAMEflank_txIdsflank_geneIdsflank_gene_distances</span><br><span class="line"><span class="number">5</span>chr3<span class="number">196625522</span><span class="number">196625873</span><span class="number">352</span>*Intron (uc003fwz.4/<span class="number">205564</span>, intron <span class="number">2</span> of <span class="number">9</span>)<span class="number">3</span><span class="number">196594727</span><span class="number">196661584</span><span class="number">66858</span><span class="number">1</span><span class="number">205564</span>uc011bty.2<span class="number">30795</span>ENSG00000119231SENP5SUMO specific peptidase <span class="number">5</span>uc003fwz.4;uc011bty.2<span class="number">205564</span>;<span class="number">205564</span><span class="number">0</span>;<span class="number">0</span></span><br></pre></td></tr></table></figure><h3 id="第4步：可视化"><a href="#第4步：可视化" class="headerlink" title="第4步：可视化"></a>第4步：可视化</h3><p>提供了多种可视化方法，如plotAnnoBar(),vennpie(),plotAnnoPie(),plotDistToTSS()等，下面展示了两个样本在基因组特征区域的分布以及转录因子在TSS区域的结合。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plotAnnoBar(peakAnnoList)</span><br><span class="line">plotDistToTSS(peakAnnoList,title=<span class="string">"Distribution of transcription factor-binding loci \n relative to TSS"</span>)</span><br></pre></td></tr></table></figure></p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-0f981c1bb6b89f8d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><h3 id="第5步：功能富集分析"><a href="#第5步：功能富集分析" class="headerlink" title="第5步：功能富集分析"></a>第5步：功能富集分析</h3><p>提取peakAnnolist中的基因，结合clusterProfiler包对peaks内的邻近基因进行富集注释。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a list with genes from each sample</span></span><br><span class="line">gene = lapply(peakAnnoList, <span class="keyword">function</span>(i) as.data.frame(i)$geneId)</span><br><span class="line"><span class="comment"># Run GO enrichment analysis </span></span><br><span class="line">ego &lt;- enrichGO(gene = entrez, </span><br><span class="line">                    keytype = <span class="string">"ENTREZID"</span>, </span><br><span class="line">                    OrgDb = org.Hs.eg.db, </span><br><span class="line">                    ont = <span class="string">"BP"</span>, </span><br><span class="line">                    pAdjustMethod = <span class="string">"BH"</span>, </span><br><span class="line">                    qvalueCutoff = <span class="number">0.05</span>, </span><br><span class="line">                    readable = <span class="literal">TRUE</span>)</span><br><span class="line"><span class="comment"># Dotplot visualization</span></span><br><span class="line">dotplot(ego, showCategory=<span class="number">50</span>)</span><br><span class="line"><span class="comment"># Multiple samples KEGG analysis</span></span><br><span class="line">compKEGG &lt;- compareCluster(geneCluster = gene, </span><br><span class="line">                         fun = <span class="string">"enrichKEGG"</span>,</span><br><span class="line">                         organism = <span class="string">"human"</span>,</span><br><span class="line">                         pvalueCutoff  = <span class="number">0.05</span>, </span><br><span class="line">                         pAdjustMethod = <span class="string">"BH"</span>)</span><br><span class="line">dotplot(compKEGG, showCategory = <span class="number">20</span>, title = <span class="string">"KEGG Pathway Enrichment Analysis"</span>)</span><br></pre></td></tr></table></figure></p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-ebcdf242c4bc96f6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><h3 id="第6步：保存文件"><a href="#第6步：保存文件" class="headerlink" title="第6步：保存文件"></a>第6步：保存文件</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Output peakAnnolist file</span></span><br><span class="line">save(peakAnnoList,file=<span class="string">"peakAnnolist.rda"</span>)</span><br><span class="line">write.table(as.data.frame(peakAnnoList$Nanog),file=<span class="string">"Nanog.PeakAnno"</span>,sep=<span class="string">'\t'</span>,quote = <span class="literal">F</span>)</span><br><span class="line"><span class="comment"># Output results from GO analysis to a table</span></span><br><span class="line">cluster_summary &lt;- data.frame(ego)</span><br><span class="line">write.csv(cluster_summary, <span class="string">"results/clusterProfiler_Nanog.csv"</span>)</span><br></pre></td></tr></table></figure><hr><h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><p>ChIPseeker详细内容请参考:</p><ul><li><a href="http://www.bioconductor.org/packages/release/bioc/vignettes/ChIPseeker/inst/doc/ChIPseeker.html" target="_blank" rel="noopener">ChIPseeker文档</a></li><li>Y叔的<a href="https://mp.weixin.qq.com/mp/homepage?__biz=MzI5NjUyNzkxMg==&amp;hid=11&amp;sn=c22229f28bd00c3efd2c89cdadd63315&amp;scene=18&amp;devicetype=android-23&amp;version=26070238&amp;lang=zh_CN&amp;nettype=3gnet&amp;ascene=7&amp;session_us=gh_ba0578f6322d" target="_blank" rel="noopener">ChIP-Seq系列</a>：<br><a href="https://mp.weixin.qq.com/s/vWTf59KDs1lp_sQXjEhI_g" target="_blank" rel="noopener">CS3: peak注释</a><br><a href="https://mp.weixin.qq.com/s/_OPzvaEAbiMolCA2mqJXLw" target="_blank" rel="noopener">CS4：关于ChIPseq注释的几个问题</a><br><a href="https://mp.weixin.qq.com/s/MqpfgkMJSFj0pYwcEjV9kQ" target="_blank" rel="noopener">CS6: ChIPseeker的可视化方法（中秋节的视觉饕餮）</a></li><li><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons" target="_blank" rel="noopener">哈佛深度NGS数据分析课程</a></li><li><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/blob/master/sessionV/lessons/07_ChIPseeker_functional_analysis.md" target="_blank" rel="noopener">07-ChIPseeker for ChIP peak Annotation, Comparison, and Visualization</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ATACseq </tag>
            
            <tag> software </tag>
            
            <tag> ChIPseq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第6篇：重复样本的处理——IDR</title>
      <link href="/2019/08/23/26155.html"/>
      <url>/2019/08/23/26155.html</url>
      
        <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p><strong>ATAC-seq/ChIP-Seq中重复样本的处理</strong></p><p>ATAC-Seq要求必须有2次或更多次生物学重复（十分珍贵或者稀有样本除外，但必须做至少2次技术重复）。理论上重复样本的peaks应该有高度的一致性，实际情况并不完全与预期一致。如何评价重复样本的重复性的好坏？如何得到一致性的peaks?</p><h3 id="这一节将介绍两种方法："><a href="#这一节将介绍两种方法：" class="headerlink" title="这一节将介绍两种方法："></a>这一节将介绍两种方法：</h3><p><strong>1. 用Bedtools进行简单的overlap合并重复样本</strong><br><strong>2. 用IDR（Irreproducibility Discovery Rate）的方法获得高重复性的peaks</strong></p><a id="more"></a><p><img src="https://upload-images.jianshu.io/upload_images/8242255-f2cf66adfcbcc2d6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p><hr><h3 id="1-Overlapping-peaks-using-bedtools"><a href="#1-Overlapping-peaks-using-bedtools" class="headerlink" title="1. Overlapping peaks using bedtools"></a>1. Overlapping peaks using bedtools</h3><p>如何得到两个重复样本间一致性的peaks? 一种简单粗暴的方法就是用<code>bedtools</code>计算peaks的overlaps。<br>用法：<code>bedtools intersect [OPTIONS] -a &lt;bed/gff/vcf/bam&gt; -b &lt;bed/gff/vcf/bam&gt;</code></p><ul><li><code>-a</code>: 参数后加重复样本1（A）</li><li><code>-b</code>：参数后加重复样本2（B），也可以加多个样本</li></ul><p>其他常用参数解释和图解如下：</p><ul><li><code>-wo</code>：Write the original A and B entries plus the number of base pairs of overlap between the two features.</li><li><code>-wa</code>：Write the original entry in A for each overlap.</li><li><code>-v</code>：Only report those entries in A that have <em>no overlaps</em> with B<br>如果只有<code>-a</code>和<code>-b</code>参数，返回的是相对于A的overlaps。加上参数<code>-wo</code>返回A和B原始的记录加上overlap的记录。参数<code>-wa</code>返回每个overlap中A的原始记录。<br><img src="https://upload-images.jianshu.io/upload_images/8242255-539217c9b07ba9fa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br><strong>使用代码示例：</strong><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bedtools intersect \</span><br><span class="line">-a macs2/Nanog-rep1_peaks.narrowPeak \</span><br><span class="line">-b macs2/Nanog-rep2_peaks.narrowPeak \</span><br><span class="line">-wo &gt; bedtools/Nanog-overlaps.bed</span><br></pre></td></tr></table></figure></li></ul><h3 id="2-Irreproducibility-Discovery-Rate-IDR"><a href="#2-Irreproducibility-Discovery-Rate-IDR" class="headerlink" title="2. Irreproducibility Discovery Rate (IDR)"></a>2. Irreproducibility Discovery Rate (IDR)</h3><p>评估重复样本间peaks一致性的另一种方法是IDR。IDR是通过比较一对经过排序的regions/peaks 的列表，然后计算反映其重复性的值。<br>IDR在<a href="https://www.encodeproject.org/atac-seq/" target="_blank" rel="noopener">ENCODE</a>和modENCODE项目中被广泛使用，也是<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3431496/" target="_blank" rel="noopener">ChIP-seq指南和标准</a>中的一部分。</p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-ed3c5559db41126f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="ENCODE_ATAC_pipeline"><br><strong>IDR的 优点：</strong></p><ul><li>避免了初始阈值的选择，解决了不同callers的不可比较性</li><li>IDR不依赖于阈值的选择，所有regions/peaks都被考虑在内。</li><li>它是依赖regions/peaks的排序，不要求对输入信号进行校准或标准化<br>IDR的详细说明参考: </li><li><a href="https://github.com/nboley/idr" target="_blank" rel="noopener">https://github.com/nboley/idr</a></li><li><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/blob/master/sessionV/lessons/06_handling-replicates.md#irreproducibility-discovery-rate-idr" target="_blank" rel="noopener">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/blob/master/sessionV/lessons/06_handling-replicates.md#irreproducibility-discovery-rate-idr</a></li></ul><p><strong>使用IDR的注意事项：</strong></p><ul><li>建议使用IDR时，MACS2 call peaks的步骤参数设置不要过于严格，以便鉴定出更多的peaks。</li><li><p>使用IDR需要先对MACS2的结果文件narrowPeak根据<code>-log10(p-value)</code>进行排序。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Call peaks</span><br><span class="line">macs2 callpeak -t  sample.final.bam -n sample --shift -100 --extsize 200 --nomodel -B --SPMR -g hs --outdir Macs2_out 2&gt; sample.macs2.log</span><br><span class="line">#Sort peak by -log10(p-value)</span><br><span class="line">sort -k8,8nr NAME_OF_INPUT_peaks.narrowPeak &gt; macs/NAME_FOR_OUPUT_peaks.narrowPeak</span><br></pre></td></tr></table></figure></li><li><p><strong>使用IDR示例</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">idr --samples sample_Rep1_sorted_peaks.narrowPeak sample_Rep2_sorted_peaks.narrowPeak \</span><br><span class="line">--input-file-type narrowPeak \</span><br><span class="line">--rank p.value \</span><br><span class="line">--output-file sample-idr \</span><br><span class="line">--plot \</span><br><span class="line">--<span class="built_in">log</span>-output-file sample.idr.log</span><br></pre></td></tr></table></figure></li></ul><p><code>--samples</code>:narrowPeak的输入文件（重复样本）<br><code>--input-file-type</code>：输入文件格式包括narrowPeak,broadPeak,bed<br><code>--rank p.value</code>：以p-value排序<br><code>--output-file</code>: 输出文件路径<br><code>--plot</code>：输出IDR度量值的结果</p><p><strong>输出文件解读：</strong><br>详细内容可参考：<a href="https://github.com/nboley/idr#output-file-format" target="_blank" rel="noopener">https://github.com/nboley/idr#output-file-format</a></p><blockquote><p>输出文件包括：</p><ul><li>sample-idr</li><li>sample-idr.log</li><li>sample-idr.png</li></ul></blockquote><p><strong>（1）sample-idr</strong><br>sample-idr是common peaks的结果输出文件，格式与输入文件格式类似，只是多了几列信息。前10列是标准的narrowPeak格式文件，包含重复样本整合后的peaks信息。</p><ul><li><strong>第5列：包含缩放的 IDR 值</strong><ul><li>score int<br>如min(int(log2(-125IDR), 1000)，那么IDR=0，缩放的IDR就是1000；IDR=0.05,  int(-125log2(0.05)) = 540；IDR=1.0,  int(-125log2(1.0) = 0。</li></ul></li><li><strong>第11列和第12列：分别是local和global IDR值</strong><ul><li>col11: localIDR float -log10(Local IDR value)</li><li>col12: globalIDR float -log10(Global IDR value)<br>global IDR值是第5列中用于计算缩放的IDR值，类似于对p值进行多个假设校正以计算FDR；local IDR类似于属于不可重复噪声部分的峰值的后验概率。详细内容可阅读<a href="https://projecteuclid.org/euclid.aoas/1318514284" target="_blank" rel="noopener">Measuring reproducibility of high-throughput experiments</a>。</li></ul></li><li><strong>第13、14、15、16列</strong>：是重复样本1相关的信息。<ul><li>col13: rep1_chromStart int</li><li>col14: rep1_chromEnd int</li><li>col15: rep1_signalValue float</li><li>col16: rep1_summit int</li></ul></li><li><strong>第17-20列</strong>：是重复样本2相关的信息，和13-16四列信息类似。</li></ul><p><strong>其他列信息如下：</strong></p><ul><li>col1: chrom string</li><li>col2: chromStart int</li><li>col3: chromEnd int</li><li>col4: name string</li><li>col6: strand [+-.] Use ‘.’ if no strand is assigned.</li><li>col7: signalValue float</li><li>col8: p-value float </li><li>col9: q-value float</li><li>col10: summit int</li></ul><p><code>wc -l *-idr</code> 计算下common peaks的个数，接着可再计算下与总peaks的比率。<br>如果想看IDR&lt;0.05的，可以通过第5列信息过滤：<br><code>awk &#39;{if($5 &gt;= 540) print $0}&#39; sample-idr | wc -l</code><br><strong>（2）sample-idr.log</strong><br>log文件会给出peaks通过IDR &lt; 0.05的比率，如下图所示<br><img src="https://upload-images.jianshu.io/upload_images/8242255-ca6774163e8a6207.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br><strong>（3）sample-idr.png</strong><br>png文件包括4个图<br><img src="https://upload-images.jianshu.io/upload_images/8242255-f605c94aaaf401d2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><p>左上： Rep1 peak ranks vs Rep2 peak ranks, 没有通过特定IDR阈值的peaks显示为红色。<br>右上：Rep1 log10 peak scores vs Rep2 log10 peak scores，没有通过特定IDR阈值的peaks显示为红色。<br>下面两个图： Peak rank vs IDR scores，箱线图展示了IDR值的分布，默认情况下，IDR值的阈值为-1E-6。</p><h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><p><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons" target="_blank" rel="noopener">哈佛深度NGS数据分析课程</a><br><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/blob/master/sessionV/lessons/06_handling-replicates.md" target="_blank" rel="noopener">06-Handling replicates in ChIP-Seq</a></p>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ATACseq </tag>
            
            <tag> ChIPseq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第5篇：对ATAC-Seq/ChIP-seq的质量评估（二）——ChIPQC</title>
      <link href="/2019/08/23/36286.html"/>
      <url>/2019/08/23/36286.html</url>
      
        <content type="html"><![CDATA[<h3 id="1-学习目标"><a href="#1-学习目标" class="headerlink" title="1. 学习目标"></a>1. 学习目标</h3><ul><li>讨论ChIP-seq数据质量评估的其他方法</li><li>用ChIPQC产生质量统计报告</li><li>鉴定低质量数据的来源</li></ul><a id="more"></a><ul><li><p><strong>概览图</strong></p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-df6c67811efb85eb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p></li></ul><p>ENCODE评估数据质量采用多种指标，如前面已经讨论过的链相关的指标NSC和RSC。这一节将会讨论评估信号分布的其他指标。</p><blockquote><p><strong>NOTE</strong>：这里给出的评估指标只是反映数据质量的好坏，符合阈值的并不意味着实验是成功的，不符合阈值的也不一定意味着失败。</p></blockquote><h3 id="2-常见质量评估指标的介绍"><a href="#2-常见质量评估指标的介绍" class="headerlink" title="2.常见质量评估指标的介绍"></a>2.常见质量评估指标的介绍</h3><ul><li><h4 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h4>SSD值是对富集效果的评估。SSD值依赖于全基因组的pile-up信号强度，对真实的ChIP富集和干扰的强信号区域都很敏感。SSD值越大表明富集越好。<blockquote><p>“It provides a measure of pileup across the genome and is computed by looking at the standard deviation of signal pile-up along the genome normalised to the total number of reads. ”</p></blockquote></li><li><h4 id="FRiP-Fraction-of-reads-in-peaks"><a href="#FRiP-Fraction-of-reads-in-peaks" class="headerlink" title="FRiP:Fraction of reads in peaks"></a>FRiP:Fraction of reads in peaks</h4>FRiP表示的是peaks中的reads与总reads的比例。它是另一个反映样本富集效果或IP好坏的评价指标。可以理解为是“信噪比”即文库中结合位点片段占背景reads的比例。<strong>一个典型质量好的TF富集FRiP值约5%或者更高，polII的FRiP值约为30%或者更高，也有一些质量好的数据FRiP值&lt;1%（如RNAPIII）</strong></li><li><h4 id="Relative-Enrichment-of-Genomic-Intervals-REGI"><a href="#Relative-Enrichment-of-Genomic-Intervals-REGI" class="headerlink" title="Relative Enrichment of Genomic Intervals (REGI)"></a>Relative Enrichment of Genomic Intervals (REGI)</h4>REGI是对peaks在不同基因组特征位点分布的统计。</li><li><h4 id="RiBL-Reads-overlapping-in-Blacklisted-Regions"><a href="#RiBL-Reads-overlapping-in-Blacklisted-Regions" class="headerlink" title="RiBL: Reads overlapping in Blacklisted Regions"></a>RiBL: Reads overlapping in Blacklisted Regions</h4>过滤人工造成的高信号区域非常重要，如ENCIDE和modENCODE提供的DAC Blacklisted Regions track。这些区域经常在特定的重复序列处出现，如着丝粒、端粒、卫星重复序列等，通过简单的比对过滤是不能去除的。来自blacklisted regions的信号会造成call peak 和片段长度评估的混淆。<br>RiBL值可以表示背景信号或input的信号水平，与input sample的SSD值以及input和ChIP sample的读长覆盖值相关。这些区域通常是基因组的0.5%，或者更高的比例（10%）。<br><img src="https://upload-images.jianshu.io/upload_images/8242255-ffa899faf5d8e033.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></li></ul><h3 id="3-ChIPQC-quality-metrics-report"><a href="#3-ChIPQC-quality-metrics-report" class="headerlink" title="3. ChIPQC: quality metrics report"></a>3. ChIPQC: quality metrics report</h3><p>ChIPQC是一个Bioconductor包，输入文件包括BAM和peak文件，可以自动计算一些质量评估值，并产生质量报告。</p><h4 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h4><ul><li><strong>BAM files</strong><br>首先对比对过滤后的bam数据（chr12_aln.bam）建索引，然后将bam和index文件从<code>~/ngs_course/chipseq/results/bowtie2</code>移动到自己的目录文件夹<code>data/bams</code></li><li><strong>peak files</strong><br>将narrowPeak 文件从macs2目录下<code>~/ngs_course/chipseq/results/macs2</code> 移动到自己目录下<code>data/peakcalls</code></li><li><p><strong>sampleSheet file</strong><br>sampleSheet file是唯一需要自己根据实验设计和数据存储地址等信息创建的一个csv格式文件（bam,peak文件分别在比对和call peak的步骤产生）。sampleSheet具体需要包含的信息如下：<br><img src="https://upload-images.jianshu.io/upload_images/8242255-3910ab7fab88b880.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="sampleSheet header"></p></li><li><p>SampleID: 样本ID</p></li><li>Tissue, Factor, Condition: 不同的实验设计对照信息，三列信息必须包含在sampleSheet里，如果没有某一列的信息设为NA。</li><li>Replicate : 重复样本的编号</li><li>bamReads : 实验组BAM 文件的路径（data/bams）</li><li>ControlID : 对照组样本ID</li><li>bamControl :对照组样本的bam文件路径</li><li>Peaks :样本peaks文件的路径</li><li>PeakCaller ：peak类型的字符串，可以是raw,bed,narrow,macs等。<h4 id="下载安装ChIPQC"><a href="#下载安装ChIPQC" class="headerlink" title="下载安装ChIPQC"></a>下载安装ChIPQC</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">source</span>(<span class="string">"http://bioconductor.org/biocLite.R"</span>)</span><br><span class="line">biocLite(<span class="string">"ChIPQC"</span>)</span><br></pre></td></tr></table></figure></li></ul><h4 id="Running-ChIPQC"><a href="#Running-ChIPQC" class="headerlink" title="Running ChIPQC"></a>Running ChIPQC</h4><p>ChIPQC只需要三步就可以完成质量评估和报告生成。</p><ul><li><p><strong>首先载入包和sampleSheet信息</strong></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Load libraries</span></span><br><span class="line"><span class="keyword">library</span>(ChIPQC)</span><br><span class="line"><span class="comment">## Load sample data</span></span><br><span class="line">samples &lt;- read.csv(<span class="string">'meta/samplesheet_chr12.csv'</span>)</span><br><span class="line">View(samples)</span><br></pre></td></tr></table></figure></li><li><p><strong>创建ChIPQC对象</strong><br>利用sampleSheet的信息读取每个样本的bam和narrowpeak文件，并计算质量评估值，结果存在一个对象里。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Create ChIPQC object</span></span><br><span class="line">chipObj &lt;- ChIPQC(samples, annotation=<span class="string">"hg19"</span>)</span><br></pre></td></tr></table></figure></li><li><p><strong>生成ChIPQC报告</strong></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Create ChIPQC report</span></span><br><span class="line">ChIPQCreport(chipObj, reportName=<span class="string">"ChIP QC report: Nanog and Pou5f1"</span>, reportFolder=<span class="string">"ChIPQCreport"</span>)</span><br></pre></td></tr></table></figure></li></ul><h4 id="ChIPQC报告解读"><a href="#ChIPQC报告解读" class="headerlink" title="ChIPQC报告解读"></a>ChIPQC报告解读</h4><p>ChIPQC生成的结果包含一个网页报告和报告中含有的所有图片。<br>网页报告有三部分：<strong>QC Summary ；QC Results；QC files and versions</strong><br><img src="https://upload-images.jianshu.io/upload_images/8242255-a929302bfd47dc9d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><h5 id="（1）QC-Summary-Overview-of-results"><a href="#（1）QC-Summary-Overview-of-results" class="headerlink" title="（1）QC Summary - Overview of results"></a>（1）QC Summary - Overview of results</h5><p><img src="https://upload-images.jianshu.io/upload_images/8242255-01749f12cf83c9af.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 1"><br>QC summary包含sampleSheet里填写的样本的基本信息Tissue,Factor,Condition,Replicate。另外还有上面提到的质量评估的常用指标SSD、RiP%和RiBL值。越高的SSD值表明富集效果越好，Pou5f1样本（2.6,3）有较高的SSD值，RiBL值不是很高，FRiP的比例在5%附近或者更高，除了Pou5f1-rep2。</p><ul><li><strong>SSD</strong> - SSD score (htSeqTools)</li><li><strong>RIP%</strong> - Percentage of reads wthin peaks</li><li><strong>RIBL%</strong> - Percentage of reads wthin Blacklist regions<br>同时表格中还给出了其他统计信息：</li><li><strong>Reads</strong> - Number of sample reads within analysed chromosomes.</li><li><strong>Dup%</strong> - Percentage of MapQ filter passing reads marked as duplicates</li><li><strong>FragLen</strong> - Estimated fragment length by cross-coverage method</li><li><strong>FragLenCC</strong> - Cross-Coverage score at the fragment length</li><li><strong>RelativeCC</strong> - Cross-coverage score at the fragment length over Cross-coverage at the read length</li></ul><h5 id="（2）QC-Results-Full-QC-results-and-figures"><a href="#（2）QC-Results-Full-QC-results-and-figures" class="headerlink" title="（2）QC Results - Full QC results and figures"></a>（2）QC Results - Full QC results and figures</h5><ul><li><strong>Mapping, Filtering and Duplication rate</strong><br>第一部分是比对、过滤和重复率质检结果，包括Table2 、Figure1和Figure2。<br><strong>Table 2</strong>主要给出了比对质量和重复率，因为BAM文件是过滤后的，所以这里Dup%都是0.<br><img src="https://upload-images.jianshu.io/upload_images/8242255-ae05107ee85bb02a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 2"><blockquote><ul><li><strong>Total Dup%</strong>-Percentage of all mapped reads which are marked as duplicates.</li><li><strong>Pass MapQ Filter%</strong>-Percentage of all mapped reads whichpass MapQ quality filter</li><li><strong>Pass MapQ Filter and Dup%</strong>-Percentage of all reads which pass MapQ filter and are marked asduplicates.</li></ul></blockquote></li></ul><p><strong>Figure 1</strong>展现了reads在blacklists中的比例，</p><p><strong>Figure 2</strong>是用基因组注释呈现了reads在基因组特征位置如启动子的分布。这幅图里显示在启动子区域富集最明显。</p><ul><li><p><strong>ChIP signal Distribution and Structure</strong><br>第二部分是ChIP信号分布和结构组成，包括Figure3和4。<br><strong>Figure 3</strong>是一个coverage plot， x轴代表在某bp位置read pileup的高度，y轴代表有多少位置有相同的pileup 高度(取log)。**有好的富集的ChIP样本会有一个tail，即更多的位置（y值大）有较高的测序深度。在我们的数据集中Nanog样本与Pou5f1 相比有较高的tails,尤其是重复样本2。但是Pou5f1有较高的SSD值。当SSD高但是coverage看起来低时，可能是存在大片段深度高的区域出现在blacklist 基因组区域。</p></li><li><p><strong>Peak Profile and ChIP Enrichment</strong><br>第3部分是peak的谱图和ChIP的富集，每个peak都集中在summit位置（summit 理解为peak的最高峰值点处）<img src="https://upload-images.jianshu.io/upload_images/8242255-d50435914800593a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p></li><li><p>peak的性状取决于研究对象的类型，如转录因子、组蛋白标记、或其他DNA结合蛋白如聚合酶等，相同类型的对象通常有独特特征的谱图。<br><strong>Figure6和7</strong>都是对比对到peak中的reads统计。富集效果好的ChIP样本的reads与peaks会有高比例的重合。尽管Nanog有较高的RiP,但是两个重复样本间的差异大于Pou5f1。</p></li><li><p>Figure8和9**表示样本的聚类效果，分别是相关性聚类热图和PCA。</p></li></ul><p><img src="https://upload-images.jianshu.io/upload_images/8242255-ee0ccb984d0ea9dc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-4f61fd17225198b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p><h3 id="4-实验偏差：ChIP-seq数据质量低的来源"><a href="#4-实验偏差：ChIP-seq数据质量低的来源" class="headerlink" title="4. 实验偏差：ChIP-seq数据质量低的来源"></a>4. 实验偏差：ChIP-seq数据质量低的来源</h3><ul><li>免疫沉淀的特异性和有效性<br>影响因素如抗体的特异性，结和沉淀的强度</li><li>片段化<br>超声裂解产生不同大小的片段可能引入偏差</li><li>文库构建时的偏差<br>如PCR扩增<h4 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h4><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons" target="_blank" rel="noopener">哈佛深度NGS数据分析课程</a><br><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/blob/master/sessionV/lessons/05_QC_quality_metrics.md" target="_blank" rel="noopener">05-ChIP-Seq Quality Assessment</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ATACseq </tag>
            
            <tag> ChIPseq </tag>
            
            <tag> QC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第4篇：对ATAC-Seq/ChIP-seq的质量评估（一）——phantompeakqualtools</title>
      <link href="/2019/08/23/21700.html"/>
      <url>/2019/08/23/21700.html</url>
      
        <content type="html"><![CDATA[<h3 id="学习目标："><a href="#学习目标：" class="headerlink" title="学习目标："></a>学习目标：</h3><ul><li>探讨ChIP-seq数据质量低的来源</li><li>理解链交叉相关性（ strand cross-correlation）</li><li>使用<code>phantompeakqualtools</code>计算交叉相关性和其他相关的质控度量值</li><li>评估交叉相关图</li></ul><a id="more"></a><h3 id="ChIP-Seq质量评估"><a href="#ChIP-Seq质量评估" class="headerlink" title="ChIP-Seq质量评估"></a>ChIP-Seq质量评估</h3><p>在下游分析前，最好是先对peak calling 后的ChIP-Seq数据进行质量评估。</p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-025dd4ff30ae61b8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p><h3 id="链交叉相关（Strand-cross-correlation）"><a href="#链交叉相关（Strand-cross-correlation）" class="headerlink" title="链交叉相关（Strand cross-correlation）"></a>链交叉相关（Strand cross-correlation）</h3><p>链交叉相关是一个有效的评估ChIP-Seq质量的方法，它不依赖于peak calling，而是基于ChIP-Seq实验。如果ChIP-Seq实验成功，DNA富集序列标签（蛋白质相互作用的序列）会在reads的双峰富集中产生显著的聚集。<br><strong>产生reads的双峰富集的原因如下：</strong><br>在ChIP-Seq实验中，DNA被片段化，蛋白质结合的片段会被免疫沉淀，所以产生了有蛋白质结合的DNA片段（fragments ）。<br>DNA的正链从5’端开始被测序（如下图红色reads），DNA负链也从5’末端被测序产生如下图所示的蓝色reads。<br><img src="https://upload-images.jianshu.io/upload_images/8242255-9095a287381f5ec6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Nat Biotechnol. 2008 Dec; 26(12): 1351–1359"><br>由于从DNA片段的5′末端测序，使+链reads的富集（下图中的蓝色部分）与负链reads的富集（下图红色部分）有少量的相互抵消区域。我们<strong>需要确定峰位移多少碱基数目可以在两个峰间产生最大的相关性。</strong>我们可以用<strong>交叉相关的度量值（cross-correlation metric）</strong>计算产生最大相关的位移。</p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-120795238a4bbaba.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p><p><strong>交叉相关性度量值</strong><br>交叉相关度量是在Watson移动k个碱基后，计算Crick链与Watson链之间的Pearson线性相关。如下面的示意图：<br>首先在链位移为0时，两个向量之间的Pearson相关值为0.539。</p><p>在链位移5bp，两个向量之间的Pearson相关值为0.931。</p><p>继续移动这些向量，对于每个链位移计算一个相关值。</p><p>最后，我们将有一个每个碱基对移位与皮尔森相关值的对应表。这是针对每个染色体的每一个峰计算的，然后该值乘以一个缩放因子，再对所有染色体的值相加，就可以绘交叉相关值（y轴）相对于移位值（x轴）生成的交叉相关图。<br><strong>典型的交叉相关图会产生两个峰</strong>：一个富集峰与主要的<strong>片段长度（predominant fragment length）</strong>相关（高相关性），另一个与<strong>read 长度（read length）</strong>相关，这个峰也被称为虚幻峰（“phantom” peak）。</p><ul><li><p>质量好的ChIP-Seq数据集倾向产生一个大的<strong>片段长度峰（fragment-length peak）</strong>，下图展示了一个来自于人细胞CTCF（zinc-finger transcription factor）的强信号。如果有好的抗体，转录因子通常产生45,000~60,000个peaks。下图红色的垂直线表示主峰的真实位移，蓝色的垂直线处有一个小的起伏表示read lenngth。</p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-f291e6c7288d5df6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p></li></ul><ul><li><p>下图是<strong>weaker signal</strong>的一个示例。这里<strong>Pol2</strong>的抗体不是很有效，有分散的峰。交叉相关图中有两个峰，一个是真实的峰位移（185-200bp），另外一个在read length。信号弱的数据集中read length的峰会成为主峰。</p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-2846dc6bb5085bf8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p></li></ul><ul><li><p>一个失败的实验产生的交叉相关图类似于<strong>input</strong>，在<strong>fragment length</strong>处很少或没有峰，在<strong>read length</strong>处有信号非常强的。这种现象的原因可能是在结合位点附近<strong>fragments</strong>没有显著聚集。</p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-8781f9f9bd780b15.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p></li></ul><h3 id="交叉相关性质量评估度量值"><a href="#交叉相关性质量评估度量值" class="headerlink" title="交叉相关性质量评估度量值"></a>交叉相关性质量评估度量值</h3><p>交叉相关谱图可以计算评估ChIP_Seq实验信噪比的度量值，并且实验设计确保<strong>fragment length</strong>准确。低信噪比和不准确的fragment length 表明ChIP-Seq实验可能有问题。<br><strong>Normalized strand cross-correlation coefficent (NSC)：</strong><br>NSC是最大交叉相关值除以背景交叉相关的比率(所有可能的链转移的最小交叉相关值)。<strong>NSC值越大表明富集效果越好，NSC值低于1.1<br>表明较弱的富集，小于1表示无富集。</strong>NSC值稍微低于1.05，有较低的信噪比或很少的峰，这肯能是生物学真实现象，比如有的因子在特定组织类型中只有很少的结合位点；也可能确实是数据质量差。<br><strong>Relative strand cross-correlation coefficient (RSC):</strong><br>RSC是片段长度相关值减去背景相关值除以phantom-peak相关值减去背景相关值。<strong>RSC的最小值可能是0，表示无信号；富集好的实验RSC值大于1；低于1表示质量低。</strong></p><h3 id="phantompeakqualtools"><a href="#phantompeakqualtools" class="headerlink" title="phantompeakqualtools"></a>phantompeakqualtools</h3><p>phantompeakqualtools 是一个用于计算ChIP-Seq数据富集和质量度量值的一个工具包。我们将使用该包来计算基于链交叉相关峰的主要插入大小(fragment length)和基于相对phantom peak的数据质量度量值。<code>phantompeakqualtools</code>是一个R包，依赖<code>samtools</code>。<br><strong>下载<code>phantompeakqualtools</code></strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/phantompeakqualtools/ccQualityControl.v.1.1.tar.gz</span><br><span class="line">tar -xzf ccQualityControl.v.1.1.tar.gz</span><br><span class="line"><span class="built_in">cd</span> phantompeakqualtools</span><br><span class="line"><span class="comment"># 查看README</span></span><br><span class="line">less README.txt</span><br></pre></td></tr></table></figure></p><p><strong>Linux下安装</strong><br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">R </span><br><span class="line">install.packages(<span class="string">"caTools"</span>, lib=<span class="string">"~/R/library"</span>)</span><br></pre></td></tr></table></figure></p><p><strong>运行phantompeakqualtools</strong></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p logs qual</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> bam <span class="keyword">in</span> bam_dir/sample1.final.bam bam_dir/sample2.final.bam</span><br><span class="line">do </span><br><span class="line">bam2=`basename $bam .final.bam`</span><br><span class="line">Rscript run_spp_nodups.R -c=$bam -savp -out=qual/$&#123;bam2&#125;.qual &gt; logs/$&#123;bam2&#125;.Rout</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p><strong>参数含义：</strong></p><ul><li><code>-c</code>: 比对过滤后的bam文件的全路径和名字</li><li><code>-savp</code>:保存交叉相关图</li><li><code>-out</code>：会产生数据集重要特征值的输出文件</li></ul><p><strong>输出文件解读</strong><br>输出文件会产生一个tab分割的名为qual的文件,包含的信息如下：</p><ul><li><p>COL1：Filename：比对过滤的bam文件名</p></li><li><p>COL2：numReads ：有效的测序深度</p></li><li><p>COL3：estFragLen：逗号分隔的交叉相关峰以相关性递减顺序排列的值</p></li><li><p>COL4: corr_estFragLen: 逗号分隔的以递减顺序排列交叉相关值</p></li><li><p>COL5: phantomPeak: Read length/phantom peak链位移</p></li><li><p>COL6: corr_phantomPeak: phantom peak相关值</p></li><li><p>COL7: argmin_corr:交叉相关最小的链位移</p></li><li><p>COL8: min_corr:交叉相关最小值</p></li><li><p>COL9: Normalized strand cross-correlation coefficient (NSC) = COL4 / COL8</p></li><li><p>COL10: Relative strand cross-correlation coefficient (RSC) = (COL4 - COL8) / (COL6 - COL8)</p></li><li><p>COL11: QualityTag: Quality tag based on thresholded RSC (codes: -2:veryLow,-1:Low,0:Medium,1:High,2:veryHigh)<br><strong>我们最关注的值是第9列和第11列。</strong><br><strong>Cross-correlation plots</strong><br>课程中的示例数据Nanog_rep1的交叉相关图</p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-4e872e4a5d5fcdbb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p></li></ul><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/tree/master/sessionV/lessons" target="_blank" rel="noopener">哈佛深度NGS数据分析课程</a><br><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/blob/master/sessionV/lessons/04_QC_cross_correlation.md" target="_blank" rel="noopener">04_ChIP-Seq Quality Assessment: Cross-correlation</a></p>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ATACseq </tag>
            
            <tag> ChIPseq </tag>
            
            <tag> QC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第3篇：用MACS2软件call peaks</title>
      <link href="/2019/08/23/8429.html"/>
      <url>/2019/08/23/8429.html</url>
      
        <content type="html"><![CDATA[<h3 id="学习目标："><a href="#学习目标：" class="headerlink" title="学习目标："></a>学习目标：</h3><ul><li>学会用MACS2 call peaks</li><li>理解MACS2 call peaks的结果</li></ul><a id="more"></a><h3 id="Peak-Calling"><a href="#Peak-Calling" class="headerlink" title="Peak Calling"></a>Peak Calling</h3><p>Peak calling即利用计算的方法找出ChIP-seq或ATAC-seq中reads富集的基因组区域。</p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-1d1cb57462bd1803.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p><p>如下图所示，比对结果的文件中reads在正负链不均匀分布，但在结合位点聚集。正负链5‘末端的reads各形成一组合，通过统计学的方法评估这些组合的分布并和对照组比较，确定这些结合位点是否是显著的。<br><img src="https://upload-images.jianshu.io/upload_images/8242255-72a8be3b74bb6659.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><blockquote><p><strong>NOTE：</strong>ChIP-seq的分析方法可以鉴定两种类型的富集模式：<strong>broad domains</strong>和<strong>narrow peaks</strong>。broad domains，如组蛋白修饰在整个基因body区域的分布；narrow peak，如转录因子的结合。narrow peak相对于broad 或者分散的marks更易被检测到。也有一些混合的结合图谱，如PolII包括narrow和broad信号。</p></blockquote><hr><h3 id="MACS2"><a href="#MACS2" class="headerlink" title="MACS2"></a>MACS2</h3><p>peaks calling 有不同的方法，MACS2是最常用的call peaks工具。 <a href="https://github.com/taoliu/MACS" target="_blank" rel="noopener">MACS全称Model-based Analysis of ChIP-Seq</a>，最初的设计是用来鉴定转录因子的结合位点，但是它也可以用于其他类型的富集方式测序。<br>MACS通过整合序列标签位置信息和方向信息提高结合位点的空间分辨率。MACS的工作流如下所示：</p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-b83dbfa6a5f77413.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p><hr><h3 id="MACS2的使用方法"><a href="#MACS2的使用方法" class="headerlink" title="MACS2的使用方法"></a>MACS2的使用方法</h3><p>MACS2的用法，call peaks的参数及输出文件的解读可以参考<a href="https://www.jianshu.com/writer#/notebooks/22796191/notes/31999734/preview" target="_blank" rel="noopener">MACS2文档学习</a>。</p><h4 id="了解相关参数："><a href="#了解相关参数：" class="headerlink" title="了解相关参数："></a>了解相关参数：</h4><p><strong>输入文件参数：</strong></p><ul><li><code>-t</code>:实验组，IP的数据文件</li><li><code>c</code>: 对照组</li><li><code>f</code>：指定输入文件的格式，默认是自动检测输入数据是什么格式，支持bam,sam,bed等</li><li><code>g</code>:有效基因组大小，由于基因组序列的重复性，基因组实际可以mapping的大小小于原始的基因组。这个参数要根据实际物种计算基因组的有效大小。软件里也给出了几个默认的-g 值：hs – 2.7e9表示人类的基因组有效大小(UCSC human hg18 assembly).<ul><li>hs: 2.7e9</li><li>mm: 1.87e9</li><li>ce: 9e7</li><li>dm: 1.2e8</li></ul></li></ul><p><strong>输出文件参数：</strong></p><ul><li><code>--outdir</code>:输出结果的存储路径</li><li><code>-n</code>:输出文件名的前缀</li><li><code>-B/--bdg</code>:输出bedgraph格式的文件，输出文件以NAME+’_treat_pileup.bdg’ for treatment data, NAME+’_control_lambda.bdg’ for local lambda values from control显示。</li></ul><p><strong>peak calling 参数</strong></p><ul><li><code>-q/--qvalue</code> 和 <code>-p/--pvalue</code><br>q value默认值是0.05，与pvalue不能同时使用。</li><li><code>--broad</code><br>peak有narrow peak和broad peak, 设置时可以call broad peak 的结果文件。</li><li><code>--broad-cutoff</code><br>和pvalue、以及qvalue相似</li><li><code>--nolambda</code>: 不要考虑在峰值候选区域的局部偏差/λ<blockquote><p>q值与峰宽有一定的联系。理想情况下，如果放宽阈值，您将简单地获得更多的peaks，但是使用MACS2放松阈值也会导致更宽的peaks。</p></blockquote></li></ul><p><strong>Shift 模型参数：</strong></p><ul><li><code>--nomodel</code><br>这个参数和extsize、shift是配套使用的，有这个参数才可以设置extsize和shift。</li><li><code>--extsize</code><br>当设置了nomodel时，MACS会用<code>--extsize</code>这个参数从5’-&gt;3’方向扩展reads修复fragments。比如说你的转录因子结合范围200bp，就设置这个参数是200。</li><li><code>--shift</code><br>当设置了–nomodel，MACS用这个参数从5’ 端移动剪切，然后用–extsize延伸，如果–shift是负值表示从3’端方向移动。建议ChIP-seq数据集这个值保持默认值为0，对于检测富集剪切位点如DNAsel数据集设置为EXTSIZE的一半。<br><strong>示例：</strong></li></ul><ol><li>想找富集剪切位点，如DNAse-seq，所有5’端的序列reads应该从两个方向延伸，如果想设置移动的窗口是200bp，参数设置如下：<br><code>--nomodel --shift -100 --extsize 200</code></li><li>对nucleosome-seq数据，用核小体大小的一半进行extsize,所以参数设置如下：<br><code>--nomodel --shift 37 --extsize 73</code></li></ol><ul><li><code>--call-summits</code><br>MACS利用此参数重新分析信号谱，解析每个peak中包含的subpeak。对相似的结合图谱，推荐使用此参数，当使用此参数时，输出的subpeak会有相同的peak边界，不同的绩点和peak summit poisitions.</li></ul><hr><h4 id="ATAC-Seq-call-peaks示例"><a href="#ATAC-Seq-call-peaks示例" class="headerlink" title="ATAC-Seq call peaks示例"></a>ATAC-Seq call peaks示例</h4><p><strong>ATAC-seq关心的是在哪切断，断点才是peak的中心，所以使用shift模型，–shift -75或-100</strong><br>对人细胞系ATAC-seq 数据call peak的参数设置如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">macs2 callpeak -t H1hesc.final.bam -n sample --<span class="built_in">shift</span> -100 --extsize 200 --nomodel -B --SPMR -g hs --outdir Macs2_out 2&gt; sample.macs2.log</span><br></pre></td></tr></table></figure></p><h3 id="MACS2输出文件解读"><a href="#MACS2输出文件解读" class="headerlink" title="MACS2输出文件解读"></a>MACS2输出文件解读</h3><ul><li><strong>NAME_peaks.xls</strong><br>包含peak信息的tab分割的文件，前几行会显示callpeak时的命令。输出信息包含：<ul><li>染色体号</li><li>peak起始位点</li><li>peak结束位点</li><li>peak区域长度</li><li>peak的峰值位点（summit position）</li><li>peak 峰值的高度（pileup height at peak summit, -log10(pvalue) for the peak summit）</li><li>peak的富集倍数（相对于random Poisson distribution with local lambda）<br><img src="https://upload-images.jianshu.io/upload_images/8242255-6f70944596087547.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br><strong>Coordinates in XLS is 1-based which is different with BED format</strong><br>XLS里的坐标和bed格式的坐标还不一样，起始坐标需要减1才与narrowPeak的起始坐标一样。</li></ul></li><li><strong>NAME_peaks.narrowPeak</strong><br>*narrowPeak文件是BED6+4格式，可以上传到UCSC浏览。输出文件每列信息分别包含：<ul><li>1；染色体号</li><li>2：peak起始位点</li><li>3：结束位点</li><li>4：peak name</li><li>5：int(-10*log10qvalue)</li><li>6 ：正负链</li><li>7：fold change</li><li>8：-log10pvalue</li><li>9：-log10qvalue</li><li>10：relative summit position to peak start（？）<br><img src="https://upload-images.jianshu.io/upload_images/8242255-836a2990e5c80537.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></li></ul></li><li><strong>NAME_summits.bed</strong><br>BED格式的文件，包含peak的summits位置，第5列是-log10pvalue。<strong>如果想找motif，推荐使用此文件。</strong><blockquote><p>Remove the beginning track line if you want to analyze it by other tools.???</p><ul><li><strong>.bdg</strong><br>bedGraph格式，可以导入UCSC或者转换为bigwig格式。两种bfg文件：treat_pileup, and control_lambda.</li></ul></blockquote></li><li><strong>NAME_peaks.broadPeak</strong><br>BED6+3格式与narrowPeak类似，只是没有第10列。</li></ul><hr><h3 id="summits-bed，narrowPeak，bdg-xls四种类型输出文件的比较："><a href="#summits-bed，narrowPeak，bdg-xls四种类型输出文件的比较：" class="headerlink" title="summits.bed，narrowPeak，bdg, xls四种类型输出文件的比较："></a>summits.bed，narrowPeak，bdg, xls四种类型输出文件的比较：</h3><p><img src="https://upload-images.jianshu.io/upload_images/8242255-539bc6f3090fc55f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><ul><li>xls文件<br>文件包含信息还是比较多的，和narrowPeak唯一不同的是peak的起始位置需要减1才是bed格式的文件，另外还包含fold_enrichment 和narrowPeak的fold change 对应，-log10pvalue,-log10qvalue,peak长度，peak 峰值位置等。</li><li>narrowPeak文件<br>和xls文件信息类似</li><li>summits.bed文件<br>包含峰的位置信息和-log10pvalue</li><li>bdg文件<br>bdg文件适合导入UCSC或IGV进行谱图可视化，或者转换为bigwig格式再进行可视化。<br><strong>为什么染色体号后面会出现其他的字符串？？？？</strong></li></ul><hr><h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><p><a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/blob/master/sessionV/lessons/03_peak_calling_macs.md" target="_blank" rel="noopener">HBC的深度NGS数据分析课程</a><br><a href="https://github.com/taoliu/MACS/" target="_blank" rel="noopener">MCAS2文档</a></p>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ATACseq </tag>
            
            <tag> ChIPseq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第2篇：原始数据的质控、比对和过滤</title>
      <link href="/2019/08/23/16037.html"/>
      <url>/2019/08/23/16037.html</url>
      
        <content type="html"><![CDATA[<p>这部分内容包括对原始测序数据质控，然后比对过滤，这是所有NGS数据处理的上游分析。</p><ul><li><strong>ATAC-Seq与其他方法不同的一点是需要过滤去除线粒体（如果是植物，还需要过滤叶绿体），因为线粒体DNA是裸露的，也可以被Tn5酶识别切割。</strong></li><li><strong>另外一点需要注意的是课程中给出的是单端比对的示例代码，如果是双端测序做相应更改即可。</strong></li></ul><h3 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h3><ul><li>用FastQC进行质控检测</li><li>用Trimmomatic进行质量过滤</li><li>用Bowtie2比对，并理解相关参数含义</li></ul><a id="more"></a><h3 id="测序reads-的质控流程示意图"><a href="#测序reads-的质控流程示意图" class="headerlink" title="测序reads 的质控流程示意图"></a>测序reads 的质控流程示意图</h3><p><img src="https://upload-images.jianshu.io/upload_images/8242255-36f81589bdad9c92.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p><h3 id="FASTQC"><a href="#FASTQC" class="headerlink" title="FASTQC"></a>FASTQC</h3><p>首先对拿到的原始测序数据（fastq或fastq.gz格式）进行质控检测，直接用<code>fastqc</code>软件，再加上<code>multiqc</code>将多个检测结果一起展示。<br>如:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fastqc -o out_dir raw_data/*gz</span><br><span class="line">multiqc *fastqc.zip --ignore *.html</span><br></pre></td></tr></table></figure></p><h3 id="Trimmomatic"><a href="#Trimmomatic" class="headerlink" title="Trimmomatic"></a>Trimmomatic</h3><p>Trimmomatic 可以用于去除接头，过滤低质量数据。相同功能的软件还有很多，如<code>trim_galore</code>、<code>cutadapt</code>等，个人比较喜欢trim_galore可以自动识别接头类型。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 课程中给出的Trimmomatic 的用法（单端测序）</span></span><br><span class="line">$ java -jar /opt/Trimmomatic-0.33/trimmomatic-0.33.jar SE \</span><br><span class="line">-threads 2 \</span><br><span class="line">-phred33 \</span><br><span class="line">H1hesc_Input_Rep1_chr12.fastq \</span><br><span class="line">../results/trimmed/H1hesc_Input_Rep1_chr12.qualtrim20.minlen36.fq \</span><br><span class="line">LEADING:20 \</span><br><span class="line">TRAILING:20 \</span><br><span class="line">MINLEN:36</span><br></pre></td></tr></table></figure></p><p><strong>Trimmomatic参数含义：</strong>可以参考<a href="https://www.jianshu.com/p/a8935adebaae" target="_blank" rel="noopener">NGS 数据过滤之 Trimmomatic 详细说明</a><br><strong>trim_galore使用示例</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trim_galore -q 20 --phred33 --stringency 3 --length 20 -e 0.1 --paired fq1 fq2  --gzip -o input_data_dir</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重新用fastqc检测进行过滤后的reads质量</span></span><br><span class="line">fastqc -o out_dir *fq.gz</span><br><span class="line">multiqc *fastqc.zip --ignore *.html</span><br></pre></td></tr></table></figure><h3 id="比对"><a href="#比对" class="headerlink" title="比对"></a>比对</h3><p>Bowtie2是一个快速精确的比对工具，基于Burrows-Wheeler Transform 构建基因组的FM 索引，比对过程所耗内存少。Bowtie2支持局部、双端、缺口比对模式，对大于50bp的reads比对效果更好（小于50bp的reads用Bowtie1）。</p><h4 id="创建Bowtie2索引"><a href="#创建Bowtie2索引" class="headerlink" title="创建Bowtie2索引"></a>创建Bowtie2索引</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bowtie2-build &lt;path_to_reference_genome.fa&gt; &lt;prefix_to_name_indexes&gt;</span><br><span class="line"><span class="comment"># Can find indexes for the entire genome on Orchestra using following path: /groups/shared_databases/igenome/Homo_sapiens/UCSC/hg19/Sequence/Bowtie2Index/</span></span><br></pre></td></tr></table></figure><h4 id="Bowtie2-比对"><a href="#Bowtie2-比对" class="headerlink" title="Bowtie2 比对"></a>Bowtie2 比对</h4><ul><li>p: 线程数</li><li>q: reads是fastq格式</li><li>x: index路径</li><li>U: fastq路径</li><li>S: 输出Sam格式文件<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 课程中给出的代码是单端比对</span></span><br><span class="line">bowtie2 -p 2 -q \</span><br><span class="line">-x ~/ngs_course/chipseq/reference_data/chr12\</span><br><span class="line">-U ~/ngs_course/chipseq/results/trimmed/H1hesc_Input_Rep1_chr12.qualtrim20.minlen36.fq \</span><br><span class="line">-S ~/ngs_course/chipseq/results/bowtie2/H1hesc_Input_Rep1_chr12_aln_unsorted.sam</span><br></pre></td></tr></table></figure></li></ul><p><strong>NOTE:</strong> 如果fastq文件是没有经过trim的，可以用局部比对执行soft-clipping，加上参数<code>--local</code></p><h3 id="过滤reads"><a href="#过滤reads" class="headerlink" title="过滤reads"></a>过滤reads</h3><p>首先将sam文件转为bam格式，再对bam文件进行排序，接着过滤唯一比对的reads，去除线粒体reads。<br><strong>转化为bam格式</strong><br>使用samtools转换格式<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">samtools view -h -S -b \</span><br><span class="line">-o H1hesc_Input_Rep1_chr12_aln_unsorted.bam \</span><br><span class="line">H1hesc_Input_Rep1_chr12_aln_unsorted.sam</span><br></pre></td></tr></table></figure></p><p><strong>对bam文件排序</strong><br>对bam文件按照基因组坐标排序，可以直接使用<code>samtools</code>，也可以使用<code>Sambamba</code>。<a href="http://lomereiter.github.io/sambamba/index.html" target="_blank" rel="noopener"><code>sambamba</code></a>快速处理bam和sam文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sambamba sort -t 2 \</span><br><span class="line">-o H1hesc_Input_Rep1_chr12_aln_sorted.bam \</span><br><span class="line">H1hesc_Input_Rep1_chr12_aln_unsorted.bam</span><br></pre></td></tr></table></figure><p><strong>过滤唯一比对的reads</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sambamba view -h -t 2 -f bam \</span><br><span class="line">-F <span class="string">"[XS] == null and not unmapped "</span> \</span><br><span class="line">H1hesc_Input_Rep1_chr12_aln_sorted.bam &gt; H1hesc_Input_Rep1_chr12_aln.bam</span><br></pre></td></tr></table></figure><p><strong>去除PCR重复</strong><br>PCR扩增和一些重复序列（如微卫星、着丝粒）会产生重复，干扰真实的富集信号，所以在call peaks前需要先去除重复，这里先用picard去除PCR重复。picard去除PCR重复时要加上参数<code>REMOVE_DUPLICATES=true</code>,否则只是标记了duplicates，并没有去除。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -jar picard-tools-1.119/MarkDuplicates.jar REMOVE_DUPLICATES=<span class="literal">true</span> I=H1hesc_Input_Rep1_chr12_aln.bam O=H1hesc_Input_Rep1_chr12_aln.dedup.bam M=H1hesc.duplicates.log</span><br></pre></td></tr></table></figure><p><strong>过滤线粒体reads</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">samtools index H1hesc_Input_Rep1_chr12_aln.dedup.bam</span><br><span class="line">samtools idxstats H1hesc_Input_Rep1_chr12_aln.dedup.bam &gt; H1hesc_Input_Rep1_chr12_aln.dedup.mitochondrial.stats</span><br><span class="line">samtools view -h H1hesc_Input_Rep1_chr12_aln.dedup.bam | grep -v <span class="string">'chrM'</span> | samtools view -bS -o H1hesc.final.bam</span><br></pre></td></tr></table></figure><p>上面给出的仅是示例代码，和参考课程不一样，实际运行需要修改相应文件。<br>此时就得到了唯一比对且已经去除过线粒体的比对文件，可以用于接下来的peaks calling。</p><h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><p>HBC的深度NGS数据分析课程：<a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/blob/master/sessionV/lessons/02_QC_and_alignment.md" target="_blank" rel="noopener">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/blob/master/sessionV/lessons/02_QC_and_alignment.md</a></p>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ATACseq </tag>
            
            <tag> QC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第1篇：ATAC-seq的背景介绍以及与ChIP-Seq的异同</title>
      <link href="/2019/08/23/57283.html"/>
      <url>/2019/08/23/57283.html</url>
      
        <content type="html"><![CDATA[<h3 id="ATAC-Seq简介"><a href="#ATAC-Seq简介" class="headerlink" title="ATAC-Seq简介"></a>ATAC-Seq简介</h3><p><strong>ATAC-seq（Assay for Transposase-Accessible Chromatin with high throughput sequencing）</strong> 是2013年由斯坦福大学<a href="http://greenleaf.stanford.edu/index.html" target="_blank" rel="noopener">William J. Greenleaf</a>和<a href="http://changlab.stanford.edu/index.html" target="_blank" rel="noopener">Howard Y. Chang</a>实验室开发的用于研究染色质可及性（通常也理解为染色质的开放性）的方法， 原理是通过转座酶Tn5容易结合在开放染色质的特性，然后对Tn5酶捕获到的DNA序列进行测序。</p><p>真核生物的核DNA并不是裸露的，而是与组蛋白结合形成染色体的基本结构单位核小体，核小体再经逐步的压缩折叠最终形成染色体高级结构（如人的DNA链完整展开约2m长，经过这样的折叠就变成了纳米级至微米级的染色质结构而可以储存在小小的细胞核）。而DNA的复制转录是需要将DNA的紧密结构打开，从而允许一些调控因子结合（转录因子或其他调控因子）。这部分打开的染色质，就叫开放染色质，打开的染色质允许其他调控因子结合的特性称为染色质的可及性（chromatin accessibility）。因此，认为染色质的可及性与转录调控密切相关。<br>开放染色质的研究方法有ATAC-seq以及传统的DNase-Seq及FAIRE-seq等，ATAC-Seq由于所需细胞量少，实验简单，可以在全基因组范围内检测染色质的开放状态，目前已经成为研究染色质开放性的首选技术方法。</p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-a18ab4a1ad419cdf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="fig"></p><p><a href="https://www.ncbi.nlm.nih.gov/pubmed/24097267#" title="Nature methods." target="_blank" rel="noopener">Nat Methods, 2013</a>. <strong>doi: 10.1038/nmeth.2688. Epub 2013 Oct.</strong></p><a id="more"></a><h3 id="ATAC-Seq与ChIP-Seq的异同"><a href="#ATAC-Seq与ChIP-Seq的异同" class="headerlink" title="ATAC-Seq与ChIP-Seq的异同"></a>ATAC-Seq与ChIP-Seq的异同</h3><p>ATAC-Seq与ChIP-Seq的不同的是ATAC-Seq是全基因组范围内检测染色质的开放程度，可以得到全基因组范围内的蛋白质可能结合的位点信息，一般用于不知道特定的转录因子，用此方法与其他方法结合筛查感兴趣的特定调控因子；但是ChIP-Seq是明确知道感兴趣的转录因子是什么，根据感兴趣的转录因子设计抗体去做ChIP实验拉DNA，验证感兴趣的转录因子是否与DNA存在相互作用。ATAC-Seq、ChIP-Seq、Dnase-Seq、MNase-Seq、FAIRE-Seq整体的分析思路一致，找到富集区域，对富集区域进行功能分析。</p><ul><li><p><strong>ChIP-Seq</strong>是揭示特定转录因子或蛋白复合物的结合区域，实际是研究DNA和蛋白质的相互作用，利用抗体将蛋白质和DNA一起富集，并对富集到的DNA进行测序。</p></li><li><p><strong>DNase-Seq、ATAC-Seq、FAIRE-Seq</strong>都是用来研究开放染色质区域。DNase-Seq是用的DNase I内切酶识别开放染色质区域，而ATAC-seq是用的Tn5转座酶，随后进行富集和扩增；FAIRE-Seq是先进行超声裂解，然后用酚-氯仿富集。</p></li><li><p><strong>MNase-Seq</strong>是用来鉴定核小体区域。</p></li></ul><ul><li><img src="https://upload-images.jianshu.io/upload_images/8242255-333e68ef5995083f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></li></ul><p><strong>翻译部分</strong><br>下面这一部分是对HBC课程中ChIP-Seq Introduction这一节的介绍，主要包括的ChIP-Seq的实验设计和分析方法总体思路。原文链接：<a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/blob/master/sessionV/lessons/01_Intro_chipseq_and_setup.md。" target="_blank" rel="noopener">https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/blob/master/sessionV/lessons/01_Intro_chipseq_and_setup.md。</a></p><h2 id="ChIP-Seq-Introduction"><a href="#ChIP-Seq-Introduction" class="headerlink" title="ChIP-Seq Introduction"></a>ChIP-Seq Introduction</h2><h3 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h3><ul><li><strong>理解ChIP-Seq的实验设计</strong><h3 id="ChIP-Seq简介"><a href="#ChIP-Seq简介" class="headerlink" title="ChIP-Seq简介"></a>ChIP-Seq简介</h3>ChIP实验（Chromatin immunoprecipitation）即染色质免疫沉淀，根据DNA与蛋白质相互作用的原理，分离富集与感兴趣的蛋白相互作用的DNA。ChIP-Seq即对分离得到的DNA扩增测序，然后通过分析得到DNA的富集区域也称为peaks，同时可以鉴定过表达的序列motif以及进行功能注释分析。</li></ul><p><img src="https://upload-images.jianshu.io/upload_images/8242255-6c4c141da0780fd4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="ChIP-Seq Overall"></p><p>下面这一部分将会介绍ChIP-Seq数据分析的整个流程，从实验设计到产生原始的测序reads，以及到最后的功能富集分析和motif查找。</p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-5a3c0ba8ea4c59ad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><h3 id="实验设计和文库构建"><a href="#实验设计和文库构建" class="headerlink" title="实验设计和文库构建"></a>实验设计和文库构建</h3><p>文库构建包括以下5步骤：</p><ul><li>蛋白质与DNA的交联</li><li>超声打断DNA链</li><li>加附有抗体的磁珠用于免疫沉淀</li><li>解交联，纯化DNA</li><li>DNA片段大小选择和PCR扩增</li></ul><p>富集到的DNA片段只有一部分是真实的信号（感兴趣的蛋白结合的DNA区域），这个比例取决于<strong>number of active binding sites, the number of starting genomes, and the efficiency of the IP.</strong></p><p>ChIP-Seq富集序列存在以下特点：</p><ul><li>开放染色质区域比紧密区域更易打断；</li><li>重复序列会出现似乎被富集的现象</li><li>序列在整个基因组上不均匀分布</li></ul><p>因此，ChIP-Seq需要有合适的对照组，对照样本需要满足以下其中一个条件：</p><ul><li>没有IP（input DAN）</li><li>没有抗体 (“mock IP”)</li><li>没有特定的抗体 (IgG “mock IP”)</li></ul><p><img src="https://upload-images.jianshu.io/upload_images/8242255-3258f63385c35669.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-57ffd903f1fc2766.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><h3 id="示例数据介绍"><a href="#示例数据介绍" class="headerlink" title="示例数据介绍"></a>示例数据介绍</h3><p>所用到的示例数据是来自于人类胚胎干细胞系（h1-ESC）中<strong>Nanog和Pou5f1（Oct4）</strong>两个转录因子的结合图谱。这两个转录因子的功能涉及干细胞的多能性，该研究的目标之一是探究这两个转录因子在转录调控中单独和相互的调控作用。<br>两组重复，每组重复包括3个实验样本信息，共6个样本，数据分析中只用到了12号染色体的信息。<br>Nanog IP<br>Pou5f1 IP<br>Control input DNA</p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-2a3a493c405b2b06.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><h3 id="分析流程"><a href="#分析流程" class="headerlink" title="分析流程"></a>分析流程</h3><p>下面这幅图给出了整个分析流程，和每一步需要的数据格式，后面会展开介绍。</p><h3 id="分析环境配置"><a href="#分析环境配置" class="headerlink" title="分析环境配置"></a>分析环境配置</h3><p>这个课程提供了示例数据和分析代码，可以参考<a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/blob/master/sessionV/lessons/orchestra_mounting.md" target="_blank" rel="noopener">这里</a>连接他们的服务器，我没有连接成功，不知道是不是打开方式不对，大家可以尝试下，如果连接成功，这一部分就是配置服务器的环境，准备数据；如果也连接不上可以用自己的数据或者下载公共数据。</p><p><img src="https://upload-images.jianshu.io/upload_images/8242255-42c0586d8549bb34.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" style="zoom:50%"></p><h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><p><a href="https://zhuanlan.zhihu.com/p/31924355" target="_blank" rel="noopener">ATAC-seq：染色质开放性测序技术</a><br><a href="https://www.nature.com/articles/nrg3788#f1" target="_blank" rel="noopener">Clifford A. et al. Nature review, 2014</a><br>HBC课程V : <a href="https://github.com/hbctraining/In-depth-NGS-Data-Analysis-Course/blob/master/sessionV/lessons/01_Intro_chipseq_and_setup.md" target="_blank" rel="noopener">01-Introduction to ChIP-Seq</a></p>]]></content>
      
      
      <categories>
          
          <category> Data Sciences </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ATACseq </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
